{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x1:', array([ 0.1227,  0.3914,  0.7725,  0.8342,  0.5084,  0.9983,  0.6643,\n",
      "        0.0954,  0.6949,  0.6075,  0.3717,  0.0193,  0.9314,  0.2206,\n",
      "        0.0903,  0.5466,  0.4331,  0.5293,  0.8955,  0.0701,  0.0771,\n",
      "        0.1972,  0.6405,  0.3203,  0.103 ,  0.5605,  0.4288,  0.7101,\n",
      "        0.6575,  0.9498,  0.555 ,  0.0947,  0.4293,  0.31  ,  0.7297,\n",
      "        0.1973,  0.1571,  0.2272,  0.2099,  0.3972,  0.0033,  0.6441,\n",
      "        0.5549,  0.9193,  0.5341,  0.1555,  0.1839,  0.9949,  0.7918,\n",
      "        0.4088,  0.2247,  0.3901,  0.4309,  0.0732,  0.8077,  0.0854,\n",
      "        0.8955,  0.8794,  0.1094,  0.0726,  0.4377,  0.889 ,  0.5791,\n",
      "        0.9721,  0.5719,  0.3156,  0.8065,  0.4777,  0.6264,  0.2117,\n",
      "        0.042 ,  0.0916,  0.6035,  0.6354,  0.4102,  0.695 ,  0.2153,\n",
      "        0.0768,  0.2356,  0.1591,  0.7171,  0.9988,  0.3936,  0.0201,\n",
      "        0.6295,  0.1771,  0.5888,  0.5302,  0.3434,  0.7154,  0.3506,\n",
      "        0.5432,  0.4687,  0.013 ,  0.1311,  0.697 ,  0.3996,  0.2208,\n",
      "        0.1119,  0.4317]))\n",
      "('x2:', array([ 0.299 ,  0.6392,  0.0826,  0.0823,  0.8025,  0.7404,  0.3861,\n",
      "        0.986 ,  0.605 ,  0.3618,  0.761 ,  0.7192,  0.5181,  0.1091,\n",
      "        0.1085,  0.2028,  0.7049,  0.688 ,  0.8477,  0.6176,  0.7883,\n",
      "        0.6273,  0.1157,  0.2305,  0.314 ,  0.3131,  0.9205,  0.0582,\n",
      "        0.6994,  0.5013,  0.5152,  0.4509,  0.8343,  0.473 ,  0.7288,\n",
      "        0.4028,  0.116 ,  0.3902,  0.5191,  0.7047,  0.0438,  0.228 ,\n",
      "        0.8297,  0.473 ,  0.3764,  0.4256,  0.5615,  0.4739,  0.1968,\n",
      "        0.8426,  0.5714,  0.3748,  0.0957,  0.3781,  0.0761,  0.1927,\n",
      "        0.9469,  0.8077,  0.1245,  0.9662,  0.603 ,  0.6766,  0.2427,\n",
      "        0.9348,  0.5331,  0.0088,  0.9705,  0.8802,  0.6473,  0.0892,\n",
      "        0.6419,  0.0732,  0.2997,  0.6253,  0.0288,  0.1586,  0.7286,\n",
      "        0.5323,  0.1967,  0.9183,  0.2153,  0.3529,  0.1582,  0.3701,\n",
      "        0.7371,  0.03  ,  0.5609,  0.2182,  0.9182,  0.5181,  0.1568,\n",
      "        0.8303,  0.7515,  0.3437,  0.6214,  0.6114,  0.609 ,  0.596 ,\n",
      "        0.0293,  0.3873]))\n",
      "('z:', array([ 1.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
      "        0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
      "        1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        0.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,\n",
      "        0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsolution from part1 is:\\nw1:\\t-2.04424259514\\nw2:\\t3.99686016866\\nb:\\t-0.924290811868\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reference: http://cs229.stanford.edu/notes/cs229-notes1.pdf\n",
    "import numpy as np\n",
    "#import matplotlib as ml\n",
    "#import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "\n",
    "data = np.loadtxt('assign1_data.txt')\n",
    "#print data\n",
    "\n",
    "x1 = data[:, 0]\n",
    "print (\"x1:\", x1)\n",
    "\n",
    "x2 = data[:, 1]\n",
    "print (\"x2:\", x2)\n",
    "\n",
    "z = data[:, 3]\n",
    "print (\"z:\", z)\n",
    "\n",
    "'''\n",
    "solution from part1 is:\n",
    "w1:\t-2.04424259514\n",
    "w2:\t3.99686016866\n",
    "b:\t-0.924290811868\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_error_epoch(accuracy_arr, lr, batch_size):\n",
    "    accuracy_arr_y = np.array(accuracy_arr)\n",
    "    epochs = []\n",
    "    for i in range(len(accuracy_arr)):\n",
    "        epochs.append(i)\n",
    "    epochs_x = np.array(epochs)\n",
    "    plt.plot(epochs_x, accuracy_arr_y)\n",
    "    title = ''\n",
    "    title += 'lr:'\n",
    "    title += str(lr)\n",
    "    title += ' batch_size:'\n",
    "    title += str(batch_size)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accurary')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation(x): # use sigmoid as activation function\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create method to train and get result with different settings like online, minibatch, batch and learning rate\n",
    "def train_and_get_result(x1, x2, lr, batch_size):\n",
    "    \n",
    "    if batch_size > 75:\n",
    "        batch_size = 75\n",
    "        \n",
    "    accuracy_arr = []\n",
    "    \n",
    "    w1 = random.random() * 3\n",
    "    w2 = random.random() * 3\n",
    "    b = random.random() * 3\n",
    "    \n",
    "    print \"random initial w1:\\t\", w1\n",
    "    print \"random initial w2:\\t\", w2\n",
    "    print \"random initial b:\\t\", b\n",
    "    \n",
    "    epoch = 0\n",
    "    # training set size : validation set size = 3 : 1\n",
    "    training_set_index = 0\n",
    "    size = len(x1)\n",
    "    validation_set_index = 0\n",
    "    validation_set_index_step = size / 4\n",
    "    pre_validation_error = sys.maxint\n",
    "    curr_validation_error = sys.maxint - 1\n",
    "    while curr_validation_error >= 1 and (pre_validation_error >= curr_validation_error or curr_validation_error <= 0): # early stopping when the validation error is greater than its previous one\n",
    "    #while True:\n",
    "\n",
    "        validation_set_index += validation_set_index_step\n",
    "        validation_set_index %= size\n",
    "\n",
    "        x1_validation = x1[validation_set_index : validation_set_index + validation_set_index_step]\n",
    "        x2_validation = x2[validation_set_index : validation_set_index + validation_set_index_step]\n",
    "        z_validation = z[validation_set_index : validation_set_index + validation_set_index_step]\n",
    "\n",
    "        # training\n",
    "        i = 1\n",
    "        for x1i, x2i, zi in zip(x1, x2, z):\n",
    "            sum_error_w1 = 0\n",
    "            sum_error_w2 = 0\n",
    "            sum_error_b = 0\n",
    "            if x1i not in zip(x1_validation) and x2i not in zip(x2_validation) and zi not in zip(z_validation):\n",
    "                error = zi - activation(x1i * w1 + x2i * w2 + b)\n",
    "                sum_error_w1 += error * x1i\n",
    "                sum_error_w2 += error * x2i\n",
    "                sum_error_b += error\n",
    "                if i >= batch_size: # only update weights after one batch\n",
    "                    w1 = w1 + lr * sum_error_w1\n",
    "                    w2 = w2 + lr * sum_error_w2\n",
    "                    b = b + lr * sum_error_b\n",
    "                    sum_error_w1 = 0\n",
    "                    sum_error_w2 = 0\n",
    "                    sum_error_b = 0\n",
    "                    i = 1\n",
    "                    continue\n",
    "                i += 1\n",
    "\n",
    "        if epoch >= 4 and epoch % 4 == 0:\n",
    "            pre_validation_error = curr_validation_error\n",
    "            if epoch % 100 == 0: # print only every 100 epochs\n",
    "                print \"epoch:\\t\", epoch, \"\\t curr_validation_error:\\t\", curr_validation_error\n",
    "            curr_validation_error = 0\n",
    "\n",
    "        # validation\n",
    "        for x1i, x2i, zi in zip(x1_validation, x2_validation, z_validation):\n",
    "            curr_validation_error += abs(zi - (x1i * w1 + x2i * w2 + b))\n",
    "            \n",
    "        # get error from the entire set for later plotting\n",
    "        accuracy = 0\n",
    "        for x1i, x2i, yi in zip(x1, x2, z):\n",
    "            if zi == activation(x1i * w1 + x2i * w2 + b):\n",
    "                accurary += 1\n",
    "        accuracy /= len(x1)\n",
    "        accuracy_arr.append(accurary)\n",
    "        epoch += 1\n",
    "\n",
    "    plot_error_epoch(accurary, lr, batch_size)\n",
    "    print \"Result: pre_validation_error:\\t\", pre_validation_error, \"curr_validation_error:\\t\", curr_validation_error\n",
    "    print \"Result: w1:\\t\", w1, \"\\tw2:\\t\", w2, \"\\tb:\\t\", b, \"\\tnum of epoch:\\t\", epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# online\n",
    "# learning rate lr = 0.001\n",
    "train_and_get_result(x1, x2, lr = 0.001, batch_size = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
