{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reference: http://cs229.stanford.edu/notes/cs229-notes1.pdf\n",
    "import numpy as np\n",
    "#import matplotlib as ml\n",
    "#import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "\n",
    "data = np.loadtxt('assign1_data.txt')\n",
    "#print data\n",
    "\n",
    "x1 = data[:, 0]\n",
    "print (\"x1:\", x1)\n",
    "\n",
    "x2 = data[:, 1]\n",
    "print (\"x2:\", x2)\n",
    "\n",
    "z = data[:, 3]\n",
    "print (\"z:\", z)\n",
    "\n",
    "'''\n",
    "solution from part1 is:\n",
    "w1:\t-2.04424259514\n",
    "w2:\t3.99686016866\n",
    "b:\t-0.924290811868\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_error_epoch(errors, lr, batch_size):\n",
    "    errors_y = np.array(errors)\n",
    "    epochs = []\n",
    "    for i in range(len(errors)):\n",
    "        epochs.append(i)\n",
    "    epochs_x = np.array(epochs)\n",
    "    plt.plot(epochs_x, errors_y)\n",
    "    title = ''\n",
    "    title += 'lr:'\n",
    "    title += lr\n",
    "    title += ' batch_size:'\n",
    "    title += batch_size\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create method to train and get result with different settings like online, minibatch, batch and learning rate\n",
    "def train_and_get_result(x1, x2, lr, batch_size):\n",
    "    \n",
    "    if batch_size > 75:\n",
    "        batch_size = 75\n",
    "        \n",
    "    errors = []\n",
    "    \n",
    "    w1 = random.random() * 3\n",
    "    w2 = random.random() * 3\n",
    "    b = random.random() * 3\n",
    "    \n",
    "    print \"random initial w1:\\t\", w1\n",
    "    print \"random initial w2:\\t\", w2\n",
    "    print \"random initial b:\\t\", b\n",
    "    \n",
    "    epoch = 0\n",
    "    # training set size : validation set size = 3 : 1\n",
    "    training_set_index = 0\n",
    "    size = len(x1)\n",
    "    validation_set_index = 0\n",
    "    validation_set_index_step = size / 4\n",
    "    pre_validation_error = sys.maxint\n",
    "    curr_validation_error = sys.maxint - 1\n",
    "    while curr_validation_error >= 1 and (pre_validation_error >= curr_validation_error or curr_validation_error <= 0): # early stopping when the validation error is greater than its previous one\n",
    "    #while True:\n",
    "\n",
    "        validation_set_index += validation_set_index_step\n",
    "        validation_set_index %= size\n",
    "\n",
    "        x1_validation = x1[validation_set_index : validation_set_index + validation_set_index_step]\n",
    "        x2_validation = x2[validation_set_index : validation_set_index + validation_set_index_step]\n",
    "        y_validation = y[validation_set_index : validation_set_index + validation_set_index_step]\n",
    "\n",
    "        # training\n",
    "        i = 1\n",
    "        for x1i, x2i, yi in zip(x1, x2, y):\n",
    "            sum_error_w1 = 0\n",
    "            sum_error_w2 = 0\n",
    "            sum_error_b = 0\n",
    "            if x1i not in zip(x1_validation) and x2i not in zip(x2_validation) and yi not in zip(y_validation):\n",
    "                error = yi - (x1i * w1 + x2i * w2 + b)\n",
    "                sum_error_w1 += error * x1i\n",
    "                sum_error_w2 += error * x2i\n",
    "                sum_error_b += error\n",
    "                if i >= batch_size: # only update weights after one batch\n",
    "                    w1 = w1 + lr * sum_error_w1\n",
    "                    w2 = w2 + lr * sum_error_w2\n",
    "                    b = b + lr * sum_error_b\n",
    "                    sum_error_w1 = 0\n",
    "                    sum_error_w2 = 0\n",
    "                    sum_error_b = 0\n",
    "                    i = 1\n",
    "                    continue\n",
    "                i += 1\n",
    "\n",
    "        if epoch >= 4 and epoch % 4 == 0:\n",
    "            pre_validation_error = curr_validation_error\n",
    "            if epoch % 100 == 0: # print only every 20 epochs\n",
    "                print \"epoch:\\t\", epoch, \"\\t curr_validation_error:\\t\", curr_validation_error\n",
    "            curr_validation_error = 0\n",
    "\n",
    "        # validation\n",
    "        for x1i, x2i, yi in zip(x1_validation, x2_validation, y_validation):\n",
    "            curr_validation_error += abs(yi - (x1i * w1 + x2i * w2 + b))\n",
    "            \n",
    "        # get error from the entire set for later plotting\n",
    "        error = 0\n",
    "        for x1i, x2i, yi in zip(x1, x2, y):\n",
    "            error += yi - (x1i * w1 + x2i * w2 + b)\n",
    "        errors.append(error)\n",
    "        epoch += 1\n",
    "\n",
    "    plot_error_epoch(errors)\n",
    "    print \"Result: pre_validation_error:\\t\", pre_validation_error, \"curr_validation_error:\\t\", curr_validation_error\n",
    "    print \"Result: w1:\\t\", w1, \"\\tw2:\\t\", w2, \"\\tb:\\t\", b, \"\\tnum of epoch:\\t\", epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
