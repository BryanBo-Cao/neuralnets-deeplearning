{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [[  2.31800000e+01   2.72720000e+01   4.26000000e+02   7.21250000e+02\n",
      "    4.79298818e-03]\n",
      " [  2.31500000e+01   2.72675000e+01   4.29500000e+02   7.14000000e+02\n",
      "    4.78344095e-03]\n",
      " [  2.31500000e+01   2.72450000e+01   4.26000000e+02   7.13500000e+02\n",
      "    4.77946352e-03]\n",
      " ..., \n",
      " [  2.11000000e+01   3.60950000e+01   4.33000000e+02   7.98500000e+02\n",
      "    5.59563902e-03]\n",
      " [  2.11000000e+01   3.62600000e+01   4.33000000e+02   8.20333333e+02\n",
      "    5.62144937e-03]\n",
      " [  2.11000000e+01   3.62000000e+01   4.47000000e+02   8.21000000e+02\n",
      "    5.61206354e-03]]\n",
      "np.shape(train_data):  (8143, 8)\n",
      "t:  [ 23.18  23.15  23.15 ...,  21.1   21.1   21.1 ]\n",
      "hu:  [ 27.272   27.2675  27.245  ...,  36.095   36.26    36.2   ]\n",
      "lt:  [ 426.   429.5  426.  ...,  433.   433.   447. ]\n",
      "co2:  [ 721.25        714.          713.5        ...,  798.5         820.33333333\n",
      "  821.        ]\n",
      "hu_r:  [ 0.00479299  0.00478344  0.00477946 ...,  0.00559564  0.00562145\n",
      "  0.00561206]\n",
      "o:  [ 1.  1.  1. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "train_data = np.genfromtxt('../data/assign2_train_data.txt', delimiter=',')\n",
    "#print \"train_data:\", train_data\n",
    "\n",
    "t = train_data[:,2]\n",
    "hu = train_data[:,3]\n",
    "lt = train_data[:,4]\n",
    "co2 = train_data[:,5]\n",
    "hu_r = train_data[:,6]\n",
    "\n",
    "o = train_data[:,7]\n",
    "\n",
    "#data\n",
    "data = np.column_stack((t, hu, lt, co2, hu_r))\n",
    "print \"data:\", data\n",
    "\n",
    "print \"np.shape(train_data): \", np.shape(train_data)\n",
    "#print \"np.shape(t): \", np.shape(t)\n",
    "\n",
    "print \"t: \", t\n",
    "print \"hu: \", hu\n",
    "print \"lt: \", lt\n",
    "print \"co2: \", co2\n",
    "print \"hu_r: \", hu_r\n",
    "print \"o: \", o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_data: [[ 1.          0.47053302  0.27549041  0.190933    0.55731842]\n",
      " [ 0.99282297  0.47033188  0.27775383  0.18644592  0.55480723]\n",
      " [ 0.99282297  0.46932618  0.27549041  0.18613647  0.55376106]\n",
      " ..., \n",
      " [ 0.50239234  0.86490111  0.28001725  0.23874362  0.76843752]\n",
      " [ 0.50239234  0.87227623  0.28001725  0.25225643  0.77522635]\n",
      " [ 0.50239234  0.86959437  0.28907092  0.25266904  0.77275762]]\n"
     ]
    }
   ],
   "source": [
    "#normalize inputs\n",
    "\n",
    "#normalize t\n",
    "t_min = np.min(t)\n",
    "t_max = np.max(t)\n",
    "d_t = t_max - t_min\n",
    "#normalized t: n_t\n",
    "n_t = []\n",
    "for each in t:\n",
    "    n_t.append((each - t_min) / d_t)\n",
    "\n",
    "#normalize hu\n",
    "hu_min = np.min(hu)\n",
    "hu_max = np.max(hu)\n",
    "d_hu = hu_max - hu_min\n",
    "#normalized h: n_hu\n",
    "n_hu = []\n",
    "for each in hu:\n",
    "    n_hu.append((each - hu_min) / d_hu)\n",
    "\n",
    "#normalize lt\n",
    "lt_min = np.min(lt)\n",
    "lt_max = np.max(lt)\n",
    "d_lt = lt_max - lt_min\n",
    "#normalized lt: n_lt\n",
    "n_lt = []\n",
    "for each in lt:\n",
    "    n_lt.append((each - lt_min) / d_lt)\n",
    "\n",
    "#normalize co2\n",
    "co2_min = np.min(co2)\n",
    "co2_max = np.max(co2)\n",
    "d_co2 = co2_max - co2_min\n",
    "#normalized co2: n_co2\n",
    "n_co2 = []\n",
    "for each in co2:\n",
    "    n_co2.append((each - co2_min) / d_co2)\n",
    "\n",
    "#normalize hu_r\n",
    "hu_r_min = np.min(hu_r)\n",
    "hu_r_max = np.max(hu_r)\n",
    "d_hu_r = hu_r_max - hu_r_min\n",
    "#normalized hu_r: n_hu_r\n",
    "n_hu_r = []\n",
    "for each in hu_r:\n",
    "    n_hu_r.append((each - hu_r_min) / d_hu_r)\n",
    "    \n",
    "#normalized data: n_data\n",
    "n_data = np.column_stack((n_t, n_hu, n_lt, n_co2, n_hu_r))\n",
    "print \"n_data:\", n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ws:  [0.2652590412732072, 0.9402782070231802, 0.07155471783377487, 0.31451503494097655, 0.36015880670712586, 0.12481358400852471]\n"
     ]
    }
   ],
   "source": [
    "def initialize_weights():\n",
    "    w_t = random.random()\n",
    "    w_hu = random.random()\n",
    "    w_lt = random.random()\n",
    "    w_co2 = random.random()\n",
    "    w_hu_r = random.random()\n",
    "    b = random.random()\n",
    "\n",
    "    #weights\n",
    "    ws = [w_t, w_hu, w_lt, w_co2, w_hu_r, b]\n",
    "    return ws\n",
    "\n",
    "ws = initialize_weights()\n",
    "print \"ws: \", ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def activation(x): # use sigmoid as activation function\n",
    "    a = sigmoid(x)\n",
    "    if a >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def perceptron(ins, ws):\n",
    "    sum = 0\n",
    "    for x, w in zip(ins, ws):\n",
    "        sum += x * w\n",
    "    return activation(sum)\n",
    "\n",
    "# lr - learning rate\n",
    "# bs - batch size\n",
    "def train(n_data, lr, bs):\n",
    "    print \"Training starts: len of data:\", len(n_data)\n",
    "    \n",
    "    accuracies = []\n",
    "    epoch = 0\n",
    "    while epoch <= 25000:\n",
    "        # train\n",
    "        i = 0\n",
    "        for (n_t_i, n_hu_i, n_lt_i, n_co2_i, n_hu_r_i, o_i) in zip(n_t, n_hu, n_lt, n_co2, n_hu_r, o):\n",
    "            sum_error_w_t = 0\n",
    "            sum_error_w_hu = 0\n",
    "            sum_error_w_lt = 0\n",
    "            sum_error_w_co2 = 0\n",
    "            sum_error_w_hu_r = 0\n",
    "            sum_error_b = 0\n",
    "            \n",
    "            error = o_i - (n_t_i * ws[0] + n_hu_i * ws[1] + n_lt_i * ws[2] + n_co2_i * ws[3] + n_hu_r_i * ws[4] + ws[5])\n",
    "            sum_error_w_t += error * n_t_i\n",
    "            sum_error_w_hu += error * n_hu_i\n",
    "            sum_error_w_lt += error * n_lt_i\n",
    "            sum_error_w_co2 += error * n_co2_i\n",
    "            sum_error_w_hu_r += error * n_hu_r_i\n",
    "            sum_error_b += error\n",
    "            \n",
    "            if i >= bs: # only update weights after one batch size\n",
    "                ws[0] += lr * sum_error_w_t\n",
    "                ws[1] += lr * sum_error_w_hu\n",
    "                ws[2] += lr * sum_error_w_lt\n",
    "                ws[3] += lr * sum_error_w_co2\n",
    "                ws[4] += lr * sum_error_w_hu_r\n",
    "                ws[5] += lr * sum_error_b\n",
    "                sum_error_w_t = 0\n",
    "                sum_error_w_hu = 0\n",
    "                sum_error_w_lt = 0\n",
    "                sum_error_w_co2 = 0\n",
    "                sum_error_w_hu_r = 0\n",
    "                sum_error_b = 0\n",
    "                i = 1\n",
    "                continue\n",
    "            \n",
    "            #test every epoch\n",
    "            accuracy = get_one_feedforward_accuracy(n_data, ws, o)\n",
    "            accuracies.append(accuracy)\n",
    "            print \"epoch:\", epoch, \" accuracy:\",accuracy\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        # count \n",
    "        epoch += 1\n",
    "    print \"Training ends.\"\n",
    "        \n",
    "def get_one_feedforward_accuracy(n_data, ws, o):\n",
    "    \n",
    "    #calculate accuracy\n",
    "    #outputs\n",
    "    os = []\n",
    "    for each in zip(n_data):\n",
    "        for ins in each:\n",
    "            os.append(perceptron(ins, ws))\n",
    "            \n",
    "    #count correct output number\n",
    "    correct_cnt = 0\n",
    "    for o_i, os_i in zip(o, os):\n",
    "        if (o_i == os_i):\n",
    "            correct_cnt += 1\n",
    "    accuracy = float(correct_cnt) / float(len(o))\n",
    "    ##calculate accuracy\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts: len of data: 8143\n",
      "epoch: 0  accuracy: 0.610217364608\n",
      "epoch: 1  accuracy: 0.610217364608\n",
      "epoch: 2  accuracy: 0.610217364608\n",
      "epoch: 3  accuracy: 0.610462974334\n",
      "epoch: 4  accuracy: 0.610585779197\n",
      "epoch: 5  accuracy: 0.610585779197\n",
      "epoch: 6  accuracy: 0.610462974334\n",
      "epoch: 7  accuracy: 0.610585779197\n",
      "epoch: 8  accuracy: 0.610462974334\n",
      "epoch: 9  accuracy: 0.610462974334\n",
      "epoch: 10  accuracy: 0.610340169471\n",
      "epoch: 11  accuracy: 0.610217364608\n",
      "epoch: 12  accuracy: 0.610340169471\n",
      "epoch: 13  accuracy: 0.610585779197\n",
      "epoch: 14  accuracy: 0.61070858406\n",
      "epoch: 15  accuracy: 0.61070858406\n",
      "epoch: 16  accuracy: 0.61070858406\n",
      "epoch: 17  accuracy: 0.610831388923\n",
      "epoch: 18  accuracy: 0.610954193786\n",
      "epoch: 19  accuracy: 0.610831388923\n",
      "epoch: 20  accuracy: 0.610585779197\n",
      "epoch: 21  accuracy: 0.61070858406\n",
      "epoch: 22  accuracy: 0.610954193786\n",
      "epoch: 23  accuracy: 0.610831388923\n",
      "epoch: 24  accuracy: 0.610831388923\n",
      "epoch: 25  accuracy: 0.610831388923\n",
      "epoch: 26  accuracy: 0.610954193786\n",
      "epoch: 27  accuracy: 0.611076998649\n",
      "epoch: 28  accuracy: 0.611076998649\n",
      "epoch: 29  accuracy: 0.610954193786\n",
      "epoch: 30  accuracy: 0.611076998649\n",
      "epoch: 31  accuracy: 0.611076998649\n",
      "epoch: 32  accuracy: 0.611076998649\n",
      "epoch: 33  accuracy: 0.611076998649\n",
      "epoch: 34  accuracy: 0.611076998649\n",
      "epoch: 35  accuracy: 0.611076998649\n",
      "epoch: 36  accuracy: 0.611076998649\n",
      "epoch: 37  accuracy: 0.611076998649\n",
      "epoch: 38  accuracy: 0.610462974334\n",
      "epoch: 39  accuracy: 0.610585779197\n",
      "epoch: 40  accuracy: 0.61070858406\n",
      "epoch: 41  accuracy: 0.610831388923\n",
      "epoch: 42  accuracy: 0.610831388923\n",
      "epoch: 43  accuracy: 0.610831388923\n",
      "epoch: 44  accuracy: 0.610954193786\n",
      "epoch: 45  accuracy: 0.610954193786\n",
      "epoch: 46  accuracy: 0.610954193786\n",
      "epoch: 47  accuracy: 0.610831388923\n",
      "epoch: 48  accuracy: 0.610831388923\n",
      "epoch: 49  accuracy: 0.610954193786\n",
      "epoch: 50  accuracy: 0.611076998649\n",
      "epoch: 51  accuracy: 0.611076998649\n",
      "epoch: 52  accuracy: 0.610954193786\n",
      "epoch: 53  accuracy: 0.610831388923\n",
      "epoch: 54  accuracy: 0.610831388923\n",
      "epoch: 55  accuracy: 0.61070858406\n",
      "epoch: 56  accuracy: 0.610954193786\n",
      "epoch: 57  accuracy: 0.610954193786\n",
      "epoch: 58  accuracy: 0.610954193786\n",
      "epoch: 59  accuracy: 0.610831388923\n",
      "epoch: 60  accuracy: 0.610585779197\n",
      "epoch: 61  accuracy: 0.610462974334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-fc998d9a317d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-0860a08cf522>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_data, lr, bs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# only update weights after one batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum_error_w_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum_error_w_hu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum_error_w_lt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(n_data, lr = 0.0001, bs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
