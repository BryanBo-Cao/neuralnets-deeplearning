{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 10\n",
    "N = 10\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.7103, Training Accuracy= 0.500\n",
      "Epoch: 10, Loss= 0.6984, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.6962, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.6951, Training Accuracy= 0.503\n",
      "Epoch: 40, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 0.6939, Training Accuracy= 0.505\n",
      "Epoch: 60, Loss= 0.6936, Training Accuracy= 0.516\n",
      "Epoch: 70, Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 80, Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 90, Loss= 0.6929, Training Accuracy= 0.517\n",
      "Epoch: 100, Loss= 0.6927, Training Accuracy= 0.518\n",
      "Epoch: 110, Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 120, Loss= 0.6925, Training Accuracy= 0.517\n",
      "Epoch: 130, Loss= 0.6923, Training Accuracy= 0.521\n",
      "Epoch: 140, Loss= 0.6917, Training Accuracy= 0.531\n",
      "Epoch: 150, Loss= 0.6755, Training Accuracy= 0.579\n",
      "Epoch: 160, Loss= 0.6257, Training Accuracy= 0.632\n",
      "Epoch: 170, Loss= 0.5022, Training Accuracy= 0.786\n",
      "Epoch: 180, Loss= 0.4676, Training Accuracy= 0.795\n",
      "Epoch: 190, Loss= 0.3395, Training Accuracy= 0.869\n",
      "Epoch: 200, Loss= 0.2715, Training Accuracy= 0.893\n",
      "Epoch: 210, Loss= 0.1907, Training Accuracy= 0.924\n",
      "Epoch: 220, Loss= 0.1488, Training Accuracy= 0.942\n",
      "Epoch: 230, Loss= 0.2180, Training Accuracy= 0.887\n",
      "Epoch: 240, Loss= 0.1065, Training Accuracy= 0.964\n",
      "Epoch: 250, Loss= 0.1058, Training Accuracy= 0.961\n",
      "Epoch: 260, Loss= 0.0902, Training Accuracy= 0.968\n",
      "Epoch: 270, Loss= 0.0835, Training Accuracy= 0.970\n",
      "Epoch: 280, Loss= 0.0800, Training Accuracy= 0.968\n",
      "Epoch: 290, Loss= 0.0841, Training Accuracy= 0.964\n",
      "Epoch: 300, Loss= 0.7443, Training Accuracy= 0.504\n",
      "Epoch: 310, Loss= 0.7143, Training Accuracy= 0.509\n",
      "Epoch: 320, Loss= 0.6960, Training Accuracy= 0.520\n",
      "Epoch: 330, Loss= 0.6826, Training Accuracy= 0.547\n",
      "Epoch: 340, Loss= 0.6506, Training Accuracy= 0.581\n",
      "Epoch: 350, Loss= 0.6140, Training Accuracy= 0.672\n",
      "Epoch: 360, Loss= 0.5639, Training Accuracy= 0.705\n",
      "Epoch: 370, Loss= 0.3040, Training Accuracy= 0.887\n",
      "Epoch: 380, Loss= 0.2698, Training Accuracy= 0.906\n",
      "Epoch: 390, Loss= 0.2448, Training Accuracy= 0.913\n",
      "Epoch: 400, Loss= 0.2373, Training Accuracy= 0.920\n",
      "Epoch: 410, Loss= 0.2240, Training Accuracy= 0.925\n",
      "Epoch: 420, Loss= 0.7968, Training Accuracy= 0.525\n",
      "Epoch: 430, Loss= 0.6720, Training Accuracy= 0.658\n",
      "Epoch: 440, Loss= 0.6514, Training Accuracy= 0.663\n",
      "Epoch: 450, Loss= 0.7087, Training Accuracy= 0.655\n",
      "Epoch: 460, Loss= 0.7848, Training Accuracy= 0.519\n",
      "Epoch: 470, Loss= 0.6567, Training Accuracy= 0.585\n",
      "Epoch: 480, Loss= 0.6134, Training Accuracy= 0.623\n",
      "Epoch: 490, Loss= 0.6122, Training Accuracy= 0.642\n",
      "Epoch: 500, Loss= 0.6478, Training Accuracy= 0.650\n",
      "Epoch: 510, Loss= 0.6233, Training Accuracy= 0.688\n",
      "Epoch: 520, Loss= 0.6117, Training Accuracy= 0.698\n",
      "Epoch: 530, Loss= 0.5850, Training Accuracy= 0.714\n",
      "Epoch: 540, Loss= 0.5547, Training Accuracy= 0.731\n",
      "Epoch: 550, Loss= 0.5211, Training Accuracy= 0.768\n",
      "Epoch: 560, Loss= 0.4921, Training Accuracy= 0.775\n",
      "Epoch: 570, Loss= 0.6887, Training Accuracy= 0.539\n",
      "Epoch: 580, Loss= 0.6171, Training Accuracy= 0.683\n",
      "Epoch: 590, Loss= 0.5804, Training Accuracy= 0.729\n",
      "Epoch: 600, Loss= 0.5555, Training Accuracy= 0.743\n",
      "Epoch: 610, Loss= 0.5330, Training Accuracy= 0.756\n",
      "Epoch: 620, Loss= 0.5091, Training Accuracy= 0.775\n",
      "Epoch: 630, Loss= 0.4817, Training Accuracy= 0.794\n",
      "Epoch: 640, Loss= 0.4741, Training Accuracy= 0.805\n",
      "Epoch: 650, Loss= 0.4684, Training Accuracy= 0.809\n",
      "Epoch: 660, Loss= 0.4673, Training Accuracy= 0.811\n",
      "Epoch: 670, Loss= 0.5310, Training Accuracy= 0.760\n",
      "Epoch: 680, Loss= 0.4587, Training Accuracy= 0.813\n",
      "Epoch: 690, Loss= 0.4979, Training Accuracy= 0.782\n",
      "Epoch: 700, Loss= 0.5065, Training Accuracy= 0.788\n",
      "Epoch: 710, Loss= 0.7578, Training Accuracy= 0.502\n",
      "Epoch: 720, Loss= 0.7113, Training Accuracy= 0.498\n",
      "Epoch: 730, Loss= 0.6986, Training Accuracy= 0.510\n",
      "Epoch: 740, Loss= 0.6986, Training Accuracy= 0.506\n",
      "Epoch: 750, Loss= 0.6956, Training Accuracy= 0.500\n",
      "Epoch: 760, Loss= 0.7052, Training Accuracy= 0.493\n",
      "Epoch: 770, Loss= 0.6948, Training Accuracy= 0.511\n",
      "Epoch: 780, Loss= 0.6959, Training Accuracy= 0.505\n",
      "Epoch: 790, Loss= 0.6964, Training Accuracy= 0.514\n",
      "Epoch: 800, Loss= 0.6984, Training Accuracy= 0.511\n",
      "Epoch: 810, Loss= 0.6955, Training Accuracy= 0.509\n",
      "Epoch: 820, Loss= 0.6925, Training Accuracy= 0.508\n",
      "Epoch: 830, Loss= 0.6919, Training Accuracy= 0.513\n",
      "Epoch: 840, Loss= 0.6908, Training Accuracy= 0.517\n",
      "Epoch: 850, Loss= 0.6921, Training Accuracy= 0.512\n",
      "Epoch: 860, Loss= 0.6905, Training Accuracy= 0.523\n",
      "Epoch: 870, Loss= 0.6895, Training Accuracy= 0.520\n",
      "Epoch: 880, Loss= 0.6917, Training Accuracy= 0.518\n",
      "Epoch: 890, Loss= 0.6888, Training Accuracy= 0.529\n",
      "Epoch: 900, Loss= 0.6878, Training Accuracy= 0.535\n",
      "Epoch: 910, Loss= 0.6867, Training Accuracy= 0.539\n",
      "Epoch: 920, Loss= 0.6858, Training Accuracy= 0.536\n",
      "Epoch: 930, Loss= 0.6903, Training Accuracy= 0.518\n",
      "Epoch: 940, Loss= 0.6829, Training Accuracy= 0.531\n",
      "Epoch: 950, Loss= 0.6871, Training Accuracy= 0.523\n",
      "Epoch: 960, Loss= 0.6828, Training Accuracy= 0.526\n",
      "Epoch: 970, Loss= 0.6825, Training Accuracy= 0.536\n",
      "Epoch: 980, Loss= 0.6808, Training Accuracy= 0.536\n",
      "Epoch: 990, Loss= 0.6830, Training Accuracy= 0.524\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5124\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.7084, Training Accuracy= 0.485\n",
      "Epoch: 10, Loss= 0.6955, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.6947, Training Accuracy= 0.496\n",
      "Epoch: 30, Loss= 0.6943, Training Accuracy= 0.500\n",
      "Epoch: 40, Loss= 0.6941, Training Accuracy= 0.496\n",
      "Epoch: 50, Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 60, Loss= 0.6937, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.6935, Training Accuracy= 0.507\n",
      "Epoch: 90, Loss= 0.6934, Training Accuracy= 0.515\n",
      "Epoch: 100, Loss= 0.6933, Training Accuracy= 0.513\n",
      "Epoch: 110, Loss= 0.6932, Training Accuracy= 0.514\n",
      "Epoch: 120, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 130, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 140, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 150, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 160, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 170, Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 180, Loss= 0.6928, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 200, Loss= 0.6928, Training Accuracy= 0.506\n",
      "Epoch: 210, Loss= 0.6927, Training Accuracy= 0.498\n",
      "Epoch: 220, Loss= 0.6927, Training Accuracy= 0.500\n",
      "Epoch: 230, Loss= 0.6926, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 0.6926, Training Accuracy= 0.505\n",
      "Epoch: 250, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 260, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 270, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 280, Loss= 0.6924, Training Accuracy= 0.512\n",
      "Epoch: 290, Loss= 0.6924, Training Accuracy= 0.512\n",
      "Epoch: 300, Loss= 0.6924, Training Accuracy= 0.516\n",
      "Epoch: 310, Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 320, Loss= 0.6923, Training Accuracy= 0.516\n",
      "Epoch: 330, Loss= 0.6922, Training Accuracy= 0.516\n",
      "Epoch: 340, Loss= 0.6922, Training Accuracy= 0.519\n",
      "Epoch: 350, Loss= 0.6922, Training Accuracy= 0.515\n",
      "Epoch: 360, Loss= 0.6921, Training Accuracy= 0.514\n",
      "Epoch: 370, Loss= 0.6921, Training Accuracy= 0.515\n",
      "Epoch: 380, Loss= 0.6920, Training Accuracy= 0.516\n",
      "Epoch: 390, Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 400, Loss= 0.6920, Training Accuracy= 0.517\n",
      "Epoch: 410, Loss= 0.6919, Training Accuracy= 0.516\n",
      "Epoch: 420, Loss= 0.6919, Training Accuracy= 0.515\n",
      "Epoch: 430, Loss= 0.6919, Training Accuracy= 0.514\n",
      "Epoch: 440, Loss= 0.6918, Training Accuracy= 0.518\n",
      "Epoch: 450, Loss= 0.6918, Training Accuracy= 0.520\n",
      "Epoch: 460, Loss= 0.6917, Training Accuracy= 0.520\n",
      "Epoch: 470, Loss= 0.6917, Training Accuracy= 0.525\n",
      "Epoch: 480, Loss= 0.6917, Training Accuracy= 0.524\n",
      "Epoch: 490, Loss= 0.6916, Training Accuracy= 0.525\n",
      "Epoch: 500, Loss= 0.6916, Training Accuracy= 0.520\n",
      "Epoch: 510, Loss= 0.6915, Training Accuracy= 0.529\n",
      "Epoch: 520, Loss= 0.6915, Training Accuracy= 0.528\n",
      "Epoch: 530, Loss= 0.6915, Training Accuracy= 0.519\n",
      "Epoch: 540, Loss= 0.6914, Training Accuracy= 0.517\n",
      "Epoch: 550, Loss= 0.6914, Training Accuracy= 0.515\n",
      "Epoch: 560, Loss= 0.6914, Training Accuracy= 0.516\n",
      "Epoch: 570, Loss= 0.6914, Training Accuracy= 0.518\n",
      "Epoch: 580, Loss= 0.6914, Training Accuracy= 0.516\n",
      "Epoch: 590, Loss= 0.6913, Training Accuracy= 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600, Loss= 0.6913, Training Accuracy= 0.516\n",
      "Epoch: 610, Loss= 0.6913, Training Accuracy= 0.515\n",
      "Epoch: 620, Loss= 0.6913, Training Accuracy= 0.516\n",
      "Epoch: 630, Loss= 0.6912, Training Accuracy= 0.516\n",
      "Epoch: 640, Loss= 0.6912, Training Accuracy= 0.518\n",
      "Epoch: 650, Loss= 0.6912, Training Accuracy= 0.518\n",
      "Epoch: 660, Loss= 0.6911, Training Accuracy= 0.522\n",
      "Epoch: 670, Loss= 0.6911, Training Accuracy= 0.522\n",
      "Epoch: 680, Loss= 0.6911, Training Accuracy= 0.521\n",
      "Epoch: 690, Loss= 0.6910, Training Accuracy= 0.525\n",
      "Epoch: 700, Loss= 0.6910, Training Accuracy= 0.526\n",
      "Epoch: 710, Loss= 0.6910, Training Accuracy= 0.528\n",
      "Epoch: 720, Loss= 0.6909, Training Accuracy= 0.526\n",
      "Epoch: 730, Loss= 0.6909, Training Accuracy= 0.529\n",
      "Epoch: 740, Loss= 0.6908, Training Accuracy= 0.527\n",
      "Epoch: 750, Loss= 0.6908, Training Accuracy= 0.528\n",
      "Epoch: 760, Loss= 0.6908, Training Accuracy= 0.532\n",
      "Epoch: 770, Loss= 0.6907, Training Accuracy= 0.531\n",
      "Epoch: 780, Loss= 0.6907, Training Accuracy= 0.529\n",
      "Epoch: 790, Loss= 0.6906, Training Accuracy= 0.528\n",
      "Epoch: 800, Loss= 0.6906, Training Accuracy= 0.525\n",
      "Epoch: 810, Loss= 0.6905, Training Accuracy= 0.523\n",
      "Epoch: 820, Loss= 0.6905, Training Accuracy= 0.525\n",
      "Epoch: 830, Loss= 0.6904, Training Accuracy= 0.525\n",
      "Epoch: 840, Loss= 0.6904, Training Accuracy= 0.528\n",
      "Epoch: 850, Loss= 0.6904, Training Accuracy= 0.530\n",
      "Epoch: 860, Loss= 0.6903, Training Accuracy= 0.528\n",
      "Epoch: 870, Loss= 0.6903, Training Accuracy= 0.530\n",
      "Epoch: 880, Loss= 0.6902, Training Accuracy= 0.533\n",
      "Epoch: 890, Loss= 0.6902, Training Accuracy= 0.534\n",
      "Epoch: 900, Loss= 0.6901, Training Accuracy= 0.535\n",
      "Epoch: 910, Loss= 0.6901, Training Accuracy= 0.539\n",
      "Epoch: 920, Loss= 0.6901, Training Accuracy= 0.535\n",
      "Epoch: 930, Loss= 0.6901, Training Accuracy= 0.534\n",
      "Epoch: 940, Loss= 0.6900, Training Accuracy= 0.534\n",
      "Epoch: 950, Loss= 0.6900, Training Accuracy= 0.531\n",
      "Epoch: 960, Loss= 0.6900, Training Accuracy= 0.529\n",
      "Epoch: 970, Loss= 0.6900, Training Accuracy= 0.524\n",
      "Epoch: 980, Loss= 0.6900, Training Accuracy= 0.524\n",
      "Epoch: 990, Loss= 0.6900, Training Accuracy= 0.527\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4908\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.7015, Training Accuracy= 0.519\n",
      "Epoch: 10, Loss= 0.6940, Training Accuracy= 0.500\n",
      "Epoch: 20, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.6935, Training Accuracy= 0.503\n",
      "Epoch: 40, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 50, Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 60, Loss= 0.6931, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 80, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 90, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 100, Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 110, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 120, Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 130, Loss= 0.6925, Training Accuracy= 0.518\n",
      "Epoch: 140, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 150, Loss= 0.6923, Training Accuracy= 0.514\n",
      "Epoch: 160, Loss= 0.6922, Training Accuracy= 0.512\n",
      "Epoch: 170, Loss= 0.6922, Training Accuracy= 0.513\n",
      "Epoch: 180, Loss= 0.6921, Training Accuracy= 0.508\n",
      "Epoch: 190, Loss= 0.6920, Training Accuracy= 0.508\n",
      "Epoch: 200, Loss= 0.6920, Training Accuracy= 0.513\n",
      "Epoch: 210, Loss= 0.6919, Training Accuracy= 0.511\n",
      "Epoch: 220, Loss= 0.6918, Training Accuracy= 0.515\n",
      "Epoch: 230, Loss= 0.6918, Training Accuracy= 0.512\n",
      "Epoch: 240, Loss= 0.6917, Training Accuracy= 0.511\n",
      "Epoch: 250, Loss= 0.6916, Training Accuracy= 0.517\n",
      "Epoch: 260, Loss= 0.6916, Training Accuracy= 0.517\n",
      "Epoch: 270, Loss= 0.6915, Training Accuracy= 0.520\n",
      "Epoch: 280, Loss= 0.6914, Training Accuracy= 0.519\n",
      "Epoch: 290, Loss= 0.6914, Training Accuracy= 0.518\n",
      "Epoch: 300, Loss= 0.6913, Training Accuracy= 0.517\n",
      "Epoch: 310, Loss= 0.6912, Training Accuracy= 0.522\n",
      "Epoch: 320, Loss= 0.6911, Training Accuracy= 0.526\n",
      "Epoch: 330, Loss= 0.6910, Training Accuracy= 0.523\n",
      "Epoch: 340, Loss= 0.6909, Training Accuracy= 0.522\n",
      "Epoch: 350, Loss= 0.6908, Training Accuracy= 0.522\n",
      "Epoch: 360, Loss= 0.6907, Training Accuracy= 0.521\n",
      "Epoch: 370, Loss= 0.6906, Training Accuracy= 0.518\n",
      "Epoch: 380, Loss= 0.6905, Training Accuracy= 0.523\n",
      "Epoch: 390, Loss= 0.6904, Training Accuracy= 0.524\n",
      "Epoch: 400, Loss= 0.6902, Training Accuracy= 0.535\n",
      "Epoch: 410, Loss= 0.6901, Training Accuracy= 0.530\n",
      "Epoch: 420, Loss= 0.6900, Training Accuracy= 0.528\n",
      "Epoch: 430, Loss= 0.6898, Training Accuracy= 0.532\n",
      "Epoch: 440, Loss= 0.6897, Training Accuracy= 0.531\n",
      "Epoch: 450, Loss= 0.6895, Training Accuracy= 0.535\n",
      "Epoch: 460, Loss= 0.6893, Training Accuracy= 0.532\n",
      "Epoch: 470, Loss= 0.6891, Training Accuracy= 0.536\n",
      "Epoch: 480, Loss= 0.6888, Training Accuracy= 0.540\n",
      "Epoch: 490, Loss= 0.6883, Training Accuracy= 0.540\n",
      "Epoch: 500, Loss= 0.6875, Training Accuracy= 0.542\n",
      "Epoch: 510, Loss= 0.6858, Training Accuracy= 0.544\n",
      "Epoch: 520, Loss= 0.6818, Training Accuracy= 0.592\n",
      "Epoch: 530, Loss= 0.6696, Training Accuracy= 0.615\n",
      "Epoch: 540, Loss= 0.6668, Training Accuracy= 0.604\n",
      "Epoch: 550, Loss= 0.5608, Training Accuracy= 0.722\n",
      "Epoch: 560, Loss= 0.4786, Training Accuracy= 0.751\n",
      "Epoch: 570, Loss= 0.4177, Training Accuracy= 0.763\n",
      "Epoch: 580, Loss= 0.3709, Training Accuracy= 0.814\n",
      "Epoch: 590, Loss= 0.3328, Training Accuracy= 0.864\n",
      "Epoch: 600, Loss= 0.3084, Training Accuracy= 0.877\n",
      "Epoch: 610, Loss= 0.2919, Training Accuracy= 0.882\n",
      "Epoch: 620, Loss= 0.4102, Training Accuracy= 0.799\n",
      "Epoch: 630, Loss= 0.3463, Training Accuracy= 0.822\n",
      "Epoch: 640, Loss= 0.2965, Training Accuracy= 0.837\n",
      "Epoch: 650, Loss= 0.2546, Training Accuracy= 0.841\n",
      "Epoch: 660, Loss= 0.2319, Training Accuracy= 0.850\n",
      "Epoch: 670, Loss= 0.2172, Training Accuracy= 0.877\n",
      "Epoch: 680, Loss= 0.2049, Training Accuracy= 0.880\n",
      "Epoch: 690, Loss= 0.1947, Training Accuracy= 0.886\n",
      "Epoch: 700, Loss= 0.1862, Training Accuracy= 0.889\n",
      "Epoch: 710, Loss= 0.1791, Training Accuracy= 0.896\n",
      "Epoch: 720, Loss= 0.1715, Training Accuracy= 0.889\n",
      "Epoch: 730, Loss= 0.1631, Training Accuracy= 0.884\n",
      "Epoch: 740, Loss= 0.1553, Training Accuracy= 0.893\n",
      "Epoch: 750, Loss= 0.1457, Training Accuracy= 0.896\n",
      "Epoch: 760, Loss= 0.1363, Training Accuracy= 0.912\n",
      "Epoch: 770, Loss= 0.1106, Training Accuracy= 0.939\n",
      "Epoch: 780, Loss= 0.0907, Training Accuracy= 0.963\n",
      "Epoch: 790, Loss= 0.0751, Training Accuracy= 0.977\n",
      "Epoch: 800, Loss= 0.0636, Training Accuracy= 0.980\n",
      "Epoch: 810, Loss= 0.0561, Training Accuracy= 0.982\n",
      "Epoch: 820, Loss= 0.0494, Training Accuracy= 0.985\n",
      "Epoch: 830, Loss= 0.0432, Training Accuracy= 0.987\n",
      "Epoch: 840, Loss= 0.0269, Training Accuracy= 0.996\n",
      "Epoch: 850, Loss= 0.0191, Training Accuracy= 0.995\n",
      "Epoch: 860, Loss= 0.0144, Training Accuracy= 0.999\n",
      "Epoch: 870, Loss= 0.0116, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0098, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0085, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0076, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0068, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0062, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0057, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0053, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0049, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0046, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0043, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0038, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.7062, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.6962, Training Accuracy= 0.496\n",
      "Epoch: 20, Loss= 0.6952, Training Accuracy= 0.495\n",
      "Epoch: 30, Loss= 0.6949, Training Accuracy= 0.496\n",
      "Epoch: 40, Loss= 0.6947, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 0.6945, Training Accuracy= 0.497\n",
      "Epoch: 60, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 80, Loss= 0.6942, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.6941, Training Accuracy= 0.504\n",
      "Epoch: 100, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.6940, Training Accuracy= 0.501\n",
      "Epoch: 120, Loss= 0.6939, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 0.6938, Training Accuracy= 0.503\n",
      "Epoch: 140, Loss= 0.6937, Training Accuracy= 0.504\n",
      "Epoch: 150, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 160, Loss= 0.6936, Training Accuracy= 0.497\n",
      "Epoch: 170, Loss= 0.6935, Training Accuracy= 0.495\n",
      "Epoch: 180, Loss= 0.6935, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190, Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 200, Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 210, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 230, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 240, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 250, Loss= 0.6924, Training Accuracy= 0.510\n",
      "Epoch: 260, Loss= 0.6918, Training Accuracy= 0.517\n",
      "Epoch: 270, Loss= 0.6911, Training Accuracy= 0.527\n",
      "Epoch: 280, Loss= 0.6901, Training Accuracy= 0.539\n",
      "Epoch: 290, Loss= 0.6888, Training Accuracy= 0.549\n",
      "Epoch: 300, Loss= 0.6878, Training Accuracy= 0.547\n",
      "Epoch: 310, Loss= 0.6575, Training Accuracy= 0.622\n",
      "Epoch: 320, Loss= 0.6916, Training Accuracy= 0.482\n",
      "Epoch: 330, Loss= 0.6436, Training Accuracy= 0.610\n",
      "Epoch: 340, Loss= 0.4542, Training Accuracy= 0.822\n",
      "Epoch: 350, Loss= 0.4798, Training Accuracy= 0.760\n",
      "Epoch: 360, Loss= 0.1655, Training Accuracy= 0.983\n",
      "Epoch: 370, Loss= 0.1202, Training Accuracy= 0.982\n",
      "Epoch: 380, Loss= 0.0883, Training Accuracy= 0.985\n",
      "Epoch: 390, Loss= 0.0686, Training Accuracy= 0.987\n",
      "Epoch: 400, Loss= 0.0546, Training Accuracy= 0.990\n",
      "Epoch: 410, Loss= 0.0450, Training Accuracy= 0.992\n",
      "Epoch: 420, Loss= 0.0380, Training Accuracy= 0.993\n",
      "Epoch: 430, Loss= 0.0333, Training Accuracy= 0.995\n",
      "Epoch: 440, Loss= 0.0537, Training Accuracy= 0.991\n",
      "Epoch: 450, Loss= 0.0287, Training Accuracy= 0.998\n",
      "Epoch: 460, Loss= 0.0308, Training Accuracy= 0.998\n",
      "Epoch: 470, Loss= 0.0450, Training Accuracy= 0.992\n",
      "Epoch: 480, Loss= 0.0238, Training Accuracy= 0.998\n",
      "Epoch: 490, Loss= 0.0226, Training Accuracy= 0.998\n",
      "Epoch: 500, Loss= 0.0223, Training Accuracy= 0.997\n",
      "Epoch: 510, Loss= 0.0221, Training Accuracy= 0.998\n",
      "Epoch: 520, Loss= 0.0145, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0172, Training Accuracy= 0.999\n",
      "Epoch: 540, Loss= 0.0239, Training Accuracy= 0.996\n",
      "Epoch: 550, Loss= 0.0127, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0139, Training Accuracy= 0.999\n",
      "Epoch: 570, Loss= 0.0092, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0081, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0074, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0068, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0063, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0059, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0055, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0052, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0049, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0046, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0044, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0042, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0040, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0038, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0034, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0032, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.7082, Training Accuracy= 0.504\n",
      "Epoch: 10, Loss= 0.7038, Training Accuracy= 0.503\n",
      "Epoch: 20, Loss= 0.7014, Training Accuracy= 0.503\n",
      "Epoch: 30, Loss= 0.7000, Training Accuracy= 0.503\n",
      "Epoch: 40, Loss= 0.6990, Training Accuracy= 0.503\n",
      "Epoch: 50, Loss= 0.6984, Training Accuracy= 0.503\n",
      "Epoch: 60, Loss= 0.6978, Training Accuracy= 0.503\n",
      "Epoch: 70, Loss= 0.6974, Training Accuracy= 0.503\n",
      "Epoch: 80, Loss= 0.6971, Training Accuracy= 0.503\n",
      "Epoch: 90, Loss= 0.6968, Training Accuracy= 0.503\n",
      "Epoch: 100, Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 110, Loss= 0.6963, Training Accuracy= 0.503\n",
      "Epoch: 120, Loss= 0.6961, Training Accuracy= 0.503\n",
      "Epoch: 130, Loss= 0.6960, Training Accuracy= 0.503\n",
      "Epoch: 140, Loss= 0.6958, Training Accuracy= 0.503\n",
      "Epoch: 150, Loss= 0.6957, Training Accuracy= 0.503\n",
      "Epoch: 160, Loss= 0.6955, Training Accuracy= 0.503\n",
      "Epoch: 170, Loss= 0.6954, Training Accuracy= 0.503\n",
      "Epoch: 180, Loss= 0.6953, Training Accuracy= 0.503\n",
      "Epoch: 190, Loss= 0.6952, Training Accuracy= 0.504\n",
      "Epoch: 200, Loss= 0.6951, Training Accuracy= 0.506\n",
      "Epoch: 210, Loss= 0.6950, Training Accuracy= 0.508\n",
      "Epoch: 220, Loss= 0.6949, Training Accuracy= 0.506\n",
      "Epoch: 230, Loss= 0.6948, Training Accuracy= 0.508\n",
      "Epoch: 240, Loss= 0.6947, Training Accuracy= 0.509\n",
      "Epoch: 250, Loss= 0.6946, Training Accuracy= 0.507\n",
      "Epoch: 260, Loss= 0.6945, Training Accuracy= 0.509\n",
      "Epoch: 270, Loss= 0.6944, Training Accuracy= 0.510\n",
      "Epoch: 280, Loss= 0.6944, Training Accuracy= 0.512\n",
      "Epoch: 290, Loss= 0.6943, Training Accuracy= 0.511\n",
      "Epoch: 300, Loss= 0.6942, Training Accuracy= 0.508\n",
      "Epoch: 310, Loss= 0.6941, Training Accuracy= 0.508\n",
      "Epoch: 320, Loss= 0.6940, Training Accuracy= 0.506\n",
      "Epoch: 330, Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 340, Loss= 0.6938, Training Accuracy= 0.507\n",
      "Epoch: 350, Loss= 0.6936, Training Accuracy= 0.507\n",
      "Epoch: 360, Loss= 0.6935, Training Accuracy= 0.512\n",
      "Epoch: 370, Loss= 0.6934, Training Accuracy= 0.521\n",
      "Epoch: 380, Loss= 0.6932, Training Accuracy= 0.519\n",
      "Epoch: 390, Loss= 0.6930, Training Accuracy= 0.518\n",
      "Epoch: 400, Loss= 0.6928, Training Accuracy= 0.518\n",
      "Epoch: 410, Loss= 0.6927, Training Accuracy= 0.520\n",
      "Epoch: 420, Loss= 0.6926, Training Accuracy= 0.523\n",
      "Epoch: 430, Loss= 0.6924, Training Accuracy= 0.517\n",
      "Epoch: 440, Loss= 0.6923, Training Accuracy= 0.519\n",
      "Epoch: 450, Loss= 0.6922, Training Accuracy= 0.521\n",
      "Epoch: 460, Loss= 0.6921, Training Accuracy= 0.525\n",
      "Epoch: 470, Loss= 0.6920, Training Accuracy= 0.528\n",
      "Epoch: 480, Loss= 0.6918, Training Accuracy= 0.530\n",
      "Epoch: 490, Loss= 0.6917, Training Accuracy= 0.530\n",
      "Epoch: 500, Loss= 0.6915, Training Accuracy= 0.532\n",
      "Epoch: 510, Loss= 0.6913, Training Accuracy= 0.534\n",
      "Epoch: 520, Loss= 0.6911, Training Accuracy= 0.534\n",
      "Epoch: 530, Loss= 0.6909, Training Accuracy= 0.528\n",
      "Epoch: 540, Loss= 0.6908, Training Accuracy= 0.529\n",
      "Epoch: 550, Loss= 0.6906, Training Accuracy= 0.522\n",
      "Epoch: 560, Loss= 0.6904, Training Accuracy= 0.523\n",
      "Epoch: 570, Loss= 0.6903, Training Accuracy= 0.525\n",
      "Epoch: 580, Loss= 0.6901, Training Accuracy= 0.525\n",
      "Epoch: 590, Loss= 0.6900, Training Accuracy= 0.528\n",
      "Epoch: 600, Loss= 0.6898, Training Accuracy= 0.535\n",
      "Epoch: 610, Loss= 0.6897, Training Accuracy= 0.538\n",
      "Epoch: 620, Loss= 0.6895, Training Accuracy= 0.540\n",
      "Epoch: 630, Loss= 0.6894, Training Accuracy= 0.543\n",
      "Epoch: 640, Loss= 0.6892, Training Accuracy= 0.544\n",
      "Epoch: 650, Loss= 0.6890, Training Accuracy= 0.548\n",
      "Epoch: 660, Loss= 0.6889, Training Accuracy= 0.544\n",
      "Epoch: 670, Loss= 0.6887, Training Accuracy= 0.552\n",
      "Epoch: 680, Loss= 0.6886, Training Accuracy= 0.553\n",
      "Epoch: 690, Loss= 0.6884, Training Accuracy= 0.553\n",
      "Epoch: 700, Loss= 0.6883, Training Accuracy= 0.556\n",
      "Epoch: 710, Loss= 0.6881, Training Accuracy= 0.550\n",
      "Epoch: 720, Loss= 0.6880, Training Accuracy= 0.548\n",
      "Epoch: 730, Loss= 0.6878, Training Accuracy= 0.547\n",
      "Epoch: 740, Loss= 0.6877, Training Accuracy= 0.545\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.03\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 1000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a RNN cell with tensorflow\n",
    "    rnn_cell = rnn.BasicRNNCell(num_hidden)\n",
    "\n",
    "    # Get RNN cell output\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
