{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 25\n",
    "N = 25\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.7656, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.7197, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.7136, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.7108, Training Accuracy= 0.502\n",
      "Epoch: 40, Loss= 0.7090, Training Accuracy= 0.502\n",
      "Epoch: 50, Loss= 0.7078, Training Accuracy= 0.502\n",
      "Epoch: 60, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 70, Loss= 0.7062, Training Accuracy= 0.502\n",
      "Epoch: 80, Loss= 0.7056, Training Accuracy= 0.502\n",
      "Epoch: 90, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 100, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.7044, Training Accuracy= 0.502\n",
      "Epoch: 120, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 130, Loss= 0.7039, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 0.7037, Training Accuracy= 0.502\n",
      "Epoch: 150, Loss= 0.7035, Training Accuracy= 0.502\n",
      "Epoch: 160, Loss= 0.7034, Training Accuracy= 0.502\n",
      "Epoch: 170, Loss= 0.7033, Training Accuracy= 0.502\n",
      "Epoch: 180, Loss= 0.7033, Training Accuracy= 0.502\n",
      "Epoch: 190, Loss= 0.7032, Training Accuracy= 0.502\n",
      "Epoch: 200, Loss= 0.7032, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.7032, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.7032, Training Accuracy= 0.502\n",
      "Epoch: 230, Loss= 0.7032, Training Accuracy= 0.502\n",
      "Epoch: 240, Loss= 0.7033, Training Accuracy= 0.502\n",
      "Epoch: 250, Loss= 0.7033, Training Accuracy= 0.502\n",
      "Epoch: 260, Loss= 0.7034, Training Accuracy= 0.502\n",
      "Epoch: 270, Loss= 0.7035, Training Accuracy= 0.502\n",
      "Epoch: 280, Loss= 0.7036, Training Accuracy= 0.502\n",
      "Epoch: 290, Loss= 0.7037, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 0.7037, Training Accuracy= 0.502\n",
      "Epoch: 310, Loss= 0.7036, Training Accuracy= 0.502\n",
      "Epoch: 320, Loss= 0.7035, Training Accuracy= 0.502\n",
      "Epoch: 330, Loss= 0.7033, Training Accuracy= 0.502\n",
      "Epoch: 340, Loss= 0.7031, Training Accuracy= 0.503\n",
      "Epoch: 350, Loss= 0.7029, Training Accuracy= 0.503\n",
      "Epoch: 360, Loss= 0.7027, Training Accuracy= 0.503\n",
      "Epoch: 370, Loss= 0.7024, Training Accuracy= 0.504\n",
      "Epoch: 380, Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 390, Loss= 0.7016, Training Accuracy= 0.504\n",
      "Epoch: 400, Loss= 0.7015, Training Accuracy= 0.504\n",
      "Epoch: 410, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 420, Loss= 0.7023, Training Accuracy= 0.504\n",
      "Epoch: 430, Loss= 0.7033, Training Accuracy= 0.504\n",
      "Epoch: 440, Loss= 0.7042, Training Accuracy= 0.504\n",
      "Epoch: 450, Loss= 0.7035, Training Accuracy= 0.504\n",
      "Epoch: 460, Loss= 0.7029, Training Accuracy= 0.504\n",
      "Epoch: 470, Loss= 0.7032, Training Accuracy= 0.506\n",
      "Epoch: 480, Loss= 0.7035, Training Accuracy= 0.505\n",
      "Epoch: 490, Loss= 0.7027, Training Accuracy= 0.505\n",
      "Epoch: 500, Loss= 0.7008, Training Accuracy= 0.508\n",
      "Epoch: 510, Loss= 0.6998, Training Accuracy= 0.510\n",
      "Epoch: 520, Loss= 0.6999, Training Accuracy= 0.511\n",
      "Epoch: 530, Loss= 0.6985, Training Accuracy= 0.517\n",
      "Epoch: 540, Loss= 0.6982, Training Accuracy= 0.516\n",
      "Epoch: 550, Loss= 0.6977, Training Accuracy= 0.518\n",
      "Epoch: 560, Loss= 0.7023, Training Accuracy= 0.514\n",
      "Epoch: 570, Loss= 0.6956, Training Accuracy= 0.528\n",
      "Epoch: 580, Loss= 0.6940, Training Accuracy= 0.529\n",
      "Epoch: 590, Loss= 0.6950, Training Accuracy= 0.533\n",
      "Epoch: 600, Loss= 0.6945, Training Accuracy= 0.534\n",
      "Epoch: 610, Loss= 0.6974, Training Accuracy= 0.533\n",
      "Epoch: 620, Loss= 0.7016, Training Accuracy= 0.531\n",
      "Epoch: 630, Loss= 0.6916, Training Accuracy= 0.543\n",
      "Epoch: 640, Loss= 0.6989, Training Accuracy= 0.527\n",
      "Epoch: 650, Loss= 0.6931, Training Accuracy= 0.537\n",
      "Epoch: 660, Loss= 0.6970, Training Accuracy= 0.525\n",
      "Epoch: 670, Loss= 0.7025, Training Accuracy= 0.527\n",
      "Epoch: 680, Loss= 0.6978, Training Accuracy= 0.539\n",
      "Epoch: 690, Loss= 0.6911, Training Accuracy= 0.548\n",
      "Epoch: 700, Loss= 0.6845, Training Accuracy= 0.561\n",
      "Epoch: 710, Loss= 0.6822, Training Accuracy= 0.569\n",
      "Epoch: 720, Loss= 0.6761, Training Accuracy= 0.580\n",
      "Epoch: 730, Loss= 0.6897, Training Accuracy= 0.565\n",
      "Epoch: 740, Loss= 0.6815, Training Accuracy= 0.573\n",
      "Epoch: 750, Loss= 0.6831, Training Accuracy= 0.569\n",
      "Epoch: 760, Loss= 0.6722, Training Accuracy= 0.585\n",
      "Epoch: 770, Loss= 0.6717, Training Accuracy= 0.590\n",
      "Epoch: 780, Loss= 0.6635, Training Accuracy= 0.595\n",
      "Epoch: 790, Loss= 0.6833, Training Accuracy= 0.580\n",
      "Epoch: 800, Loss= 0.6765, Training Accuracy= 0.584\n",
      "Epoch: 810, Loss= 0.6734, Training Accuracy= 0.593\n",
      "Epoch: 820, Loss= 0.6479, Training Accuracy= 0.617\n",
      "Epoch: 830, Loss= 0.6523, Training Accuracy= 0.614\n",
      "Epoch: 840, Loss= 0.6530, Training Accuracy= 0.612\n",
      "Epoch: 850, Loss= 0.6598, Training Accuracy= 0.608\n",
      "Epoch: 860, Loss= 0.6350, Training Accuracy= 0.629\n",
      "Epoch: 870, Loss= 0.6638, Training Accuracy= 0.609\n",
      "Epoch: 880, Loss= 0.6378, Training Accuracy= 0.635\n",
      "Epoch: 890, Loss= 0.7834, Training Accuracy= 0.523\n",
      "Epoch: 900, Loss= 0.6494, Training Accuracy= 0.621\n",
      "Epoch: 910, Loss= 0.6468, Training Accuracy= 0.631\n",
      "Epoch: 920, Loss= 0.6226, Training Accuracy= 0.648\n",
      "Epoch: 930, Loss= 0.6886, Training Accuracy= 0.589\n",
      "Epoch: 940, Loss= 0.6352, Training Accuracy= 0.642\n",
      "Epoch: 950, Loss= 0.7054, Training Accuracy= 0.568\n",
      "Epoch: 960, Loss= 0.6628, Training Accuracy= 0.617\n",
      "Epoch: 970, Loss= 0.6224, Training Accuracy= 0.650\n",
      "Epoch: 980, Loss= 0.6096, Training Accuracy= 0.658\n",
      "Epoch: 990, Loss= 0.6006, Training Accuracy= 0.669\n",
      "Epoch: 1000, Loss= 0.6276, Training Accuracy= 0.642\n",
      "Epoch: 1010, Loss= 0.6618, Training Accuracy= 0.622\n",
      "Epoch: 1020, Loss= 0.6398, Training Accuracy= 0.636\n",
      "Epoch: 1030, Loss= 0.6133, Training Accuracy= 0.655\n",
      "Epoch: 1040, Loss= 0.6194, Training Accuracy= 0.656\n",
      "Epoch: 1050, Loss= 0.6640, Training Accuracy= 0.626\n",
      "Epoch: 1060, Loss= 0.6197, Training Accuracy= 0.659\n",
      "Epoch: 1070, Loss= 0.6200, Training Accuracy= 0.652\n",
      "Epoch: 1080, Loss= 0.6855, Training Accuracy= 0.600\n",
      "Epoch: 1090, Loss= 0.6372, Training Accuracy= 0.631\n",
      "Epoch: 1100, Loss= 0.6427, Training Accuracy= 0.636\n",
      "Epoch: 1110, Loss= 0.6168, Training Accuracy= 0.662\n",
      "Epoch: 1120, Loss= 0.6161, Training Accuracy= 0.664\n",
      "Epoch: 1130, Loss= 0.6158, Training Accuracy= 0.661\n",
      "Epoch: 1140, Loss= 0.6084, Training Accuracy= 0.661\n",
      "Epoch: 1150, Loss= 0.6156, Training Accuracy= 0.656\n",
      "Epoch: 1160, Loss= 0.6614, Training Accuracy= 0.615\n",
      "Epoch: 1170, Loss= 0.6355, Training Accuracy= 0.641\n",
      "Epoch: 1180, Loss= 0.6070, Training Accuracy= 0.667\n",
      "Epoch: 1190, Loss= 0.6213, Training Accuracy= 0.654\n",
      "Epoch: 1200, Loss= 0.5865, Training Accuracy= 0.690\n",
      "Epoch: 1210, Loss= 0.5957, Training Accuracy= 0.672\n",
      "Epoch: 1220, Loss= 0.6256, Training Accuracy= 0.648\n",
      "Epoch: 1230, Loss= 0.6427, Training Accuracy= 0.646\n",
      "Epoch: 1240, Loss= 0.6224, Training Accuracy= 0.653\n",
      "Epoch: 1250, Loss= 0.6193, Training Accuracy= 0.655\n",
      "Epoch: 1260, Loss= 0.5927, Training Accuracy= 0.681\n",
      "Epoch: 1270, Loss= 0.6082, Training Accuracy= 0.664\n",
      "Epoch: 1280, Loss= 0.5955, Training Accuracy= 0.673\n",
      "Epoch: 1290, Loss= 0.6926, Training Accuracy= 0.604\n",
      "Epoch: 1300, Loss= 0.6259, Training Accuracy= 0.651\n",
      "Epoch: 1310, Loss= 0.6179, Training Accuracy= 0.651\n",
      "Epoch: 1320, Loss= 0.6057, Training Accuracy= 0.668\n",
      "Epoch: 1330, Loss= 0.6049, Training Accuracy= 0.672\n",
      "Epoch: 1340, Loss= 0.5799, Training Accuracy= 0.689\n",
      "Epoch: 1350, Loss= 0.6579, Training Accuracy= 0.633\n",
      "Epoch: 1360, Loss= 0.5778, Training Accuracy= 0.696\n",
      "Epoch: 1370, Loss= 0.5520, Training Accuracy= 0.715\n",
      "Epoch: 1380, Loss= 0.6282, Training Accuracy= 0.651\n",
      "Epoch: 1390, Loss= 0.5765, Training Accuracy= 0.696\n",
      "Epoch: 1400, Loss= 0.6063, Training Accuracy= 0.671\n",
      "Epoch: 1410, Loss= 0.5699, Training Accuracy= 0.700\n",
      "Epoch: 1420, Loss= 0.6044, Training Accuracy= 0.672\n",
      "Epoch: 1430, Loss= 0.5661, Training Accuracy= 0.698\n",
      "Epoch: 1440, Loss= 0.5562, Training Accuracy= 0.708\n",
      "Epoch: 1450, Loss= 0.5854, Training Accuracy= 0.693\n",
      "Epoch: 1460, Loss= 0.5703, Training Accuracy= 0.698\n",
      "Epoch: 1470, Loss= 0.5939, Training Accuracy= 0.684\n",
      "Epoch: 1480, Loss= 0.5700, Training Accuracy= 0.700\n",
      "Epoch: 1490, Loss= 0.6351, Training Accuracy= 0.654\n",
      "Epoch: 1500, Loss= 0.5677, Training Accuracy= 0.701\n",
      "Epoch: 1510, Loss= 0.5641, Training Accuracy= 0.702\n",
      "Epoch: 1520, Loss= 0.5731, Training Accuracy= 0.695\n",
      "Epoch: 1530, Loss= 0.5845, Training Accuracy= 0.691\n",
      "Epoch: 1540, Loss= 0.6247, Training Accuracy= 0.657\n",
      "Epoch: 1550, Loss= 0.5737, Training Accuracy= 0.693\n",
      "Epoch: 1560, Loss= 0.5635, Training Accuracy= 0.706\n",
      "Epoch: 1570, Loss= 0.5375, Training Accuracy= 0.729\n",
      "Epoch: 1580, Loss= 0.5409, Training Accuracy= 0.727\n",
      "Epoch: 1590, Loss= 0.5324, Training Accuracy= 0.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss= 0.6403, Training Accuracy= 0.648\n",
      "Epoch: 1610, Loss= 0.5898, Training Accuracy= 0.685\n",
      "Epoch: 1620, Loss= 0.6928, Training Accuracy= 0.580\n",
      "Epoch: 1630, Loss= 0.5888, Training Accuracy= 0.686\n",
      "Epoch: 1640, Loss= 0.5977, Training Accuracy= 0.675\n",
      "Epoch: 1650, Loss= 0.5346, Training Accuracy= 0.727\n",
      "Epoch: 1660, Loss= 0.6375, Training Accuracy= 0.655\n",
      "Epoch: 1670, Loss= 0.5944, Training Accuracy= 0.682\n",
      "Epoch: 1680, Loss= 0.5802, Training Accuracy= 0.694\n",
      "Epoch: 1690, Loss= 0.5842, Training Accuracy= 0.696\n",
      "Epoch: 1700, Loss= 0.6799, Training Accuracy= 0.596\n",
      "Epoch: 1710, Loss= 0.5915, Training Accuracy= 0.682\n",
      "Epoch: 1720, Loss= 0.5669, Training Accuracy= 0.702\n",
      "Epoch: 1730, Loss= 0.5600, Training Accuracy= 0.709\n",
      "Epoch: 1740, Loss= 0.5586, Training Accuracy= 0.707\n",
      "Epoch: 1750, Loss= 0.5735, Training Accuracy= 0.699\n",
      "Epoch: 1760, Loss= 0.5654, Training Accuracy= 0.703\n",
      "Epoch: 1770, Loss= 0.6250, Training Accuracy= 0.653\n",
      "Epoch: 1780, Loss= 0.6187, Training Accuracy= 0.667\n",
      "Epoch: 1790, Loss= 0.6383, Training Accuracy= 0.652\n",
      "Epoch: 1800, Loss= 0.5700, Training Accuracy= 0.697\n",
      "Epoch: 1810, Loss= 0.5765, Training Accuracy= 0.693\n",
      "Epoch: 1820, Loss= 0.6057, Training Accuracy= 0.671\n",
      "Epoch: 1830, Loss= 0.6579, Training Accuracy= 0.638\n",
      "Epoch: 1840, Loss= 0.5499, Training Accuracy= 0.719\n",
      "Epoch: 1850, Loss= 0.5680, Training Accuracy= 0.702\n",
      "Epoch: 1860, Loss= 0.5483, Training Accuracy= 0.716\n",
      "Epoch: 1870, Loss= 0.5930, Training Accuracy= 0.678\n",
      "Epoch: 1880, Loss= 0.5854, Training Accuracy= 0.689\n",
      "Epoch: 1890, Loss= 0.5920, Training Accuracy= 0.687\n",
      "Epoch: 1900, Loss= 0.5545, Training Accuracy= 0.715\n",
      "Epoch: 1910, Loss= 0.5425, Training Accuracy= 0.720\n",
      "Epoch: 1920, Loss= 0.5817, Training Accuracy= 0.690\n",
      "Epoch: 1930, Loss= 0.5619, Training Accuracy= 0.707\n",
      "Epoch: 1940, Loss= 0.5777, Training Accuracy= 0.695\n",
      "Epoch: 1950, Loss= 0.5573, Training Accuracy= 0.710\n",
      "Epoch: 1960, Loss= 0.5554, Training Accuracy= 0.704\n",
      "Epoch: 1970, Loss= 0.5813, Training Accuracy= 0.692\n",
      "Epoch: 1980, Loss= 0.6196, Training Accuracy= 0.667\n",
      "Epoch: 1990, Loss= 0.6170, Training Accuracy= 0.669\n",
      "Epoch: 2000, Loss= 0.5470, Training Accuracy= 0.718\n",
      "Epoch: 2010, Loss= 0.5487, Training Accuracy= 0.716\n",
      "Epoch: 2020, Loss= 0.5923, Training Accuracy= 0.684\n",
      "Epoch: 2030, Loss= 0.6410, Training Accuracy= 0.659\n",
      "Epoch: 2040, Loss= 0.5620, Training Accuracy= 0.707\n",
      "Epoch: 2050, Loss= 0.5435, Training Accuracy= 0.719\n",
      "Epoch: 2060, Loss= 0.5609, Training Accuracy= 0.708\n",
      "Epoch: 2070, Loss= 0.5458, Training Accuracy= 0.719\n",
      "Epoch: 2080, Loss= 0.5356, Training Accuracy= 0.726\n",
      "Epoch: 2090, Loss= 0.6746, Training Accuracy= 0.624\n",
      "Epoch: 2100, Loss= 0.5831, Training Accuracy= 0.691\n",
      "Epoch: 2110, Loss= 0.5802, Training Accuracy= 0.690\n",
      "Epoch: 2120, Loss= 0.6309, Training Accuracy= 0.662\n",
      "Epoch: 2130, Loss= 0.5371, Training Accuracy= 0.725\n",
      "Epoch: 2140, Loss= 0.6298, Training Accuracy= 0.661\n",
      "Epoch: 2150, Loss= 0.5542, Training Accuracy= 0.714\n",
      "Epoch: 2160, Loss= 0.5725, Training Accuracy= 0.697\n",
      "Epoch: 2170, Loss= 0.7016, Training Accuracy= 0.589\n",
      "Epoch: 2180, Loss= 0.5567, Training Accuracy= 0.708\n",
      "Epoch: 2190, Loss= 0.5291, Training Accuracy= 0.730\n",
      "Epoch: 2200, Loss= 0.5671, Training Accuracy= 0.706\n",
      "Epoch: 2210, Loss= 0.5648, Training Accuracy= 0.703\n",
      "Epoch: 2220, Loss= 0.5544, Training Accuracy= 0.709\n",
      "Epoch: 2230, Loss= 0.5440, Training Accuracy= 0.721\n",
      "Epoch: 2240, Loss= 0.5850, Training Accuracy= 0.692\n",
      "Epoch: 2250, Loss= 0.6989, Training Accuracy= 0.597\n",
      "Epoch: 2260, Loss= 0.5592, Training Accuracy= 0.711\n",
      "Epoch: 2270, Loss= 0.5395, Training Accuracy= 0.722\n",
      "Epoch: 2280, Loss= 0.5401, Training Accuracy= 0.726\n",
      "Epoch: 2290, Loss= 0.5488, Training Accuracy= 0.716\n",
      "Epoch: 2300, Loss= 0.5850, Training Accuracy= 0.690\n",
      "Epoch: 2310, Loss= 0.5440, Training Accuracy= 0.723\n",
      "Epoch: 2320, Loss= 0.6600, Training Accuracy= 0.610\n",
      "Epoch: 2330, Loss= 0.5522, Training Accuracy= 0.715\n",
      "Epoch: 2340, Loss= 0.5201, Training Accuracy= 0.745\n",
      "Epoch: 2350, Loss= 0.5861, Training Accuracy= 0.688\n",
      "Epoch: 2360, Loss= 0.5254, Training Accuracy= 0.732\n",
      "Epoch: 2370, Loss= 0.6773, Training Accuracy= 0.629\n",
      "Epoch: 2380, Loss= 0.5351, Training Accuracy= 0.723\n",
      "Epoch: 2390, Loss= 0.5728, Training Accuracy= 0.701\n",
      "Epoch: 2400, Loss= 0.6159, Training Accuracy= 0.659\n",
      "Epoch: 2410, Loss= 0.5758, Training Accuracy= 0.698\n",
      "Epoch: 2420, Loss= 0.5636, Training Accuracy= 0.709\n",
      "Epoch: 2430, Loss= 0.5580, Training Accuracy= 0.711\n",
      "Epoch: 2440, Loss= 0.5480, Training Accuracy= 0.715\n",
      "Epoch: 2450, Loss= 0.5475, Training Accuracy= 0.715\n",
      "Epoch: 2460, Loss= 0.5786, Training Accuracy= 0.692\n",
      "Epoch: 2470, Loss= 0.5709, Training Accuracy= 0.697\n",
      "Epoch: 2480, Loss= 0.5852, Training Accuracy= 0.688\n",
      "Epoch: 2490, Loss= 0.7845, Training Accuracy= 0.516\n",
      "Epoch: 2500, Loss= 0.6917, Training Accuracy= 0.542\n",
      "Epoch: 2510, Loss= 0.6812, Training Accuracy= 0.562\n",
      "Epoch: 2520, Loss= 0.6759, Training Accuracy= 0.568\n",
      "Epoch: 2530, Loss= 0.6630, Training Accuracy= 0.586\n",
      "Epoch: 2540, Loss= 0.6643, Training Accuracy= 0.586\n",
      "Epoch: 2550, Loss= 0.6479, Training Accuracy= 0.607\n",
      "Epoch: 2560, Loss= 0.6620, Training Accuracy= 0.588\n",
      "Epoch: 2570, Loss= 0.6582, Training Accuracy= 0.602\n",
      "Epoch: 2580, Loss= 0.6284, Training Accuracy= 0.637\n",
      "Epoch: 2590, Loss= 0.6299, Training Accuracy= 0.630\n",
      "Epoch: 2600, Loss= 0.6214, Training Accuracy= 0.641\n",
      "Epoch: 2610, Loss= 0.6174, Training Accuracy= 0.647\n",
      "Epoch: 2620, Loss= 0.6238, Training Accuracy= 0.643\n",
      "Epoch: 2630, Loss= 0.6329, Training Accuracy= 0.633\n",
      "Epoch: 2640, Loss= 0.5903, Training Accuracy= 0.663\n",
      "Epoch: 2650, Loss= 0.5280, Training Accuracy= 0.701\n",
      "Epoch: 2660, Loss= 0.4561, Training Accuracy= 0.754\n",
      "Epoch: 2670, Loss= 0.3426, Training Accuracy= 0.823\n",
      "Epoch: 2680, Loss= 0.4009, Training Accuracy= 0.788\n",
      "Epoch: 2690, Loss= 0.2303, Training Accuracy= 0.881\n",
      "Epoch: 2700, Loss= 0.4299, Training Accuracy= 0.757\n",
      "Epoch: 2710, Loss= 0.2438, Training Accuracy= 0.879\n",
      "Epoch: 2720, Loss= 0.1278, Training Accuracy= 0.942\n",
      "Epoch: 2730, Loss= 0.0803, Training Accuracy= 0.970\n",
      "Epoch: 2740, Loss= 0.3752, Training Accuracy= 0.844\n",
      "Epoch: 2750, Loss= 0.0628, Training Accuracy= 0.975\n",
      "Epoch: 2760, Loss= 0.0477, Training Accuracy= 0.983\n",
      "Epoch: 2770, Loss= 0.0336, Training Accuracy= 0.988\n",
      "Epoch: 2780, Loss= 0.0278, Training Accuracy= 0.990\n",
      "Epoch: 2790, Loss= 0.0241, Training Accuracy= 0.992\n",
      "Epoch: 2800, Loss= 0.0203, Training Accuracy= 0.993\n",
      "Epoch: 2810, Loss= 0.0181, Training Accuracy= 0.994\n",
      "Epoch: 2820, Loss= 0.0145, Training Accuracy= 0.995\n",
      "Epoch: 2830, Loss= 0.0126, Training Accuracy= 0.996\n",
      "Epoch: 2840, Loss= 0.0110, Training Accuracy= 0.997\n",
      "Epoch: 2850, Loss= 0.0609, Training Accuracy= 0.973\n",
      "Epoch: 2860, Loss= 0.0431, Training Accuracy= 0.982\n",
      "Epoch: 2870, Loss= 0.0315, Training Accuracy= 0.987\n",
      "Epoch: 2880, Loss= 0.0239, Training Accuracy= 0.990\n",
      "Epoch: 2890, Loss= 0.0208, Training Accuracy= 0.990\n",
      "Epoch: 2900, Loss= 0.0172, Training Accuracy= 0.993\n",
      "Epoch: 2910, Loss= 0.0152, Training Accuracy= 0.994\n",
      "Epoch: 2920, Loss= 0.0135, Training Accuracy= 0.994\n",
      "Epoch: 2930, Loss= 0.0129, Training Accuracy= 0.995\n",
      "Epoch: 2940, Loss= 0.2820, Training Accuracy= 0.854\n",
      "Epoch: 2950, Loss= 0.1935, Training Accuracy= 0.900\n",
      "Epoch: 2960, Loss= 0.1592, Training Accuracy= 0.917\n",
      "Epoch: 2970, Loss= 0.1311, Training Accuracy= 0.924\n",
      "Epoch: 2980, Loss= 0.1035, Training Accuracy= 0.947\n",
      "Epoch: 2990, Loss= 0.0888, Training Accuracy= 0.957\n",
      "Epoch: 3000, Loss= 0.0546, Training Accuracy= 0.975\n",
      "Epoch: 3010, Loss= 0.0350, Training Accuracy= 0.986\n",
      "Epoch: 3020, Loss= 0.1079, Training Accuracy= 0.966\n",
      "Epoch: 3030, Loss= 0.0232, Training Accuracy= 0.992\n",
      "Epoch: 3040, Loss= 0.0117, Training Accuracy= 0.997\n",
      "Epoch: 3050, Loss= 0.0090, Training Accuracy= 0.998\n",
      "Epoch: 3060, Loss= 0.0078, Training Accuracy= 0.998\n",
      "Epoch: 3070, Loss= 0.0062, Training Accuracy= 0.998\n",
      "Epoch: 3080, Loss= 0.3817, Training Accuracy= 0.798\n",
      "Epoch: 3090, Loss= 0.3409, Training Accuracy= 0.819\n",
      "Epoch: 3100, Loss= 0.3069, Training Accuracy= 0.837\n",
      "Epoch: 3110, Loss= 0.2445, Training Accuracy= 0.865\n",
      "Epoch: 3120, Loss= 0.2031, Training Accuracy= 0.887\n",
      "Epoch: 3130, Loss= 0.1877, Training Accuracy= 0.902\n",
      "Epoch: 3140, Loss= 0.2337, Training Accuracy= 0.897\n",
      "Epoch: 3150, Loss= 0.3174, Training Accuracy= 0.888\n",
      "Epoch: 3160, Loss= 0.0540, Training Accuracy= 0.979\n",
      "Epoch: 3170, Loss= 0.0386, Training Accuracy= 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3180, Loss= 0.0384, Training Accuracy= 0.984\n",
      "Epoch: 3190, Loss= 0.0257, Training Accuracy= 0.989\n",
      "Epoch: 3200, Loss= 0.0264, Training Accuracy= 0.989\n",
      "Epoch: 3210, Loss= 0.0133, Training Accuracy= 0.995\n",
      "Epoch: 3220, Loss= 0.0108, Training Accuracy= 0.996\n",
      "Epoch: 3230, Loss= 0.0095, Training Accuracy= 0.997\n",
      "Epoch: 3240, Loss= 0.0076, Training Accuracy= 0.997\n",
      "Epoch: 3250, Loss= 0.0062, Training Accuracy= 0.997\n",
      "Epoch: 3260, Loss= 0.5080, Training Accuracy= 0.744\n",
      "Epoch: 3270, Loss= 0.4838, Training Accuracy= 0.754\n",
      "Epoch: 3280, Loss= 0.4920, Training Accuracy= 0.783\n",
      "Epoch: 3290, Loss= 0.4223, Training Accuracy= 0.847\n",
      "Epoch: 3300, Loss= 0.8517, Training Accuracy= 0.502\n",
      "Epoch: 3310, Loss= 0.8369, Training Accuracy= 0.502\n",
      "Epoch: 3320, Loss= 0.8260, Training Accuracy= 0.502\n",
      "Epoch: 3330, Loss= 0.8185, Training Accuracy= 0.502\n",
      "Epoch: 3340, Loss= 0.8139, Training Accuracy= 0.502\n",
      "Epoch: 3350, Loss= 0.8113, Training Accuracy= 0.502\n",
      "Epoch: 3360, Loss= 0.8096, Training Accuracy= 0.502\n",
      "Epoch: 3370, Loss= 0.8078, Training Accuracy= 0.502\n",
      "Epoch: 3380, Loss= 0.8048, Training Accuracy= 0.502\n",
      "Epoch: 3390, Loss= 0.8001, Training Accuracy= 0.502\n",
      "Epoch: 3400, Loss= 0.7984, Training Accuracy= 0.502\n",
      "Epoch: 3410, Loss= 0.7976, Training Accuracy= 0.502\n",
      "Epoch: 3420, Loss= 0.7972, Training Accuracy= 0.502\n",
      "Epoch: 3430, Loss= 0.7967, Training Accuracy= 0.502\n",
      "Epoch: 3440, Loss= 0.7963, Training Accuracy= 0.502\n",
      "Epoch: 3450, Loss= 0.7960, Training Accuracy= 0.502\n",
      "Epoch: 3460, Loss= 0.7956, Training Accuracy= 0.502\n",
      "Epoch: 3470, Loss= 0.7953, Training Accuracy= 0.502\n",
      "Epoch: 3480, Loss= 0.7950, Training Accuracy= 0.502\n",
      "Epoch: 3490, Loss= 0.7947, Training Accuracy= 0.502\n",
      "Epoch: 3500, Loss= 0.7944, Training Accuracy= 0.502\n",
      "Epoch: 3510, Loss= 0.7939, Training Accuracy= 0.502\n",
      "Epoch: 3520, Loss= 0.7935, Training Accuracy= 0.502\n",
      "Epoch: 3530, Loss= 0.7931, Training Accuracy= 0.502\n",
      "Epoch: 3540, Loss= 0.7929, Training Accuracy= 0.502\n",
      "Epoch: 3550, Loss= 0.7928, Training Accuracy= 0.502\n",
      "Epoch: 3560, Loss= 0.7927, Training Accuracy= 0.502\n",
      "Epoch: 3570, Loss= 0.7928, Training Accuracy= 0.502\n",
      "Epoch: 3580, Loss= 0.7957, Training Accuracy= 0.502\n",
      "Epoch: 3590, Loss= 0.7932, Training Accuracy= 0.502\n",
      "Epoch: 3600, Loss= 0.7941, Training Accuracy= 0.502\n",
      "Epoch: 3610, Loss= 0.7970, Training Accuracy= 0.502\n",
      "Epoch: 3620, Loss= 0.8038, Training Accuracy= 0.508\n",
      "Epoch: 3630, Loss= 0.7879, Training Accuracy= 0.528\n",
      "Epoch: 3640, Loss= 0.8604, Training Accuracy= 0.502\n",
      "Epoch: 3650, Loss= 0.7366, Training Accuracy= 0.572\n",
      "Epoch: 3660, Loss= 0.8398, Training Accuracy= 0.516\n",
      "Epoch: 3670, Loss= 0.7864, Training Accuracy= 0.574\n",
      "Epoch: 3680, Loss= 0.7128, Training Accuracy= 0.615\n",
      "Epoch: 3690, Loss= 0.8611, Training Accuracy= 0.590\n",
      "Epoch: 3700, Loss= 0.2701, Training Accuracy= 0.874\n",
      "Epoch: 3710, Loss= 0.6524, Training Accuracy= 0.732\n",
      "Epoch: 3720, Loss= 0.1700, Training Accuracy= 0.922\n",
      "Epoch: 3730, Loss= 0.8761, Training Accuracy= 0.502\n",
      "Epoch: 3740, Loss= 0.8407, Training Accuracy= 0.502\n",
      "Epoch: 3750, Loss= 0.8209, Training Accuracy= 0.502\n",
      "Epoch: 3760, Loss= 0.8091, Training Accuracy= 0.502\n",
      "Epoch: 3770, Loss= 0.8011, Training Accuracy= 0.502\n",
      "Epoch: 3780, Loss= 0.7944, Training Accuracy= 0.502\n",
      "Epoch: 3790, Loss= 0.7881, Training Accuracy= 0.502\n",
      "Epoch: 3800, Loss= 0.7819, Training Accuracy= 0.502\n",
      "Epoch: 3810, Loss= 0.7768, Training Accuracy= 0.502\n",
      "Epoch: 3820, Loss= 0.7729, Training Accuracy= 0.502\n",
      "Epoch: 3830, Loss= 0.7686, Training Accuracy= 0.502\n",
      "Epoch: 3840, Loss= 0.7636, Training Accuracy= 0.502\n",
      "Epoch: 3850, Loss= 0.7586, Training Accuracy= 0.502\n",
      "Epoch: 3860, Loss= 0.7545, Training Accuracy= 0.502\n",
      "Epoch: 3870, Loss= 0.7513, Training Accuracy= 0.502\n",
      "Epoch: 3880, Loss= 0.7488, Training Accuracy= 0.502\n",
      "Epoch: 3890, Loss= 0.7469, Training Accuracy= 0.502\n",
      "Epoch: 3900, Loss= 0.7454, Training Accuracy= 0.502\n",
      "Epoch: 3910, Loss= 0.7442, Training Accuracy= 0.502\n",
      "Epoch: 3920, Loss= 0.7432, Training Accuracy= 0.502\n",
      "Epoch: 3930, Loss= 0.7424, Training Accuracy= 0.502\n",
      "Epoch: 3940, Loss= 0.7418, Training Accuracy= 0.502\n",
      "Epoch: 3950, Loss= 0.7412, Training Accuracy= 0.502\n",
      "Epoch: 3960, Loss= 0.7407, Training Accuracy= 0.502\n",
      "Epoch: 3970, Loss= 0.7402, Training Accuracy= 0.502\n",
      "Epoch: 3980, Loss= 0.7398, Training Accuracy= 0.502\n",
      "Epoch: 3990, Loss= 0.7394, Training Accuracy= 0.502\n",
      "Epoch: 4000, Loss= 0.7390, Training Accuracy= 0.502\n",
      "Epoch: 4010, Loss= 0.7386, Training Accuracy= 0.502\n",
      "Epoch: 4020, Loss= 0.7382, Training Accuracy= 0.502\n",
      "Epoch: 4030, Loss= 0.7378, Training Accuracy= 0.502\n",
      "Epoch: 4040, Loss= 0.7374, Training Accuracy= 0.502\n",
      "Epoch: 4050, Loss= 0.7370, Training Accuracy= 0.502\n",
      "Epoch: 4060, Loss= 0.7365, Training Accuracy= 0.502\n",
      "Epoch: 4070, Loss= 0.7360, Training Accuracy= 0.502\n",
      "Epoch: 4080, Loss= 0.7355, Training Accuracy= 0.502\n",
      "Epoch: 4090, Loss= 0.7350, Training Accuracy= 0.502\n",
      "Epoch: 4100, Loss= 0.7345, Training Accuracy= 0.502\n",
      "Epoch: 4110, Loss= 0.7340, Training Accuracy= 0.502\n",
      "Epoch: 4120, Loss= 0.7336, Training Accuracy= 0.502\n",
      "Epoch: 4130, Loss= 0.7332, Training Accuracy= 0.502\n",
      "Epoch: 4140, Loss= 0.7328, Training Accuracy= 0.502\n",
      "Epoch: 4150, Loss= 0.7324, Training Accuracy= 0.502\n",
      "Epoch: 4160, Loss= 0.7322, Training Accuracy= 0.502\n",
      "Epoch: 4170, Loss= 0.7319, Training Accuracy= 0.502\n",
      "Epoch: 4180, Loss= 0.7317, Training Accuracy= 0.502\n",
      "Epoch: 4190, Loss= 0.7316, Training Accuracy= 0.502\n",
      "Epoch: 4200, Loss= 0.7314, Training Accuracy= 0.502\n",
      "Epoch: 4210, Loss= 0.7313, Training Accuracy= 0.502\n",
      "Epoch: 4220, Loss= 0.7312, Training Accuracy= 0.502\n",
      "Epoch: 4230, Loss= 0.7311, Training Accuracy= 0.502\n",
      "Epoch: 4240, Loss= 0.7311, Training Accuracy= 0.502\n",
      "Epoch: 4250, Loss= 0.7310, Training Accuracy= 0.502\n",
      "Epoch: 4260, Loss= 0.7310, Training Accuracy= 0.502\n",
      "Epoch: 4270, Loss= 0.7310, Training Accuracy= 0.502\n",
      "Epoch: 4280, Loss= 0.7310, Training Accuracy= 0.502\n",
      "Epoch: 4290, Loss= 0.7310, Training Accuracy= 0.502\n",
      "Epoch: 4300, Loss= 0.7310, Training Accuracy= 0.502\n",
      "Epoch: 4310, Loss= 0.7310, Training Accuracy= 0.502\n",
      "Epoch: 4320, Loss= 0.7310, Training Accuracy= 0.502\n",
      "Epoch: 4330, Loss= 0.7310, Training Accuracy= 0.502\n",
      "Epoch: 4340, Loss= 0.7310, Training Accuracy= 0.502\n",
      "Epoch: 4350, Loss= 0.7309, Training Accuracy= 0.502\n",
      "Epoch: 4360, Loss= 0.7309, Training Accuracy= 0.502\n",
      "Epoch: 4370, Loss= 0.7309, Training Accuracy= 0.502\n",
      "Epoch: 4380, Loss= 0.7309, Training Accuracy= 0.502\n",
      "Epoch: 4390, Loss= 0.7308, Training Accuracy= 0.502\n",
      "Epoch: 4400, Loss= 0.7308, Training Accuracy= 0.502\n",
      "Epoch: 4410, Loss= 0.7308, Training Accuracy= 0.502\n",
      "Epoch: 4420, Loss= 0.7307, Training Accuracy= 0.502\n",
      "Epoch: 4430, Loss= 0.7307, Training Accuracy= 0.502\n",
      "Epoch: 4440, Loss= 0.7306, Training Accuracy= 0.502\n",
      "Epoch: 4450, Loss= 0.7306, Training Accuracy= 0.502\n",
      "Epoch: 4460, Loss= 0.7306, Training Accuracy= 0.502\n",
      "Epoch: 4470, Loss= 0.7305, Training Accuracy= 0.502\n",
      "Epoch: 4480, Loss= 0.7305, Training Accuracy= 0.502\n",
      "Epoch: 4490, Loss= 0.7304, Training Accuracy= 0.502\n",
      "Epoch: 4500, Loss= 0.7304, Training Accuracy= 0.502\n",
      "Epoch: 4510, Loss= 0.7303, Training Accuracy= 0.502\n",
      "Epoch: 4520, Loss= 0.7303, Training Accuracy= 0.502\n",
      "Epoch: 4530, Loss= 0.7302, Training Accuracy= 0.502\n",
      "Epoch: 4540, Loss= 0.7302, Training Accuracy= 0.502\n",
      "Epoch: 4550, Loss= 0.7301, Training Accuracy= 0.502\n",
      "Epoch: 4560, Loss= 0.7301, Training Accuracy= 0.502\n",
      "Epoch: 4570, Loss= 0.7300, Training Accuracy= 0.502\n",
      "Epoch: 4580, Loss= 0.7299, Training Accuracy= 0.502\n",
      "Epoch: 4590, Loss= 0.7298, Training Accuracy= 0.502\n",
      "Epoch: 4600, Loss= 0.7298, Training Accuracy= 0.502\n",
      "Epoch: 4610, Loss= 0.7297, Training Accuracy= 0.502\n",
      "Epoch: 4620, Loss= 0.7296, Training Accuracy= 0.502\n",
      "Epoch: 4630, Loss= 0.7295, Training Accuracy= 0.502\n",
      "Epoch: 4640, Loss= 0.7294, Training Accuracy= 0.502\n",
      "Epoch: 4650, Loss= 0.7293, Training Accuracy= 0.502\n",
      "Epoch: 4660, Loss= 0.7292, Training Accuracy= 0.502\n",
      "Epoch: 4670, Loss= 0.7291, Training Accuracy= 0.502\n",
      "Epoch: 4680, Loss= 0.7289, Training Accuracy= 0.502\n",
      "Epoch: 4690, Loss= 0.7287, Training Accuracy= 0.502\n",
      "Epoch: 4700, Loss= 0.7285, Training Accuracy= 0.502\n",
      "Epoch: 4710, Loss= 0.7282, Training Accuracy= 0.502\n",
      "Epoch: 4720, Loss= 0.7280, Training Accuracy= 0.502\n",
      "Epoch: 4730, Loss= 0.7278, Training Accuracy= 0.502\n",
      "Epoch: 4740, Loss= 0.7277, Training Accuracy= 0.502\n",
      "Epoch: 4750, Loss= 0.7276, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4760, Loss= 0.7277, Training Accuracy= 0.502\n",
      "Epoch: 4770, Loss= 0.7276, Training Accuracy= 0.502\n",
      "Epoch: 4780, Loss= 0.7270, Training Accuracy= 0.502\n",
      "Epoch: 4790, Loss= 0.7263, Training Accuracy= 0.502\n",
      "Epoch: 4800, Loss= 0.7259, Training Accuracy= 0.502\n",
      "Epoch: 4810, Loss= 0.7255, Training Accuracy= 0.503\n",
      "Epoch: 4820, Loss= 0.7252, Training Accuracy= 0.503\n",
      "Epoch: 4830, Loss= 0.7249, Training Accuracy= 0.503\n",
      "Epoch: 4840, Loss= 0.7245, Training Accuracy= 0.503\n",
      "Epoch: 4850, Loss= 0.7242, Training Accuracy= 0.503\n",
      "Epoch: 4860, Loss= 0.7239, Training Accuracy= 0.503\n",
      "Epoch: 4870, Loss= 0.7234, Training Accuracy= 0.503\n",
      "Epoch: 4880, Loss= 0.7231, Training Accuracy= 0.503\n",
      "Epoch: 4890, Loss= 0.7229, Training Accuracy= 0.503\n",
      "Epoch: 4900, Loss= 0.7227, Training Accuracy= 0.503\n",
      "Epoch: 4910, Loss= 0.7226, Training Accuracy= 0.503\n",
      "Epoch: 4920, Loss= 0.7228, Training Accuracy= 0.503\n",
      "Epoch: 4930, Loss= 0.7219, Training Accuracy= 0.503\n",
      "Epoch: 4940, Loss= 0.7218, Training Accuracy= 0.503\n",
      "Epoch: 4950, Loss= 0.7217, Training Accuracy= 0.503\n",
      "Epoch: 4960, Loss= 0.7217, Training Accuracy= 0.503\n",
      "Epoch: 4970, Loss= 0.7215, Training Accuracy= 0.503\n",
      "Epoch: 4980, Loss= 0.7213, Training Accuracy= 0.502\n",
      "Epoch: 4990, Loss= 0.7212, Training Accuracy= 0.502\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5076\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.7279, Training Accuracy= 0.495\n",
      "Epoch: 10, Loss= 0.7137, Training Accuracy= 0.495\n",
      "Epoch: 20, Loss= 0.7088, Training Accuracy= 0.495\n",
      "Epoch: 30, Loss= 0.7061, Training Accuracy= 0.495\n",
      "Epoch: 40, Loss= 0.7044, Training Accuracy= 0.495\n",
      "Epoch: 50, Loss= 0.7032, Training Accuracy= 0.495\n",
      "Epoch: 60, Loss= 0.7023, Training Accuracy= 0.495\n",
      "Epoch: 70, Loss= 0.7016, Training Accuracy= 0.495\n",
      "Epoch: 80, Loss= 0.7011, Training Accuracy= 0.495\n",
      "Epoch: 90, Loss= 0.7006, Training Accuracy= 0.495\n",
      "Epoch: 100, Loss= 0.7003, Training Accuracy= 0.495\n",
      "Epoch: 110, Loss= 0.7000, Training Accuracy= 0.495\n",
      "Epoch: 120, Loss= 0.6997, Training Accuracy= 0.495\n",
      "Epoch: 130, Loss= 0.6995, Training Accuracy= 0.495\n",
      "Epoch: 140, Loss= 0.6993, Training Accuracy= 0.495\n",
      "Epoch: 150, Loss= 0.6991, Training Accuracy= 0.495\n",
      "Epoch: 160, Loss= 0.6989, Training Accuracy= 0.495\n",
      "Epoch: 170, Loss= 0.6988, Training Accuracy= 0.495\n",
      "Epoch: 180, Loss= 0.6987, Training Accuracy= 0.495\n",
      "Epoch: 190, Loss= 0.6985, Training Accuracy= 0.495\n",
      "Epoch: 200, Loss= 0.6984, Training Accuracy= 0.495\n",
      "Epoch: 210, Loss= 0.6984, Training Accuracy= 0.495\n",
      "Epoch: 220, Loss= 0.6983, Training Accuracy= 0.495\n",
      "Epoch: 230, Loss= 0.6982, Training Accuracy= 0.495\n",
      "Epoch: 240, Loss= 0.6981, Training Accuracy= 0.495\n",
      "Epoch: 250, Loss= 0.6981, Training Accuracy= 0.495\n",
      "Epoch: 260, Loss= 0.6980, Training Accuracy= 0.495\n",
      "Epoch: 270, Loss= 0.6979, Training Accuracy= 0.495\n",
      "Epoch: 280, Loss= 0.6979, Training Accuracy= 0.495\n",
      "Epoch: 290, Loss= 0.6979, Training Accuracy= 0.495\n",
      "Epoch: 300, Loss= 0.6978, Training Accuracy= 0.495\n",
      "Epoch: 310, Loss= 0.6978, Training Accuracy= 0.495\n",
      "Epoch: 320, Loss= 0.6978, Training Accuracy= 0.495\n",
      "Epoch: 330, Loss= 0.6977, Training Accuracy= 0.495\n",
      "Epoch: 340, Loss= 0.6977, Training Accuracy= 0.495\n",
      "Epoch: 350, Loss= 0.6977, Training Accuracy= 0.495\n",
      "Epoch: 360, Loss= 0.6977, Training Accuracy= 0.496\n",
      "Epoch: 370, Loss= 0.6977, Training Accuracy= 0.496\n",
      "Epoch: 380, Loss= 0.6977, Training Accuracy= 0.496\n",
      "Epoch: 390, Loss= 0.6976, Training Accuracy= 0.496\n",
      "Epoch: 400, Loss= 0.6976, Training Accuracy= 0.497\n",
      "Epoch: 410, Loss= 0.6975, Training Accuracy= 0.497\n",
      "Epoch: 420, Loss= 0.6975, Training Accuracy= 0.496\n",
      "Epoch: 430, Loss= 0.6975, Training Accuracy= 0.497\n",
      "Epoch: 440, Loss= 0.6974, Training Accuracy= 0.497\n",
      "Epoch: 450, Loss= 0.6974, Training Accuracy= 0.497\n",
      "Epoch: 460, Loss= 0.6973, Training Accuracy= 0.497\n",
      "Epoch: 470, Loss= 0.6973, Training Accuracy= 0.498\n",
      "Epoch: 480, Loss= 0.6973, Training Accuracy= 0.498\n",
      "Epoch: 490, Loss= 0.6973, Training Accuracy= 0.498\n",
      "Epoch: 500, Loss= 0.6973, Training Accuracy= 0.498\n",
      "Epoch: 510, Loss= 0.6973, Training Accuracy= 0.497\n",
      "Epoch: 520, Loss= 0.6973, Training Accuracy= 0.498\n",
      "Epoch: 530, Loss= 0.6973, Training Accuracy= 0.498\n",
      "Epoch: 540, Loss= 0.6973, Training Accuracy= 0.499\n",
      "Epoch: 550, Loss= 0.6972, Training Accuracy= 0.499\n",
      "Epoch: 560, Loss= 0.6972, Training Accuracy= 0.498\n",
      "Epoch: 570, Loss= 0.6972, Training Accuracy= 0.499\n",
      "Epoch: 580, Loss= 0.6972, Training Accuracy= 0.499\n",
      "Epoch: 590, Loss= 0.6971, Training Accuracy= 0.499\n",
      "Epoch: 600, Loss= 0.6971, Training Accuracy= 0.498\n",
      "Epoch: 610, Loss= 0.6970, Training Accuracy= 0.499\n",
      "Epoch: 620, Loss= 0.6970, Training Accuracy= 0.500\n",
      "Epoch: 630, Loss= 0.6970, Training Accuracy= 0.499\n",
      "Epoch: 640, Loss= 0.6970, Training Accuracy= 0.499\n",
      "Epoch: 650, Loss= 0.6970, Training Accuracy= 0.499\n",
      "Epoch: 660, Loss= 0.6972, Training Accuracy= 0.500\n",
      "Epoch: 670, Loss= 0.6972, Training Accuracy= 0.498\n",
      "Epoch: 680, Loss= 0.6972, Training Accuracy= 0.498\n",
      "Epoch: 690, Loss= 0.6969, Training Accuracy= 0.498\n",
      "Epoch: 700, Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 710, Loss= 0.6978, Training Accuracy= 0.504\n",
      "Epoch: 720, Loss= 0.6969, Training Accuracy= 0.502\n",
      "Epoch: 730, Loss= 0.6971, Training Accuracy= 0.502\n",
      "Epoch: 740, Loss= 0.6974, Training Accuracy= 0.503\n",
      "Epoch: 750, Loss= 0.6967, Training Accuracy= 0.504\n",
      "Epoch: 760, Loss= 0.6963, Training Accuracy= 0.505\n",
      "Epoch: 770, Loss= 0.6958, Training Accuracy= 0.506\n",
      "Epoch: 780, Loss= 0.6959, Training Accuracy= 0.506\n",
      "Epoch: 790, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 800, Loss= 0.6958, Training Accuracy= 0.504\n",
      "Epoch: 810, Loss= 0.6959, Training Accuracy= 0.511\n",
      "Epoch: 820, Loss= 0.6985, Training Accuracy= 0.501\n",
      "Epoch: 830, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 840, Loss= 0.6966, Training Accuracy= 0.508\n",
      "Epoch: 850, Loss= 0.6947, Training Accuracy= 0.511\n",
      "Epoch: 860, Loss= 0.7016, Training Accuracy= 0.503\n",
      "Epoch: 870, Loss= 0.6940, Training Accuracy= 0.517\n",
      "Epoch: 880, Loss= 0.7008, Training Accuracy= 0.500\n",
      "Epoch: 890, Loss= 0.7038, Training Accuracy= 0.498\n",
      "Epoch: 900, Loss= 0.7039, Training Accuracy= 0.500\n",
      "Epoch: 910, Loss= 0.7045, Training Accuracy= 0.501\n",
      "Epoch: 920, Loss= 0.7039, Training Accuracy= 0.503\n",
      "Epoch: 930, Loss= 0.7040, Training Accuracy= 0.499\n",
      "Epoch: 940, Loss= 0.7023, Training Accuracy= 0.499\n",
      "Epoch: 950, Loss= 0.7014, Training Accuracy= 0.501\n",
      "Epoch: 960, Loss= 0.7024, Training Accuracy= 0.502\n",
      "Epoch: 970, Loss= 0.7003, Training Accuracy= 0.507\n",
      "Epoch: 980, Loss= 0.7013, Training Accuracy= 0.505\n",
      "Epoch: 990, Loss= 0.7006, Training Accuracy= 0.510\n",
      "Epoch: 1000, Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1010, Loss= 0.7027, Training Accuracy= 0.509\n",
      "Epoch: 1020, Loss= 0.7112, Training Accuracy= 0.496\n",
      "Epoch: 1030, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1040, Loss= 0.6996, Training Accuracy= 0.505\n",
      "Epoch: 1050, Loss= 0.6981, Training Accuracy= 0.508\n",
      "Epoch: 1060, Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 1070, Loss= 0.6991, Training Accuracy= 0.504\n",
      "Epoch: 1080, Loss= 0.7004, Training Accuracy= 0.511\n",
      "Epoch: 1090, Loss= 0.6990, Training Accuracy= 0.517\n",
      "Epoch: 1100, Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 1110, Loss= 0.6920, Training Accuracy= 0.516\n",
      "Epoch: 1120, Loss= 0.6920, Training Accuracy= 0.523\n",
      "Epoch: 1130, Loss= 0.6896, Training Accuracy= 0.531\n",
      "Epoch: 1140, Loss= 0.6937, Training Accuracy= 0.528\n",
      "Epoch: 1150, Loss= 0.7210, Training Accuracy= 0.503\n",
      "Epoch: 1160, Loss= 0.6932, Training Accuracy= 0.529\n",
      "Epoch: 1170, Loss= 0.6905, Training Accuracy= 0.539\n",
      "Epoch: 1180, Loss= 0.6853, Training Accuracy= 0.546\n",
      "Epoch: 1190, Loss= 0.6880, Training Accuracy= 0.539\n",
      "Epoch: 1200, Loss= 0.6904, Training Accuracy= 0.544\n",
      "Epoch: 1210, Loss= 0.6886, Training Accuracy= 0.539\n",
      "Epoch: 1220, Loss= 0.6861, Training Accuracy= 0.551\n",
      "Epoch: 1230, Loss= 0.6865, Training Accuracy= 0.544\n",
      "Epoch: 1240, Loss= 0.7007, Training Accuracy= 0.534\n",
      "Epoch: 1250, Loss= 0.6819, Training Accuracy= 0.559\n",
      "Epoch: 1260, Loss= 0.6877, Training Accuracy= 0.551\n",
      "Epoch: 1270, Loss= 0.6855, Training Accuracy= 0.561\n",
      "Epoch: 1280, Loss= 0.6783, Training Accuracy= 0.561\n",
      "Epoch: 1290, Loss= 0.6803, Training Accuracy= 0.558\n",
      "Epoch: 1300, Loss= 0.6291, Training Accuracy= 0.639\n",
      "Epoch: 1310, Loss= 0.4502, Training Accuracy= 0.749\n",
      "Epoch: 1320, Loss= 0.4272, Training Accuracy= 0.745\n",
      "Epoch: 1330, Loss= 0.3008, Training Accuracy= 0.827\n",
      "Epoch: 1340, Loss= 0.2210, Training Accuracy= 0.878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1350, Loss= 0.0984, Training Accuracy= 0.956\n",
      "Epoch: 1360, Loss= 0.2720, Training Accuracy= 0.843\n",
      "Epoch: 1370, Loss= 0.2248, Training Accuracy= 0.885\n",
      "Epoch: 1380, Loss= 0.6866, Training Accuracy= 0.622\n",
      "Epoch: 1390, Loss= 0.3602, Training Accuracy= 0.816\n",
      "Epoch: 1400, Loss= 0.3404, Training Accuracy= 0.828\n",
      "Epoch: 1410, Loss= 0.4039, Training Accuracy= 0.774\n",
      "Epoch: 1420, Loss= 0.2716, Training Accuracy= 0.856\n",
      "Epoch: 1430, Loss= 0.2293, Training Accuracy= 0.874\n",
      "Epoch: 1440, Loss= 0.4213, Training Accuracy= 0.793\n",
      "Epoch: 1450, Loss= 1.0739, Training Accuracy= 0.495\n",
      "Epoch: 1460, Loss= 0.9199, Training Accuracy= 0.495\n",
      "Epoch: 1470, Loss= 0.8819, Training Accuracy= 0.495\n",
      "Epoch: 1480, Loss= 0.7883, Training Accuracy= 0.495\n",
      "Epoch: 1490, Loss= 0.7684, Training Accuracy= 0.495\n",
      "Epoch: 1500, Loss= 0.7647, Training Accuracy= 0.495\n",
      "Epoch: 1510, Loss= 0.7626, Training Accuracy= 0.495\n",
      "Epoch: 1520, Loss= 0.7607, Training Accuracy= 0.495\n",
      "Epoch: 1530, Loss= 0.7576, Training Accuracy= 0.495\n",
      "Epoch: 1540, Loss= 0.7526, Training Accuracy= 0.495\n",
      "Epoch: 1550, Loss= 0.7491, Training Accuracy= 0.495\n",
      "Epoch: 1560, Loss= 0.7479, Training Accuracy= 0.495\n",
      "Epoch: 1570, Loss= 0.7473, Training Accuracy= 0.495\n",
      "Epoch: 1580, Loss= 0.7470, Training Accuracy= 0.495\n",
      "Epoch: 1590, Loss= 0.7468, Training Accuracy= 0.495\n",
      "Epoch: 1600, Loss= 0.7466, Training Accuracy= 0.495\n",
      "Epoch: 1610, Loss= 0.7465, Training Accuracy= 0.495\n",
      "Epoch: 1620, Loss= 0.7464, Training Accuracy= 0.495\n",
      "Epoch: 1630, Loss= 0.7463, Training Accuracy= 0.495\n",
      "Epoch: 1640, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 1650, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 1660, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 1670, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 1680, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 1690, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 1700, Loss= 0.7463, Training Accuracy= 0.495\n",
      "Epoch: 1710, Loss= 0.7464, Training Accuracy= 0.495\n",
      "Epoch: 1720, Loss= 0.7465, Training Accuracy= 0.495\n",
      "Epoch: 1730, Loss= 0.7466, Training Accuracy= 0.495\n",
      "Epoch: 1740, Loss= 0.7467, Training Accuracy= 0.495\n",
      "Epoch: 1750, Loss= 0.7468, Training Accuracy= 0.495\n",
      "Epoch: 1760, Loss= 0.7469, Training Accuracy= 0.495\n",
      "Epoch: 1770, Loss= 0.7470, Training Accuracy= 0.495\n",
      "Epoch: 1780, Loss= 0.7471, Training Accuracy= 0.495\n",
      "Epoch: 1790, Loss= 0.7472, Training Accuracy= 0.495\n",
      "Epoch: 1800, Loss= 0.7473, Training Accuracy= 0.495\n",
      "Epoch: 1810, Loss= 0.7474, Training Accuracy= 0.495\n",
      "Epoch: 1820, Loss= 0.7476, Training Accuracy= 0.495\n",
      "Epoch: 1830, Loss= 0.7477, Training Accuracy= 0.495\n",
      "Epoch: 1840, Loss= 0.7478, Training Accuracy= 0.495\n",
      "Epoch: 1850, Loss= 0.7480, Training Accuracy= 0.495\n",
      "Epoch: 1860, Loss= 0.7481, Training Accuracy= 0.495\n",
      "Epoch: 1870, Loss= 0.7483, Training Accuracy= 0.495\n",
      "Epoch: 1880, Loss= 0.7485, Training Accuracy= 0.495\n",
      "Epoch: 1890, Loss= 0.7486, Training Accuracy= 0.495\n",
      "Epoch: 1900, Loss= 0.7488, Training Accuracy= 0.495\n",
      "Epoch: 1910, Loss= 0.7489, Training Accuracy= 0.495\n",
      "Epoch: 1920, Loss= 0.7491, Training Accuracy= 0.495\n",
      "Epoch: 1930, Loss= 0.7492, Training Accuracy= 0.495\n",
      "Epoch: 1940, Loss= 0.7493, Training Accuracy= 0.495\n",
      "Epoch: 1950, Loss= 0.7494, Training Accuracy= 0.495\n",
      "Epoch: 1960, Loss= 0.7495, Training Accuracy= 0.495\n",
      "Epoch: 1970, Loss= 0.7496, Training Accuracy= 0.495\n",
      "Epoch: 1980, Loss= 0.7497, Training Accuracy= 0.495\n",
      "Epoch: 1990, Loss= 0.7498, Training Accuracy= 0.495\n",
      "Epoch: 2000, Loss= 0.7498, Training Accuracy= 0.495\n",
      "Epoch: 2010, Loss= 0.7499, Training Accuracy= 0.495\n",
      "Epoch: 2020, Loss= 0.7499, Training Accuracy= 0.495\n",
      "Epoch: 2030, Loss= 0.7500, Training Accuracy= 0.495\n",
      "Epoch: 2040, Loss= 0.7500, Training Accuracy= 0.495\n",
      "Epoch: 2050, Loss= 0.7501, Training Accuracy= 0.495\n",
      "Epoch: 2060, Loss= 0.7501, Training Accuracy= 0.495\n",
      "Epoch: 2070, Loss= 0.7501, Training Accuracy= 0.495\n",
      "Epoch: 2080, Loss= 0.7502, Training Accuracy= 0.495\n",
      "Epoch: 2090, Loss= 0.7502, Training Accuracy= 0.495\n",
      "Epoch: 2100, Loss= 0.7502, Training Accuracy= 0.495\n",
      "Epoch: 2110, Loss= 0.7502, Training Accuracy= 0.495\n",
      "Epoch: 2120, Loss= 0.7502, Training Accuracy= 0.495\n",
      "Epoch: 2130, Loss= 0.7502, Training Accuracy= 0.495\n",
      "Epoch: 2140, Loss= 0.7502, Training Accuracy= 0.495\n",
      "Epoch: 2150, Loss= 0.7502, Training Accuracy= 0.495\n",
      "Epoch: 2160, Loss= 0.7502, Training Accuracy= 0.495\n",
      "Epoch: 2170, Loss= 0.7501, Training Accuracy= 0.495\n",
      "Epoch: 2180, Loss= 0.7500, Training Accuracy= 0.495\n",
      "Epoch: 2190, Loss= 0.7500, Training Accuracy= 0.495\n",
      "Epoch: 2200, Loss= 0.7498, Training Accuracy= 0.495\n",
      "Epoch: 2210, Loss= 0.7496, Training Accuracy= 0.495\n",
      "Epoch: 2220, Loss= 0.7494, Training Accuracy= 0.495\n",
      "Epoch: 2230, Loss= 0.7490, Training Accuracy= 0.495\n",
      "Epoch: 2240, Loss= 0.7484, Training Accuracy= 0.495\n",
      "Epoch: 2250, Loss= 0.7477, Training Accuracy= 0.495\n",
      "Epoch: 2260, Loss= 0.7471, Training Accuracy= 0.495\n",
      "Epoch: 2270, Loss= 0.7466, Training Accuracy= 0.495\n",
      "Epoch: 2280, Loss= 0.7463, Training Accuracy= 0.495\n",
      "Epoch: 2290, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 2300, Loss= 0.7461, Training Accuracy= 0.495\n",
      "Epoch: 2310, Loss= 0.7461, Training Accuracy= 0.495\n",
      "Epoch: 2320, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2330, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2340, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2350, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2360, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2370, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2380, Loss= 0.7459, Training Accuracy= 0.495\n",
      "Epoch: 2390, Loss= 0.7459, Training Accuracy= 0.495\n",
      "Epoch: 2400, Loss= 0.7459, Training Accuracy= 0.495\n",
      "Epoch: 2410, Loss= 0.7459, Training Accuracy= 0.495\n",
      "Epoch: 2420, Loss= 0.7459, Training Accuracy= 0.495\n",
      "Epoch: 2430, Loss= 0.7459, Training Accuracy= 0.495\n",
      "Epoch: 2440, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2450, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2460, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2470, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2480, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2490, Loss= 0.7461, Training Accuracy= 0.495\n",
      "Epoch: 2500, Loss= 0.7461, Training Accuracy= 0.495\n",
      "Epoch: 2510, Loss= 0.7461, Training Accuracy= 0.495\n",
      "Epoch: 2520, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 2530, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 2540, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 2550, Loss= 0.7463, Training Accuracy= 0.495\n",
      "Epoch: 2560, Loss= 0.7463, Training Accuracy= 0.495\n",
      "Epoch: 2570, Loss= 0.7463, Training Accuracy= 0.495\n",
      "Epoch: 2580, Loss= 0.7463, Training Accuracy= 0.495\n",
      "Epoch: 2590, Loss= 0.7464, Training Accuracy= 0.495\n",
      "Epoch: 2600, Loss= 0.7464, Training Accuracy= 0.495\n",
      "Epoch: 2610, Loss= 0.7464, Training Accuracy= 0.495\n",
      "Epoch: 2620, Loss= 0.7464, Training Accuracy= 0.495\n",
      "Epoch: 2630, Loss= 0.7463, Training Accuracy= 0.495\n",
      "Epoch: 2640, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 2650, Loss= 0.7461, Training Accuracy= 0.495\n",
      "Epoch: 2660, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2670, Loss= 0.7459, Training Accuracy= 0.495\n",
      "Epoch: 2680, Loss= 0.7458, Training Accuracy= 0.495\n",
      "Epoch: 2690, Loss= 0.7458, Training Accuracy= 0.495\n",
      "Epoch: 2700, Loss= 0.7457, Training Accuracy= 0.495\n",
      "Epoch: 2710, Loss= 0.7457, Training Accuracy= 0.495\n",
      "Epoch: 2720, Loss= 0.7458, Training Accuracy= 0.495\n",
      "Epoch: 2730, Loss= 0.7459, Training Accuracy= 0.495\n",
      "Epoch: 2740, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2750, Loss= 0.7460, Training Accuracy= 0.495\n",
      "Epoch: 2760, Loss= 0.7462, Training Accuracy= 0.495\n",
      "Epoch: 2770, Loss= 0.7463, Training Accuracy= 0.495\n",
      "Epoch: 2780, Loss= 0.7466, Training Accuracy= 0.495\n",
      "Epoch: 2790, Loss= 0.7470, Training Accuracy= 0.495\n",
      "Epoch: 2800, Loss= 0.7472, Training Accuracy= 0.495\n",
      "Epoch: 2810, Loss= 0.7472, Training Accuracy= 0.495\n",
      "Epoch: 2820, Loss= 0.7475, Training Accuracy= 0.495\n",
      "Epoch: 2830, Loss= 0.7479, Training Accuracy= 0.495\n",
      "Epoch: 2840, Loss= 0.7485, Training Accuracy= 0.495\n",
      "Epoch: 2850, Loss= 0.7493, Training Accuracy= 0.495\n",
      "Epoch: 2860, Loss= 0.7493, Training Accuracy= 0.495\n",
      "Epoch: 2870, Loss= 0.7490, Training Accuracy= 0.495\n",
      "Epoch: 2880, Loss= 0.7495, Training Accuracy= 0.495\n",
      "Epoch: 2890, Loss= 0.7489, Training Accuracy= 0.495\n",
      "Epoch: 2900, Loss= 0.7478, Training Accuracy= 0.495\n",
      "Epoch: 2910, Loss= 0.7464, Training Accuracy= 0.495\n",
      "Epoch: 2920, Loss= 0.7459, Training Accuracy= 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2930, Loss= 0.7438, Training Accuracy= 0.495\n",
      "Epoch: 2940, Loss= 0.7435, Training Accuracy= 0.495\n",
      "Epoch: 2950, Loss= 0.7420, Training Accuracy= 0.495\n",
      "Epoch: 2960, Loss= 0.7406, Training Accuracy= 0.495\n",
      "Epoch: 2970, Loss= 0.7397, Training Accuracy= 0.495\n",
      "Epoch: 2980, Loss= 0.7389, Training Accuracy= 0.495\n",
      "Epoch: 2990, Loss= 0.7398, Training Accuracy= 0.495\n",
      "Epoch: 3000, Loss= 0.7385, Training Accuracy= 0.495\n",
      "Epoch: 3010, Loss= 0.7381, Training Accuracy= 0.496\n",
      "Epoch: 3020, Loss= 0.7372, Training Accuracy= 0.496\n",
      "Epoch: 3030, Loss= 0.7379, Training Accuracy= 0.495\n",
      "Epoch: 3040, Loss= 0.7372, Training Accuracy= 0.496\n",
      "Epoch: 3050, Loss= 0.7399, Training Accuracy= 0.495\n",
      "Epoch: 3060, Loss= 0.7378, Training Accuracy= 0.495\n",
      "Epoch: 3070, Loss= 0.7366, Training Accuracy= 0.496\n",
      "Epoch: 3080, Loss= 0.7369, Training Accuracy= 0.496\n",
      "Epoch: 3090, Loss= 0.7413, Training Accuracy= 0.496\n",
      "Epoch: 3100, Loss= 0.7415, Training Accuracy= 0.497\n",
      "Epoch: 3110, Loss= 0.7407, Training Accuracy= 0.496\n",
      "Epoch: 3120, Loss= 0.7418, Training Accuracy= 0.496\n",
      "Epoch: 3130, Loss= 0.7419, Training Accuracy= 0.497\n",
      "Epoch: 3140, Loss= 0.7412, Training Accuracy= 0.498\n",
      "Epoch: 3150, Loss= 0.7360, Training Accuracy= 0.498\n",
      "Epoch: 3160, Loss= 0.7401, Training Accuracy= 0.496\n",
      "Epoch: 3170, Loss= 0.7435, Training Accuracy= 0.498\n",
      "Epoch: 3180, Loss= 0.7449, Training Accuracy= 0.497\n",
      "Epoch: 3190, Loss= 0.7393, Training Accuracy= 0.498\n",
      "Epoch: 3200, Loss= 0.7384, Training Accuracy= 0.498\n",
      "Epoch: 3210, Loss= 0.7398, Training Accuracy= 0.497\n",
      "Epoch: 3220, Loss= 0.7410, Training Accuracy= 0.497\n",
      "Epoch: 3230, Loss= 0.7390, Training Accuracy= 0.497\n",
      "Epoch: 3240, Loss= 0.7357, Training Accuracy= 0.499\n",
      "Epoch: 3250, Loss= 0.7347, Training Accuracy= 0.495\n",
      "Epoch: 3260, Loss= 0.7386, Training Accuracy= 0.495\n",
      "Epoch: 3270, Loss= 0.7804, Training Accuracy= 0.495\n",
      "Epoch: 3280, Loss= 0.7518, Training Accuracy= 0.495\n",
      "Epoch: 3290, Loss= 0.7500, Training Accuracy= 0.495\n",
      "Epoch: 3300, Loss= 0.7471, Training Accuracy= 0.495\n",
      "Epoch: 3310, Loss= 0.7452, Training Accuracy= 0.495\n",
      "Epoch: 3320, Loss= 0.7436, Training Accuracy= 0.495\n",
      "Epoch: 3330, Loss= 0.7420, Training Accuracy= 0.495\n",
      "Epoch: 3340, Loss= 0.7406, Training Accuracy= 0.495\n",
      "Epoch: 3350, Loss= 0.7393, Training Accuracy= 0.495\n",
      "Epoch: 3360, Loss= 0.7382, Training Accuracy= 0.495\n",
      "Epoch: 3370, Loss= 0.7375, Training Accuracy= 0.495\n",
      "Epoch: 3380, Loss= 0.7369, Training Accuracy= 0.495\n",
      "Epoch: 3390, Loss= 0.7364, Training Accuracy= 0.495\n",
      "Epoch: 3400, Loss= 0.7360, Training Accuracy= 0.495\n",
      "Epoch: 3410, Loss= 0.7354, Training Accuracy= 0.495\n",
      "Epoch: 3420, Loss= 0.7346, Training Accuracy= 0.495\n",
      "Epoch: 3430, Loss= 0.7338, Training Accuracy= 0.495\n",
      "Epoch: 3440, Loss= 0.7331, Training Accuracy= 0.495\n",
      "Epoch: 3450, Loss= 0.7323, Training Accuracy= 0.495\n",
      "Epoch: 3460, Loss= 0.7314, Training Accuracy= 0.495\n",
      "Epoch: 3470, Loss= 0.7305, Training Accuracy= 0.496\n",
      "Epoch: 3480, Loss= 0.7298, Training Accuracy= 0.497\n",
      "Epoch: 3490, Loss= 0.7298, Training Accuracy= 0.497\n",
      "Epoch: 3500, Loss= 0.7316, Training Accuracy= 0.499\n",
      "Epoch: 3510, Loss= 0.7373, Training Accuracy= 0.500\n",
      "Epoch: 3520, Loss= 0.7372, Training Accuracy= 0.499\n",
      "Epoch: 3530, Loss= 0.7453, Training Accuracy= 0.497\n",
      "Epoch: 3540, Loss= 0.7389, Training Accuracy= 0.499\n",
      "Epoch: 3550, Loss= 0.7372, Training Accuracy= 0.501\n",
      "Epoch: 3560, Loss= 0.7382, Training Accuracy= 0.502\n",
      "Epoch: 3570, Loss= 0.7372, Training Accuracy= 0.502\n",
      "Epoch: 3580, Loss= 0.7345, Training Accuracy= 0.504\n",
      "Epoch: 3590, Loss= 0.7412, Training Accuracy= 0.503\n",
      "Epoch: 3600, Loss= 0.7399, Training Accuracy= 0.504\n",
      "Epoch: 3610, Loss= 0.7349, Training Accuracy= 0.506\n",
      "Epoch: 3620, Loss= 0.7304, Training Accuracy= 0.507\n",
      "Epoch: 3630, Loss= 0.7335, Training Accuracy= 0.507\n",
      "Epoch: 3640, Loss= 0.7310, Training Accuracy= 0.509\n",
      "Epoch: 3650, Loss= 0.7303, Training Accuracy= 0.509\n",
      "Epoch: 3660, Loss= 0.7323, Training Accuracy= 0.495\n",
      "Epoch: 3670, Loss= 0.7310, Training Accuracy= 0.495\n",
      "Epoch: 3680, Loss= 0.7276, Training Accuracy= 0.495\n",
      "Epoch: 3690, Loss= 0.7252, Training Accuracy= 0.495\n",
      "Epoch: 3700, Loss= 0.7251, Training Accuracy= 0.495\n",
      "Epoch: 3710, Loss= 0.7243, Training Accuracy= 0.495\n",
      "Epoch: 3720, Loss= 0.7237, Training Accuracy= 0.495\n",
      "Epoch: 3730, Loss= 0.7234, Training Accuracy= 0.495\n",
      "Epoch: 3740, Loss= 0.7231, Training Accuracy= 0.495\n",
      "Epoch: 3750, Loss= 0.7228, Training Accuracy= 0.495\n",
      "Epoch: 3760, Loss= 0.7227, Training Accuracy= 0.495\n",
      "Epoch: 3770, Loss= 0.7226, Training Accuracy= 0.495\n",
      "Epoch: 3780, Loss= 0.7225, Training Accuracy= 0.495\n",
      "Epoch: 3790, Loss= 0.7224, Training Accuracy= 0.495\n",
      "Epoch: 3800, Loss= 0.7224, Training Accuracy= 0.495\n",
      "Epoch: 3810, Loss= 0.7224, Training Accuracy= 0.495\n",
      "Epoch: 3820, Loss= 0.7224, Training Accuracy= 0.495\n",
      "Epoch: 3830, Loss= 0.7225, Training Accuracy= 0.495\n",
      "Epoch: 3840, Loss= 0.7226, Training Accuracy= 0.495\n",
      "Epoch: 3850, Loss= 0.7227, Training Accuracy= 0.495\n",
      "Epoch: 3860, Loss= 0.7235, Training Accuracy= 0.496\n",
      "Epoch: 3870, Loss= 0.7238, Training Accuracy= 0.496\n",
      "Epoch: 3880, Loss= 0.7235, Training Accuracy= 0.496\n",
      "Epoch: 3890, Loss= 0.7225, Training Accuracy= 0.496\n",
      "Epoch: 3900, Loss= 0.7211, Training Accuracy= 0.496\n",
      "Epoch: 3910, Loss= 0.7197, Training Accuracy= 0.496\n",
      "Epoch: 3920, Loss= 0.7210, Training Accuracy= 0.497\n",
      "Epoch: 3930, Loss= 0.7184, Training Accuracy= 0.497\n",
      "Epoch: 3940, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 3950, Loss= 0.7200, Training Accuracy= 0.497\n",
      "Epoch: 3960, Loss= 0.7178, Training Accuracy= 0.498\n",
      "Epoch: 3970, Loss= 0.7185, Training Accuracy= 0.497\n",
      "Epoch: 3980, Loss= 0.7161, Training Accuracy= 0.499\n",
      "Epoch: 3990, Loss= 0.7151, Training Accuracy= 0.501\n",
      "Epoch: 4000, Loss= 0.7148, Training Accuracy= 0.502\n",
      "Epoch: 4010, Loss= 0.7202, Training Accuracy= 0.495\n",
      "Epoch: 4020, Loss= 0.7212, Training Accuracy= 0.496\n",
      "Epoch: 4030, Loss= 0.7271, Training Accuracy= 0.495\n",
      "Epoch: 4040, Loss= 0.7204, Training Accuracy= 0.495\n",
      "Epoch: 4050, Loss= 0.7159, Training Accuracy= 0.496\n",
      "Epoch: 4060, Loss= 0.7136, Training Accuracy= 0.497\n",
      "Epoch: 4070, Loss= 0.7152, Training Accuracy= 0.496\n",
      "Epoch: 4080, Loss= 0.7181, Training Accuracy= 0.497\n",
      "Epoch: 4090, Loss= 0.7171, Training Accuracy= 0.497\n",
      "Epoch: 4100, Loss= 0.7172, Training Accuracy= 0.498\n",
      "Epoch: 4110, Loss= 0.7190, Training Accuracy= 0.497\n",
      "Epoch: 4120, Loss= 0.7196, Training Accuracy= 0.497\n",
      "Epoch: 4130, Loss= 0.7206, Training Accuracy= 0.497\n",
      "Epoch: 4140, Loss= 0.7211, Training Accuracy= 0.498\n",
      "Epoch: 4150, Loss= 0.7194, Training Accuracy= 0.499\n",
      "Epoch: 4160, Loss= 0.7229, Training Accuracy= 0.498\n",
      "Epoch: 4170, Loss= 0.7286, Training Accuracy= 0.496\n",
      "Epoch: 4180, Loss= 0.7305, Training Accuracy= 0.496\n",
      "Epoch: 4190, Loss= 0.7317, Training Accuracy= 0.496\n",
      "Epoch: 4200, Loss= 0.7335, Training Accuracy= 0.496\n",
      "Epoch: 4210, Loss= 0.7340, Training Accuracy= 0.496\n",
      "Epoch: 4220, Loss= 0.7357, Training Accuracy= 0.496\n",
      "Epoch: 4230, Loss= 0.7355, Training Accuracy= 0.497\n",
      "Epoch: 4240, Loss= 0.7231, Training Accuracy= 0.497\n",
      "Epoch: 4250, Loss= 0.7224, Training Accuracy= 0.496\n",
      "Epoch: 4260, Loss= 0.7225, Training Accuracy= 0.497\n",
      "Epoch: 4270, Loss= 0.7225, Training Accuracy= 0.497\n",
      "Epoch: 4280, Loss= 0.7229, Training Accuracy= 0.498\n",
      "Epoch: 4290, Loss= 0.7231, Training Accuracy= 0.498\n",
      "Epoch: 4300, Loss= 0.7226, Training Accuracy= 0.499\n",
      "Epoch: 4310, Loss= 0.7231, Training Accuracy= 0.498\n",
      "Epoch: 4320, Loss= 0.7428, Training Accuracy= 0.495\n",
      "Epoch: 4330, Loss= 0.7376, Training Accuracy= 0.495\n",
      "Epoch: 4340, Loss= 0.7364, Training Accuracy= 0.495\n",
      "Epoch: 4350, Loss= 0.7382, Training Accuracy= 0.495\n",
      "Epoch: 4360, Loss= 0.7380, Training Accuracy= 0.495\n",
      "Epoch: 4370, Loss= 0.7379, Training Accuracy= 0.495\n",
      "Epoch: 4380, Loss= 0.7375, Training Accuracy= 0.495\n",
      "Epoch: 4390, Loss= 0.7370, Training Accuracy= 0.495\n",
      "Epoch: 4400, Loss= 0.7370, Training Accuracy= 0.495\n",
      "Epoch: 4410, Loss= 0.7373, Training Accuracy= 0.495\n",
      "Epoch: 4420, Loss= 0.7381, Training Accuracy= 0.495\n",
      "Epoch: 4430, Loss= 0.7361, Training Accuracy= 0.495\n",
      "Epoch: 4440, Loss= 0.7382, Training Accuracy= 0.495\n",
      "Epoch: 4450, Loss= 0.7379, Training Accuracy= 0.495\n",
      "Epoch: 4460, Loss= 0.7378, Training Accuracy= 0.495\n",
      "Epoch: 4470, Loss= 0.7381, Training Accuracy= 0.495\n",
      "Epoch: 4480, Loss= 0.7380, Training Accuracy= 0.496\n",
      "Epoch: 4490, Loss= 0.7380, Training Accuracy= 0.496\n",
      "Epoch: 4500, Loss= 0.7378, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4510, Loss= 0.7376, Training Accuracy= 0.496\n",
      "Epoch: 4520, Loss= 0.7356, Training Accuracy= 0.496\n",
      "Epoch: 4530, Loss= 0.7376, Training Accuracy= 0.496\n",
      "Epoch: 4540, Loss= 0.7353, Training Accuracy= 0.496\n",
      "Epoch: 4550, Loss= 0.7374, Training Accuracy= 0.498\n",
      "Epoch: 4560, Loss= 0.7305, Training Accuracy= 0.495\n",
      "Epoch: 4570, Loss= 0.7355, Training Accuracy= 0.496\n",
      "Epoch: 4580, Loss= 0.7369, Training Accuracy= 0.495\n",
      "Epoch: 4590, Loss= 0.7296, Training Accuracy= 0.497\n",
      "Epoch: 4600, Loss= 0.7309, Training Accuracy= 0.497\n",
      "Epoch: 4610, Loss= 0.7312, Training Accuracy= 0.497\n",
      "Epoch: 4620, Loss= 0.7326, Training Accuracy= 0.496\n",
      "Epoch: 4630, Loss= 0.7362, Training Accuracy= 0.496\n",
      "Epoch: 4640, Loss= 0.7290, Training Accuracy= 0.498\n",
      "Epoch: 4650, Loss= 0.7345, Training Accuracy= 0.496\n",
      "Epoch: 4660, Loss= 0.7242, Training Accuracy= 0.495\n",
      "Epoch: 4670, Loss= 0.7210, Training Accuracy= 0.495\n",
      "Epoch: 4680, Loss= 0.7191, Training Accuracy= 0.495\n",
      "Epoch: 4690, Loss= 0.7194, Training Accuracy= 0.495\n",
      "Epoch: 4700, Loss= 0.7194, Training Accuracy= 0.495\n",
      "Epoch: 4710, Loss= 0.7188, Training Accuracy= 0.495\n",
      "Epoch: 4720, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 4730, Loss= 0.7157, Training Accuracy= 0.497\n",
      "Epoch: 4740, Loss= 0.7144, Training Accuracy= 0.498\n",
      "Epoch: 4750, Loss= 0.7193, Training Accuracy= 0.495\n",
      "Epoch: 4760, Loss= 0.7178, Training Accuracy= 0.496\n",
      "Epoch: 4770, Loss= 0.7176, Training Accuracy= 0.495\n",
      "Epoch: 4780, Loss= 0.7115, Training Accuracy= 0.497\n",
      "Epoch: 4790, Loss= 0.7158, Training Accuracy= 0.496\n",
      "Epoch: 4800, Loss= 0.7149, Training Accuracy= 0.497\n",
      "Epoch: 4810, Loss= 0.7134, Training Accuracy= 0.497\n",
      "Epoch: 4820, Loss= 0.7128, Training Accuracy= 0.495\n",
      "Epoch: 4830, Loss= 0.7127, Training Accuracy= 0.497\n",
      "Epoch: 4840, Loss= 0.7112, Training Accuracy= 0.497\n",
      "Epoch: 4850, Loss= 0.7097, Training Accuracy= 0.498\n",
      "Epoch: 4860, Loss= 0.7121, Training Accuracy= 0.498\n",
      "Epoch: 4870, Loss= 0.7117, Training Accuracy= 0.498\n",
      "Epoch: 4880, Loss= 0.7127, Training Accuracy= 0.496\n",
      "Epoch: 4890, Loss= 0.7122, Training Accuracy= 0.498\n",
      "Epoch: 4900, Loss= 0.7124, Training Accuracy= 0.498\n",
      "Epoch: 4910, Loss= 0.7129, Training Accuracy= 0.500\n",
      "Epoch: 4920, Loss= 0.7126, Training Accuracy= 0.501\n",
      "Epoch: 4930, Loss= 0.7119, Training Accuracy= 0.503\n",
      "Epoch: 4940, Loss= 0.7116, Training Accuracy= 0.503\n",
      "Epoch: 4950, Loss= 0.7115, Training Accuracy= 0.504\n",
      "Epoch: 4960, Loss= 0.7119, Training Accuracy= 0.499\n",
      "Epoch: 4970, Loss= 0.7101, Training Accuracy= 0.503\n",
      "Epoch: 4980, Loss= 0.7103, Training Accuracy= 0.505\n",
      "Epoch: 4990, Loss= 0.7097, Training Accuracy= 0.508\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4903\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.7298, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 0.7018, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.6984, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.6970, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.6962, Training Accuracy= 0.497\n",
      "Epoch: 50, Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 60, Loss= 0.6950, Training Accuracy= 0.507\n",
      "Epoch: 70, Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 80, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 90, Loss= 0.6941, Training Accuracy= 0.506\n",
      "Epoch: 100, Loss= 0.6939, Training Accuracy= 0.506\n",
      "Epoch: 110, Loss= 0.6938, Training Accuracy= 0.507\n",
      "Epoch: 120, Loss= 0.6937, Training Accuracy= 0.507\n",
      "Epoch: 130, Loss= 0.6936, Training Accuracy= 0.508\n",
      "Epoch: 140, Loss= 0.6936, Training Accuracy= 0.509\n",
      "Epoch: 150, Loss= 0.6935, Training Accuracy= 0.508\n",
      "Epoch: 160, Loss= 0.6934, Training Accuracy= 0.508\n",
      "Epoch: 170, Loss= 0.6934, Training Accuracy= 0.508\n",
      "Epoch: 180, Loss= 0.6934, Training Accuracy= 0.508\n",
      "Epoch: 190, Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 200, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 210, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 220, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 230, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 240, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 250, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 260, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 270, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 280, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 290, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 300, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 310, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 320, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 330, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 340, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 350, Loss= 0.6934, Training Accuracy= 0.510\n",
      "Epoch: 360, Loss= 0.6934, Training Accuracy= 0.510\n",
      "Epoch: 370, Loss= 0.6935, Training Accuracy= 0.510\n",
      "Epoch: 380, Loss= 0.6936, Training Accuracy= 0.511\n",
      "Epoch: 390, Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 400, Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 410, Loss= 0.6940, Training Accuracy= 0.508\n",
      "Epoch: 420, Loss= 0.6952, Training Accuracy= 0.509\n",
      "Epoch: 430, Loss= 0.6961, Training Accuracy= 0.511\n",
      "Epoch: 440, Loss= 0.6948, Training Accuracy= 0.508\n",
      "Epoch: 450, Loss= 0.6943, Training Accuracy= 0.510\n",
      "Epoch: 460, Loss= 0.6941, Training Accuracy= 0.511\n",
      "Epoch: 470, Loss= 0.6942, Training Accuracy= 0.510\n",
      "Epoch: 480, Loss= 0.6940, Training Accuracy= 0.509\n",
      "Epoch: 490, Loss= 0.6944, Training Accuracy= 0.510\n",
      "Epoch: 500, Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 510, Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 520, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 530, Loss= 0.6918, Training Accuracy= 0.511\n",
      "Epoch: 540, Loss= 0.6920, Training Accuracy= 0.514\n",
      "Epoch: 550, Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 560, Loss= 0.6913, Training Accuracy= 0.517\n",
      "Epoch: 570, Loss= 0.6930, Training Accuracy= 0.523\n",
      "Epoch: 580, Loss= 0.6903, Training Accuracy= 0.520\n",
      "Epoch: 590, Loss= 0.6907, Training Accuracy= 0.522\n",
      "Epoch: 600, Loss= 0.6896, Training Accuracy= 0.530\n",
      "Epoch: 610, Loss= 0.6922, Training Accuracy= 0.526\n",
      "Epoch: 620, Loss= 0.6889, Training Accuracy= 0.537\n",
      "Epoch: 630, Loss= 0.6900, Training Accuracy= 0.537\n",
      "Epoch: 640, Loss= 0.6837, Training Accuracy= 0.540\n",
      "Epoch: 650, Loss= 0.6955, Training Accuracy= 0.512\n",
      "Epoch: 660, Loss= 0.6806, Training Accuracy= 0.543\n",
      "Epoch: 670, Loss= 0.6987, Training Accuracy= 0.517\n",
      "Epoch: 680, Loss= 0.6945, Training Accuracy= 0.542\n",
      "Epoch: 690, Loss= 0.6916, Training Accuracy= 0.535\n",
      "Epoch: 700, Loss= 0.6972, Training Accuracy= 0.525\n",
      "Epoch: 710, Loss= 0.6890, Training Accuracy= 0.532\n",
      "Epoch: 720, Loss= 0.6922, Training Accuracy= 0.531\n",
      "Epoch: 730, Loss= 0.6882, Training Accuracy= 0.539\n",
      "Epoch: 740, Loss= 0.6878, Training Accuracy= 0.540\n",
      "Epoch: 750, Loss= 0.6897, Training Accuracy= 0.543\n",
      "Epoch: 760, Loss= 0.6848, Training Accuracy= 0.552\n",
      "Epoch: 770, Loss= 0.6842, Training Accuracy= 0.560\n",
      "Epoch: 780, Loss= 0.6818, Training Accuracy= 0.556\n",
      "Epoch: 790, Loss= 0.6781, Training Accuracy= 0.567\n",
      "Epoch: 800, Loss= 0.6777, Training Accuracy= 0.568\n",
      "Epoch: 810, Loss= 0.6792, Training Accuracy= 0.564\n",
      "Epoch: 820, Loss= 0.6774, Training Accuracy= 0.566\n",
      "Epoch: 830, Loss= 0.6709, Training Accuracy= 0.578\n",
      "Epoch: 840, Loss= 0.6712, Training Accuracy= 0.579\n",
      "Epoch: 850, Loss= 0.6705, Training Accuracy= 0.579\n",
      "Epoch: 860, Loss= 0.6783, Training Accuracy= 0.568\n",
      "Epoch: 870, Loss= 0.6649, Training Accuracy= 0.585\n",
      "Epoch: 880, Loss= 0.6586, Training Accuracy= 0.596\n",
      "Epoch: 890, Loss= 0.6701, Training Accuracy= 0.585\n",
      "Epoch: 900, Loss= 0.6569, Training Accuracy= 0.604\n",
      "Epoch: 910, Loss= 0.6453, Training Accuracy= 0.619\n",
      "Epoch: 920, Loss= 0.6545, Training Accuracy= 0.610\n",
      "Epoch: 930, Loss= 0.6637, Training Accuracy= 0.594\n",
      "Epoch: 940, Loss= 0.6428, Training Accuracy= 0.625\n",
      "Epoch: 950, Loss= 0.6495, Training Accuracy= 0.615\n",
      "Epoch: 960, Loss= 0.6907, Training Accuracy= 0.567\n",
      "Epoch: 970, Loss= 0.5396, Training Accuracy= 0.694\n",
      "Epoch: 980, Loss= 0.6322, Training Accuracy= 0.583\n",
      "Epoch: 990, Loss= 0.4401, Training Accuracy= 0.727\n",
      "Epoch: 1000, Loss= 1.1868, Training Accuracy= 0.527\n",
      "Epoch: 1010, Loss= 0.9333, Training Accuracy= 0.497\n",
      "Epoch: 1020, Loss= 0.8630, Training Accuracy= 0.497\n",
      "Epoch: 1030, Loss= 0.8282, Training Accuracy= 0.497\n",
      "Epoch: 1040, Loss= 0.7954, Training Accuracy= 0.497\n",
      "Epoch: 1050, Loss= 0.7747, Training Accuracy= 0.497\n",
      "Epoch: 1060, Loss= 0.7634, Training Accuracy= 0.497\n",
      "Epoch: 1070, Loss= 0.7548, Training Accuracy= 0.497\n",
      "Epoch: 1080, Loss= 0.7483, Training Accuracy= 0.497\n",
      "Epoch: 1090, Loss= 0.7436, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1100, Loss= 0.7401, Training Accuracy= 0.497\n",
      "Epoch: 1110, Loss= 0.7375, Training Accuracy= 0.497\n",
      "Epoch: 1120, Loss= 0.7353, Training Accuracy= 0.497\n",
      "Epoch: 1130, Loss= 0.7332, Training Accuracy= 0.497\n",
      "Epoch: 1140, Loss= 0.7311, Training Accuracy= 0.497\n",
      "Epoch: 1150, Loss= 0.7289, Training Accuracy= 0.497\n",
      "Epoch: 1160, Loss= 0.7266, Training Accuracy= 0.497\n",
      "Epoch: 1170, Loss= 0.7246, Training Accuracy= 0.497\n",
      "Epoch: 1180, Loss= 0.7228, Training Accuracy= 0.497\n",
      "Epoch: 1190, Loss= 0.7215, Training Accuracy= 0.497\n",
      "Epoch: 1200, Loss= 0.7202, Training Accuracy= 0.497\n",
      "Epoch: 1210, Loss= 0.7187, Training Accuracy= 0.498\n",
      "Epoch: 1220, Loss= 0.7172, Training Accuracy= 0.498\n",
      "Epoch: 1230, Loss= 0.7158, Training Accuracy= 0.499\n",
      "Epoch: 1240, Loss= 0.7147, Training Accuracy= 0.500\n",
      "Epoch: 1250, Loss= 0.7136, Training Accuracy= 0.499\n",
      "Epoch: 1260, Loss= 0.7125, Training Accuracy= 0.499\n",
      "Epoch: 1270, Loss= 0.7115, Training Accuracy= 0.500\n",
      "Epoch: 1280, Loss= 0.7105, Training Accuracy= 0.501\n",
      "Epoch: 1290, Loss= 0.7097, Training Accuracy= 0.501\n",
      "Epoch: 1300, Loss= 0.7090, Training Accuracy= 0.503\n",
      "Epoch: 1310, Loss= 0.7084, Training Accuracy= 0.504\n",
      "Epoch: 1320, Loss= 0.7079, Training Accuracy= 0.505\n",
      "Epoch: 1330, Loss= 0.7074, Training Accuracy= 0.507\n",
      "Epoch: 1340, Loss= 0.7070, Training Accuracy= 0.507\n",
      "Epoch: 1350, Loss= 0.7067, Training Accuracy= 0.508\n",
      "Epoch: 1360, Loss= 0.7064, Training Accuracy= 0.508\n",
      "Epoch: 1370, Loss= 0.7061, Training Accuracy= 0.509\n",
      "Epoch: 1380, Loss= 0.7059, Training Accuracy= 0.509\n",
      "Epoch: 1390, Loss= 0.7056, Training Accuracy= 0.509\n",
      "Epoch: 1400, Loss= 0.7054, Training Accuracy= 0.509\n",
      "Epoch: 1410, Loss= 0.7051, Training Accuracy= 0.508\n",
      "Epoch: 1420, Loss= 0.7046, Training Accuracy= 0.508\n",
      "Epoch: 1430, Loss= 0.7041, Training Accuracy= 0.509\n",
      "Epoch: 1440, Loss= 0.7039, Training Accuracy= 0.509\n",
      "Epoch: 1450, Loss= 0.7033, Training Accuracy= 0.511\n",
      "Epoch: 1460, Loss= 0.7029, Training Accuracy= 0.513\n",
      "Epoch: 1470, Loss= 0.7025, Training Accuracy= 0.513\n",
      "Epoch: 1480, Loss= 0.7023, Training Accuracy= 0.512\n",
      "Epoch: 1490, Loss= 0.7017, Training Accuracy= 0.514\n",
      "Epoch: 1500, Loss= 0.7011, Training Accuracy= 0.515\n",
      "Epoch: 1510, Loss= 0.7013, Training Accuracy= 0.515\n",
      "Epoch: 1520, Loss= 0.7001, Training Accuracy= 0.513\n",
      "Epoch: 1530, Loss= 0.7006, Training Accuracy= 0.516\n",
      "Epoch: 1540, Loss= 0.6970, Training Accuracy= 0.524\n",
      "Epoch: 1550, Loss= 0.7009, Training Accuracy= 0.517\n",
      "Epoch: 1560, Loss= 0.6946, Training Accuracy= 0.525\n",
      "Epoch: 1570, Loss= 0.7022, Training Accuracy= 0.522\n",
      "Epoch: 1580, Loss= 0.7017, Training Accuracy= 0.521\n",
      "Epoch: 1590, Loss= 0.6969, Training Accuracy= 0.529\n",
      "Epoch: 1600, Loss= 0.6933, Training Accuracy= 0.540\n",
      "Epoch: 1610, Loss= 0.6980, Training Accuracy= 0.528\n",
      "Epoch: 1620, Loss= 0.7020, Training Accuracy= 0.529\n",
      "Epoch: 1630, Loss= 0.6945, Training Accuracy= 0.539\n",
      "Epoch: 1640, Loss= 0.6909, Training Accuracy= 0.542\n",
      "Epoch: 1650, Loss= 0.6885, Training Accuracy= 0.545\n",
      "Epoch: 1660, Loss= 0.6871, Training Accuracy= 0.548\n",
      "Epoch: 1670, Loss= 0.6825, Training Accuracy= 0.557\n",
      "Epoch: 1680, Loss= 0.6881, Training Accuracy= 0.547\n",
      "Epoch: 1690, Loss= 0.6970, Training Accuracy= 0.538\n",
      "Epoch: 1700, Loss= 0.6951, Training Accuracy= 0.548\n",
      "Epoch: 1710, Loss= 0.7060, Training Accuracy= 0.520\n",
      "Epoch: 1720, Loss= 0.6823, Training Accuracy= 0.563\n",
      "Epoch: 1730, Loss= 0.6822, Training Accuracy= 0.562\n",
      "Epoch: 1740, Loss= 0.6955, Training Accuracy= 0.534\n",
      "Epoch: 1750, Loss= 0.6810, Training Accuracy= 0.563\n",
      "Epoch: 1760, Loss= 0.6809, Training Accuracy= 0.570\n",
      "Epoch: 1770, Loss= 0.5932, Training Accuracy= 0.666\n",
      "Epoch: 1780, Loss= 0.6094, Training Accuracy= 0.630\n",
      "Epoch: 1790, Loss= 0.4088, Training Accuracy= 0.785\n",
      "Epoch: 1800, Loss= 0.2575, Training Accuracy= 0.860\n",
      "Epoch: 1810, Loss= 0.5729, Training Accuracy= 0.753\n",
      "Epoch: 1820, Loss= 0.3248, Training Accuracy= 0.807\n",
      "Epoch: 1830, Loss= 0.5640, Training Accuracy= 0.709\n",
      "Epoch: 1840, Loss= 0.2889, Training Accuracy= 0.859\n",
      "Epoch: 1850, Loss= 0.2713, Training Accuracy= 0.857\n",
      "Epoch: 1860, Loss= 0.2192, Training Accuracy= 0.861\n",
      "Epoch: 1870, Loss= 0.9588, Training Accuracy= 0.498\n",
      "Epoch: 1880, Loss= 0.7736, Training Accuracy= 0.497\n",
      "Epoch: 1890, Loss= 0.7489, Training Accuracy= 0.498\n",
      "Epoch: 1900, Loss= 0.7374, Training Accuracy= 0.498\n",
      "Epoch: 1910, Loss= 0.7303, Training Accuracy= 0.498\n",
      "Epoch: 1920, Loss= 0.7253, Training Accuracy= 0.498\n",
      "Epoch: 1930, Loss= 0.7211, Training Accuracy= 0.499\n",
      "Epoch: 1940, Loss= 0.7190, Training Accuracy= 0.499\n",
      "Epoch: 1950, Loss= 0.7171, Training Accuracy= 0.500\n",
      "Epoch: 1960, Loss= 0.7154, Training Accuracy= 0.501\n",
      "Epoch: 1970, Loss= 0.7140, Training Accuracy= 0.502\n",
      "Epoch: 1980, Loss= 0.7128, Training Accuracy= 0.502\n",
      "Epoch: 1990, Loss= 0.7115, Training Accuracy= 0.503\n",
      "Epoch: 2000, Loss= 0.7102, Training Accuracy= 0.505\n",
      "Epoch: 2010, Loss= 0.7090, Training Accuracy= 0.507\n",
      "Epoch: 2020, Loss= 0.7081, Training Accuracy= 0.510\n",
      "Epoch: 2030, Loss= 0.7073, Training Accuracy= 0.511\n",
      "Epoch: 2040, Loss= 0.7065, Training Accuracy= 0.513\n",
      "Epoch: 2050, Loss= 0.7058, Training Accuracy= 0.514\n",
      "Epoch: 2060, Loss= 0.7057, Training Accuracy= 0.512\n",
      "Epoch: 2070, Loss= 0.7059, Training Accuracy= 0.512\n",
      "Epoch: 2080, Loss= 0.7059, Training Accuracy= 0.513\n",
      "Epoch: 2090, Loss= 0.7056, Training Accuracy= 0.515\n",
      "Epoch: 2100, Loss= 0.7053, Training Accuracy= 0.515\n",
      "Epoch: 2110, Loss= 0.7110, Training Accuracy= 0.511\n",
      "Epoch: 2120, Loss= 0.7065, Training Accuracy= 0.516\n",
      "Epoch: 2130, Loss= 0.7115, Training Accuracy= 0.514\n",
      "Epoch: 2140, Loss= 0.7092, Training Accuracy= 0.516\n",
      "Epoch: 2150, Loss= 0.7061, Training Accuracy= 0.517\n",
      "Epoch: 2160, Loss= 0.7084, Training Accuracy= 0.516\n",
      "Epoch: 2170, Loss= 0.7055, Training Accuracy= 0.516\n",
      "Epoch: 2180, Loss= 0.7071, Training Accuracy= 0.520\n",
      "Epoch: 2190, Loss= 0.7091, Training Accuracy= 0.519\n",
      "Epoch: 2200, Loss= 0.7033, Training Accuracy= 0.524\n",
      "Epoch: 2210, Loss= 0.7082, Training Accuracy= 0.520\n",
      "Epoch: 2220, Loss= 0.7195, Training Accuracy= 0.514\n",
      "Epoch: 2230, Loss= 0.6992, Training Accuracy= 0.529\n",
      "Epoch: 2240, Loss= 0.7009, Training Accuracy= 0.528\n",
      "Epoch: 2250, Loss= 0.6989, Training Accuracy= 0.529\n",
      "Epoch: 2260, Loss= 0.7023, Training Accuracy= 0.526\n",
      "Epoch: 2270, Loss= 0.6987, Training Accuracy= 0.531\n",
      "Epoch: 2280, Loss= 0.6990, Training Accuracy= 0.532\n",
      "Epoch: 2290, Loss= 0.6977, Training Accuracy= 0.529\n",
      "Epoch: 2300, Loss= 0.6959, Training Accuracy= 0.533\n",
      "Epoch: 2310, Loss= 0.7010, Training Accuracy= 0.529\n",
      "Epoch: 2320, Loss= 0.6977, Training Accuracy= 0.533\n",
      "Epoch: 2330, Loss= 0.6963, Training Accuracy= 0.531\n",
      "Epoch: 2340, Loss= 0.6909, Training Accuracy= 0.537\n",
      "Epoch: 2350, Loss= 0.6928, Training Accuracy= 0.537\n",
      "Epoch: 2360, Loss= 0.6967, Training Accuracy= 0.531\n",
      "Epoch: 2370, Loss= 0.6917, Training Accuracy= 0.543\n",
      "Epoch: 2380, Loss= 0.6880, Training Accuracy= 0.543\n",
      "Epoch: 2390, Loss= 0.6926, Training Accuracy= 0.539\n",
      "Epoch: 2400, Loss= 0.6884, Training Accuracy= 0.545\n",
      "Epoch: 2410, Loss= 0.7172, Training Accuracy= 0.508\n",
      "Epoch: 2420, Loss= 0.6876, Training Accuracy= 0.541\n",
      "Epoch: 2430, Loss= 0.6902, Training Accuracy= 0.551\n",
      "Epoch: 2440, Loss= 0.6865, Training Accuracy= 0.557\n",
      "Epoch: 2450, Loss= 0.6997, Training Accuracy= 0.535\n",
      "Epoch: 2460, Loss= 0.6881, Training Accuracy= 0.555\n",
      "Epoch: 2470, Loss= 0.6873, Training Accuracy= 0.560\n",
      "Epoch: 2480, Loss= 0.6859, Training Accuracy= 0.561\n",
      "Epoch: 2490, Loss= 0.6833, Training Accuracy= 0.567\n",
      "Epoch: 2500, Loss= 0.7152, Training Accuracy= 0.544\n",
      "Epoch: 2510, Loss= 0.6991, Training Accuracy= 0.532\n",
      "Epoch: 2520, Loss= 0.6869, Training Accuracy= 0.556\n",
      "Epoch: 2530, Loss= 0.6784, Training Accuracy= 0.565\n",
      "Epoch: 2540, Loss= 0.6734, Training Accuracy= 0.571\n",
      "Epoch: 2550, Loss= 0.6858, Training Accuracy= 0.562\n",
      "Epoch: 2560, Loss= 0.6756, Training Accuracy= 0.568\n",
      "Epoch: 2570, Loss= 0.6677, Training Accuracy= 0.578\n",
      "Epoch: 2580, Loss= 0.6696, Training Accuracy= 0.582\n",
      "Epoch: 2590, Loss= 0.6843, Training Accuracy= 0.552\n",
      "Epoch: 2600, Loss= 0.6843, Training Accuracy= 0.561\n",
      "Epoch: 2610, Loss= 0.6810, Training Accuracy= 0.565\n",
      "Epoch: 2620, Loss= 0.6766, Training Accuracy= 0.572\n",
      "Epoch: 2630, Loss= 0.6933, Training Accuracy= 0.548\n",
      "Epoch: 2640, Loss= 0.6841, Training Accuracy= 0.557\n",
      "Epoch: 2650, Loss= 0.6762, Training Accuracy= 0.572\n",
      "Epoch: 2660, Loss= 0.6745, Training Accuracy= 0.575\n",
      "Epoch: 2670, Loss= 0.6668, Training Accuracy= 0.583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2680, Loss= 0.6682, Training Accuracy= 0.582\n",
      "Epoch: 2690, Loss= 0.6631, Training Accuracy= 0.588\n",
      "Epoch: 2700, Loss= 0.6673, Training Accuracy= 0.581\n",
      "Epoch: 2710, Loss= 0.6680, Training Accuracy= 0.586\n",
      "Epoch: 2720, Loss= 0.6666, Training Accuracy= 0.581\n",
      "Epoch: 2730, Loss= 0.6576, Training Accuracy= 0.595\n",
      "Epoch: 2740, Loss= 0.6638, Training Accuracy= 0.595\n",
      "Epoch: 2750, Loss= 0.6707, Training Accuracy= 0.586\n",
      "Epoch: 2760, Loss= 0.6571, Training Accuracy= 0.595\n",
      "Epoch: 2770, Loss= 0.6648, Training Accuracy= 0.592\n",
      "Epoch: 2780, Loss= 0.6589, Training Accuracy= 0.597\n",
      "Epoch: 2790, Loss= 0.6494, Training Accuracy= 0.604\n",
      "Epoch: 2800, Loss= 0.6430, Training Accuracy= 0.611\n",
      "Epoch: 2810, Loss= 0.6451, Training Accuracy= 0.613\n",
      "Epoch: 2820, Loss= 0.6463, Training Accuracy= 0.613\n",
      "Epoch: 2830, Loss= 0.6694, Training Accuracy= 0.593\n",
      "Epoch: 2840, Loss= 0.6571, Training Accuracy= 0.602\n",
      "Epoch: 2850, Loss= 0.6525, Training Accuracy= 0.606\n",
      "Epoch: 2860, Loss= 0.6491, Training Accuracy= 0.613\n",
      "Epoch: 2870, Loss= 0.6436, Training Accuracy= 0.615\n",
      "Epoch: 2880, Loss= 0.6369, Training Accuracy= 0.621\n",
      "Epoch: 2890, Loss= 0.6452, Training Accuracy= 0.612\n",
      "Epoch: 2900, Loss= 0.6338, Training Accuracy= 0.630\n",
      "Epoch: 2910, Loss= 0.6415, Training Accuracy= 0.619\n",
      "Epoch: 2920, Loss= 0.6324, Training Accuracy= 0.626\n",
      "Epoch: 2930, Loss= 0.6313, Training Accuracy= 0.627\n",
      "Epoch: 2940, Loss= 0.6321, Training Accuracy= 0.632\n",
      "Epoch: 2950, Loss= 0.6337, Training Accuracy= 0.628\n",
      "Epoch: 2960, Loss= 0.6272, Training Accuracy= 0.633\n",
      "Epoch: 2970, Loss= 0.6370, Training Accuracy= 0.622\n",
      "Epoch: 2980, Loss= 0.7811, Training Accuracy= 0.497\n",
      "Epoch: 2990, Loss= 0.7644, Training Accuracy= 0.497\n",
      "Epoch: 3000, Loss= 0.7481, Training Accuracy= 0.497\n",
      "Epoch: 3010, Loss= 0.7410, Training Accuracy= 0.497\n",
      "Epoch: 3020, Loss= 0.7360, Training Accuracy= 0.497\n",
      "Epoch: 3030, Loss= 0.7295, Training Accuracy= 0.497\n",
      "Epoch: 3040, Loss= 0.7308, Training Accuracy= 0.497\n",
      "Epoch: 3050, Loss= 0.7276, Training Accuracy= 0.497\n",
      "Epoch: 3060, Loss= 0.7269, Training Accuracy= 0.497\n",
      "Epoch: 3070, Loss= 0.7243, Training Accuracy= 0.497\n",
      "Epoch: 3080, Loss= 0.7236, Training Accuracy= 0.498\n",
      "Epoch: 3090, Loss= 0.7197, Training Accuracy= 0.499\n",
      "Epoch: 3100, Loss= 0.7195, Training Accuracy= 0.500\n",
      "Epoch: 3110, Loss= 0.7161, Training Accuracy= 0.501\n",
      "Epoch: 3120, Loss= 0.7160, Training Accuracy= 0.503\n",
      "Epoch: 3130, Loss= 0.7160, Training Accuracy= 0.506\n",
      "Epoch: 3140, Loss= 0.7158, Training Accuracy= 0.508\n",
      "Epoch: 3150, Loss= 0.7138, Training Accuracy= 0.509\n",
      "Epoch: 3160, Loss= 0.7151, Training Accuracy= 0.510\n",
      "Epoch: 3170, Loss= 0.7165, Training Accuracy= 0.511\n",
      "Epoch: 3180, Loss= 0.7187, Training Accuracy= 0.511\n",
      "Epoch: 3190, Loss= 0.7173, Training Accuracy= 0.513\n",
      "Epoch: 3200, Loss= 0.7191, Training Accuracy= 0.512\n",
      "Epoch: 3210, Loss= 0.7209, Training Accuracy= 0.512\n",
      "Epoch: 3220, Loss= 0.7182, Training Accuracy= 0.514\n",
      "Epoch: 3230, Loss= 0.7065, Training Accuracy= 0.518\n",
      "Epoch: 3240, Loss= 0.7179, Training Accuracy= 0.521\n",
      "Epoch: 3250, Loss= 0.7125, Training Accuracy= 0.523\n",
      "Epoch: 3260, Loss= 0.7117, Training Accuracy= 0.518\n",
      "Epoch: 3270, Loss= 0.7079, Training Accuracy= 0.516\n",
      "Epoch: 3280, Loss= 0.6973, Training Accuracy= 0.529\n",
      "Epoch: 3290, Loss= 0.7045, Training Accuracy= 0.530\n",
      "Epoch: 3300, Loss= 0.7060, Training Accuracy= 0.533\n",
      "Epoch: 3310, Loss= 0.7017, Training Accuracy= 0.535\n",
      "Epoch: 3320, Loss= 0.6977, Training Accuracy= 0.537\n",
      "Epoch: 3330, Loss= 0.7021, Training Accuracy= 0.533\n",
      "Epoch: 3340, Loss= 0.7001, Training Accuracy= 0.540\n",
      "Epoch: 3350, Loss= 0.7217, Training Accuracy= 0.510\n",
      "Epoch: 3360, Loss= 0.7140, Training Accuracy= 0.498\n",
      "Epoch: 3370, Loss= 0.7099, Training Accuracy= 0.497\n",
      "Epoch: 3380, Loss= 0.7077, Training Accuracy= 0.497\n",
      "Epoch: 3390, Loss= 0.7110, Training Accuracy= 0.498\n",
      "Epoch: 3400, Loss= 0.7076, Training Accuracy= 0.498\n",
      "Epoch: 3410, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3420, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 3430, Loss= 0.7002, Training Accuracy= 0.510\n",
      "Epoch: 3440, Loss= 0.6951, Training Accuracy= 0.523\n",
      "Epoch: 3450, Loss= 0.6993, Training Accuracy= 0.515\n",
      "Epoch: 3460, Loss= 0.6976, Training Accuracy= 0.520\n",
      "Epoch: 3470, Loss= 0.6941, Training Accuracy= 0.524\n",
      "Epoch: 3480, Loss= 0.6940, Training Accuracy= 0.525\n",
      "Epoch: 3490, Loss= 0.6970, Training Accuracy= 0.519\n",
      "Epoch: 3500, Loss= 0.6930, Training Accuracy= 0.534\n",
      "Epoch: 3510, Loss= 0.6939, Training Accuracy= 0.523\n",
      "Epoch: 3520, Loss= 0.6935, Training Accuracy= 0.528\n",
      "Epoch: 3530, Loss= 0.7041, Training Accuracy= 0.506\n",
      "Epoch: 3540, Loss= 0.6973, Training Accuracy= 0.517\n",
      "Epoch: 3550, Loss= 0.7038, Training Accuracy= 0.508\n",
      "Epoch: 3560, Loss= 0.7029, Training Accuracy= 0.507\n",
      "Epoch: 3570, Loss= 0.7314, Training Accuracy= 0.497\n",
      "Epoch: 3580, Loss= 0.7243, Training Accuracy= 0.498\n",
      "Epoch: 3590, Loss= 0.7219, Training Accuracy= 0.498\n",
      "Epoch: 3600, Loss= 0.7201, Training Accuracy= 0.498\n",
      "Epoch: 3610, Loss= 0.7183, Training Accuracy= 0.499\n",
      "Epoch: 3620, Loss= 0.7170, Training Accuracy= 0.500\n",
      "Epoch: 3630, Loss= 0.7152, Training Accuracy= 0.501\n",
      "Epoch: 3640, Loss= 0.7129, Training Accuracy= 0.502\n",
      "Epoch: 3650, Loss= 0.7104, Training Accuracy= 0.502\n",
      "Epoch: 3660, Loss= 0.7073, Training Accuracy= 0.503\n",
      "Epoch: 3670, Loss= 0.7031, Training Accuracy= 0.509\n",
      "Epoch: 3680, Loss= 0.7041, Training Accuracy= 0.511\n",
      "Epoch: 3690, Loss= 0.6981, Training Accuracy= 0.524\n",
      "Epoch: 3700, Loss= 0.6981, Training Accuracy= 0.521\n",
      "Epoch: 3710, Loss= 0.6933, Training Accuracy= 0.526\n",
      "Epoch: 3720, Loss= 0.6910, Training Accuracy= 0.535\n",
      "Epoch: 3730, Loss= 0.6960, Training Accuracy= 0.524\n",
      "Epoch: 3740, Loss= 0.6877, Training Accuracy= 0.536\n",
      "Epoch: 3750, Loss= 0.6862, Training Accuracy= 0.544\n",
      "Epoch: 3760, Loss= 0.6898, Training Accuracy= 0.539\n",
      "Epoch: 3770, Loss= 0.6849, Training Accuracy= 0.547\n",
      "Epoch: 3780, Loss= 0.6871, Training Accuracy= 0.541\n",
      "Epoch: 3790, Loss= 0.6983, Training Accuracy= 0.528\n",
      "Epoch: 3800, Loss= 0.6848, Training Accuracy= 0.547\n",
      "Epoch: 3810, Loss= 0.6845, Training Accuracy= 0.550\n",
      "Epoch: 3820, Loss= 0.6873, Training Accuracy= 0.539\n",
      "Epoch: 3830, Loss= 0.6841, Training Accuracy= 0.556\n",
      "Epoch: 3840, Loss= 0.6889, Training Accuracy= 0.548\n",
      "Epoch: 3850, Loss= 0.6806, Training Accuracy= 0.562\n",
      "Epoch: 3860, Loss= 0.6813, Training Accuracy= 0.562\n",
      "Epoch: 3870, Loss= 0.6781, Training Accuracy= 0.566\n",
      "Epoch: 3880, Loss= 0.6784, Training Accuracy= 0.563\n",
      "Epoch: 3890, Loss= 0.6841, Training Accuracy= 0.548\n",
      "Epoch: 3900, Loss= 1.0787, Training Accuracy= 0.497\n",
      "Epoch: 3910, Loss= 0.9730, Training Accuracy= 0.497\n",
      "Epoch: 3920, Loss= 0.9152, Training Accuracy= 0.497\n",
      "Epoch: 3930, Loss= 0.8799, Training Accuracy= 0.497\n",
      "Epoch: 3940, Loss= 0.8443, Training Accuracy= 0.497\n",
      "Epoch: 3950, Loss= 0.8120, Training Accuracy= 0.497\n",
      "Epoch: 3960, Loss= 0.7961, Training Accuracy= 0.497\n",
      "Epoch: 3970, Loss= 0.7854, Training Accuracy= 0.497\n",
      "Epoch: 3980, Loss= 0.7729, Training Accuracy= 0.497\n",
      "Epoch: 3990, Loss= 0.7651, Training Accuracy= 0.497\n",
      "Epoch: 4000, Loss= 0.7593, Training Accuracy= 0.497\n",
      "Epoch: 4010, Loss= 0.7549, Training Accuracy= 0.497\n",
      "Epoch: 4020, Loss= 0.7513, Training Accuracy= 0.497\n",
      "Epoch: 4030, Loss= 0.7495, Training Accuracy= 0.498\n",
      "Epoch: 4040, Loss= 0.7493, Training Accuracy= 0.500\n",
      "Epoch: 4050, Loss= 0.7481, Training Accuracy= 0.501\n",
      "Epoch: 4060, Loss= 0.7459, Training Accuracy= 0.503\n",
      "Epoch: 4070, Loss= 0.7457, Training Accuracy= 0.503\n",
      "Epoch: 4080, Loss= 0.7429, Training Accuracy= 0.504\n",
      "Epoch: 4090, Loss= 0.7434, Training Accuracy= 0.504\n",
      "Epoch: 4100, Loss= 0.7410, Training Accuracy= 0.505\n",
      "Epoch: 4110, Loss= 0.7408, Training Accuracy= 0.505\n",
      "Epoch: 4120, Loss= 0.7362, Training Accuracy= 0.507\n",
      "Epoch: 4130, Loss= 0.7414, Training Accuracy= 0.507\n",
      "Epoch: 4140, Loss= 0.7407, Training Accuracy= 0.507\n",
      "Epoch: 4150, Loss= 0.7377, Training Accuracy= 0.509\n",
      "Epoch: 4160, Loss= 0.7395, Training Accuracy= 0.509\n",
      "Epoch: 4170, Loss= 0.7327, Training Accuracy= 0.510\n",
      "Epoch: 4180, Loss= 0.7383, Training Accuracy= 0.510\n",
      "Epoch: 4190, Loss= 0.7326, Training Accuracy= 0.509\n",
      "Epoch: 4200, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 4210, Loss= 0.7733, Training Accuracy= 0.500\n",
      "Epoch: 4220, Loss= 0.7653, Training Accuracy= 0.501\n",
      "Epoch: 4230, Loss= 0.7666, Training Accuracy= 0.503\n",
      "Epoch: 4240, Loss= 0.7737, Training Accuracy= 0.502\n",
      "Epoch: 4250, Loss= 0.7610, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4260, Loss= 0.7673, Training Accuracy= 0.506\n",
      "Epoch: 4270, Loss= 0.7757, Training Accuracy= 0.498\n",
      "Epoch: 4280, Loss= 0.7536, Training Accuracy= 0.507\n",
      "Epoch: 4290, Loss= 0.7645, Training Accuracy= 0.505\n",
      "Epoch: 4300, Loss= 0.7475, Training Accuracy= 0.510\n",
      "Epoch: 4310, Loss= 0.7452, Training Accuracy= 0.511\n",
      "Epoch: 4320, Loss= 0.7415, Training Accuracy= 0.513\n",
      "Epoch: 4330, Loss= 0.7401, Training Accuracy= 0.510\n",
      "Epoch: 4340, Loss= 0.7583, Training Accuracy= 0.507\n",
      "Epoch: 4350, Loss= 0.7616, Training Accuracy= 0.503\n",
      "Epoch: 4360, Loss= 0.7721, Training Accuracy= 0.504\n",
      "Epoch: 4370, Loss= 0.7555, Training Accuracy= 0.509\n",
      "Epoch: 4380, Loss= 0.7472, Training Accuracy= 0.510\n",
      "Epoch: 4390, Loss= 0.7254, Training Accuracy= 0.521\n",
      "Epoch: 4400, Loss= 0.7371, Training Accuracy= 0.516\n",
      "Epoch: 4410, Loss= 0.7317, Training Accuracy= 0.516\n",
      "Epoch: 4420, Loss= 0.7238, Training Accuracy= 0.519\n",
      "Epoch: 4430, Loss= 0.7345, Training Accuracy= 0.514\n",
      "Epoch: 4440, Loss= 0.7167, Training Accuracy= 0.524\n",
      "Epoch: 4450, Loss= 0.7254, Training Accuracy= 0.523\n",
      "Epoch: 4460, Loss= 0.7196, Training Accuracy= 0.511\n",
      "Epoch: 4470, Loss= 0.7855, Training Accuracy= 0.498\n",
      "Epoch: 4480, Loss= 0.7791, Training Accuracy= 0.497\n",
      "Epoch: 4490, Loss= 0.7893, Training Accuracy= 0.497\n",
      "Epoch: 4500, Loss= 0.7523, Training Accuracy= 0.498\n",
      "Epoch: 4510, Loss= 0.7574, Training Accuracy= 0.498\n",
      "Epoch: 4520, Loss= 0.7500, Training Accuracy= 0.497\n",
      "Epoch: 4530, Loss= 0.7575, Training Accuracy= 0.498\n",
      "Epoch: 4540, Loss= 0.7468, Training Accuracy= 0.500\n",
      "Epoch: 4550, Loss= 0.7497, Training Accuracy= 0.499\n",
      "Epoch: 4560, Loss= 0.7432, Training Accuracy= 0.504\n",
      "Epoch: 4570, Loss= 0.7574, Training Accuracy= 0.504\n",
      "Epoch: 4580, Loss= 0.7376, Training Accuracy= 0.507\n",
      "Epoch: 4590, Loss= 0.7268, Training Accuracy= 0.509\n",
      "Epoch: 4600, Loss= 0.7198, Training Accuracy= 0.518\n",
      "Epoch: 4610, Loss= 0.7421, Training Accuracy= 0.510\n",
      "Epoch: 4620, Loss= 0.7221, Training Accuracy= 0.521\n",
      "Epoch: 4630, Loss= 0.7293, Training Accuracy= 0.515\n",
      "Epoch: 4640, Loss= 0.7110, Training Accuracy= 0.521\n",
      "Epoch: 4650, Loss= 0.7213, Training Accuracy= 0.516\n",
      "Epoch: 4660, Loss= 0.7244, Training Accuracy= 0.518\n",
      "Epoch: 4670, Loss= 0.7178, Training Accuracy= 0.524\n",
      "Epoch: 4680, Loss= 0.7145, Training Accuracy= 0.529\n",
      "Epoch: 4690, Loss= 0.7070, Training Accuracy= 0.530\n",
      "Epoch: 4700, Loss= 0.7052, Training Accuracy= 0.530\n",
      "Epoch: 4710, Loss= 0.6913, Training Accuracy= 0.551\n",
      "Epoch: 4720, Loss= 0.6881, Training Accuracy= 0.547\n",
      "Epoch: 4730, Loss= 0.6855, Training Accuracy= 0.553\n",
      "Epoch: 4740, Loss= 0.6827, Training Accuracy= 0.556\n",
      "Epoch: 4750, Loss= 0.6981, Training Accuracy= 0.536\n",
      "Epoch: 4760, Loss= 0.6726, Training Accuracy= 0.570\n",
      "Epoch: 4770, Loss= 0.6981, Training Accuracy= 0.550\n",
      "Epoch: 4780, Loss= 0.6784, Training Accuracy= 0.565\n",
      "Epoch: 4790, Loss= 0.6731, Training Accuracy= 0.571\n",
      "Epoch: 4800, Loss= 0.6663, Training Accuracy= 0.585\n",
      "Epoch: 4810, Loss= 0.6719, Training Accuracy= 0.566\n",
      "Epoch: 4820, Loss= 0.6704, Training Accuracy= 0.578\n",
      "Epoch: 4830, Loss= 0.6704, Training Accuracy= 0.582\n",
      "Epoch: 4840, Loss= 0.6676, Training Accuracy= 0.579\n",
      "Epoch: 4850, Loss= 0.6669, Training Accuracy= 0.578\n",
      "Epoch: 4860, Loss= 0.6671, Training Accuracy= 0.581\n",
      "Epoch: 4870, Loss= 0.7101, Training Accuracy= 0.530\n",
      "Epoch: 4880, Loss= 0.6630, Training Accuracy= 0.582\n",
      "Epoch: 4890, Loss= 0.6698, Training Accuracy= 0.579\n",
      "Epoch: 4900, Loss= 0.6953, Training Accuracy= 0.539\n",
      "Epoch: 4910, Loss= 0.7369, Training Accuracy= 0.523\n",
      "Epoch: 4920, Loss= 0.6887, Training Accuracy= 0.547\n",
      "Epoch: 4930, Loss= 0.6851, Training Accuracy= 0.553\n",
      "Epoch: 4940, Loss= 0.7202, Training Accuracy= 0.520\n",
      "Epoch: 4950, Loss= 0.6856, Training Accuracy= 0.551\n",
      "Epoch: 4960, Loss= 0.6711, Training Accuracy= 0.576\n",
      "Epoch: 4970, Loss= 0.6664, Training Accuracy= 0.585\n",
      "Epoch: 4980, Loss= 0.6914, Training Accuracy= 0.548\n",
      "Epoch: 4990, Loss= 0.7358, Training Accuracy= 0.508\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5017\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.6948, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.6937, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.6934, Training Accuracy= 0.507\n",
      "Epoch: 40, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 50, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 60, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 70, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 80, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 90, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 100, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 110, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 120, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 130, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.6928, Training Accuracy= 0.507\n",
      "Epoch: 150, Loss= 0.6928, Training Accuracy= 0.507\n",
      "Epoch: 160, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 170, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 180, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 190, Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 200, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 210, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 220, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 230, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 240, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 250, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 260, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 270, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 280, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 290, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 300, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 310, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 320, Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 330, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 340, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 350, Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 360, Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 370, Loss= 0.6925, Training Accuracy= 0.520\n",
      "Epoch: 380, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 390, Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 400, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 410, Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 420, Loss= 0.6926, Training Accuracy= 0.510\n",
      "Epoch: 430, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 440, Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 450, Loss= 0.6930, Training Accuracy= 0.518\n",
      "Epoch: 460, Loss= 0.6922, Training Accuracy= 0.521\n",
      "Epoch: 470, Loss= 0.6922, Training Accuracy= 0.518\n",
      "Epoch: 480, Loss= 0.6917, Training Accuracy= 0.521\n",
      "Epoch: 490, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 500, Loss= 0.6903, Training Accuracy= 0.527\n",
      "Epoch: 510, Loss= 0.6928, Training Accuracy= 0.504\n",
      "Epoch: 520, Loss= 0.6921, Training Accuracy= 0.509\n",
      "Epoch: 530, Loss= 0.6914, Training Accuracy= 0.509\n",
      "Epoch: 540, Loss= 0.6927, Training Accuracy= 0.516\n",
      "Epoch: 550, Loss= 0.6920, Training Accuracy= 0.515\n",
      "Epoch: 560, Loss= 0.6917, Training Accuracy= 0.515\n",
      "Epoch: 570, Loss= 0.6918, Training Accuracy= 0.512\n",
      "Epoch: 580, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 590, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 600, Loss= 0.6918, Training Accuracy= 0.511\n",
      "Epoch: 610, Loss= 0.6914, Training Accuracy= 0.520\n",
      "Epoch: 620, Loss= 0.6906, Training Accuracy= 0.516\n",
      "Epoch: 630, Loss= 0.6903, Training Accuracy= 0.517\n",
      "Epoch: 640, Loss= 0.6905, Training Accuracy= 0.518\n",
      "Epoch: 650, Loss= 0.6904, Training Accuracy= 0.523\n",
      "Epoch: 660, Loss= 0.6897, Training Accuracy= 0.524\n",
      "Epoch: 670, Loss= 0.6903, Training Accuracy= 0.526\n",
      "Epoch: 680, Loss= 0.6911, Training Accuracy= 0.524\n",
      "Epoch: 690, Loss= 0.6912, Training Accuracy= 0.518\n",
      "Epoch: 700, Loss= 0.6907, Training Accuracy= 0.522\n",
      "Epoch: 710, Loss= 0.6925, Training Accuracy= 0.522\n",
      "Epoch: 720, Loss= 0.6899, Training Accuracy= 0.520\n",
      "Epoch: 730, Loss= 0.6893, Training Accuracy= 0.525\n",
      "Epoch: 740, Loss= 0.6889, Training Accuracy= 0.526\n",
      "Epoch: 750, Loss= 0.6880, Training Accuracy= 0.530\n",
      "Epoch: 760, Loss= 0.6871, Training Accuracy= 0.530\n",
      "Epoch: 770, Loss= 0.6864, Training Accuracy= 0.531\n",
      "Epoch: 780, Loss= 0.6860, Training Accuracy= 0.531\n",
      "Epoch: 790, Loss= 0.6903, Training Accuracy= 0.528\n",
      "Epoch: 800, Loss= 0.6852, Training Accuracy= 0.540\n",
      "Epoch: 810, Loss= 0.6809, Training Accuracy= 0.546\n",
      "Epoch: 820, Loss= 0.6802, Training Accuracy= 0.550\n",
      "Epoch: 830, Loss= 0.6834, Training Accuracy= 0.545\n",
      "Epoch: 840, Loss= 0.6776, Training Accuracy= 0.554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 850, Loss= 0.6761, Training Accuracy= 0.558\n",
      "Epoch: 860, Loss= 0.6744, Training Accuracy= 0.563\n",
      "Epoch: 870, Loss= 0.6760, Training Accuracy= 0.562\n",
      "Epoch: 880, Loss= 0.6747, Training Accuracy= 0.566\n",
      "Epoch: 890, Loss= 0.6784, Training Accuracy= 0.560\n",
      "Epoch: 900, Loss= 0.6907, Training Accuracy= 0.544\n",
      "Epoch: 910, Loss= 0.6730, Training Accuracy= 0.568\n",
      "Epoch: 920, Loss= 0.6711, Training Accuracy= 0.569\n",
      "Epoch: 930, Loss= 0.6674, Training Accuracy= 0.578\n",
      "Epoch: 940, Loss= 0.6741, Training Accuracy= 0.573\n",
      "Epoch: 950, Loss= 0.6653, Training Accuracy= 0.582\n",
      "Epoch: 960, Loss= 0.6702, Training Accuracy= 0.578\n",
      "Epoch: 970, Loss= 0.6570, Training Accuracy= 0.588\n",
      "Epoch: 980, Loss= 0.6604, Training Accuracy= 0.591\n",
      "Epoch: 990, Loss= 0.6497, Training Accuracy= 0.603\n",
      "Epoch: 1000, Loss= 0.6498, Training Accuracy= 0.601\n",
      "Epoch: 1010, Loss= 0.6452, Training Accuracy= 0.613\n",
      "Epoch: 1020, Loss= 0.6399, Training Accuracy= 0.619\n",
      "Epoch: 1030, Loss= 0.6820, Training Accuracy= 0.574\n",
      "Epoch: 1040, Loss= 0.6483, Training Accuracy= 0.612\n",
      "Epoch: 1050, Loss= 0.6363, Training Accuracy= 0.622\n",
      "Epoch: 1060, Loss= 0.6423, Training Accuracy= 0.626\n",
      "Epoch: 1070, Loss= 0.5633, Training Accuracy= 0.680\n",
      "Epoch: 1080, Loss= 0.5022, Training Accuracy= 0.714\n",
      "Epoch: 1090, Loss= 0.4923, Training Accuracy= 0.714\n",
      "Epoch: 1100, Loss= 0.3967, Training Accuracy= 0.779\n",
      "Epoch: 1110, Loss= 0.3296, Training Accuracy= 0.824\n",
      "Epoch: 1120, Loss= 0.9944, Training Accuracy= 0.543\n",
      "Epoch: 1130, Loss= 0.1247, Training Accuracy= 0.941\n",
      "Epoch: 1140, Loss= 0.6358, Training Accuracy= 0.618\n",
      "Epoch: 1150, Loss= 0.2927, Training Accuracy= 0.835\n",
      "Epoch: 1160, Loss= 0.3024, Training Accuracy= 0.823\n",
      "Epoch: 1170, Loss= 0.2128, Training Accuracy= 0.899\n",
      "Epoch: 1180, Loss= 0.7336, Training Accuracy= 0.519\n",
      "Epoch: 1190, Loss= 0.7359, Training Accuracy= 0.512\n",
      "Epoch: 1200, Loss= 0.7292, Training Accuracy= 0.507\n",
      "Epoch: 1210, Loss= 0.7102, Training Accuracy= 0.517\n",
      "Epoch: 1220, Loss= 0.7069, Training Accuracy= 0.513\n",
      "Epoch: 1230, Loss= 0.7042, Training Accuracy= 0.505\n",
      "Epoch: 1240, Loss= 0.7022, Training Accuracy= 0.506\n",
      "Epoch: 1250, Loss= 0.7012, Training Accuracy= 0.509\n",
      "Epoch: 1260, Loss= 0.7005, Training Accuracy= 0.507\n",
      "Epoch: 1270, Loss= 0.7000, Training Accuracy= 0.508\n",
      "Epoch: 1280, Loss= 0.6994, Training Accuracy= 0.510\n",
      "Epoch: 1290, Loss= 0.6988, Training Accuracy= 0.510\n",
      "Epoch: 1300, Loss= 0.6984, Training Accuracy= 0.513\n",
      "Epoch: 1310, Loss= 0.6980, Training Accuracy= 0.514\n",
      "Epoch: 1320, Loss= 0.6977, Training Accuracy= 0.516\n",
      "Epoch: 1330, Loss= 0.6973, Training Accuracy= 0.516\n",
      "Epoch: 1340, Loss= 0.6970, Training Accuracy= 0.516\n",
      "Epoch: 1350, Loss= 0.6966, Training Accuracy= 0.515\n",
      "Epoch: 1360, Loss= 0.6961, Training Accuracy= 0.515\n",
      "Epoch: 1370, Loss= 0.6956, Training Accuracy= 0.516\n",
      "Epoch: 1380, Loss= 0.6952, Training Accuracy= 0.520\n",
      "Epoch: 1390, Loss= 0.6947, Training Accuracy= 0.521\n",
      "Epoch: 1400, Loss= 0.6943, Training Accuracy= 0.521\n",
      "Epoch: 1410, Loss= 0.6940, Training Accuracy= 0.522\n",
      "Epoch: 1420, Loss= 0.6937, Training Accuracy= 0.525\n",
      "Epoch: 1430, Loss= 0.6934, Training Accuracy= 0.527\n",
      "Epoch: 1440, Loss= 0.6931, Training Accuracy= 0.528\n",
      "Epoch: 1450, Loss= 0.6930, Training Accuracy= 0.528\n",
      "Epoch: 1460, Loss= 0.6929, Training Accuracy= 0.527\n",
      "Epoch: 1470, Loss= 0.6929, Training Accuracy= 0.528\n",
      "Epoch: 1480, Loss= 0.6928, Training Accuracy= 0.529\n",
      "Epoch: 1490, Loss= 0.6927, Training Accuracy= 0.530\n",
      "Epoch: 1500, Loss= 0.6925, Training Accuracy= 0.533\n",
      "Epoch: 1510, Loss= 0.6919, Training Accuracy= 0.535\n",
      "Epoch: 1520, Loss= 0.6912, Training Accuracy= 0.539\n",
      "Epoch: 1530, Loss= 0.6903, Training Accuracy= 0.546\n",
      "Epoch: 1540, Loss= 0.6854, Training Accuracy= 0.557\n",
      "Epoch: 1550, Loss= 0.6792, Training Accuracy= 0.556\n",
      "Epoch: 1560, Loss= 0.6749, Training Accuracy= 0.568\n",
      "Epoch: 1570, Loss= 0.6721, Training Accuracy= 0.576\n",
      "Epoch: 1580, Loss= 0.6711, Training Accuracy= 0.580\n",
      "Epoch: 1590, Loss= 0.6662, Training Accuracy= 0.582\n",
      "Epoch: 1600, Loss= 0.6646, Training Accuracy= 0.587\n",
      "Epoch: 1610, Loss= 0.6651, Training Accuracy= 0.588\n",
      "Epoch: 1620, Loss= 0.6610, Training Accuracy= 0.592\n",
      "Epoch: 1630, Loss= 0.6699, Training Accuracy= 0.583\n",
      "Epoch: 1640, Loss= 0.6475, Training Accuracy= 0.604\n",
      "Epoch: 1650, Loss= 0.6607, Training Accuracy= 0.600\n",
      "Epoch: 1660, Loss= 0.6419, Training Accuracy= 0.612\n",
      "Epoch: 1670, Loss= 0.6178, Training Accuracy= 0.636\n",
      "Epoch: 1680, Loss= 0.7484, Training Accuracy= 0.501\n",
      "Epoch: 1690, Loss= 0.7030, Training Accuracy= 0.508\n",
      "Epoch: 1700, Loss= 0.6996, Training Accuracy= 0.511\n",
      "Epoch: 1710, Loss= 0.6981, Training Accuracy= 0.511\n",
      "Epoch: 1720, Loss= 0.6972, Training Accuracy= 0.514\n",
      "Epoch: 1730, Loss= 0.6965, Training Accuracy= 0.517\n",
      "Epoch: 1740, Loss= 0.6960, Training Accuracy= 0.518\n",
      "Epoch: 1750, Loss= 0.6957, Training Accuracy= 0.521\n",
      "Epoch: 1760, Loss= 0.6952, Training Accuracy= 0.523\n",
      "Epoch: 1770, Loss= 0.6943, Training Accuracy= 0.526\n",
      "Epoch: 1780, Loss= 0.6926, Training Accuracy= 0.529\n",
      "Epoch: 1790, Loss= 0.6906, Training Accuracy= 0.538\n",
      "Epoch: 1800, Loss= 0.6889, Training Accuracy= 0.548\n",
      "Epoch: 1810, Loss= 0.6881, Training Accuracy= 0.549\n",
      "Epoch: 1820, Loss= 0.6874, Training Accuracy= 0.554\n",
      "Epoch: 1830, Loss= 0.6854, Training Accuracy= 0.554\n",
      "Epoch: 1840, Loss= 0.6872, Training Accuracy= 0.548\n",
      "Epoch: 1850, Loss= 0.6854, Training Accuracy= 0.554\n",
      "Epoch: 1860, Loss= 0.6878, Training Accuracy= 0.549\n",
      "Epoch: 1870, Loss= 0.6821, Training Accuracy= 0.555\n",
      "Epoch: 1880, Loss= 0.6795, Training Accuracy= 0.563\n",
      "Epoch: 1890, Loss= 0.6781, Training Accuracy= 0.567\n",
      "Epoch: 1900, Loss= 0.6845, Training Accuracy= 0.561\n",
      "Epoch: 1910, Loss= 0.6908, Training Accuracy= 0.550\n",
      "Epoch: 1920, Loss= 0.6761, Training Accuracy= 0.575\n",
      "Epoch: 1930, Loss= 0.6715, Training Accuracy= 0.578\n",
      "Epoch: 1940, Loss= 0.6679, Training Accuracy= 0.588\n",
      "Epoch: 1950, Loss= 0.6830, Training Accuracy= 0.568\n",
      "Epoch: 1960, Loss= 0.6950, Training Accuracy= 0.557\n",
      "Epoch: 1970, Loss= 0.6772, Training Accuracy= 0.579\n",
      "Epoch: 1980, Loss= 0.6783, Training Accuracy= 0.574\n",
      "Epoch: 1990, Loss= 0.6681, Training Accuracy= 0.586\n",
      "Epoch: 2000, Loss= 0.6747, Training Accuracy= 0.583\n",
      "Epoch: 2010, Loss= 0.6790, Training Accuracy= 0.579\n",
      "Epoch: 2020, Loss= 0.6770, Training Accuracy= 0.584\n",
      "Epoch: 2030, Loss= 0.6736, Training Accuracy= 0.583\n",
      "Epoch: 2040, Loss= 0.6740, Training Accuracy= 0.590\n",
      "Epoch: 2050, Loss= 0.6737, Training Accuracy= 0.585\n",
      "Epoch: 2060, Loss= 0.6632, Training Accuracy= 0.603\n",
      "Epoch: 2070, Loss= 0.6617, Training Accuracy= 0.596\n",
      "Epoch: 2080, Loss= 0.6688, Training Accuracy= 0.596\n",
      "Epoch: 2090, Loss= 0.6675, Training Accuracy= 0.592\n",
      "Epoch: 2100, Loss= 0.6495, Training Accuracy= 0.613\n",
      "Epoch: 2110, Loss= 0.6443, Training Accuracy= 0.622\n",
      "Epoch: 2120, Loss= 0.6381, Training Accuracy= 0.625\n",
      "Epoch: 2130, Loss= 0.6400, Training Accuracy= 0.627\n",
      "Epoch: 2140, Loss= 0.6463, Training Accuracy= 0.618\n",
      "Epoch: 2150, Loss= 0.6335, Training Accuracy= 0.632\n",
      "Epoch: 2160, Loss= 0.6453, Training Accuracy= 0.618\n",
      "Epoch: 2170, Loss= 0.6314, Training Accuracy= 0.632\n",
      "Epoch: 2180, Loss= 0.6396, Training Accuracy= 0.627\n",
      "Epoch: 2190, Loss= 0.6357, Training Accuracy= 0.632\n",
      "Epoch: 2200, Loss= 0.6283, Training Accuracy= 0.639\n",
      "Epoch: 2210, Loss= 0.6339, Training Accuracy= 0.632\n",
      "Epoch: 2220, Loss= 0.6311, Training Accuracy= 0.637\n",
      "Epoch: 2230, Loss= 0.6171, Training Accuracy= 0.648\n",
      "Epoch: 2240, Loss= 0.6404, Training Accuracy= 0.626\n",
      "Epoch: 2250, Loss= 0.6320, Training Accuracy= 0.636\n",
      "Epoch: 2260, Loss= 0.6764, Training Accuracy= 0.569\n",
      "Epoch: 2270, Loss= 0.6717, Training Accuracy= 0.597\n",
      "Epoch: 2280, Loss= 0.6169, Training Accuracy= 0.646\n",
      "Epoch: 2290, Loss= 0.6251, Training Accuracy= 0.641\n",
      "Epoch: 2300, Loss= 0.6231, Training Accuracy= 0.643\n",
      "Epoch: 2310, Loss= 0.6187, Training Accuracy= 0.649\n",
      "Epoch: 2320, Loss= 0.6200, Training Accuracy= 0.652\n",
      "Epoch: 2330, Loss= 0.6437, Training Accuracy= 0.618\n",
      "Epoch: 2340, Loss= 0.6098, Training Accuracy= 0.659\n",
      "Epoch: 2350, Loss= 0.6257, Training Accuracy= 0.647\n",
      "Epoch: 2360, Loss= 0.6320, Training Accuracy= 0.638\n",
      "Epoch: 2370, Loss= 0.6094, Training Accuracy= 0.661\n",
      "Epoch: 2380, Loss= 0.6052, Training Accuracy= 0.663\n",
      "Epoch: 2390, Loss= 0.6155, Training Accuracy= 0.654\n",
      "Epoch: 2400, Loss= 0.6274, Training Accuracy= 0.642\n",
      "Epoch: 2410, Loss= 0.6132, Training Accuracy= 0.648\n",
      "Epoch: 2420, Loss= 0.6031, Training Accuracy= 0.664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2430, Loss= 0.6126, Training Accuracy= 0.656\n",
      "Epoch: 2440, Loss= 0.6263, Training Accuracy= 0.641\n",
      "Epoch: 2450, Loss= 0.6068, Training Accuracy= 0.659\n",
      "Epoch: 2460, Loss= 0.6160, Training Accuracy= 0.652\n",
      "Epoch: 2470, Loss= 0.6417, Training Accuracy= 0.632\n",
      "Epoch: 2480, Loss= 0.6842, Training Accuracy= 0.598\n",
      "Epoch: 2490, Loss= 0.7245, Training Accuracy= 0.507\n",
      "Epoch: 2500, Loss= 0.7060, Training Accuracy= 0.514\n",
      "Epoch: 2510, Loss= 0.6998, Training Accuracy= 0.516\n",
      "Epoch: 2520, Loss= 0.6971, Training Accuracy= 0.518\n",
      "Epoch: 2530, Loss= 0.6960, Training Accuracy= 0.520\n",
      "Epoch: 2540, Loss= 0.6946, Training Accuracy= 0.524\n",
      "Epoch: 2550, Loss= 0.6919, Training Accuracy= 0.526\n",
      "Epoch: 2560, Loss= 0.6920, Training Accuracy= 0.528\n",
      "Epoch: 2570, Loss= 0.6892, Training Accuracy= 0.536\n",
      "Epoch: 2580, Loss= 0.6885, Training Accuracy= 0.538\n",
      "Epoch: 2590, Loss= 0.6885, Training Accuracy= 0.539\n",
      "Epoch: 2600, Loss= 0.6868, Training Accuracy= 0.548\n",
      "Epoch: 2610, Loss= 0.6857, Training Accuracy= 0.549\n",
      "Epoch: 2620, Loss= 0.6843, Training Accuracy= 0.552\n",
      "Epoch: 2630, Loss= 0.6882, Training Accuracy= 0.545\n",
      "Epoch: 2640, Loss= 0.6867, Training Accuracy= 0.553\n",
      "Epoch: 2650, Loss= 0.6828, Training Accuracy= 0.556\n",
      "Epoch: 2660, Loss= 0.6790, Training Accuracy= 0.561\n",
      "Epoch: 2670, Loss= 0.6801, Training Accuracy= 0.563\n",
      "Epoch: 2680, Loss= 0.6746, Training Accuracy= 0.572\n",
      "Epoch: 2690, Loss= 0.6788, Training Accuracy= 0.567\n",
      "Epoch: 2700, Loss= 0.6705, Training Accuracy= 0.579\n",
      "Epoch: 2710, Loss= 0.6795, Training Accuracy= 0.571\n",
      "Epoch: 2720, Loss= 0.7105, Training Accuracy= 0.513\n",
      "Epoch: 2730, Loss= 0.7002, Training Accuracy= 0.511\n",
      "Epoch: 2740, Loss= 0.6973, Training Accuracy= 0.519\n",
      "Epoch: 2750, Loss= 0.6940, Training Accuracy= 0.527\n",
      "Epoch: 2760, Loss= 0.6924, Training Accuracy= 0.532\n",
      "Epoch: 2770, Loss= 0.6906, Training Accuracy= 0.536\n",
      "Epoch: 2780, Loss= 0.6946, Training Accuracy= 0.525\n",
      "Epoch: 2790, Loss= 0.6933, Training Accuracy= 0.528\n",
      "Epoch: 2800, Loss= 0.6909, Training Accuracy= 0.534\n",
      "Epoch: 2810, Loss= 0.6955, Training Accuracy= 0.522\n",
      "Epoch: 2820, Loss= 0.6897, Training Accuracy= 0.538\n",
      "Epoch: 2830, Loss= 0.6867, Training Accuracy= 0.544\n",
      "Epoch: 2840, Loss= 0.6855, Training Accuracy= 0.547\n",
      "Epoch: 2850, Loss= 0.6889, Training Accuracy= 0.548\n",
      "Epoch: 2860, Loss= 0.6862, Training Accuracy= 0.551\n",
      "Epoch: 2870, Loss= 0.6854, Training Accuracy= 0.554\n",
      "Epoch: 2880, Loss= 0.6770, Training Accuracy= 0.564\n",
      "Epoch: 2890, Loss= 0.6760, Training Accuracy= 0.568\n",
      "Epoch: 2900, Loss= 0.6770, Training Accuracy= 0.569\n",
      "Epoch: 2910, Loss= 0.6794, Training Accuracy= 0.564\n",
      "Epoch: 2920, Loss= 0.6746, Training Accuracy= 0.576\n",
      "Epoch: 2930, Loss= 0.7055, Training Accuracy= 0.517\n",
      "Epoch: 2940, Loss= 0.6907, Training Accuracy= 0.537\n",
      "Epoch: 2950, Loss= 0.6987, Training Accuracy= 0.517\n",
      "Epoch: 2960, Loss= 0.6900, Training Accuracy= 0.539\n",
      "Epoch: 2970, Loss= 0.6858, Training Accuracy= 0.551\n",
      "Epoch: 2980, Loss= 0.6895, Training Accuracy= 0.546\n",
      "Epoch: 2990, Loss= 0.6921, Training Accuracy= 0.541\n",
      "Epoch: 3000, Loss= 0.6849, Training Accuracy= 0.550\n",
      "Epoch: 3010, Loss= 0.6836, Training Accuracy= 0.552\n",
      "Epoch: 3020, Loss= 0.6789, Training Accuracy= 0.567\n",
      "Epoch: 3030, Loss= 0.6825, Training Accuracy= 0.559\n",
      "Epoch: 3040, Loss= 0.6816, Training Accuracy= 0.556\n",
      "Epoch: 3050, Loss= 0.6828, Training Accuracy= 0.559\n",
      "Epoch: 3060, Loss= 0.6807, Training Accuracy= 0.562\n",
      "Epoch: 3070, Loss= 0.6813, Training Accuracy= 0.560\n",
      "Epoch: 3080, Loss= 0.6708, Training Accuracy= 0.580\n",
      "Epoch: 3090, Loss= 0.6815, Training Accuracy= 0.565\n",
      "Epoch: 3100, Loss= 0.6740, Training Accuracy= 0.575\n",
      "Epoch: 3110, Loss= 0.6709, Training Accuracy= 0.581\n",
      "Epoch: 3120, Loss= 0.6744, Training Accuracy= 0.575\n",
      "Epoch: 3130, Loss= 0.6876, Training Accuracy= 0.544\n",
      "Epoch: 3140, Loss= 0.6675, Training Accuracy= 0.587\n",
      "Epoch: 3150, Loss= 0.6922, Training Accuracy= 0.527\n",
      "Epoch: 3160, Loss= 0.6925, Training Accuracy= 0.522\n",
      "Epoch: 3170, Loss= 0.6885, Training Accuracy= 0.538\n",
      "Epoch: 3180, Loss= 0.6947, Training Accuracy= 0.517\n",
      "Epoch: 3190, Loss= 0.6922, Training Accuracy= 0.524\n",
      "Epoch: 3200, Loss= 0.6904, Training Accuracy= 0.530\n",
      "Epoch: 3210, Loss= 0.6888, Training Accuracy= 0.540\n",
      "Epoch: 3220, Loss= 0.6870, Training Accuracy= 0.542\n",
      "Epoch: 3230, Loss= 0.6850, Training Accuracy= 0.547\n",
      "Epoch: 3240, Loss= 0.6848, Training Accuracy= 0.552\n",
      "Epoch: 3250, Loss= 0.6844, Training Accuracy= 0.554\n",
      "Epoch: 3260, Loss= 0.6768, Training Accuracy= 0.564\n",
      "Epoch: 3270, Loss= 0.6788, Training Accuracy= 0.558\n",
      "Epoch: 3280, Loss= 0.6710, Training Accuracy= 0.576\n",
      "Epoch: 3290, Loss= 0.6700, Training Accuracy= 0.577\n",
      "Epoch: 3300, Loss= 0.6768, Training Accuracy= 0.575\n",
      "Epoch: 3310, Loss= 0.6631, Training Accuracy= 0.588\n",
      "Epoch: 3320, Loss= 0.6655, Training Accuracy= 0.580\n",
      "Epoch: 3330, Loss= 0.6529, Training Accuracy= 0.605\n",
      "Epoch: 3340, Loss= 0.6608, Training Accuracy= 0.593\n",
      "Epoch: 3350, Loss= 0.6593, Training Accuracy= 0.597\n",
      "Epoch: 3360, Loss= 0.6856, Training Accuracy= 0.556\n",
      "Epoch: 3370, Loss= 0.6699, Training Accuracy= 0.581\n",
      "Epoch: 3380, Loss= 0.6835, Training Accuracy= 0.554\n",
      "Epoch: 3390, Loss= 0.6630, Training Accuracy= 0.592\n",
      "Epoch: 3400, Loss= 0.6594, Training Accuracy= 0.601\n",
      "Epoch: 3410, Loss= 0.6522, Training Accuracy= 0.605\n",
      "Epoch: 3420, Loss= 0.6543, Training Accuracy= 0.604\n",
      "Epoch: 3430, Loss= 0.6609, Training Accuracy= 0.594\n",
      "Epoch: 3440, Loss= 0.6717, Training Accuracy= 0.583\n",
      "Epoch: 3450, Loss= 0.6535, Training Accuracy= 0.600\n",
      "Epoch: 3460, Loss= 0.6643, Training Accuracy= 0.594\n",
      "Epoch: 3470, Loss= 0.6579, Training Accuracy= 0.600\n",
      "Epoch: 3480, Loss= 0.6655, Training Accuracy= 0.588\n",
      "Epoch: 3490, Loss= 0.6435, Training Accuracy= 0.622\n",
      "Epoch: 3500, Loss= 0.6800, Training Accuracy= 0.573\n",
      "Epoch: 3510, Loss= 0.6724, Training Accuracy= 0.571\n",
      "Epoch: 3520, Loss= 0.6492, Training Accuracy= 0.613\n",
      "Epoch: 3530, Loss= 0.6422, Training Accuracy= 0.620\n",
      "Epoch: 3540, Loss= 0.6591, Training Accuracy= 0.603\n",
      "Epoch: 3550, Loss= 0.6821, Training Accuracy= 0.577\n",
      "Epoch: 3560, Loss= 0.6388, Training Accuracy= 0.625\n",
      "Epoch: 3570, Loss= 0.6309, Training Accuracy= 0.630\n",
      "Epoch: 3580, Loss= 0.6316, Training Accuracy= 0.629\n",
      "Epoch: 3590, Loss= 0.6437, Training Accuracy= 0.620\n",
      "Epoch: 3600, Loss= 0.6595, Training Accuracy= 0.608\n",
      "Epoch: 3610, Loss= 0.6710, Training Accuracy= 0.589\n",
      "Epoch: 3620, Loss= 0.6823, Training Accuracy= 0.558\n",
      "Epoch: 3630, Loss= 0.6437, Training Accuracy= 0.618\n",
      "Epoch: 3640, Loss= 0.6503, Training Accuracy= 0.609\n",
      "Epoch: 3650, Loss= 0.6806, Training Accuracy= 0.582\n",
      "Epoch: 3660, Loss= 0.6984, Training Accuracy= 0.513\n",
      "Epoch: 3670, Loss= 0.6957, Training Accuracy= 0.508\n",
      "Epoch: 3680, Loss= 0.6930, Training Accuracy= 0.520\n",
      "Epoch: 3690, Loss= 0.6923, Training Accuracy= 0.522\n",
      "Epoch: 3700, Loss= 0.6939, Training Accuracy= 0.512\n",
      "Epoch: 3710, Loss= 0.6933, Training Accuracy= 0.513\n",
      "Epoch: 3720, Loss= 0.6931, Training Accuracy= 0.516\n",
      "Epoch: 3730, Loss= 0.6933, Training Accuracy= 0.519\n",
      "Epoch: 3740, Loss= 0.6921, Training Accuracy= 0.523\n",
      "Epoch: 3750, Loss= 0.6916, Training Accuracy= 0.528\n",
      "Epoch: 3760, Loss= 0.6901, Training Accuracy= 0.531\n",
      "Epoch: 3770, Loss= 0.6899, Training Accuracy= 0.538\n",
      "Epoch: 3780, Loss= 0.6884, Training Accuracy= 0.541\n",
      "Epoch: 3790, Loss= 0.6900, Training Accuracy= 0.533\n",
      "Epoch: 3800, Loss= 0.6870, Training Accuracy= 0.540\n",
      "Epoch: 3810, Loss= 0.6870, Training Accuracy= 0.541\n",
      "Epoch: 3820, Loss= 0.6878, Training Accuracy= 0.541\n",
      "Epoch: 3830, Loss= 0.6881, Training Accuracy= 0.539\n",
      "Epoch: 3840, Loss= 0.6856, Training Accuracy= 0.549\n",
      "Epoch: 3850, Loss= 0.6838, Training Accuracy= 0.556\n",
      "Epoch: 3860, Loss= 0.6837, Training Accuracy= 0.556\n",
      "Epoch: 3870, Loss= 0.6799, Training Accuracy= 0.557\n",
      "Epoch: 3880, Loss= 0.6813, Training Accuracy= 0.560\n",
      "Epoch: 3890, Loss= 0.6832, Training Accuracy= 0.550\n",
      "Epoch: 3900, Loss= 0.6781, Training Accuracy= 0.565\n",
      "Epoch: 3910, Loss= 0.6921, Training Accuracy= 0.529\n",
      "Epoch: 3920, Loss= 0.6893, Training Accuracy= 0.535\n",
      "Epoch: 3930, Loss= 0.6906, Training Accuracy= 0.533\n",
      "Epoch: 3940, Loss= 0.6884, Training Accuracy= 0.538\n",
      "Epoch: 3950, Loss= 0.6860, Training Accuracy= 0.544\n",
      "Epoch: 3960, Loss= 0.6867, Training Accuracy= 0.546\n",
      "Epoch: 3970, Loss= 0.6862, Training Accuracy= 0.546\n",
      "Epoch: 3980, Loss= 0.6853, Training Accuracy= 0.549\n",
      "Epoch: 3990, Loss= 0.6850, Training Accuracy= 0.547\n",
      "Epoch: 4000, Loss= 0.6840, Training Accuracy= 0.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4010, Loss= 0.6800, Training Accuracy= 0.558\n",
      "Epoch: 4020, Loss= 0.6779, Training Accuracy= 0.566\n",
      "Epoch: 4030, Loss= 0.6769, Training Accuracy= 0.569\n",
      "Epoch: 4040, Loss= 0.6796, Training Accuracy= 0.558\n",
      "Epoch: 4050, Loss= 0.6797, Training Accuracy= 0.558\n",
      "Epoch: 4060, Loss= 0.6739, Training Accuracy= 0.573\n",
      "Epoch: 4070, Loss= 0.6717, Training Accuracy= 0.579\n",
      "Epoch: 4080, Loss= 0.6734, Training Accuracy= 0.576\n",
      "Epoch: 4090, Loss= 0.6696, Training Accuracy= 0.582\n",
      "Epoch: 4100, Loss= 0.6773, Training Accuracy= 0.567\n",
      "Epoch: 4110, Loss= 0.6641, Training Accuracy= 0.591\n",
      "Epoch: 4120, Loss= 0.6751, Training Accuracy= 0.571\n",
      "Epoch: 4130, Loss= 0.6627, Training Accuracy= 0.585\n",
      "Epoch: 4140, Loss= 0.6777, Training Accuracy= 0.568\n",
      "Epoch: 4150, Loss= 0.6816, Training Accuracy= 0.563\n",
      "Epoch: 4160, Loss= 0.6691, Training Accuracy= 0.584\n",
      "Epoch: 4170, Loss= 0.6641, Training Accuracy= 0.589\n",
      "Epoch: 4180, Loss= 0.6655, Training Accuracy= 0.590\n",
      "Epoch: 4190, Loss= 0.6891, Training Accuracy= 0.541\n",
      "Epoch: 4200, Loss= 0.6807, Training Accuracy= 0.560\n",
      "Epoch: 4210, Loss= 0.6711, Training Accuracy= 0.583\n",
      "Epoch: 4220, Loss= 0.6617, Training Accuracy= 0.592\n",
      "Epoch: 4230, Loss= 0.6956, Training Accuracy= 0.510\n",
      "Epoch: 4240, Loss= 0.6909, Training Accuracy= 0.524\n",
      "Epoch: 4250, Loss= 0.6955, Training Accuracy= 0.514\n",
      "Epoch: 4260, Loss= 0.6941, Training Accuracy= 0.518\n",
      "Epoch: 4270, Loss= 0.6934, Training Accuracy= 0.514\n",
      "Epoch: 4280, Loss= 0.6934, Training Accuracy= 0.521\n",
      "Epoch: 4290, Loss= 0.6930, Training Accuracy= 0.519\n",
      "Epoch: 4300, Loss= 0.6916, Training Accuracy= 0.526\n",
      "Epoch: 4310, Loss= 0.6922, Training Accuracy= 0.530\n",
      "Epoch: 4320, Loss= 0.6903, Training Accuracy= 0.533\n",
      "Epoch: 4330, Loss= 0.6918, Training Accuracy= 0.533\n",
      "Epoch: 4340, Loss= 0.6892, Training Accuracy= 0.535\n",
      "Epoch: 4350, Loss= 0.6884, Training Accuracy= 0.535\n",
      "Epoch: 4360, Loss= 0.6873, Training Accuracy= 0.541\n",
      "Epoch: 4370, Loss= 0.6930, Training Accuracy= 0.522\n",
      "Epoch: 4380, Loss= 0.6863, Training Accuracy= 0.541\n",
      "Epoch: 4390, Loss= 0.6840, Training Accuracy= 0.547\n",
      "Epoch: 4400, Loss= 0.6833, Training Accuracy= 0.553\n",
      "Epoch: 4410, Loss= 0.6792, Training Accuracy= 0.562\n",
      "Epoch: 4420, Loss= 0.6768, Training Accuracy= 0.564\n",
      "Epoch: 4430, Loss= 0.6757, Training Accuracy= 0.568\n",
      "Epoch: 4440, Loss= 0.6736, Training Accuracy= 0.573\n",
      "Epoch: 4450, Loss= 0.6873, Training Accuracy= 0.543\n",
      "Epoch: 4460, Loss= 0.6816, Training Accuracy= 0.559\n",
      "Epoch: 4470, Loss= 0.6821, Training Accuracy= 0.559\n",
      "Epoch: 4480, Loss= 0.6750, Training Accuracy= 0.574\n",
      "Epoch: 4490, Loss= 0.6664, Training Accuracy= 0.594\n",
      "Epoch: 4500, Loss= 0.6510, Training Accuracy= 0.624\n",
      "Epoch: 4510, Loss= 0.6444, Training Accuracy= 0.632\n",
      "Epoch: 4520, Loss= 0.6446, Training Accuracy= 0.629\n",
      "Epoch: 4530, Loss= 0.6281, Training Accuracy= 0.649\n",
      "Epoch: 4540, Loss= 0.6265, Training Accuracy= 0.649\n",
      "Epoch: 4550, Loss= 0.6216, Training Accuracy= 0.655\n",
      "Epoch: 4560, Loss= 0.6030, Training Accuracy= 0.672\n",
      "Epoch: 4570, Loss= 0.5936, Training Accuracy= 0.675\n",
      "Epoch: 4580, Loss= 0.5831, Training Accuracy= 0.684\n",
      "Epoch: 4590, Loss= 0.5855, Training Accuracy= 0.682\n",
      "Epoch: 4600, Loss= 0.5574, Training Accuracy= 0.698\n",
      "Epoch: 4610, Loss= 0.5638, Training Accuracy= 0.695\n",
      "Epoch: 4620, Loss= 0.5178, Training Accuracy= 0.724\n",
      "Epoch: 4630, Loss= 0.5064, Training Accuracy= 0.733\n",
      "Epoch: 4640, Loss= 0.5006, Training Accuracy= 0.736\n",
      "Epoch: 4650, Loss= 0.4787, Training Accuracy= 0.755\n",
      "Epoch: 4660, Loss= 0.4372, Training Accuracy= 0.770\n",
      "Epoch: 4670, Loss= 0.3982, Training Accuracy= 0.803\n",
      "Epoch: 4680, Loss= 0.3780, Training Accuracy= 0.812\n",
      "Epoch: 4690, Loss= 0.3353, Training Accuracy= 0.838\n",
      "Epoch: 4700, Loss= 0.3926, Training Accuracy= 0.806\n",
      "Epoch: 4710, Loss= 0.1969, Training Accuracy= 0.908\n",
      "Epoch: 4720, Loss= 0.1622, Training Accuracy= 0.930\n",
      "Epoch: 4730, Loss= 0.0954, Training Accuracy= 0.968\n",
      "Epoch: 4740, Loss= 0.0660, Training Accuracy= 0.981\n",
      "Epoch: 4750, Loss= 0.0582, Training Accuracy= 0.985\n",
      "Epoch: 4760, Loss= 0.7369, Training Accuracy= 0.503\n",
      "Epoch: 4770, Loss= 0.7155, Training Accuracy= 0.506\n",
      "Epoch: 4780, Loss= 0.7138, Training Accuracy= 0.506\n",
      "Epoch: 4790, Loss= 0.7129, Training Accuracy= 0.506\n",
      "Epoch: 4800, Loss= 0.7122, Training Accuracy= 0.506\n",
      "Epoch: 4810, Loss= 0.7117, Training Accuracy= 0.506\n",
      "Epoch: 4820, Loss= 0.7112, Training Accuracy= 0.507\n",
      "Epoch: 4830, Loss= 0.7108, Training Accuracy= 0.507\n",
      "Epoch: 4840, Loss= 0.7104, Training Accuracy= 0.507\n",
      "Epoch: 4850, Loss= 0.7100, Training Accuracy= 0.507\n",
      "Epoch: 4860, Loss= 0.7097, Training Accuracy= 0.507\n",
      "Epoch: 4870, Loss= 0.7094, Training Accuracy= 0.509\n",
      "Epoch: 4880, Loss= 0.7092, Training Accuracy= 0.510\n",
      "Epoch: 4890, Loss= 0.7089, Training Accuracy= 0.510\n",
      "Epoch: 4900, Loss= 0.7087, Training Accuracy= 0.511\n",
      "Epoch: 4910, Loss= 0.7085, Training Accuracy= 0.511\n",
      "Epoch: 4920, Loss= 0.7083, Training Accuracy= 0.513\n",
      "Epoch: 4930, Loss= 0.7080, Training Accuracy= 0.513\n",
      "Epoch: 4940, Loss= 0.7077, Training Accuracy= 0.513\n",
      "Epoch: 4950, Loss= 0.7072, Training Accuracy= 0.514\n",
      "Epoch: 4960, Loss= 0.7067, Training Accuracy= 0.517\n",
      "Epoch: 4970, Loss= 0.7060, Training Accuracy= 0.519\n",
      "Epoch: 4980, Loss= 0.7052, Training Accuracy= 0.519\n",
      "Epoch: 4990, Loss= 0.7042, Training Accuracy= 0.518\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4963\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 20, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 30, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 40, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 50, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 70, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 80, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 90, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 100, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 110, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 120, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 130, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 140, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 150, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 160, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 170, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 180, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 190, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 200, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 210, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 220, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 230, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 240, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 250, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 260, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 270, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 280, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 290, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 310, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 320, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 330, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 340, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 350, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 360, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 370, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 380, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 390, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 400, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 410, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 420, Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 430, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 440, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 450, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 460, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 470, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 480, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 490, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 500, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 510, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 520, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 530, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 540, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 550, Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 560, Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 570, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 580, Loss= 0.6932, Training Accuracy= 0.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 590, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 600, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 610, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 620, Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 630, Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 640, Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 650, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 660, Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 670, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 680, Loss= 0.6924, Training Accuracy= 0.512\n",
      "Epoch: 690, Loss= 0.6920, Training Accuracy= 0.523\n",
      "Epoch: 700, Loss= 0.6918, Training Accuracy= 0.524\n",
      "Epoch: 710, Loss= 0.6916, Training Accuracy= 0.525\n",
      "Epoch: 720, Loss= 0.6915, Training Accuracy= 0.525\n",
      "Epoch: 730, Loss= 0.6916, Training Accuracy= 0.523\n",
      "Epoch: 740, Loss= 0.6914, Training Accuracy= 0.527\n",
      "Epoch: 750, Loss= 0.6912, Training Accuracy= 0.534\n",
      "Epoch: 760, Loss= 0.6910, Training Accuracy= 0.534\n",
      "Epoch: 770, Loss= 0.6908, Training Accuracy= 0.537\n",
      "Epoch: 780, Loss= 0.6906, Training Accuracy= 0.537\n",
      "Epoch: 790, Loss= 0.6902, Training Accuracy= 0.538\n",
      "Epoch: 800, Loss= 0.6898, Training Accuracy= 0.538\n",
      "Epoch: 810, Loss= 0.6893, Training Accuracy= 0.540\n",
      "Epoch: 820, Loss= 0.6884, Training Accuracy= 0.546\n",
      "Epoch: 830, Loss= 0.6875, Training Accuracy= 0.547\n",
      "Epoch: 840, Loss= 0.6868, Training Accuracy= 0.551\n",
      "Epoch: 850, Loss= 0.6864, Training Accuracy= 0.552\n",
      "Epoch: 860, Loss= 0.6857, Training Accuracy= 0.548\n",
      "Epoch: 870, Loss= 0.6853, Training Accuracy= 0.550\n",
      "Epoch: 880, Loss= 0.6850, Training Accuracy= 0.552\n",
      "Epoch: 890, Loss= 0.6861, Training Accuracy= 0.552\n",
      "Epoch: 900, Loss= 0.6863, Training Accuracy= 0.549\n",
      "Epoch: 910, Loss= 0.6852, Training Accuracy= 0.550\n",
      "Epoch: 920, Loss= 0.6861, Training Accuracy= 0.546\n",
      "Epoch: 930, Loss= 0.6878, Training Accuracy= 0.545\n",
      "Epoch: 940, Loss= 0.6828, Training Accuracy= 0.559\n",
      "Epoch: 950, Loss= 0.6824, Training Accuracy= 0.557\n",
      "Epoch: 960, Loss= 0.6987, Training Accuracy= 0.531\n",
      "Epoch: 970, Loss= 0.6887, Training Accuracy= 0.550\n",
      "Epoch: 980, Loss= 0.6834, Training Accuracy= 0.564\n",
      "Epoch: 990, Loss= 0.6774, Training Accuracy= 0.572\n",
      "Epoch: 1000, Loss= 0.7129, Training Accuracy= 0.530\n",
      "Epoch: 1010, Loss= 0.7084, Training Accuracy= 0.530\n",
      "Epoch: 1020, Loss= 0.6709, Training Accuracy= 0.586\n",
      "Epoch: 1030, Loss= 0.6814, Training Accuracy= 0.577\n",
      "Epoch: 1040, Loss= 0.6666, Training Accuracy= 0.592\n",
      "Epoch: 1050, Loss= 0.6775, Training Accuracy= 0.586\n",
      "Epoch: 1060, Loss= 0.6598, Training Accuracy= 0.611\n",
      "Epoch: 1070, Loss= 0.6647, Training Accuracy= 0.605\n",
      "Epoch: 1080, Loss= 0.6483, Training Accuracy= 0.624\n",
      "Epoch: 1090, Loss= 0.6506, Training Accuracy= 0.615\n",
      "Epoch: 1100, Loss= 0.6377, Training Accuracy= 0.632\n",
      "Epoch: 1110, Loss= 0.6469, Training Accuracy= 0.628\n",
      "Epoch: 1120, Loss= 0.6773, Training Accuracy= 0.593\n",
      "Epoch: 1130, Loss= 0.6481, Training Accuracy= 0.623\n",
      "Epoch: 1140, Loss= 0.6481, Training Accuracy= 0.622\n",
      "Epoch: 1150, Loss= 0.6486, Training Accuracy= 0.627\n",
      "Epoch: 1160, Loss= 0.6402, Training Accuracy= 0.632\n",
      "Epoch: 1170, Loss= 0.6400, Training Accuracy= 0.634\n",
      "Epoch: 1180, Loss= 0.6493, Training Accuracy= 0.625\n",
      "Epoch: 1190, Loss= 0.6329, Training Accuracy= 0.643\n",
      "Epoch: 1200, Loss= 0.6157, Training Accuracy= 0.657\n",
      "Epoch: 1210, Loss= 0.6464, Training Accuracy= 0.623\n",
      "Epoch: 1220, Loss= 0.6393, Training Accuracy= 0.635\n",
      "Epoch: 1230, Loss= 0.6485, Training Accuracy= 0.629\n",
      "Epoch: 1240, Loss= 0.6850, Training Accuracy= 0.600\n",
      "Epoch: 1250, Loss= 0.6104, Training Accuracy= 0.663\n",
      "Epoch: 1260, Loss= 0.6243, Training Accuracy= 0.652\n",
      "Epoch: 1270, Loss= 0.6310, Training Accuracy= 0.645\n",
      "Epoch: 1280, Loss= 0.6449, Training Accuracy= 0.641\n",
      "Epoch: 1290, Loss= 0.6288, Training Accuracy= 0.650\n",
      "Epoch: 1300, Loss= 0.7089, Training Accuracy= 0.582\n",
      "Epoch: 1310, Loss= 0.6012, Training Accuracy= 0.676\n",
      "Epoch: 1320, Loss= 0.7406, Training Accuracy= 0.564\n",
      "Epoch: 1330, Loss= 0.6058, Training Accuracy= 0.669\n",
      "Epoch: 1340, Loss= 0.6287, Training Accuracy= 0.653\n",
      "Epoch: 1350, Loss= 0.6191, Training Accuracy= 0.655\n",
      "Epoch: 1360, Loss= 0.7332, Training Accuracy= 0.563\n",
      "Epoch: 1370, Loss= 0.5813, Training Accuracy= 0.694\n",
      "Epoch: 1380, Loss= 0.6385, Training Accuracy= 0.644\n",
      "Epoch: 1390, Loss= 0.6168, Training Accuracy= 0.665\n",
      "Epoch: 1400, Loss= 0.5952, Training Accuracy= 0.682\n",
      "Epoch: 1410, Loss= 0.5951, Training Accuracy= 0.680\n",
      "Epoch: 1420, Loss= 0.6124, Training Accuracy= 0.666\n",
      "Epoch: 1430, Loss= 0.6089, Training Accuracy= 0.668\n",
      "Epoch: 1440, Loss= 0.5635, Training Accuracy= 0.707\n",
      "Epoch: 1450, Loss= 0.6868, Training Accuracy= 0.612\n",
      "Epoch: 1460, Loss= 0.5893, Training Accuracy= 0.686\n",
      "Epoch: 1470, Loss= 0.6584, Training Accuracy= 0.630\n",
      "Epoch: 1480, Loss= 0.5910, Training Accuracy= 0.684\n",
      "Epoch: 1490, Loss= 0.5728, Training Accuracy= 0.697\n",
      "Epoch: 1500, Loss= 0.5973, Training Accuracy= 0.682\n",
      "Epoch: 1510, Loss= 0.6170, Training Accuracy= 0.663\n",
      "Epoch: 1520, Loss= 0.5742, Training Accuracy= 0.695\n",
      "Epoch: 1530, Loss= 0.5838, Training Accuracy= 0.694\n",
      "Epoch: 1540, Loss= 0.6400, Training Accuracy= 0.648\n",
      "Epoch: 1550, Loss= 0.5928, Training Accuracy= 0.682\n",
      "Epoch: 1560, Loss= 0.6436, Training Accuracy= 0.645\n",
      "Epoch: 1570, Loss= 0.6149, Training Accuracy= 0.663\n",
      "Epoch: 1580, Loss= 0.6043, Training Accuracy= 0.674\n",
      "Epoch: 1590, Loss= 0.6312, Training Accuracy= 0.654\n",
      "Epoch: 1600, Loss= 0.6378, Training Accuracy= 0.643\n",
      "Epoch: 1610, Loss= 0.6046, Training Accuracy= 0.676\n",
      "Epoch: 1620, Loss= 0.6092, Training Accuracy= 0.667\n",
      "Epoch: 1630, Loss= 0.6106, Training Accuracy= 0.671\n",
      "Epoch: 1640, Loss= 0.5792, Training Accuracy= 0.699\n",
      "Epoch: 1650, Loss= 0.6082, Training Accuracy= 0.671\n",
      "Epoch: 1660, Loss= 0.5723, Training Accuracy= 0.696\n",
      "Epoch: 1670, Loss= 0.6203, Training Accuracy= 0.669\n",
      "Epoch: 1680, Loss= 0.5571, Training Accuracy= 0.713\n",
      "Epoch: 1690, Loss= 0.5964, Training Accuracy= 0.681\n",
      "Epoch: 1700, Loss= 0.6203, Training Accuracy= 0.666\n",
      "Epoch: 1710, Loss= 0.5965, Training Accuracy= 0.685\n",
      "Epoch: 1720, Loss= 0.6096, Training Accuracy= 0.672\n",
      "Epoch: 1730, Loss= 0.5819, Training Accuracy= 0.692\n",
      "Epoch: 1740, Loss= 0.5740, Training Accuracy= 0.698\n",
      "Epoch: 1750, Loss= 0.6175, Training Accuracy= 0.668\n",
      "Epoch: 1760, Loss= 0.6426, Training Accuracy= 0.650\n",
      "Epoch: 1770, Loss= 0.5635, Training Accuracy= 0.709\n",
      "Epoch: 1780, Loss= 0.6035, Training Accuracy= 0.680\n",
      "Epoch: 1790, Loss= 0.5758, Training Accuracy= 0.696\n",
      "Epoch: 1800, Loss= 0.5895, Training Accuracy= 0.685\n",
      "Epoch: 1810, Loss= 0.5677, Training Accuracy= 0.701\n",
      "Epoch: 1820, Loss= 0.5946, Training Accuracy= 0.684\n",
      "Epoch: 1830, Loss= 0.5871, Training Accuracy= 0.688\n",
      "Epoch: 1840, Loss= 0.5566, Training Accuracy= 0.710\n",
      "Epoch: 1850, Loss= 0.5703, Training Accuracy= 0.706\n",
      "Epoch: 1860, Loss= 0.5850, Training Accuracy= 0.688\n",
      "Epoch: 1870, Loss= 0.6885, Training Accuracy= 0.606\n",
      "Epoch: 1880, Loss= 0.5777, Training Accuracy= 0.692\n",
      "Epoch: 1890, Loss= 0.5536, Training Accuracy= 0.714\n",
      "Epoch: 1900, Loss= 0.6318, Training Accuracy= 0.652\n",
      "Epoch: 1910, Loss= 0.5824, Training Accuracy= 0.692\n",
      "Epoch: 1920, Loss= 0.5584, Training Accuracy= 0.709\n",
      "Epoch: 1930, Loss= 0.5611, Training Accuracy= 0.706\n",
      "Epoch: 1940, Loss= 0.6930, Training Accuracy= 0.525\n",
      "Epoch: 1950, Loss= 0.6805, Training Accuracy= 0.557\n",
      "Epoch: 1960, Loss= 0.6739, Training Accuracy= 0.573\n",
      "Epoch: 1970, Loss= 0.6810, Training Accuracy= 0.562\n",
      "Epoch: 1980, Loss= 0.6719, Training Accuracy= 0.580\n",
      "Epoch: 1990, Loss= 0.6937, Training Accuracy= 0.533\n",
      "Epoch: 2000, Loss= 0.6698, Training Accuracy= 0.580\n",
      "Epoch: 2010, Loss= 0.6609, Training Accuracy= 0.594\n",
      "Epoch: 2020, Loss= 0.6544, Training Accuracy= 0.608\n",
      "Epoch: 2030, Loss= 0.6500, Training Accuracy= 0.613\n",
      "Epoch: 2040, Loss= 0.6466, Training Accuracy= 0.622\n",
      "Epoch: 2050, Loss= 0.6360, Training Accuracy= 0.629\n",
      "Epoch: 2060, Loss= 0.6342, Training Accuracy= 0.630\n",
      "Epoch: 2070, Loss= 0.6675, Training Accuracy= 0.591\n",
      "Epoch: 2080, Loss= 0.6280, Training Accuracy= 0.635\n",
      "Epoch: 2090, Loss= 0.6446, Training Accuracy= 0.621\n",
      "Epoch: 2100, Loss= 0.6224, Training Accuracy= 0.646\n",
      "Epoch: 2110, Loss= 0.6838, Training Accuracy= 0.573\n",
      "Epoch: 2120, Loss= 0.6512, Training Accuracy= 0.614\n",
      "Epoch: 2130, Loss= 0.6557, Training Accuracy= 0.605\n",
      "Epoch: 2140, Loss= 0.6436, Training Accuracy= 0.624\n",
      "Epoch: 2150, Loss= 0.6283, Training Accuracy= 0.643\n",
      "Epoch: 2160, Loss= 0.6225, Training Accuracy= 0.648\n",
      "Epoch: 2170, Loss= 0.6167, Training Accuracy= 0.650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2180, Loss= 0.6198, Training Accuracy= 0.645\n",
      "Epoch: 2190, Loss= 0.6152, Training Accuracy= 0.652\n",
      "Epoch: 2200, Loss= 0.6109, Training Accuracy= 0.657\n",
      "Epoch: 2210, Loss= 0.6077, Training Accuracy= 0.662\n",
      "Epoch: 2220, Loss= 0.6080, Training Accuracy= 0.661\n",
      "Epoch: 2230, Loss= 0.6079, Training Accuracy= 0.661\n",
      "Epoch: 2240, Loss= 0.5909, Training Accuracy= 0.675\n",
      "Epoch: 2250, Loss= 0.6815, Training Accuracy= 0.590\n",
      "Epoch: 2260, Loss= 0.6009, Training Accuracy= 0.665\n",
      "Epoch: 2270, Loss= 0.6693, Training Accuracy= 0.607\n",
      "Epoch: 2280, Loss= 0.5893, Training Accuracy= 0.683\n",
      "Epoch: 2290, Loss= 0.6060, Training Accuracy= 0.665\n",
      "Epoch: 2300, Loss= 0.5881, Training Accuracy= 0.683\n",
      "Epoch: 2310, Loss= 0.5977, Training Accuracy= 0.671\n",
      "Epoch: 2320, Loss= 0.5804, Training Accuracy= 0.690\n",
      "Epoch: 2330, Loss= 0.5765, Training Accuracy= 0.692\n",
      "Epoch: 2340, Loss= 0.5955, Training Accuracy= 0.676\n",
      "Epoch: 2350, Loss= 0.5647, Training Accuracy= 0.695\n",
      "Epoch: 2360, Loss= 0.5745, Training Accuracy= 0.694\n",
      "Epoch: 2370, Loss= 0.5810, Training Accuracy= 0.688\n",
      "Epoch: 2380, Loss= 0.6207, Training Accuracy= 0.653\n",
      "Epoch: 2390, Loss= 0.6118, Training Accuracy= 0.659\n",
      "Epoch: 2400, Loss= 0.6028, Training Accuracy= 0.664\n",
      "Epoch: 2410, Loss= 0.5985, Training Accuracy= 0.669\n",
      "Epoch: 2420, Loss= 0.5807, Training Accuracy= 0.688\n",
      "Epoch: 2430, Loss= 0.5582, Training Accuracy= 0.704\n",
      "Epoch: 2440, Loss= 0.6607, Training Accuracy= 0.596\n",
      "Epoch: 2450, Loss= 0.6296, Training Accuracy= 0.636\n",
      "Epoch: 2460, Loss= 0.6013, Training Accuracy= 0.668\n",
      "Epoch: 2470, Loss= 0.5842, Training Accuracy= 0.684\n",
      "Epoch: 2480, Loss= 0.6086, Training Accuracy= 0.666\n",
      "Epoch: 2490, Loss= 0.6345, Training Accuracy= 0.632\n",
      "Epoch: 2500, Loss= 0.5560, Training Accuracy= 0.705\n",
      "Epoch: 2510, Loss= 0.5500, Training Accuracy= 0.713\n",
      "Epoch: 2520, Loss= 0.6481, Training Accuracy= 0.636\n",
      "Epoch: 2530, Loss= 0.6073, Training Accuracy= 0.664\n",
      "Epoch: 2540, Loss= 0.6185, Training Accuracy= 0.653\n",
      "Epoch: 2550, Loss= 0.5663, Training Accuracy= 0.704\n",
      "Epoch: 2560, Loss= 0.5616, Training Accuracy= 0.704\n",
      "Epoch: 2570, Loss= 0.5759, Training Accuracy= 0.687\n",
      "Epoch: 2580, Loss= 0.5659, Training Accuracy= 0.706\n",
      "Epoch: 2590, Loss= 0.5449, Training Accuracy= 0.718\n",
      "Epoch: 2600, Loss= 0.5489, Training Accuracy= 0.714\n",
      "Epoch: 2610, Loss= 0.7363, Training Accuracy= 0.581\n",
      "Epoch: 2620, Loss= 0.5542, Training Accuracy= 0.709\n",
      "Epoch: 2630, Loss= 0.5894, Training Accuracy= 0.681\n",
      "Epoch: 2640, Loss= 0.5781, Training Accuracy= 0.685\n",
      "Epoch: 2650, Loss= 0.5553, Training Accuracy= 0.703\n",
      "Epoch: 2660, Loss= 0.5633, Training Accuracy= 0.707\n",
      "Epoch: 2670, Loss= 0.5987, Training Accuracy= 0.672\n",
      "Epoch: 2680, Loss= 0.5816, Training Accuracy= 0.687\n",
      "Epoch: 2690, Loss= 0.5851, Training Accuracy= 0.684\n",
      "Epoch: 2700, Loss= 0.5789, Training Accuracy= 0.688\n",
      "Epoch: 2710, Loss= 0.5348, Training Accuracy= 0.725\n",
      "Epoch: 2720, Loss= 0.5378, Training Accuracy= 0.723\n",
      "Epoch: 2730, Loss= 0.6098, Training Accuracy= 0.658\n",
      "Epoch: 2740, Loss= 0.5886, Training Accuracy= 0.686\n",
      "Epoch: 2750, Loss= 0.5310, Training Accuracy= 0.732\n",
      "Epoch: 2760, Loss= 0.5355, Training Accuracy= 0.730\n",
      "Epoch: 2770, Loss= 0.5526, Training Accuracy= 0.712\n",
      "Epoch: 2780, Loss= 0.7984, Training Accuracy= 0.525\n",
      "Epoch: 2790, Loss= 0.6802, Training Accuracy= 0.553\n",
      "Epoch: 2800, Loss= 0.6734, Training Accuracy= 0.570\n",
      "Epoch: 2810, Loss= 0.6697, Training Accuracy= 0.577\n",
      "Epoch: 2820, Loss= 0.6601, Training Accuracy= 0.590\n",
      "Epoch: 2830, Loss= 0.6551, Training Accuracy= 0.600\n",
      "Epoch: 2840, Loss= 0.6479, Training Accuracy= 0.613\n",
      "Epoch: 2850, Loss= 0.6448, Training Accuracy= 0.613\n",
      "Epoch: 2860, Loss= 0.6423, Training Accuracy= 0.616\n",
      "Epoch: 2870, Loss= 0.6538, Training Accuracy= 0.600\n",
      "Epoch: 2880, Loss= 0.6308, Training Accuracy= 0.628\n",
      "Epoch: 2890, Loss= 0.7030, Training Accuracy= 0.540\n",
      "Epoch: 2900, Loss= 0.6279, Training Accuracy= 0.631\n",
      "Epoch: 2910, Loss= 0.6360, Training Accuracy= 0.629\n",
      "Epoch: 2920, Loss= 0.6195, Training Accuracy= 0.643\n",
      "Epoch: 2930, Loss= 0.6623, Training Accuracy= 0.599\n",
      "Epoch: 2940, Loss= 0.6262, Training Accuracy= 0.639\n",
      "Epoch: 2950, Loss= 0.6242, Training Accuracy= 0.642\n",
      "Epoch: 2960, Loss= 0.6225, Training Accuracy= 0.646\n",
      "Epoch: 2970, Loss= 0.6121, Training Accuracy= 0.653\n",
      "Epoch: 2980, Loss= 0.6051, Training Accuracy= 0.658\n",
      "Epoch: 2990, Loss= 0.6205, Training Accuracy= 0.650\n",
      "Epoch: 3000, Loss= 0.6056, Training Accuracy= 0.663\n",
      "Epoch: 3010, Loss= 0.6497, Training Accuracy= 0.610\n",
      "Epoch: 3020, Loss= 0.5914, Training Accuracy= 0.670\n",
      "Epoch: 3030, Loss= 0.5948, Training Accuracy= 0.671\n",
      "Epoch: 3040, Loss= 0.6912, Training Accuracy= 0.525\n",
      "Epoch: 3050, Loss= 0.6935, Training Accuracy= 0.524\n",
      "Epoch: 3060, Loss= 0.6903, Training Accuracy= 0.528\n",
      "Epoch: 3070, Loss= 0.6875, Training Accuracy= 0.541\n",
      "Epoch: 3080, Loss= 0.6848, Training Accuracy= 0.545\n",
      "Epoch: 3090, Loss= 0.6815, Training Accuracy= 0.554\n",
      "Epoch: 3100, Loss= 0.6782, Training Accuracy= 0.562\n",
      "Epoch: 3110, Loss= 0.6772, Training Accuracy= 0.561\n",
      "Epoch: 3120, Loss= 0.6734, Training Accuracy= 0.571\n",
      "Epoch: 3130, Loss= 0.6688, Training Accuracy= 0.580\n",
      "Epoch: 3140, Loss= 0.6662, Training Accuracy= 0.586\n",
      "Epoch: 3150, Loss= 0.6731, Training Accuracy= 0.575\n",
      "Epoch: 3160, Loss= 0.6780, Training Accuracy= 0.575\n",
      "Epoch: 3170, Loss= 0.6605, Training Accuracy= 0.598\n",
      "Epoch: 3180, Loss= 0.6619, Training Accuracy= 0.600\n",
      "Epoch: 3190, Loss= 0.6642, Training Accuracy= 0.604\n",
      "Epoch: 3200, Loss= 0.6756, Training Accuracy= 0.581\n",
      "Epoch: 3210, Loss= 0.6527, Training Accuracy= 0.608\n",
      "Epoch: 3220, Loss= 0.6455, Training Accuracy= 0.620\n",
      "Epoch: 3230, Loss= 0.6698, Training Accuracy= 0.595\n",
      "Epoch: 3240, Loss= 0.6476, Training Accuracy= 0.614\n",
      "Epoch: 3250, Loss= 0.6847, Training Accuracy= 0.572\n",
      "Epoch: 3260, Loss= 0.6919, Training Accuracy= 0.571\n",
      "Epoch: 3270, Loss= 0.6672, Training Accuracy= 0.600\n",
      "Epoch: 3280, Loss= 0.6405, Training Accuracy= 0.630\n",
      "Epoch: 3290, Loss= 0.6768, Training Accuracy= 0.591\n",
      "Epoch: 3300, Loss= 0.6560, Training Accuracy= 0.611\n",
      "Epoch: 3310, Loss= 0.6650, Training Accuracy= 0.597\n",
      "Epoch: 3320, Loss= 0.6451, Training Accuracy= 0.624\n",
      "Epoch: 3330, Loss= 0.6534, Training Accuracy= 0.615\n",
      "Epoch: 3340, Loss= 0.6368, Training Accuracy= 0.633\n",
      "Epoch: 3350, Loss= 0.6425, Training Accuracy= 0.627\n",
      "Epoch: 3360, Loss= 0.6596, Training Accuracy= 0.603\n",
      "Epoch: 3370, Loss= 0.6711, Training Accuracy= 0.601\n",
      "Epoch: 3380, Loss= 0.6324, Training Accuracy= 0.638\n",
      "Epoch: 3390, Loss= 0.6397, Training Accuracy= 0.625\n",
      "Epoch: 3400, Loss= 0.6310, Training Accuracy= 0.640\n",
      "Epoch: 3410, Loss= 0.6276, Training Accuracy= 0.642\n",
      "Epoch: 3420, Loss= 0.6158, Training Accuracy= 0.653\n",
      "Epoch: 3430, Loss= 0.7004, Training Accuracy= 0.573\n",
      "Epoch: 3440, Loss= 0.6576, Training Accuracy= 0.612\n",
      "Epoch: 3450, Loss= 0.6369, Training Accuracy= 0.633\n",
      "Epoch: 3460, Loss= 0.6957, Training Accuracy= 0.572\n",
      "Epoch: 3470, Loss= 0.6186, Training Accuracy= 0.647\n",
      "Epoch: 3480, Loss= 0.6269, Training Accuracy= 0.641\n",
      "Epoch: 3490, Loss= 0.6180, Training Accuracy= 0.650\n",
      "Epoch: 3500, Loss= 0.6456, Training Accuracy= 0.620\n",
      "Epoch: 3510, Loss= 0.6484, Training Accuracy= 0.618\n",
      "Epoch: 3520, Loss= 0.6388, Training Accuracy= 0.634\n",
      "Epoch: 3530, Loss= 0.6196, Training Accuracy= 0.653\n",
      "Epoch: 3540, Loss= 0.6605, Training Accuracy= 0.615\n",
      "Epoch: 3550, Loss= 0.6917, Training Accuracy= 0.530\n",
      "Epoch: 3560, Loss= 0.6777, Training Accuracy= 0.565\n",
      "Epoch: 3570, Loss= 0.6696, Training Accuracy= 0.577\n",
      "Epoch: 3580, Loss= 0.6613, Training Accuracy= 0.590\n",
      "Epoch: 3590, Loss= 0.6677, Training Accuracy= 0.579\n",
      "Epoch: 3600, Loss= 0.6511, Training Accuracy= 0.602\n",
      "Epoch: 3610, Loss= 0.6505, Training Accuracy= 0.601\n",
      "Epoch: 3620, Loss= 0.6400, Training Accuracy= 0.615\n",
      "Epoch: 3630, Loss= 0.6399, Training Accuracy= 0.615\n",
      "Epoch: 3640, Loss= 0.6371, Training Accuracy= 0.618\n",
      "Epoch: 3650, Loss= 0.6379, Training Accuracy= 0.622\n",
      "Epoch: 3660, Loss= 0.6373, Training Accuracy= 0.616\n",
      "Epoch: 3670, Loss= 0.6372, Training Accuracy= 0.622\n",
      "Epoch: 3680, Loss= 0.6234, Training Accuracy= 0.636\n",
      "Epoch: 3690, Loss= 0.6192, Training Accuracy= 0.638\n",
      "Epoch: 3700, Loss= 0.6471, Training Accuracy= 0.619\n",
      "Epoch: 3710, Loss= 0.6152, Training Accuracy= 0.646\n",
      "Epoch: 3720, Loss= 0.6221, Training Accuracy= 0.643\n",
      "Epoch: 3730, Loss= 0.6187, Training Accuracy= 0.645\n",
      "Epoch: 3740, Loss= 0.6092, Training Accuracy= 0.658\n",
      "Epoch: 3750, Loss= 0.6878, Training Accuracy= 0.544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3760, Loss= 0.6847, Training Accuracy= 0.548\n",
      "Epoch: 3770, Loss= 0.6791, Training Accuracy= 0.558\n",
      "Epoch: 3780, Loss= 0.6731, Training Accuracy= 0.565\n",
      "Epoch: 3790, Loss= 0.6698, Training Accuracy= 0.573\n",
      "Epoch: 3800, Loss= 0.6672, Training Accuracy= 0.575\n",
      "Epoch: 3810, Loss= 0.6623, Training Accuracy= 0.587\n",
      "Epoch: 3820, Loss= 0.6582, Training Accuracy= 0.594\n",
      "Epoch: 3830, Loss= 0.6536, Training Accuracy= 0.599\n",
      "Epoch: 3840, Loss= 0.6885, Training Accuracy= 0.535\n",
      "Epoch: 3850, Loss= 0.6832, Training Accuracy= 0.550\n",
      "Epoch: 3860, Loss= 0.7016, Training Accuracy= 0.507\n",
      "Epoch: 3870, Loss= 0.6931, Training Accuracy= 0.510\n",
      "Epoch: 3880, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 3890, Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 3900, Loss= 0.6921, Training Accuracy= 0.516\n",
      "Epoch: 3910, Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 3920, Loss= 0.6924, Training Accuracy= 0.511\n",
      "Epoch: 3930, Loss= 0.6924, Training Accuracy= 0.514\n",
      "Epoch: 3940, Loss= 0.6922, Training Accuracy= 0.515\n",
      "Epoch: 3950, Loss= 0.6923, Training Accuracy= 0.516\n",
      "Epoch: 3960, Loss= 0.6920, Training Accuracy= 0.522\n",
      "Epoch: 3970, Loss= 0.6927, Training Accuracy= 0.518\n",
      "Epoch: 3980, Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 3990, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 4000, Loss= 0.6922, Training Accuracy= 0.524\n",
      "Epoch: 4010, Loss= 0.6921, Training Accuracy= 0.524\n",
      "Epoch: 4020, Loss= 0.6920, Training Accuracy= 0.523\n",
      "Epoch: 4030, Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 4040, Loss= 0.6918, Training Accuracy= 0.524\n",
      "Epoch: 4050, Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 4060, Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 4070, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 4080, Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 4090, Loss= 0.6930, Training Accuracy= 0.514\n",
      "Epoch: 4100, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 4110, Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 4120, Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 4130, Loss= 0.6927, Training Accuracy= 0.514\n",
      "Epoch: 4140, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 4150, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 4160, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 4170, Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 4180, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 4190, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 4200, Loss= 0.6925, Training Accuracy= 0.516\n",
      "Epoch: 4210, Loss= 0.6925, Training Accuracy= 0.517\n",
      "Epoch: 4220, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 4230, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 4240, Loss= 0.6923, Training Accuracy= 0.521\n",
      "Epoch: 4250, Loss= 0.6923, Training Accuracy= 0.521\n",
      "Epoch: 4260, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 4270, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 4280, Loss= 0.6921, Training Accuracy= 0.525\n",
      "Epoch: 4290, Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 4300, Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 4310, Loss= 0.6917, Training Accuracy= 0.523\n",
      "Epoch: 4320, Loss= 0.6915, Training Accuracy= 0.525\n",
      "Epoch: 4330, Loss= 0.6913, Training Accuracy= 0.527\n",
      "Epoch: 4340, Loss= 0.6911, Training Accuracy= 0.526\n",
      "Epoch: 4350, Loss= 0.6909, Training Accuracy= 0.528\n",
      "Epoch: 4360, Loss= 0.6908, Training Accuracy= 0.527\n",
      "Epoch: 4370, Loss= 0.6905, Training Accuracy= 0.528\n",
      "Epoch: 4380, Loss= 0.6903, Training Accuracy= 0.528\n",
      "Epoch: 4390, Loss= 0.6902, Training Accuracy= 0.528\n",
      "Epoch: 4400, Loss= 0.6900, Training Accuracy= 0.529\n",
      "Epoch: 4410, Loss= 0.6898, Training Accuracy= 0.532\n",
      "Epoch: 4420, Loss= 0.6895, Training Accuracy= 0.533\n",
      "Epoch: 4430, Loss= 0.6892, Training Accuracy= 0.533\n",
      "Epoch: 4440, Loss= 0.6897, Training Accuracy= 0.533\n",
      "Epoch: 4450, Loss= 0.6892, Training Accuracy= 0.534\n",
      "Epoch: 4460, Loss= 0.6889, Training Accuracy= 0.535\n",
      "Epoch: 4470, Loss= 0.6887, Training Accuracy= 0.535\n",
      "Epoch: 4480, Loss= 0.6888, Training Accuracy= 0.535\n",
      "Epoch: 4490, Loss= 0.6885, Training Accuracy= 0.537\n",
      "Epoch: 4500, Loss= 0.6880, Training Accuracy= 0.539\n",
      "Epoch: 4510, Loss= 0.6878, Training Accuracy= 0.540\n",
      "Epoch: 4520, Loss= 0.6905, Training Accuracy= 0.529\n",
      "Epoch: 4530, Loss= 0.6881, Training Accuracy= 0.537\n",
      "Epoch: 4540, Loss= 0.6899, Training Accuracy= 0.529\n",
      "Epoch: 4550, Loss= 0.6933, Training Accuracy= 0.515\n",
      "Epoch: 4560, Loss= 0.6924, Training Accuracy= 0.520\n",
      "Epoch: 4570, Loss= 0.6922, Training Accuracy= 0.521\n",
      "Epoch: 4580, Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 4590, Loss= 0.6918, Training Accuracy= 0.526\n",
      "Epoch: 4600, Loss= 0.6916, Training Accuracy= 0.526\n",
      "Epoch: 4610, Loss= 0.6915, Training Accuracy= 0.526\n",
      "Epoch: 4620, Loss= 0.6912, Training Accuracy= 0.526\n",
      "Epoch: 4630, Loss= 0.6910, Training Accuracy= 0.527\n",
      "Epoch: 4640, Loss= 0.6905, Training Accuracy= 0.529\n",
      "Epoch: 4650, Loss= 0.6903, Training Accuracy= 0.530\n",
      "Epoch: 4660, Loss= 0.6901, Training Accuracy= 0.530\n",
      "Epoch: 4670, Loss= 0.6900, Training Accuracy= 0.530\n",
      "Epoch: 4680, Loss= 0.6898, Training Accuracy= 0.533\n",
      "Epoch: 4690, Loss= 0.6897, Training Accuracy= 0.533\n",
      "Epoch: 4700, Loss= 0.6895, Training Accuracy= 0.534\n",
      "Epoch: 4710, Loss= 0.6892, Training Accuracy= 0.535\n",
      "Epoch: 4720, Loss= 0.6889, Training Accuracy= 0.537\n",
      "Epoch: 4730, Loss= 0.6883, Training Accuracy= 0.539\n",
      "Epoch: 4740, Loss= 0.6883, Training Accuracy= 0.538\n",
      "Epoch: 4750, Loss= 0.6883, Training Accuracy= 0.536\n",
      "Epoch: 4760, Loss= 0.6874, Training Accuracy= 0.540\n",
      "Epoch: 4770, Loss= 0.6868, Training Accuracy= 0.541\n",
      "Epoch: 4780, Loss= 0.6878, Training Accuracy= 0.537\n",
      "Epoch: 4790, Loss= 0.6865, Training Accuracy= 0.540\n",
      "Epoch: 4800, Loss= 0.6945, Training Accuracy= 0.509\n",
      "Epoch: 4810, Loss= 0.6932, Training Accuracy= 0.518\n",
      "Epoch: 4820, Loss= 0.6930, Training Accuracy= 0.510\n",
      "Epoch: 4830, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 4840, Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 4850, Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 4860, Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 4870, Loss= 0.6923, Training Accuracy= 0.516\n",
      "Epoch: 4880, Loss= 0.6920, Training Accuracy= 0.518\n",
      "Epoch: 4890, Loss= 0.6917, Training Accuracy= 0.520\n",
      "Epoch: 4900, Loss= 0.6914, Training Accuracy= 0.519\n",
      "Epoch: 4910, Loss= 0.6950, Training Accuracy= 0.504\n",
      "Epoch: 4920, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 4930, Loss= 0.6913, Training Accuracy= 0.521\n",
      "Epoch: 4940, Loss= 0.6889, Training Accuracy= 0.529\n",
      "Epoch: 4950, Loss= 0.6848, Training Accuracy= 0.537\n",
      "Epoch: 4960, Loss= 0.6792, Training Accuracy= 0.550\n",
      "Epoch: 4970, Loss= 0.6703, Training Accuracy= 0.558\n",
      "Epoch: 4980, Loss= 0.6591, Training Accuracy= 0.574\n",
      "Epoch: 4990, Loss= 0.6435, Training Accuracy= 0.567\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5775\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 10, Loss= 0.6959, Training Accuracy= 0.504\n",
      "Epoch: 20, Loss= 0.6950, Training Accuracy= 0.504\n",
      "Epoch: 30, Loss= 0.6946, Training Accuracy= 0.504\n",
      "Epoch: 40, Loss= 0.6944, Training Accuracy= 0.504\n",
      "Epoch: 50, Loss= 0.6942, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6941, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6941, Training Accuracy= 0.504\n",
      "Epoch: 80, Loss= 0.6940, Training Accuracy= 0.504\n",
      "Epoch: 90, Loss= 0.6939, Training Accuracy= 0.504\n",
      "Epoch: 100, Loss= 0.6938, Training Accuracy= 0.504\n",
      "Epoch: 110, Loss= 0.6938, Training Accuracy= 0.504\n",
      "Epoch: 120, Loss= 0.6937, Training Accuracy= 0.504\n",
      "Epoch: 130, Loss= 0.6937, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.6936, Training Accuracy= 0.507\n",
      "Epoch: 150, Loss= 0.6936, Training Accuracy= 0.508\n",
      "Epoch: 160, Loss= 0.6935, Training Accuracy= 0.509\n",
      "Epoch: 170, Loss= 0.6935, Training Accuracy= 0.511\n",
      "Epoch: 180, Loss= 0.6935, Training Accuracy= 0.512\n",
      "Epoch: 190, Loss= 0.6934, Training Accuracy= 0.511\n",
      "Epoch: 200, Loss= 0.6934, Training Accuracy= 0.511\n",
      "Epoch: 210, Loss= 0.6934, Training Accuracy= 0.510\n",
      "Epoch: 220, Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 230, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 240, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 250, Loss= 0.6933, Training Accuracy= 0.511\n",
      "Epoch: 260, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 270, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 280, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 290, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 300, Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 310, Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 320, Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 330, Loss= 0.6930, Training Accuracy= 0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340, Loss= 0.6929, Training Accuracy= 0.515\n",
      "Epoch: 350, Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 360, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 370, Loss= 0.6925, Training Accuracy= 0.516\n",
      "Epoch: 380, Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 390, Loss= 0.6921, Training Accuracy= 0.519\n",
      "Epoch: 400, Loss= 0.6917, Training Accuracy= 0.518\n",
      "Epoch: 410, Loss= 0.6913, Training Accuracy= 0.521\n",
      "Epoch: 420, Loss= 0.6936, Training Accuracy= 0.512\n",
      "Epoch: 430, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 440, Loss= 0.6927, Training Accuracy= 0.522\n",
      "Epoch: 450, Loss= 0.6953, Training Accuracy= 0.509\n",
      "Epoch: 460, Loss= 0.6936, Training Accuracy= 0.520\n",
      "Epoch: 470, Loss= 0.6945, Training Accuracy= 0.515\n",
      "Epoch: 480, Loss= 0.6907, Training Accuracy= 0.522\n",
      "Epoch: 490, Loss= 0.6911, Training Accuracy= 0.526\n",
      "Epoch: 500, Loss= 0.6909, Training Accuracy= 0.528\n",
      "Epoch: 510, Loss= 0.6843, Training Accuracy= 0.546\n",
      "Epoch: 520, Loss= 0.6883, Training Accuracy= 0.535\n",
      "Epoch: 530, Loss= 0.6926, Training Accuracy= 0.530\n",
      "Epoch: 540, Loss= 0.6884, Training Accuracy= 0.539\n",
      "Epoch: 550, Loss= 0.6851, Training Accuracy= 0.548\n",
      "Epoch: 560, Loss= 0.6843, Training Accuracy= 0.548\n",
      "Epoch: 570, Loss= 0.6869, Training Accuracy= 0.543\n",
      "Epoch: 580, Loss= 0.6813, Training Accuracy= 0.552\n",
      "Epoch: 590, Loss= 0.6798, Training Accuracy= 0.556\n",
      "Epoch: 600, Loss= 0.6769, Training Accuracy= 0.561\n",
      "Epoch: 610, Loss= 0.6943, Training Accuracy= 0.514\n",
      "Epoch: 620, Loss= 0.6905, Training Accuracy= 0.531\n",
      "Epoch: 630, Loss= 0.6969, Training Accuracy= 0.510\n",
      "Epoch: 640, Loss= 0.6954, Training Accuracy= 0.512\n",
      "Epoch: 650, Loss= 0.6946, Training Accuracy= 0.516\n",
      "Epoch: 660, Loss= 0.6932, Training Accuracy= 0.531\n",
      "Epoch: 670, Loss= 0.6946, Training Accuracy= 0.512\n",
      "Epoch: 680, Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 690, Loss= 0.6950, Training Accuracy= 0.516\n",
      "Epoch: 700, Loss= 0.6806, Training Accuracy= 0.549\n",
      "Epoch: 710, Loss= 0.6920, Training Accuracy= 0.514\n",
      "Epoch: 720, Loss= 0.6961, Training Accuracy= 0.506\n",
      "Epoch: 730, Loss= 0.6912, Training Accuracy= 0.520\n",
      "Epoch: 740, Loss= 0.6949, Training Accuracy= 0.508\n",
      "Epoch: 750, Loss= 0.6940, Training Accuracy= 0.515\n",
      "Epoch: 760, Loss= 0.6936, Training Accuracy= 0.513\n",
      "Epoch: 770, Loss= 0.6932, Training Accuracy= 0.513\n",
      "Epoch: 780, Loss= 0.6921, Training Accuracy= 0.517\n",
      "Epoch: 790, Loss= 0.6863, Training Accuracy= 0.529\n",
      "Epoch: 800, Loss= 0.7015, Training Accuracy= 0.504\n",
      "Epoch: 810, Loss= 0.6942, Training Accuracy= 0.508\n",
      "Epoch: 820, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 830, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 840, Loss= 0.6921, Training Accuracy= 0.516\n",
      "Epoch: 850, Loss= 0.6913, Training Accuracy= 0.515\n",
      "Epoch: 860, Loss= 0.6910, Training Accuracy= 0.520\n",
      "Epoch: 870, Loss= 0.6906, Training Accuracy= 0.523\n",
      "Epoch: 880, Loss= 0.6893, Training Accuracy= 0.526\n",
      "Epoch: 890, Loss= 0.6885, Training Accuracy= 0.527\n",
      "Epoch: 900, Loss= 0.6882, Training Accuracy= 0.527\n",
      "Epoch: 910, Loss= 0.6875, Training Accuracy= 0.534\n",
      "Epoch: 920, Loss= 0.6869, Training Accuracy= 0.536\n",
      "Epoch: 930, Loss= 0.6865, Training Accuracy= 0.538\n",
      "Epoch: 940, Loss= 0.6857, Training Accuracy= 0.540\n",
      "Epoch: 950, Loss= 0.6858, Training Accuracy= 0.542\n",
      "Epoch: 960, Loss= 0.6864, Training Accuracy= 0.546\n",
      "Epoch: 970, Loss= 0.6862, Training Accuracy= 0.548\n",
      "Epoch: 980, Loss= 0.6888, Training Accuracy= 0.536\n",
      "Epoch: 990, Loss= 0.6783, Training Accuracy= 0.571\n",
      "Epoch: 1000, Loss= 0.6799, Training Accuracy= 0.559\n",
      "Epoch: 1010, Loss= 0.6758, Training Accuracy= 0.560\n",
      "Epoch: 1020, Loss= 0.6759, Training Accuracy= 0.555\n",
      "Epoch: 1030, Loss= 0.6783, Training Accuracy= 0.552\n",
      "Epoch: 1040, Loss= 0.6821, Training Accuracy= 0.553\n",
      "Epoch: 1050, Loss= 0.6686, Training Accuracy= 0.574\n",
      "Epoch: 1060, Loss= 0.6679, Training Accuracy= 0.573\n",
      "Epoch: 1070, Loss= 0.6742, Training Accuracy= 0.563\n",
      "Epoch: 1080, Loss= 0.6786, Training Accuracy= 0.560\n",
      "Epoch: 1090, Loss= 0.6693, Training Accuracy= 0.571\n",
      "Epoch: 1100, Loss= 0.6730, Training Accuracy= 0.570\n",
      "Epoch: 1110, Loss= 0.6703, Training Accuracy= 0.578\n",
      "Epoch: 1120, Loss= 0.6566, Training Accuracy= 0.586\n",
      "Epoch: 1130, Loss= 0.6574, Training Accuracy= 0.587\n",
      "Epoch: 1140, Loss= 0.6478, Training Accuracy= 0.594\n",
      "Epoch: 1150, Loss= 0.6705, Training Accuracy= 0.583\n",
      "Epoch: 1160, Loss= 0.6787, Training Accuracy= 0.575\n",
      "Epoch: 1170, Loss= 0.6417, Training Accuracy= 0.612\n",
      "Epoch: 1180, Loss= 0.6705, Training Accuracy= 0.584\n",
      "Epoch: 1190, Loss= 0.6252, Training Accuracy= 0.616\n",
      "Epoch: 1200, Loss= 0.6675, Training Accuracy= 0.584\n",
      "Epoch: 1210, Loss= 0.6558, Training Accuracy= 0.590\n",
      "Epoch: 1220, Loss= 0.6341, Training Accuracy= 0.605\n",
      "Epoch: 1230, Loss= 0.6670, Training Accuracy= 0.564\n",
      "Epoch: 1240, Loss= 0.6841, Training Accuracy= 0.571\n",
      "Epoch: 1250, Loss= 0.7791, Training Accuracy= 0.523\n",
      "Epoch: 1260, Loss= 0.2504, Training Accuracy= 0.878\n",
      "Epoch: 1270, Loss= 0.1242, Training Accuracy= 0.938\n",
      "Epoch: 1280, Loss= 0.0794, Training Accuracy= 0.969\n",
      "Epoch: 1290, Loss= 0.0598, Training Accuracy= 0.975\n",
      "Epoch: 1300, Loss= 0.0472, Training Accuracy= 0.976\n",
      "Epoch: 1310, Loss= 0.0418, Training Accuracy= 0.982\n",
      "Epoch: 1320, Loss= 0.0385, Training Accuracy= 0.984\n",
      "Epoch: 1330, Loss= 0.0362, Training Accuracy= 0.984\n",
      "Epoch: 1340, Loss= 0.3513, Training Accuracy= 0.819\n",
      "Epoch: 1350, Loss= 0.1574, Training Accuracy= 0.929\n",
      "Epoch: 1360, Loss= 0.3696, Training Accuracy= 0.837\n",
      "Epoch: 1370, Loss= 0.1625, Training Accuracy= 0.919\n",
      "Epoch: 1380, Loss= 0.2453, Training Accuracy= 0.883\n",
      "Epoch: 1390, Loss= 0.8378, Training Accuracy= 0.504\n",
      "Epoch: 1400, Loss= 0.7289, Training Accuracy= 0.504\n",
      "Epoch: 1410, Loss= 0.7172, Training Accuracy= 0.504\n",
      "Epoch: 1420, Loss= 0.7109, Training Accuracy= 0.504\n",
      "Epoch: 1430, Loss= 0.7074, Training Accuracy= 0.504\n",
      "Epoch: 1440, Loss= 0.7056, Training Accuracy= 0.504\n",
      "Epoch: 1450, Loss= 0.7046, Training Accuracy= 0.504\n",
      "Epoch: 1460, Loss= 0.7040, Training Accuracy= 0.504\n",
      "Epoch: 1470, Loss= 0.7035, Training Accuracy= 0.504\n",
      "Epoch: 1480, Loss= 0.7032, Training Accuracy= 0.504\n",
      "Epoch: 1490, Loss= 0.7030, Training Accuracy= 0.504\n",
      "Epoch: 1500, Loss= 0.7028, Training Accuracy= 0.504\n",
      "Epoch: 1510, Loss= 0.7027, Training Accuracy= 0.504\n",
      "Epoch: 1520, Loss= 0.7026, Training Accuracy= 0.504\n",
      "Epoch: 1530, Loss= 0.7025, Training Accuracy= 0.504\n",
      "Epoch: 1540, Loss= 0.7024, Training Accuracy= 0.504\n",
      "Epoch: 1550, Loss= 0.7023, Training Accuracy= 0.504\n",
      "Epoch: 1560, Loss= 0.7023, Training Accuracy= 0.504\n",
      "Epoch: 1570, Loss= 0.7022, Training Accuracy= 0.504\n",
      "Epoch: 1580, Loss= 0.7022, Training Accuracy= 0.504\n",
      "Epoch: 1590, Loss= 0.7022, Training Accuracy= 0.504\n",
      "Epoch: 1600, Loss= 0.7021, Training Accuracy= 0.504\n",
      "Epoch: 1610, Loss= 0.7021, Training Accuracy= 0.504\n",
      "Epoch: 1620, Loss= 0.7021, Training Accuracy= 0.504\n",
      "Epoch: 1630, Loss= 0.7021, Training Accuracy= 0.504\n",
      "Epoch: 1640, Loss= 0.7021, Training Accuracy= 0.504\n",
      "Epoch: 1650, Loss= 0.7021, Training Accuracy= 0.504\n",
      "Epoch: 1660, Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 1670, Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 1680, Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 1690, Loss= 0.7019, Training Accuracy= 0.504\n",
      "Epoch: 1700, Loss= 0.7019, Training Accuracy= 0.504\n",
      "Epoch: 1710, Loss= 0.7019, Training Accuracy= 0.504\n",
      "Epoch: 1720, Loss= 0.7019, Training Accuracy= 0.504\n",
      "Epoch: 1730, Loss= 0.7018, Training Accuracy= 0.504\n",
      "Epoch: 1740, Loss= 0.7018, Training Accuracy= 0.504\n",
      "Epoch: 1750, Loss= 0.7018, Training Accuracy= 0.504\n",
      "Epoch: 1760, Loss= 0.7018, Training Accuracy= 0.504\n",
      "Epoch: 1770, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1780, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1790, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1800, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1810, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1820, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1830, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1840, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1850, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1860, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1870, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1880, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1890, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1900, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1910, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1920, Loss= 0.7018, Training Accuracy= 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1930, Loss= 0.7018, Training Accuracy= 0.504\n",
      "Epoch: 1940, Loss= 0.7018, Training Accuracy= 0.504\n",
      "Epoch: 1950, Loss= 0.7018, Training Accuracy= 0.504\n",
      "Epoch: 1960, Loss= 0.7019, Training Accuracy= 0.504\n",
      "Epoch: 1970, Loss= 0.7019, Training Accuracy= 0.504\n",
      "Epoch: 1980, Loss= 0.7019, Training Accuracy= 0.504\n",
      "Epoch: 1990, Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 2000, Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 2010, Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 2020, Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 2030, Loss= 0.7019, Training Accuracy= 0.504\n",
      "Epoch: 2040, Loss= 0.7018, Training Accuracy= 0.504\n",
      "Epoch: 2050, Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 2060, Loss= 0.7016, Training Accuracy= 0.504\n",
      "Epoch: 2070, Loss= 0.7014, Training Accuracy= 0.504\n",
      "Epoch: 2080, Loss= 0.7013, Training Accuracy= 0.504\n",
      "Epoch: 2090, Loss= 0.7011, Training Accuracy= 0.504\n",
      "Epoch: 2100, Loss= 0.7010, Training Accuracy= 0.504\n",
      "Epoch: 2110, Loss= 0.7008, Training Accuracy= 0.504\n",
      "Epoch: 2120, Loss= 0.7007, Training Accuracy= 0.505\n",
      "Epoch: 2130, Loss= 0.7006, Training Accuracy= 0.505\n",
      "Epoch: 2140, Loss= 0.7005, Training Accuracy= 0.505\n",
      "Epoch: 2150, Loss= 0.7004, Training Accuracy= 0.505\n",
      "Epoch: 2160, Loss= 0.7002, Training Accuracy= 0.505\n",
      "Epoch: 2170, Loss= 0.6999, Training Accuracy= 0.505\n",
      "Epoch: 2180, Loss= 0.6995, Training Accuracy= 0.506\n",
      "Epoch: 2190, Loss= 0.6992, Training Accuracy= 0.506\n",
      "Epoch: 2200, Loss= 0.6989, Training Accuracy= 0.506\n",
      "Epoch: 2210, Loss= 0.6986, Training Accuracy= 0.507\n",
      "Epoch: 2220, Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 2230, Loss= 0.6979, Training Accuracy= 0.507\n",
      "Epoch: 2240, Loss= 0.6973, Training Accuracy= 0.507\n",
      "Epoch: 2250, Loss= 0.6964, Training Accuracy= 0.508\n",
      "Epoch: 2260, Loss= 0.6954, Training Accuracy= 0.508\n",
      "Epoch: 2270, Loss= 0.6949, Training Accuracy= 0.506\n",
      "Epoch: 2280, Loss= 0.6949, Training Accuracy= 0.507\n",
      "Epoch: 2290, Loss= 0.6956, Training Accuracy= 0.507\n",
      "Epoch: 2300, Loss= 0.6954, Training Accuracy= 0.508\n",
      "Epoch: 2310, Loss= 0.6954, Training Accuracy= 0.509\n",
      "Epoch: 2320, Loss= 0.6951, Training Accuracy= 0.510\n",
      "Epoch: 2330, Loss= 0.6943, Training Accuracy= 0.511\n",
      "Epoch: 2340, Loss= 0.6941, Training Accuracy= 0.511\n",
      "Epoch: 2350, Loss= 0.6973, Training Accuracy= 0.506\n",
      "Epoch: 2360, Loss= 0.6939, Training Accuracy= 0.513\n",
      "Epoch: 2370, Loss= 0.6936, Training Accuracy= 0.513\n",
      "Epoch: 2380, Loss= 0.6933, Training Accuracy= 0.516\n",
      "Epoch: 2390, Loss= 0.6952, Training Accuracy= 0.513\n",
      "Epoch: 2400, Loss= 0.6937, Training Accuracy= 0.515\n",
      "Epoch: 2410, Loss= 0.6938, Training Accuracy= 0.515\n",
      "Epoch: 2420, Loss= 0.6939, Training Accuracy= 0.513\n",
      "Epoch: 2430, Loss= 0.5591, Training Accuracy= 0.752\n",
      "Epoch: 2440, Loss= 0.2275, Training Accuracy= 0.881\n",
      "Epoch: 2450, Loss= 0.1725, Training Accuracy= 0.882\n",
      "Epoch: 2460, Loss= 0.3499, Training Accuracy= 0.753\n",
      "Epoch: 2470, Loss= 0.3485, Training Accuracy= 0.751\n",
      "Epoch: 2480, Loss= 0.3479, Training Accuracy= 0.752\n",
      "Epoch: 2490, Loss= 0.3474, Training Accuracy= 0.753\n",
      "Epoch: 2500, Loss= 0.3471, Training Accuracy= 0.753\n",
      "Epoch: 2510, Loss= 0.3468, Training Accuracy= 0.754\n",
      "Epoch: 2520, Loss= 0.3465, Training Accuracy= 0.754\n",
      "Epoch: 2530, Loss= 0.3463, Training Accuracy= 0.754\n",
      "Epoch: 2540, Loss= 0.3461, Training Accuracy= 0.754\n",
      "Epoch: 2550, Loss= 0.3459, Training Accuracy= 0.755\n",
      "Epoch: 2560, Loss= 0.3457, Training Accuracy= 0.755\n",
      "Epoch: 2570, Loss= 0.3455, Training Accuracy= 0.755\n",
      "Epoch: 2580, Loss= 0.3454, Training Accuracy= 0.756\n",
      "Epoch: 2590, Loss= 0.3453, Training Accuracy= 0.756\n",
      "Epoch: 2600, Loss= 0.3452, Training Accuracy= 0.757\n",
      "Epoch: 2610, Loss= 0.3451, Training Accuracy= 0.757\n",
      "Epoch: 2620, Loss= 0.3450, Training Accuracy= 0.757\n",
      "Epoch: 2630, Loss= 0.3449, Training Accuracy= 0.757\n",
      "Epoch: 2640, Loss= 0.3449, Training Accuracy= 0.757\n",
      "Epoch: 2650, Loss= 0.3448, Training Accuracy= 0.757\n",
      "Epoch: 2660, Loss= 0.3448, Training Accuracy= 0.757\n",
      "Epoch: 2670, Loss= 0.3447, Training Accuracy= 0.757\n",
      "Epoch: 2680, Loss= 0.3447, Training Accuracy= 0.757\n",
      "Epoch: 2690, Loss= 0.3446, Training Accuracy= 0.757\n",
      "Epoch: 2700, Loss= 0.3446, Training Accuracy= 0.757\n",
      "Epoch: 2710, Loss= 0.3445, Training Accuracy= 0.757\n",
      "Epoch: 2720, Loss= 0.3445, Training Accuracy= 0.758\n",
      "Epoch: 2730, Loss= 0.3444, Training Accuracy= 0.758\n",
      "Epoch: 2740, Loss= 0.3444, Training Accuracy= 0.758\n",
      "Epoch: 2750, Loss= 0.3444, Training Accuracy= 0.757\n",
      "Epoch: 2760, Loss= 0.3443, Training Accuracy= 0.757\n",
      "Epoch: 2770, Loss= 0.3443, Training Accuracy= 0.757\n",
      "Epoch: 2780, Loss= 0.7062, Training Accuracy= 0.504\n",
      "Epoch: 2790, Loss= 0.7042, Training Accuracy= 0.504\n",
      "Epoch: 2800, Loss= 0.7027, Training Accuracy= 0.504\n",
      "Epoch: 2810, Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 2820, Loss= 0.7016, Training Accuracy= 0.504\n",
      "Epoch: 2830, Loss= 0.7014, Training Accuracy= 0.504\n",
      "Epoch: 2840, Loss= 0.7012, Training Accuracy= 0.504\n",
      "Epoch: 2850, Loss= 0.7009, Training Accuracy= 0.504\n",
      "Epoch: 2860, Loss= 0.7007, Training Accuracy= 0.504\n",
      "Epoch: 2870, Loss= 0.7006, Training Accuracy= 0.505\n",
      "Epoch: 2880, Loss= 0.7004, Training Accuracy= 0.505\n",
      "Epoch: 2890, Loss= 0.7002, Training Accuracy= 0.506\n",
      "Epoch: 2900, Loss= 0.7000, Training Accuracy= 0.507\n",
      "Epoch: 2910, Loss= 0.6999, Training Accuracy= 0.507\n",
      "Epoch: 2920, Loss= 0.6997, Training Accuracy= 0.507\n",
      "Epoch: 2930, Loss= 0.6996, Training Accuracy= 0.508\n",
      "Epoch: 2940, Loss= 0.6995, Training Accuracy= 0.508\n",
      "Epoch: 2950, Loss= 0.6993, Training Accuracy= 0.508\n",
      "Epoch: 2960, Loss= 0.6992, Training Accuracy= 0.509\n",
      "Epoch: 2970, Loss= 0.6991, Training Accuracy= 0.509\n",
      "Epoch: 2980, Loss= 0.6990, Training Accuracy= 0.509\n",
      "Epoch: 2990, Loss= 0.6989, Training Accuracy= 0.509\n",
      "Epoch: 3000, Loss= 0.6988, Training Accuracy= 0.510\n",
      "Epoch: 3010, Loss= 0.6988, Training Accuracy= 0.509\n",
      "Epoch: 3020, Loss= 0.6987, Training Accuracy= 0.509\n",
      "Epoch: 3030, Loss= 0.6985, Training Accuracy= 0.510\n",
      "Epoch: 3040, Loss= 0.6984, Training Accuracy= 0.510\n",
      "Epoch: 3050, Loss= 0.6982, Training Accuracy= 0.511\n",
      "Epoch: 3060, Loss= 0.6980, Training Accuracy= 0.512\n",
      "Epoch: 3070, Loss= 0.6979, Training Accuracy= 0.512\n",
      "Epoch: 3080, Loss= 0.6978, Training Accuracy= 0.511\n",
      "Epoch: 3090, Loss= 0.6977, Training Accuracy= 0.513\n",
      "Epoch: 3100, Loss= 0.6976, Training Accuracy= 0.516\n",
      "Epoch: 3110, Loss= 0.6975, Training Accuracy= 0.516\n",
      "Epoch: 3120, Loss= 0.6974, Training Accuracy= 0.517\n",
      "Epoch: 3130, Loss= 0.6973, Training Accuracy= 0.518\n",
      "Epoch: 3140, Loss= 0.6970, Training Accuracy= 0.518\n",
      "Epoch: 3150, Loss= 0.6968, Training Accuracy= 0.519\n",
      "Epoch: 3160, Loss= 0.6964, Training Accuracy= 0.520\n",
      "Epoch: 3170, Loss= 0.6963, Training Accuracy= 0.520\n",
      "Epoch: 3180, Loss= 0.6959, Training Accuracy= 0.523\n",
      "Epoch: 3190, Loss= 0.6958, Training Accuracy= 0.524\n",
      "Epoch: 3200, Loss= 0.6952, Training Accuracy= 0.523\n",
      "Epoch: 3210, Loss= 0.6952, Training Accuracy= 0.524\n",
      "Epoch: 3220, Loss= 0.6947, Training Accuracy= 0.525\n",
      "Epoch: 3230, Loss= 0.6947, Training Accuracy= 0.525\n",
      "Epoch: 3240, Loss= 0.6945, Training Accuracy= 0.527\n",
      "Epoch: 3250, Loss= 0.6945, Training Accuracy= 0.526\n",
      "Epoch: 3260, Loss= 0.6941, Training Accuracy= 0.527\n",
      "Epoch: 3270, Loss= 0.6936, Training Accuracy= 0.530\n",
      "Epoch: 3280, Loss= 0.6933, Training Accuracy= 0.530\n",
      "Epoch: 3290, Loss= 0.6941, Training Accuracy= 0.531\n",
      "Epoch: 3300, Loss= 0.6936, Training Accuracy= 0.531\n",
      "Epoch: 3310, Loss= 0.6929, Training Accuracy= 0.531\n",
      "Epoch: 3320, Loss= 0.6930, Training Accuracy= 0.531\n",
      "Epoch: 3330, Loss= 0.6925, Training Accuracy= 0.535\n",
      "Epoch: 3340, Loss= 0.6914, Training Accuracy= 0.533\n",
      "Epoch: 3350, Loss= 0.6906, Training Accuracy= 0.535\n",
      "Epoch: 3360, Loss= 0.6903, Training Accuracy= 0.534\n",
      "Epoch: 3370, Loss= 0.6895, Training Accuracy= 0.538\n",
      "Epoch: 3380, Loss= 0.6898, Training Accuracy= 0.535\n",
      "Epoch: 3390, Loss= 0.6909, Training Accuracy= 0.533\n",
      "Epoch: 3400, Loss= 0.6879, Training Accuracy= 0.542\n",
      "Epoch: 3410, Loss= 0.6879, Training Accuracy= 0.546\n",
      "Epoch: 3420, Loss= 0.6876, Training Accuracy= 0.543\n",
      "Epoch: 3430, Loss= 0.6887, Training Accuracy= 0.544\n",
      "Epoch: 3440, Loss= 0.6864, Training Accuracy= 0.551\n",
      "Epoch: 3450, Loss= 0.6859, Training Accuracy= 0.547\n",
      "Epoch: 3460, Loss= 0.6916, Training Accuracy= 0.535\n",
      "Epoch: 3470, Loss= 0.6877, Training Accuracy= 0.543\n",
      "Epoch: 3480, Loss= 0.6999, Training Accuracy= 0.506\n",
      "Epoch: 3490, Loss= 0.6965, Training Accuracy= 0.515\n",
      "Epoch: 3500, Loss= 0.6951, Training Accuracy= 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3510, Loss= 0.6944, Training Accuracy= 0.516\n",
      "Epoch: 3520, Loss= 0.6942, Training Accuracy= 0.518\n",
      "Epoch: 3530, Loss= 0.6946, Training Accuracy= 0.518\n",
      "Epoch: 3540, Loss= 0.6949, Training Accuracy= 0.517\n",
      "Epoch: 3550, Loss= 0.6945, Training Accuracy= 0.516\n",
      "Epoch: 3560, Loss= 0.6941, Training Accuracy= 0.517\n",
      "Epoch: 3570, Loss= 0.6938, Training Accuracy= 0.517\n",
      "Epoch: 3580, Loss= 0.6936, Training Accuracy= 0.519\n",
      "Epoch: 3590, Loss= 0.6935, Training Accuracy= 0.518\n",
      "Epoch: 3600, Loss= 0.6936, Training Accuracy= 0.517\n",
      "Epoch: 3610, Loss= 0.6935, Training Accuracy= 0.519\n",
      "Epoch: 3620, Loss= 0.6932, Training Accuracy= 0.521\n",
      "Epoch: 3630, Loss= 0.6927, Training Accuracy= 0.523\n",
      "Epoch: 3640, Loss= 0.6926, Training Accuracy= 0.524\n",
      "Epoch: 3650, Loss= 0.6919, Training Accuracy= 0.524\n",
      "Epoch: 3660, Loss= 0.6923, Training Accuracy= 0.524\n",
      "Epoch: 3670, Loss= 0.6920, Training Accuracy= 0.525\n",
      "Epoch: 3680, Loss= 0.6914, Training Accuracy= 0.525\n",
      "Epoch: 3690, Loss= 0.6912, Training Accuracy= 0.526\n",
      "Epoch: 3700, Loss= 0.6907, Training Accuracy= 0.527\n",
      "Epoch: 3710, Loss= 0.6883, Training Accuracy= 0.530\n",
      "Epoch: 3720, Loss= 0.6891, Training Accuracy= 0.529\n",
      "Epoch: 3730, Loss= 0.6931, Training Accuracy= 0.524\n",
      "Epoch: 3740, Loss= 0.6940, Training Accuracy= 0.524\n",
      "Epoch: 3750, Loss= 0.6933, Training Accuracy= 0.525\n",
      "Epoch: 3760, Loss= 0.6941, Training Accuracy= 0.524\n",
      "Epoch: 3770, Loss= 0.6964, Training Accuracy= 0.523\n",
      "Epoch: 3780, Loss= 0.6955, Training Accuracy= 0.524\n",
      "Epoch: 3790, Loss= 0.6943, Training Accuracy= 0.526\n",
      "Epoch: 3800, Loss= 0.6953, Training Accuracy= 0.526\n",
      "Epoch: 3810, Loss= 0.6943, Training Accuracy= 0.527\n",
      "Epoch: 3820, Loss= 0.6951, Training Accuracy= 0.530\n",
      "Epoch: 3830, Loss= 0.6946, Training Accuracy= 0.530\n",
      "Epoch: 3840, Loss= 0.6925, Training Accuracy= 0.534\n",
      "Epoch: 3850, Loss= 0.6913, Training Accuracy= 0.535\n",
      "Epoch: 3860, Loss= 0.6880, Training Accuracy= 0.538\n",
      "Epoch: 3870, Loss= 0.6892, Training Accuracy= 0.535\n",
      "Epoch: 3880, Loss= 0.6939, Training Accuracy= 0.528\n",
      "Epoch: 3890, Loss= 0.7130, Training Accuracy= 0.504\n",
      "Epoch: 3900, Loss= 0.7074, Training Accuracy= 0.505\n",
      "Epoch: 3910, Loss= 0.7056, Training Accuracy= 0.505\n",
      "Epoch: 3920, Loss= 0.7048, Training Accuracy= 0.505\n",
      "Epoch: 3930, Loss= 0.7043, Training Accuracy= 0.506\n",
      "Epoch: 3940, Loss= 0.7040, Training Accuracy= 0.506\n",
      "Epoch: 3950, Loss= 0.7039, Training Accuracy= 0.507\n",
      "Epoch: 3960, Loss= 0.7038, Training Accuracy= 0.507\n",
      "Epoch: 3970, Loss= 0.7037, Training Accuracy= 0.507\n",
      "Epoch: 3980, Loss= 0.7036, Training Accuracy= 0.507\n",
      "Epoch: 3990, Loss= 0.7036, Training Accuracy= 0.507\n",
      "Epoch: 4000, Loss= 0.7035, Training Accuracy= 0.508\n",
      "Epoch: 4010, Loss= 0.7034, Training Accuracy= 0.509\n",
      "Epoch: 4020, Loss= 0.7032, Training Accuracy= 0.509\n",
      "Epoch: 4030, Loss= 0.7030, Training Accuracy= 0.510\n",
      "Epoch: 4040, Loss= 0.7028, Training Accuracy= 0.511\n",
      "Epoch: 4050, Loss= 0.7026, Training Accuracy= 0.511\n",
      "Epoch: 4060, Loss= 0.7023, Training Accuracy= 0.512\n",
      "Epoch: 4070, Loss= 0.7022, Training Accuracy= 0.511\n",
      "Epoch: 4080, Loss= 0.7020, Training Accuracy= 0.512\n",
      "Epoch: 4090, Loss= 0.7017, Training Accuracy= 0.513\n",
      "Epoch: 4100, Loss= 0.7015, Training Accuracy= 0.514\n",
      "Epoch: 4110, Loss= 0.7010, Training Accuracy= 0.514\n",
      "Epoch: 4120, Loss= 0.7004, Training Accuracy= 0.514\n",
      "Epoch: 4130, Loss= 0.6998, Training Accuracy= 0.515\n",
      "Epoch: 4140, Loss= 0.6987, Training Accuracy= 0.517\n",
      "Epoch: 4150, Loss= 0.6979, Training Accuracy= 0.518\n",
      "Epoch: 4160, Loss= 0.6970, Training Accuracy= 0.521\n",
      "Epoch: 4170, Loss= 0.6988, Training Accuracy= 0.519\n",
      "Epoch: 4180, Loss= 0.6975, Training Accuracy= 0.521\n",
      "Epoch: 4190, Loss= 0.6962, Training Accuracy= 0.522\n",
      "Epoch: 4200, Loss= 0.6977, Training Accuracy= 0.520\n",
      "Epoch: 4210, Loss= 0.6992, Training Accuracy= 0.522\n",
      "Epoch: 4220, Loss= 0.6980, Training Accuracy= 0.524\n",
      "Epoch: 4230, Loss= 0.7012, Training Accuracy= 0.521\n",
      "Epoch: 4240, Loss= 0.7012, Training Accuracy= 0.522\n",
      "Epoch: 4250, Loss= 0.6967, Training Accuracy= 0.526\n",
      "Epoch: 4260, Loss= 0.6978, Training Accuracy= 0.524\n",
      "Epoch: 4270, Loss= 0.6963, Training Accuracy= 0.526\n",
      "Epoch: 4280, Loss= 0.6962, Training Accuracy= 0.525\n",
      "Epoch: 4290, Loss= 0.6991, Training Accuracy= 0.525\n",
      "Epoch: 4300, Loss= 0.6988, Training Accuracy= 0.525\n",
      "Epoch: 4310, Loss= 0.6984, Training Accuracy= 0.526\n",
      "Epoch: 4320, Loss= 0.6972, Training Accuracy= 0.527\n",
      "Epoch: 4330, Loss= 0.6999, Training Accuracy= 0.526\n",
      "Epoch: 4340, Loss= 0.6994, Training Accuracy= 0.525\n",
      "Epoch: 4350, Loss= 0.6988, Training Accuracy= 0.528\n",
      "Epoch: 4360, Loss= 0.6973, Training Accuracy= 0.529\n",
      "Epoch: 4370, Loss= 0.6956, Training Accuracy= 0.531\n",
      "Epoch: 4380, Loss= 0.6941, Training Accuracy= 0.533\n",
      "Epoch: 4390, Loss= 0.6970, Training Accuracy= 0.530\n",
      "Epoch: 4400, Loss= 0.6956, Training Accuracy= 0.531\n",
      "Epoch: 4410, Loss= 0.6907, Training Accuracy= 0.536\n",
      "Epoch: 4420, Loss= 0.6906, Training Accuracy= 0.536\n",
      "Epoch: 4430, Loss= 0.6894, Training Accuracy= 0.539\n",
      "Epoch: 4440, Loss= 0.6907, Training Accuracy= 0.534\n",
      "Epoch: 4450, Loss= 0.6920, Training Accuracy= 0.536\n",
      "Epoch: 4460, Loss= 0.6881, Training Accuracy= 0.539\n",
      "Epoch: 4470, Loss= 0.6872, Training Accuracy= 0.539\n",
      "Epoch: 4480, Loss= 0.6868, Training Accuracy= 0.540\n",
      "Epoch: 4490, Loss= 0.6837, Training Accuracy= 0.541\n",
      "Epoch: 4500, Loss= 0.6835, Training Accuracy= 0.541\n",
      "Epoch: 4510, Loss= 0.6814, Training Accuracy= 0.541\n",
      "Epoch: 4520, Loss= 0.6829, Training Accuracy= 0.539\n",
      "Epoch: 4530, Loss= 0.7018, Training Accuracy= 0.524\n",
      "Epoch: 4540, Loss= 0.6829, Training Accuracy= 0.541\n",
      "Epoch: 4550, Loss= 0.6800, Training Accuracy= 0.543\n",
      "Epoch: 4560, Loss= 0.6842, Training Accuracy= 0.541\n",
      "Epoch: 4570, Loss= 0.6938, Training Accuracy= 0.529\n",
      "Epoch: 4580, Loss= 0.6817, Training Accuracy= 0.540\n",
      "Epoch: 4590, Loss= 0.6881, Training Accuracy= 0.533\n",
      "Epoch: 4600, Loss= 0.6836, Training Accuracy= 0.539\n",
      "Epoch: 4610, Loss= 0.6903, Training Accuracy= 0.531\n",
      "Epoch: 4620, Loss= 0.6748, Training Accuracy= 0.544\n",
      "Epoch: 4630, Loss= 0.6800, Training Accuracy= 0.544\n",
      "Epoch: 4640, Loss= 0.6910, Training Accuracy= 0.536\n",
      "Epoch: 4650, Loss= 0.6792, Training Accuracy= 0.541\n",
      "Epoch: 4660, Loss= 0.6806, Training Accuracy= 0.542\n",
      "Epoch: 4670, Loss= 0.6740, Training Accuracy= 0.548\n",
      "Epoch: 4680, Loss= 0.6734, Training Accuracy= 0.547\n",
      "Epoch: 4690, Loss= 0.6834, Training Accuracy= 0.539\n",
      "Epoch: 4700, Loss= 0.7010, Training Accuracy= 0.510\n",
      "Epoch: 4710, Loss= 0.6991, Training Accuracy= 0.512\n",
      "Epoch: 4720, Loss= 0.6970, Training Accuracy= 0.515\n",
      "Epoch: 4730, Loss= 0.6959, Training Accuracy= 0.517\n",
      "Epoch: 4740, Loss= 0.6932, Training Accuracy= 0.523\n",
      "Epoch: 4750, Loss= 0.6920, Training Accuracy= 0.525\n",
      "Epoch: 4760, Loss= 0.6917, Training Accuracy= 0.526\n",
      "Epoch: 4770, Loss= 0.6888, Training Accuracy= 0.532\n",
      "Epoch: 4780, Loss= 0.6874, Training Accuracy= 0.536\n",
      "Epoch: 4790, Loss= 0.6879, Training Accuracy= 0.532\n",
      "Epoch: 4800, Loss= 0.6860, Training Accuracy= 0.538\n",
      "Epoch: 4810, Loss= 0.6847, Training Accuracy= 0.541\n",
      "Epoch: 4820, Loss= 0.6882, Training Accuracy= 0.531\n",
      "Epoch: 4830, Loss= 0.8765, Training Accuracy= 0.496\n",
      "Epoch: 4840, Loss= 0.7684, Training Accuracy= 0.504\n",
      "Epoch: 4850, Loss= 0.7342, Training Accuracy= 0.505\n",
      "Epoch: 4860, Loss= 0.7256, Training Accuracy= 0.507\n",
      "Epoch: 4870, Loss= 0.7220, Training Accuracy= 0.508\n",
      "Epoch: 4880, Loss= 0.7202, Training Accuracy= 0.507\n",
      "Epoch: 4890, Loss= 0.7185, Training Accuracy= 0.507\n",
      "Epoch: 4900, Loss= 0.7173, Training Accuracy= 0.508\n",
      "Epoch: 4910, Loss= 0.7163, Training Accuracy= 0.508\n",
      "Epoch: 4920, Loss= 0.7164, Training Accuracy= 0.507\n",
      "Epoch: 4930, Loss= 0.7143, Training Accuracy= 0.508\n",
      "Epoch: 4940, Loss= 0.7127, Training Accuracy= 0.508\n",
      "Epoch: 4950, Loss= 0.7144, Training Accuracy= 0.508\n",
      "Epoch: 4960, Loss= 0.7157, Training Accuracy= 0.508\n",
      "Epoch: 4970, Loss= 0.7158, Training Accuracy= 0.508\n",
      "Epoch: 4980, Loss= 0.7127, Training Accuracy= 0.508\n",
      "Epoch: 4990, Loss= 0.7207, Training Accuracy= 0.508\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5013\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.8707, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.7469, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.7299, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.7224, Training Accuracy= 0.502\n",
      "Epoch: 40, Loss= 0.7179, Training Accuracy= 0.502\n",
      "Epoch: 50, Loss= 0.7150, Training Accuracy= 0.502\n",
      "Epoch: 60, Loss= 0.7128, Training Accuracy= 0.502\n",
      "Epoch: 70, Loss= 0.7112, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Loss= 0.7100, Training Accuracy= 0.502\n",
      "Epoch: 90, Loss= 0.7089, Training Accuracy= 0.502\n",
      "Epoch: 100, Loss= 0.7081, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.7074, Training Accuracy= 0.502\n",
      "Epoch: 120, Loss= 0.7068, Training Accuracy= 0.502\n",
      "Epoch: 130, Loss= 0.7062, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 0.7058, Training Accuracy= 0.502\n",
      "Epoch: 150, Loss= 0.7054, Training Accuracy= 0.502\n",
      "Epoch: 160, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 170, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 180, Loss= 0.7044, Training Accuracy= 0.502\n",
      "Epoch: 190, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 200, Loss= 0.7039, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.7037, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.7035, Training Accuracy= 0.502\n",
      "Epoch: 230, Loss= 0.7033, Training Accuracy= 0.502\n",
      "Epoch: 240, Loss= 0.7031, Training Accuracy= 0.502\n",
      "Epoch: 250, Loss= 0.7030, Training Accuracy= 0.502\n",
      "Epoch: 260, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 270, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 280, Loss= 0.7026, Training Accuracy= 0.502\n",
      "Epoch: 290, Loss= 0.7025, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 0.7024, Training Accuracy= 0.502\n",
      "Epoch: 310, Loss= 0.7023, Training Accuracy= 0.502\n",
      "Epoch: 320, Loss= 0.7022, Training Accuracy= 0.502\n",
      "Epoch: 330, Loss= 0.7021, Training Accuracy= 0.502\n",
      "Epoch: 340, Loss= 0.7020, Training Accuracy= 0.502\n",
      "Epoch: 350, Loss= 0.7019, Training Accuracy= 0.502\n",
      "Epoch: 360, Loss= 0.7019, Training Accuracy= 0.502\n",
      "Epoch: 370, Loss= 0.7018, Training Accuracy= 0.502\n",
      "Epoch: 380, Loss= 0.7017, Training Accuracy= 0.502\n",
      "Epoch: 390, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 400, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 410, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 420, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 430, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 440, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 450, Loss= 0.7013, Training Accuracy= 0.502\n",
      "Epoch: 460, Loss= 0.7012, Training Accuracy= 0.502\n",
      "Epoch: 470, Loss= 0.7012, Training Accuracy= 0.502\n",
      "Epoch: 480, Loss= 0.7011, Training Accuracy= 0.502\n",
      "Epoch: 490, Loss= 0.7011, Training Accuracy= 0.502\n",
      "Epoch: 500, Loss= 0.7010, Training Accuracy= 0.502\n",
      "Epoch: 510, Loss= 0.7010, Training Accuracy= 0.502\n",
      "Epoch: 520, Loss= 0.7009, Training Accuracy= 0.502\n",
      "Epoch: 530, Loss= 0.7009, Training Accuracy= 0.502\n",
      "Epoch: 540, Loss= 0.7008, Training Accuracy= 0.502\n",
      "Epoch: 550, Loss= 0.7007, Training Accuracy= 0.502\n",
      "Epoch: 560, Loss= 0.7007, Training Accuracy= 0.502\n",
      "Epoch: 570, Loss= 0.7007, Training Accuracy= 0.502\n",
      "Epoch: 580, Loss= 0.7007, Training Accuracy= 0.502\n",
      "Epoch: 590, Loss= 0.7006, Training Accuracy= 0.502\n",
      "Epoch: 600, Loss= 0.7005, Training Accuracy= 0.502\n",
      "Epoch: 610, Loss= 0.7004, Training Accuracy= 0.502\n",
      "Epoch: 620, Loss= 0.7004, Training Accuracy= 0.502\n",
      "Epoch: 630, Loss= 0.7015, Training Accuracy= 0.503\n",
      "Epoch: 640, Loss= 0.7021, Training Accuracy= 0.505\n",
      "Epoch: 650, Loss= 0.7022, Training Accuracy= 0.505\n",
      "Epoch: 660, Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 670, Loss= 0.7017, Training Accuracy= 0.506\n",
      "Epoch: 680, Loss= 0.7016, Training Accuracy= 0.506\n",
      "Epoch: 690, Loss= 0.7016, Training Accuracy= 0.505\n",
      "Epoch: 700, Loss= 0.7010, Training Accuracy= 0.507\n",
      "Epoch: 710, Loss= 0.7006, Training Accuracy= 0.507\n",
      "Epoch: 720, Loss= 0.7002, Training Accuracy= 0.510\n",
      "Epoch: 730, Loss= 0.7001, Training Accuracy= 0.511\n",
      "Epoch: 740, Loss= 0.7000, Training Accuracy= 0.511\n",
      "Epoch: 750, Loss= 0.6998, Training Accuracy= 0.512\n",
      "Epoch: 760, Loss= 0.6996, Training Accuracy= 0.511\n",
      "Epoch: 770, Loss= 0.7002, Training Accuracy= 0.508\n",
      "Epoch: 780, Loss= 0.7000, Training Accuracy= 0.508\n",
      "Epoch: 790, Loss= 0.6993, Training Accuracy= 0.511\n",
      "Epoch: 800, Loss= 0.6993, Training Accuracy= 0.513\n",
      "Epoch: 810, Loss= 0.6986, Training Accuracy= 0.515\n",
      "Epoch: 820, Loss= 0.6981, Training Accuracy= 0.525\n",
      "Epoch: 830, Loss= 0.6999, Training Accuracy= 0.521\n",
      "Epoch: 840, Loss= 0.6974, Training Accuracy= 0.521\n",
      "Epoch: 850, Loss= 0.7000, Training Accuracy= 0.525\n",
      "Epoch: 860, Loss= 0.6976, Training Accuracy= 0.527\n",
      "Epoch: 870, Loss= 0.6989, Training Accuracy= 0.524\n",
      "Epoch: 880, Loss= 0.6947, Training Accuracy= 0.535\n",
      "Epoch: 890, Loss= 0.6949, Training Accuracy= 0.533\n",
      "Epoch: 900, Loss= 0.6945, Training Accuracy= 0.536\n",
      "Epoch: 910, Loss= 0.6968, Training Accuracy= 0.528\n",
      "Epoch: 920, Loss= 0.7017, Training Accuracy= 0.530\n",
      "Epoch: 930, Loss= 0.6957, Training Accuracy= 0.541\n",
      "Epoch: 940, Loss= 0.6958, Training Accuracy= 0.535\n",
      "Epoch: 950, Loss= 0.6946, Training Accuracy= 0.537\n",
      "Epoch: 960, Loss= 0.6943, Training Accuracy= 0.540\n",
      "Epoch: 970, Loss= 0.6909, Training Accuracy= 0.549\n",
      "Epoch: 980, Loss= 0.6891, Training Accuracy= 0.545\n",
      "Epoch: 990, Loss= 0.6873, Training Accuracy= 0.553\n",
      "Epoch: 1000, Loss= 0.6836, Training Accuracy= 0.562\n",
      "Epoch: 1010, Loss= 0.6859, Training Accuracy= 0.559\n",
      "Epoch: 1020, Loss= 0.6965, Training Accuracy= 0.537\n",
      "Epoch: 1030, Loss= 0.6918, Training Accuracy= 0.556\n",
      "Epoch: 1040, Loss= 0.6938, Training Accuracy= 0.545\n",
      "Epoch: 1050, Loss= 0.6804, Training Accuracy= 0.567\n",
      "Epoch: 1060, Loss= 0.6842, Training Accuracy= 0.567\n",
      "Epoch: 1070, Loss= 0.6836, Training Accuracy= 0.559\n",
      "Epoch: 1080, Loss= 0.6787, Training Accuracy= 0.577\n",
      "Epoch: 1090, Loss= 0.6971, Training Accuracy= 0.556\n",
      "Epoch: 1100, Loss= 0.6802, Training Accuracy= 0.580\n",
      "Epoch: 1110, Loss= 0.6875, Training Accuracy= 0.546\n",
      "Epoch: 1120, Loss= 0.6693, Training Accuracy= 0.582\n",
      "Epoch: 1130, Loss= 0.6666, Training Accuracy= 0.597\n",
      "Epoch: 1140, Loss= 0.6614, Training Accuracy= 0.602\n",
      "Epoch: 1150, Loss= 0.6580, Training Accuracy= 0.609\n",
      "Epoch: 1160, Loss= 0.6600, Training Accuracy= 0.606\n",
      "Epoch: 1170, Loss= 0.7073, Training Accuracy= 0.538\n",
      "Epoch: 1180, Loss= 0.6574, Training Accuracy= 0.609\n",
      "Epoch: 1190, Loss= 0.6757, Training Accuracy= 0.572\n",
      "Epoch: 1200, Loss= 0.6565, Training Accuracy= 0.598\n",
      "Epoch: 1210, Loss= 0.6438, Training Accuracy= 0.617\n",
      "Epoch: 1220, Loss= 0.6496, Training Accuracy= 0.616\n",
      "Epoch: 1230, Loss= 0.7027, Training Accuracy= 0.539\n",
      "Epoch: 1240, Loss= 0.6757, Training Accuracy= 0.572\n",
      "Epoch: 1250, Loss= 0.6434, Training Accuracy= 0.619\n",
      "Epoch: 1260, Loss= 0.6396, Training Accuracy= 0.628\n",
      "Epoch: 1270, Loss= 0.6486, Training Accuracy= 0.615\n",
      "Epoch: 1280, Loss= 0.6311, Training Accuracy= 0.643\n",
      "Epoch: 1290, Loss= 0.6594, Training Accuracy= 0.610\n",
      "Epoch: 1300, Loss= 0.6335, Training Accuracy= 0.633\n",
      "Epoch: 1310, Loss= 0.6532, Training Accuracy= 0.620\n",
      "Epoch: 1320, Loss= 0.6694, Training Accuracy= 0.591\n",
      "Epoch: 1330, Loss= 0.6205, Training Accuracy= 0.652\n",
      "Epoch: 1340, Loss= 0.7353, Training Accuracy= 0.499\n",
      "Epoch: 1350, Loss= 0.7067, Training Accuracy= 0.519\n",
      "Epoch: 1360, Loss= 0.7021, Training Accuracy= 0.519\n",
      "Epoch: 1370, Loss= 0.7076, Training Accuracy= 0.515\n",
      "Epoch: 1380, Loss= 0.6972, Training Accuracy= 0.523\n",
      "Epoch: 1390, Loss= 0.7061, Training Accuracy= 0.511\n",
      "Epoch: 1400, Loss= 0.7050, Training Accuracy= 0.510\n",
      "Epoch: 1410, Loss= 0.6988, Training Accuracy= 0.525\n",
      "Epoch: 1420, Loss= 0.6887, Training Accuracy= 0.536\n",
      "Epoch: 1430, Loss= 0.6900, Training Accuracy= 0.546\n",
      "Epoch: 1440, Loss= 0.6782, Training Accuracy= 0.557\n",
      "Epoch: 1450, Loss= 0.6956, Training Accuracy= 0.534\n",
      "Epoch: 1460, Loss= 0.7155, Training Accuracy= 0.505\n",
      "Epoch: 1470, Loss= 0.7037, Training Accuracy= 0.511\n",
      "Epoch: 1480, Loss= 0.7072, Training Accuracy= 0.512\n",
      "Epoch: 1490, Loss= 0.7162, Training Accuracy= 0.504\n",
      "Epoch: 1500, Loss= 0.7098, Training Accuracy= 0.506\n",
      "Epoch: 1510, Loss= 0.6990, Training Accuracy= 0.512\n",
      "Epoch: 1520, Loss= 0.7014, Training Accuracy= 0.517\n",
      "Epoch: 1530, Loss= 0.6924, Training Accuracy= 0.530\n",
      "Epoch: 1540, Loss= 0.6897, Training Accuracy= 0.536\n",
      "Epoch: 1550, Loss= 0.7054, Training Accuracy= 0.512\n",
      "Epoch: 1560, Loss= 0.7015, Training Accuracy= 0.522\n",
      "Epoch: 1570, Loss= 0.6974, Training Accuracy= 0.520\n",
      "Epoch: 1580, Loss= 0.6891, Training Accuracy= 0.542\n",
      "Epoch: 1590, Loss= 0.7329, Training Accuracy= 0.502\n",
      "Epoch: 1600, Loss= 0.8516, Training Accuracy= 0.502\n",
      "Epoch: 1610, Loss= 0.8136, Training Accuracy= 0.502\n",
      "Epoch: 1620, Loss= 0.7959, Training Accuracy= 0.502\n",
      "Epoch: 1630, Loss= 0.7828, Training Accuracy= 0.502\n",
      "Epoch: 1640, Loss= 0.7717, Training Accuracy= 0.502\n",
      "Epoch: 1650, Loss= 0.7624, Training Accuracy= 0.502\n",
      "Epoch: 1660, Loss= 0.7544, Training Accuracy= 0.502\n",
      "Epoch: 1670, Loss= 0.7475, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1680, Loss= 0.7418, Training Accuracy= 0.502\n",
      "Epoch: 1690, Loss= 0.7374, Training Accuracy= 0.502\n",
      "Epoch: 1700, Loss= 0.7338, Training Accuracy= 0.502\n",
      "Epoch: 1710, Loss= 0.7309, Training Accuracy= 0.502\n",
      "Epoch: 1720, Loss= 0.7286, Training Accuracy= 0.502\n",
      "Epoch: 1730, Loss= 0.7268, Training Accuracy= 0.502\n",
      "Epoch: 1740, Loss= 0.7252, Training Accuracy= 0.502\n",
      "Epoch: 1750, Loss= 0.7237, Training Accuracy= 0.502\n",
      "Epoch: 1760, Loss= 0.7223, Training Accuracy= 0.502\n",
      "Epoch: 1770, Loss= 0.7209, Training Accuracy= 0.502\n",
      "Epoch: 1780, Loss= 0.7194, Training Accuracy= 0.503\n",
      "Epoch: 1790, Loss= 0.7181, Training Accuracy= 0.503\n",
      "Epoch: 1800, Loss= 0.7169, Training Accuracy= 0.504\n",
      "Epoch: 1810, Loss= 0.7157, Training Accuracy= 0.504\n",
      "Epoch: 1820, Loss= 0.7148, Training Accuracy= 0.505\n",
      "Epoch: 1830, Loss= 0.7139, Training Accuracy= 0.506\n",
      "Epoch: 1840, Loss= 0.7130, Training Accuracy= 0.507\n",
      "Epoch: 1850, Loss= 0.7119, Training Accuracy= 0.510\n",
      "Epoch: 1860, Loss= 0.7108, Training Accuracy= 0.513\n",
      "Epoch: 1870, Loss= 0.7096, Training Accuracy= 0.513\n",
      "Epoch: 1880, Loss= 0.7083, Training Accuracy= 0.515\n",
      "Epoch: 1890, Loss= 0.7069, Training Accuracy= 0.517\n",
      "Epoch: 1900, Loss= 0.7054, Training Accuracy= 0.519\n",
      "Epoch: 1910, Loss= 0.7033, Training Accuracy= 0.524\n",
      "Epoch: 1920, Loss= 0.7011, Training Accuracy= 0.527\n",
      "Epoch: 1930, Loss= 0.6995, Training Accuracy= 0.527\n",
      "Epoch: 1940, Loss= 0.6978, Training Accuracy= 0.533\n",
      "Epoch: 1950, Loss= 0.6953, Training Accuracy= 0.537\n",
      "Epoch: 1960, Loss= 0.6927, Training Accuracy= 0.542\n",
      "Epoch: 1970, Loss= 0.6894, Training Accuracy= 0.545\n",
      "Epoch: 1980, Loss= 0.6864, Training Accuracy= 0.554\n",
      "Epoch: 1990, Loss= 0.6835, Training Accuracy= 0.555\n",
      "Epoch: 2000, Loss= 0.6806, Training Accuracy= 0.563\n",
      "Epoch: 2010, Loss= 0.6775, Training Accuracy= 0.565\n",
      "Epoch: 2020, Loss= 0.6768, Training Accuracy= 0.569\n",
      "Epoch: 2030, Loss= 0.6744, Training Accuracy= 0.575\n",
      "Epoch: 2040, Loss= 0.6750, Training Accuracy= 0.572\n",
      "Epoch: 2050, Loss= 0.6669, Training Accuracy= 0.584\n",
      "Epoch: 2060, Loss= 0.6892, Training Accuracy= 0.562\n",
      "Epoch: 2070, Loss= 0.6905, Training Accuracy= 0.559\n",
      "Epoch: 2080, Loss= 0.6630, Training Accuracy= 0.590\n",
      "Epoch: 2090, Loss= 0.6918, Training Accuracy= 0.568\n",
      "Epoch: 2100, Loss= 0.6594, Training Accuracy= 0.592\n",
      "Epoch: 2110, Loss= 0.6576, Training Accuracy= 0.594\n",
      "Epoch: 2120, Loss= 0.6642, Training Accuracy= 0.589\n",
      "Epoch: 2130, Loss= 0.6741, Training Accuracy= 0.583\n",
      "Epoch: 2140, Loss= 0.6582, Training Accuracy= 0.602\n",
      "Epoch: 2150, Loss= 0.6654, Training Accuracy= 0.590\n",
      "Epoch: 2160, Loss= 0.6551, Training Accuracy= 0.608\n",
      "Epoch: 2170, Loss= 0.6951, Training Accuracy= 0.568\n",
      "Epoch: 2180, Loss= 0.6918, Training Accuracy= 0.580\n",
      "Epoch: 2190, Loss= 0.6518, Training Accuracy= 0.611\n",
      "Epoch: 2200, Loss= 0.6549, Training Accuracy= 0.611\n",
      "Epoch: 2210, Loss= 0.6396, Training Accuracy= 0.619\n",
      "Epoch: 2220, Loss= 0.6365, Training Accuracy= 0.625\n",
      "Epoch: 2230, Loss= 0.6619, Training Accuracy= 0.602\n",
      "Epoch: 2240, Loss= 0.6451, Training Accuracy= 0.621\n",
      "Epoch: 2250, Loss= 0.6355, Training Accuracy= 0.625\n",
      "Epoch: 2260, Loss= 0.6425, Training Accuracy= 0.619\n",
      "Epoch: 2270, Loss= 0.6620, Training Accuracy= 0.607\n",
      "Epoch: 2280, Loss= 0.6547, Training Accuracy= 0.610\n",
      "Epoch: 2290, Loss= 0.6520, Training Accuracy= 0.618\n",
      "Epoch: 2300, Loss= 0.6244, Training Accuracy= 0.641\n",
      "Epoch: 2310, Loss= 0.6271, Training Accuracy= 0.631\n",
      "Epoch: 2320, Loss= 0.6371, Training Accuracy= 0.625\n",
      "Epoch: 2330, Loss= 0.6159, Training Accuracy= 0.649\n",
      "Epoch: 2340, Loss= 0.6202, Training Accuracy= 0.644\n",
      "Epoch: 2350, Loss= 0.6688, Training Accuracy= 0.605\n",
      "Epoch: 2360, Loss= 0.6378, Training Accuracy= 0.630\n",
      "Epoch: 2370, Loss= 0.6538, Training Accuracy= 0.611\n",
      "Epoch: 2380, Loss= 0.6045, Training Accuracy= 0.658\n",
      "Epoch: 2390, Loss= 0.6108, Training Accuracy= 0.650\n",
      "Epoch: 2400, Loss= 0.6198, Training Accuracy= 0.647\n",
      "Epoch: 2410, Loss= 0.6001, Training Accuracy= 0.661\n",
      "Epoch: 2420, Loss= 0.6117, Training Accuracy= 0.654\n",
      "Epoch: 2430, Loss= 0.6856, Training Accuracy= 0.557\n",
      "Epoch: 2440, Loss= 0.6833, Training Accuracy= 0.567\n",
      "Epoch: 2450, Loss= 0.5938, Training Accuracy= 0.672\n",
      "Epoch: 2460, Loss= 0.5333, Training Accuracy= 0.720\n",
      "Epoch: 2470, Loss= 0.4369, Training Accuracy= 0.781\n",
      "Epoch: 2480, Loss= 0.4150, Training Accuracy= 0.820\n",
      "Epoch: 2490, Loss= 0.9451, Training Accuracy= 0.502\n",
      "Epoch: 2500, Loss= 0.9608, Training Accuracy= 0.502\n",
      "Epoch: 2510, Loss= 0.9474, Training Accuracy= 0.502\n",
      "Epoch: 2520, Loss= 0.9254, Training Accuracy= 0.502\n",
      "Epoch: 2530, Loss= 0.9151, Training Accuracy= 0.502\n",
      "Epoch: 2540, Loss= 0.9097, Training Accuracy= 0.502\n",
      "Epoch: 2550, Loss= 0.9053, Training Accuracy= 0.502\n",
      "Epoch: 2560, Loss= 0.9016, Training Accuracy= 0.502\n",
      "Epoch: 2570, Loss= 0.8981, Training Accuracy= 0.502\n",
      "Epoch: 2580, Loss= 0.8951, Training Accuracy= 0.502\n",
      "Epoch: 2590, Loss= 0.8911, Training Accuracy= 0.502\n",
      "Epoch: 2600, Loss= 0.8868, Training Accuracy= 0.502\n",
      "Epoch: 2610, Loss= 0.8817, Training Accuracy= 0.502\n",
      "Epoch: 2620, Loss= 0.8763, Training Accuracy= 0.502\n",
      "Epoch: 2630, Loss= 0.8684, Training Accuracy= 0.502\n",
      "Epoch: 2640, Loss= 0.8634, Training Accuracy= 0.502\n",
      "Epoch: 2650, Loss= 0.8570, Training Accuracy= 0.502\n",
      "Epoch: 2660, Loss= 0.8510, Training Accuracy= 0.502\n",
      "Epoch: 2670, Loss= 0.8468, Training Accuracy= 0.502\n",
      "Epoch: 2680, Loss= 0.8446, Training Accuracy= 0.502\n",
      "Epoch: 2690, Loss= 0.8431, Training Accuracy= 0.502\n",
      "Epoch: 2700, Loss= 0.8415, Training Accuracy= 0.502\n",
      "Epoch: 2710, Loss= 0.8399, Training Accuracy= 0.502\n",
      "Epoch: 2720, Loss= 0.8398, Training Accuracy= 0.502\n",
      "Epoch: 2730, Loss= 0.8362, Training Accuracy= 0.502\n",
      "Epoch: 2740, Loss= 0.8344, Training Accuracy= 0.502\n",
      "Epoch: 2750, Loss= 0.8334, Training Accuracy= 0.502\n",
      "Epoch: 2760, Loss= 0.8328, Training Accuracy= 0.502\n",
      "Epoch: 2770, Loss= 0.8322, Training Accuracy= 0.502\n",
      "Epoch: 2780, Loss= 0.8316, Training Accuracy= 0.502\n",
      "Epoch: 2790, Loss= 0.8310, Training Accuracy= 0.502\n",
      "Epoch: 2800, Loss= 0.8305, Training Accuracy= 0.502\n",
      "Epoch: 2810, Loss= 0.8299, Training Accuracy= 0.502\n",
      "Epoch: 2820, Loss= 0.8294, Training Accuracy= 0.502\n",
      "Epoch: 2830, Loss= 0.8290, Training Accuracy= 0.502\n",
      "Epoch: 2840, Loss= 0.8285, Training Accuracy= 0.502\n",
      "Epoch: 2850, Loss= 0.8280, Training Accuracy= 0.502\n",
      "Epoch: 2860, Loss= 0.8275, Training Accuracy= 0.502\n",
      "Epoch: 2870, Loss= 0.8270, Training Accuracy= 0.502\n",
      "Epoch: 2880, Loss= 0.8265, Training Accuracy= 0.502\n",
      "Epoch: 2890, Loss= 0.8259, Training Accuracy= 0.502\n",
      "Epoch: 2900, Loss= 0.8254, Training Accuracy= 0.502\n",
      "Epoch: 2910, Loss= 0.8249, Training Accuracy= 0.502\n",
      "Epoch: 2920, Loss= 0.8244, Training Accuracy= 0.502\n",
      "Epoch: 2930, Loss= 0.8239, Training Accuracy= 0.502\n",
      "Epoch: 2940, Loss= 0.8236, Training Accuracy= 0.502\n",
      "Epoch: 2950, Loss= 0.8239, Training Accuracy= 0.502\n",
      "Epoch: 2960, Loss= 0.8238, Training Accuracy= 0.502\n",
      "Epoch: 2970, Loss= 0.8229, Training Accuracy= 0.502\n",
      "Epoch: 2980, Loss= 0.8220, Training Accuracy= 0.502\n",
      "Epoch: 2990, Loss= 0.8212, Training Accuracy= 0.502\n",
      "Epoch: 3000, Loss= 0.8207, Training Accuracy= 0.502\n",
      "Epoch: 3010, Loss= 0.8202, Training Accuracy= 0.502\n",
      "Epoch: 3020, Loss= 0.8200, Training Accuracy= 0.502\n",
      "Epoch: 3030, Loss= 0.8193, Training Accuracy= 0.502\n",
      "Epoch: 3040, Loss= 0.8186, Training Accuracy= 0.502\n",
      "Epoch: 3050, Loss= 0.8192, Training Accuracy= 0.502\n",
      "Epoch: 3060, Loss= 0.8185, Training Accuracy= 0.502\n",
      "Epoch: 3070, Loss= 0.8178, Training Accuracy= 0.503\n",
      "Epoch: 3080, Loss= 0.8185, Training Accuracy= 0.503\n",
      "Epoch: 3090, Loss= 0.8185, Training Accuracy= 0.503\n",
      "Epoch: 3100, Loss= 0.8163, Training Accuracy= 0.503\n",
      "Epoch: 3110, Loss= 0.8178, Training Accuracy= 0.503\n",
      "Epoch: 3120, Loss= 0.8659, Training Accuracy= 0.502\n",
      "Epoch: 3130, Loss= 0.8105, Training Accuracy= 0.537\n",
      "Epoch: 3140, Loss= 0.8294, Training Accuracy= 0.534\n",
      "Epoch: 3150, Loss= 0.8041, Training Accuracy= 0.545\n",
      "Epoch: 3160, Loss= 0.7260, Training Accuracy= 0.577\n",
      "Epoch: 3170, Loss= 0.6496, Training Accuracy= 0.621\n",
      "Epoch: 3180, Loss= 0.6203, Training Accuracy= 0.655\n",
      "Epoch: 3190, Loss= 0.6010, Training Accuracy= 0.661\n",
      "Epoch: 3200, Loss= 0.5702, Training Accuracy= 0.684\n",
      "Epoch: 3210, Loss= 0.7056, Training Accuracy= 0.677\n",
      "Epoch: 3220, Loss= 0.9491, Training Accuracy= 0.502\n",
      "Epoch: 3230, Loss= 0.9233, Training Accuracy= 0.502\n",
      "Epoch: 3240, Loss= 0.9218, Training Accuracy= 0.502\n",
      "Epoch: 3250, Loss= 0.9213, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3260, Loss= 0.9210, Training Accuracy= 0.502\n",
      "Epoch: 3270, Loss= 0.9208, Training Accuracy= 0.502\n",
      "Epoch: 3280, Loss= 0.9206, Training Accuracy= 0.502\n",
      "Epoch: 3290, Loss= 0.9205, Training Accuracy= 0.502\n",
      "Epoch: 3300, Loss= 0.9204, Training Accuracy= 0.502\n",
      "Epoch: 3310, Loss= 0.9203, Training Accuracy= 0.502\n",
      "Epoch: 3320, Loss= 0.9203, Training Accuracy= 0.502\n",
      "Epoch: 3330, Loss= 0.9202, Training Accuracy= 0.502\n",
      "Epoch: 3340, Loss= 0.9202, Training Accuracy= 0.502\n",
      "Epoch: 3350, Loss= 0.9201, Training Accuracy= 0.502\n",
      "Epoch: 3360, Loss= 0.9201, Training Accuracy= 0.502\n",
      "Epoch: 3370, Loss= 0.9201, Training Accuracy= 0.502\n",
      "Epoch: 3380, Loss= 0.9200, Training Accuracy= 0.502\n",
      "Epoch: 3390, Loss= 0.9200, Training Accuracy= 0.502\n",
      "Epoch: 3400, Loss= 0.9200, Training Accuracy= 0.502\n",
      "Epoch: 3410, Loss= 0.9200, Training Accuracy= 0.502\n",
      "Epoch: 3420, Loss= 0.9199, Training Accuracy= 0.502\n",
      "Epoch: 3430, Loss= 0.9199, Training Accuracy= 0.502\n",
      "Epoch: 3440, Loss= 0.9199, Training Accuracy= 0.502\n",
      "Epoch: 3450, Loss= 0.9199, Training Accuracy= 0.502\n",
      "Epoch: 3460, Loss= 0.9199, Training Accuracy= 0.502\n",
      "Epoch: 3470, Loss= 0.9199, Training Accuracy= 0.502\n",
      "Epoch: 3480, Loss= 0.9198, Training Accuracy= 0.502\n",
      "Epoch: 3490, Loss= 0.9198, Training Accuracy= 0.502\n",
      "Epoch: 3500, Loss= 0.9198, Training Accuracy= 0.502\n",
      "Epoch: 3510, Loss= 0.9198, Training Accuracy= 0.502\n",
      "Epoch: 3520, Loss= 0.9198, Training Accuracy= 0.502\n",
      "Epoch: 3530, Loss= 0.9198, Training Accuracy= 0.502\n",
      "Epoch: 3540, Loss= 0.9198, Training Accuracy= 0.502\n",
      "Epoch: 3550, Loss= 0.9198, Training Accuracy= 0.502\n",
      "Epoch: 3560, Loss= 0.9198, Training Accuracy= 0.502\n",
      "Epoch: 3570, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3580, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3590, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3600, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3610, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3620, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3630, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3640, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3650, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3660, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3670, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3680, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3690, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3700, Loss= 0.9197, Training Accuracy= 0.502\n",
      "Epoch: 3710, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3720, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3730, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3740, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3750, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3760, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3770, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3780, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3790, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3800, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3810, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3820, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3830, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3840, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3850, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3860, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3870, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3880, Loss= 0.9196, Training Accuracy= 0.502\n",
      "Epoch: 3890, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 3900, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 3910, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 3920, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 3930, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 3940, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 3950, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 3960, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 3970, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 3980, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 3990, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 4000, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 4010, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 4020, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 4030, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 4040, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 4050, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 4060, Loss= 0.9195, Training Accuracy= 0.502\n",
      "Epoch: 4070, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4080, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4090, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4100, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4110, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4120, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4130, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4140, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4150, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4160, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4170, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4180, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4190, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4200, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4210, Loss= 0.9194, Training Accuracy= 0.502\n",
      "Epoch: 4220, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4230, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4240, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4250, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4260, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4270, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4280, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4290, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4300, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4310, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4320, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4330, Loss= 0.9193, Training Accuracy= 0.502\n",
      "Epoch: 4340, Loss= 0.9192, Training Accuracy= 0.502\n",
      "Epoch: 4350, Loss= 0.9192, Training Accuracy= 0.502\n",
      "Epoch: 4360, Loss= 0.9192, Training Accuracy= 0.502\n",
      "Epoch: 4370, Loss= 0.9192, Training Accuracy= 0.502\n",
      "Epoch: 4380, Loss= 0.9192, Training Accuracy= 0.502\n",
      "Epoch: 4390, Loss= 0.9192, Training Accuracy= 0.502\n",
      "Epoch: 4400, Loss= 0.9192, Training Accuracy= 0.502\n",
      "Epoch: 4410, Loss= 0.9192, Training Accuracy= 0.502\n",
      "Epoch: 4420, Loss= 0.9192, Training Accuracy= 0.502\n",
      "Epoch: 4430, Loss= 0.9192, Training Accuracy= 0.502\n",
      "Epoch: 4440, Loss= 0.9191, Training Accuracy= 0.502\n",
      "Epoch: 4450, Loss= 0.9191, Training Accuracy= 0.502\n",
      "Epoch: 4460, Loss= 0.9191, Training Accuracy= 0.502\n",
      "Epoch: 4470, Loss= 0.9191, Training Accuracy= 0.502\n",
      "Epoch: 4480, Loss= 0.9191, Training Accuracy= 0.502\n",
      "Epoch: 4490, Loss= 0.9191, Training Accuracy= 0.502\n",
      "Epoch: 4500, Loss= 0.9191, Training Accuracy= 0.502\n",
      "Epoch: 4510, Loss= 0.9191, Training Accuracy= 0.502\n",
      "Epoch: 4520, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4530, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4540, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4550, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4560, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4570, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4580, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4590, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4600, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4610, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4620, Loss= 0.9189, Training Accuracy= 0.502\n",
      "Epoch: 4630, Loss= 0.9189, Training Accuracy= 0.502\n",
      "Epoch: 4640, Loss= 0.9189, Training Accuracy= 0.502\n",
      "Epoch: 4650, Loss= 0.9200, Training Accuracy= 0.502\n",
      "Epoch: 4660, Loss= 0.9191, Training Accuracy= 0.502\n",
      "Epoch: 4670, Loss= 0.9190, Training Accuracy= 0.502\n",
      "Epoch: 4680, Loss= 0.9189, Training Accuracy= 0.502\n",
      "Epoch: 4690, Loss= 0.9189, Training Accuracy= 0.502\n",
      "Epoch: 4700, Loss= 0.9188, Training Accuracy= 0.502\n",
      "Epoch: 4710, Loss= 0.9188, Training Accuracy= 0.502\n",
      "Epoch: 4720, Loss= 0.9188, Training Accuracy= 0.502\n",
      "Epoch: 4730, Loss= 0.9187, Training Accuracy= 0.502\n",
      "Epoch: 4740, Loss= 0.9187, Training Accuracy= 0.502\n",
      "Epoch: 4750, Loss= 0.9187, Training Accuracy= 0.502\n",
      "Epoch: 4760, Loss= 0.9187, Training Accuracy= 0.502\n",
      "Epoch: 4770, Loss= 0.9186, Training Accuracy= 0.502\n",
      "Epoch: 4780, Loss= 0.9186, Training Accuracy= 0.502\n",
      "Epoch: 4790, Loss= 0.9186, Training Accuracy= 0.502\n",
      "Epoch: 4800, Loss= 0.9186, Training Accuracy= 0.502\n",
      "Epoch: 4810, Loss= 0.9186, Training Accuracy= 0.502\n",
      "Epoch: 4820, Loss= 0.9186, Training Accuracy= 0.502\n",
      "Epoch: 4830, Loss= 0.9185, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4840, Loss= 0.9185, Training Accuracy= 0.502\n",
      "Epoch: 4850, Loss= 0.9185, Training Accuracy= 0.502\n",
      "Epoch: 4860, Loss= 0.9185, Training Accuracy= 0.502\n",
      "Epoch: 4870, Loss= 0.9185, Training Accuracy= 0.502\n",
      "Epoch: 4880, Loss= 0.9185, Training Accuracy= 0.502\n",
      "Epoch: 4890, Loss= 0.9184, Training Accuracy= 0.502\n",
      "Epoch: 4900, Loss= 0.9184, Training Accuracy= 0.502\n",
      "Epoch: 4910, Loss= 0.9184, Training Accuracy= 0.502\n",
      "Epoch: 4920, Loss= 0.9184, Training Accuracy= 0.502\n",
      "Epoch: 4930, Loss= 0.9184, Training Accuracy= 0.502\n",
      "Epoch: 4940, Loss= 0.9184, Training Accuracy= 0.502\n",
      "Epoch: 4950, Loss= 0.9184, Training Accuracy= 0.502\n",
      "Epoch: 4960, Loss= 0.9183, Training Accuracy= 0.502\n",
      "Epoch: 4970, Loss= 0.9183, Training Accuracy= 0.502\n",
      "Epoch: 4980, Loss= 0.9183, Training Accuracy= 0.502\n",
      "Epoch: 4990, Loss= 0.9183, Training Accuracy= 0.502\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5005\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 0.7649, Training Accuracy= 0.506\n",
      "Epoch: 10, Loss= 0.7341, Training Accuracy= 0.506\n",
      "Epoch: 20, Loss= 0.7228, Training Accuracy= 0.506\n",
      "Epoch: 30, Loss= 0.7170, Training Accuracy= 0.506\n",
      "Epoch: 40, Loss= 0.7134, Training Accuracy= 0.506\n",
      "Epoch: 50, Loss= 0.7110, Training Accuracy= 0.506\n",
      "Epoch: 60, Loss= 0.7093, Training Accuracy= 0.506\n",
      "Epoch: 70, Loss= 0.7080, Training Accuracy= 0.506\n",
      "Epoch: 80, Loss= 0.7069, Training Accuracy= 0.506\n",
      "Epoch: 90, Loss= 0.7061, Training Accuracy= 0.506\n",
      "Epoch: 100, Loss= 0.7053, Training Accuracy= 0.506\n",
      "Epoch: 110, Loss= 0.7047, Training Accuracy= 0.506\n",
      "Epoch: 120, Loss= 0.7041, Training Accuracy= 0.506\n",
      "Epoch: 130, Loss= 0.7036, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.7032, Training Accuracy= 0.506\n",
      "Epoch: 150, Loss= 0.7028, Training Accuracy= 0.506\n",
      "Epoch: 160, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 170, Loss= 0.7022, Training Accuracy= 0.506\n",
      "Epoch: 180, Loss= 0.7020, Training Accuracy= 0.506\n",
      "Epoch: 190, Loss= 0.7018, Training Accuracy= 0.506\n",
      "Epoch: 200, Loss= 0.7016, Training Accuracy= 0.506\n",
      "Epoch: 210, Loss= 0.7014, Training Accuracy= 0.507\n",
      "Epoch: 220, Loss= 0.7012, Training Accuracy= 0.508\n",
      "Epoch: 230, Loss= 0.7010, Training Accuracy= 0.509\n",
      "Epoch: 240, Loss= 0.7009, Training Accuracy= 0.508\n",
      "Epoch: 250, Loss= 0.7008, Training Accuracy= 0.509\n",
      "Epoch: 260, Loss= 0.7007, Training Accuracy= 0.509\n",
      "Epoch: 270, Loss= 0.7006, Training Accuracy= 0.512\n",
      "Epoch: 280, Loss= 0.7002, Training Accuracy= 0.513\n",
      "Epoch: 290, Loss= 0.7000, Training Accuracy= 0.515\n",
      "Epoch: 300, Loss= 0.6999, Training Accuracy= 0.516\n",
      "Epoch: 310, Loss= 0.6997, Training Accuracy= 0.517\n",
      "Epoch: 320, Loss= 0.6995, Training Accuracy= 0.516\n",
      "Epoch: 330, Loss= 0.6995, Training Accuracy= 0.519\n",
      "Epoch: 340, Loss= 0.6994, Training Accuracy= 0.520\n",
      "Epoch: 350, Loss= 0.6993, Training Accuracy= 0.518\n",
      "Epoch: 360, Loss= 0.6996, Training Accuracy= 0.518\n",
      "Epoch: 370, Loss= 0.7001, Training Accuracy= 0.518\n",
      "Epoch: 380, Loss= 0.7000, Training Accuracy= 0.518\n",
      "Epoch: 390, Loss= 0.6999, Training Accuracy= 0.519\n",
      "Epoch: 400, Loss= 0.7000, Training Accuracy= 0.519\n",
      "Epoch: 410, Loss= 0.7003, Training Accuracy= 0.521\n",
      "Epoch: 420, Loss= 0.7001, Training Accuracy= 0.513\n",
      "Epoch: 430, Loss= 0.6998, Training Accuracy= 0.522\n",
      "Epoch: 440, Loss= 0.6986, Training Accuracy= 0.525\n",
      "Epoch: 450, Loss= 0.6979, Training Accuracy= 0.526\n",
      "Epoch: 460, Loss= 0.6987, Training Accuracy= 0.528\n",
      "Epoch: 470, Loss= 0.6971, Training Accuracy= 0.533\n",
      "Epoch: 480, Loss= 0.6979, Training Accuracy= 0.527\n",
      "Epoch: 490, Loss= 0.6963, Training Accuracy= 0.535\n",
      "Epoch: 500, Loss= 0.6974, Training Accuracy= 0.533\n",
      "Epoch: 510, Loss= 0.6980, Training Accuracy= 0.530\n",
      "Epoch: 520, Loss= 0.7003, Training Accuracy= 0.529\n",
      "Epoch: 530, Loss= 0.6984, Training Accuracy= 0.535\n",
      "Epoch: 540, Loss= 0.7026, Training Accuracy= 0.535\n",
      "Epoch: 550, Loss= 0.7013, Training Accuracy= 0.536\n",
      "Epoch: 560, Loss= 0.7022, Training Accuracy= 0.540\n",
      "Epoch: 570, Loss= 0.6986, Training Accuracy= 0.543\n",
      "Epoch: 580, Loss= 0.7117, Training Accuracy= 0.526\n",
      "Epoch: 590, Loss= 0.7014, Training Accuracy= 0.546\n",
      "Epoch: 600, Loss= 0.7007, Training Accuracy= 0.551\n",
      "Epoch: 610, Loss= 0.7062, Training Accuracy= 0.541\n",
      "Epoch: 620, Loss= 0.7112, Training Accuracy= 0.544\n",
      "Epoch: 630, Loss= 0.7021, Training Accuracy= 0.559\n",
      "Epoch: 640, Loss= 0.7059, Training Accuracy= 0.549\n",
      "Epoch: 650, Loss= 0.6950, Training Accuracy= 0.562\n",
      "Epoch: 660, Loss= 0.6935, Training Accuracy= 0.562\n",
      "Epoch: 670, Loss= 0.6928, Training Accuracy= 0.572\n",
      "Epoch: 680, Loss= 0.6927, Training Accuracy= 0.568\n",
      "Epoch: 690, Loss= 0.7009, Training Accuracy= 0.571\n",
      "Epoch: 700, Loss= 0.7056, Training Accuracy= 0.565\n",
      "Epoch: 710, Loss= 0.6854, Training Accuracy= 0.584\n",
      "Epoch: 720, Loss= 0.6783, Training Accuracy= 0.592\n",
      "Epoch: 730, Loss= 0.6840, Training Accuracy= 0.588\n",
      "Epoch: 740, Loss= 0.6866, Training Accuracy= 0.582\n",
      "Epoch: 750, Loss= 0.6794, Training Accuracy= 0.595\n",
      "Epoch: 760, Loss= 0.6677, Training Accuracy= 0.607\n",
      "Epoch: 770, Loss= 0.6700, Training Accuracy= 0.602\n",
      "Epoch: 780, Loss= 0.6565, Training Accuracy= 0.617\n",
      "Epoch: 790, Loss= 0.7150, Training Accuracy= 0.584\n",
      "Epoch: 800, Loss= 0.6668, Training Accuracy= 0.610\n",
      "Epoch: 810, Loss= 0.6715, Training Accuracy= 0.608\n",
      "Epoch: 820, Loss= 0.6796, Training Accuracy= 0.603\n",
      "Epoch: 830, Loss= 0.6726, Training Accuracy= 0.613\n",
      "Epoch: 840, Loss= 0.7308, Training Accuracy= 0.570\n",
      "Epoch: 850, Loss= 0.7030, Training Accuracy= 0.589\n",
      "Epoch: 860, Loss= 0.7022, Training Accuracy= 0.588\n",
      "Epoch: 870, Loss= 0.6778, Training Accuracy= 0.604\n",
      "Epoch: 880, Loss= 0.6707, Training Accuracy= 0.611\n",
      "Epoch: 890, Loss= 0.6489, Training Accuracy= 0.635\n",
      "Epoch: 900, Loss= 0.6562, Training Accuracy= 0.627\n",
      "Epoch: 910, Loss= 0.6459, Training Accuracy= 0.633\n",
      "Epoch: 920, Loss= 0.6543, Training Accuracy= 0.623\n",
      "Epoch: 930, Loss= 0.6292, Training Accuracy= 0.640\n",
      "Epoch: 940, Loss= 0.6540, Training Accuracy= 0.630\n",
      "Epoch: 950, Loss= 0.6343, Training Accuracy= 0.646\n",
      "Epoch: 960, Loss= 0.6377, Training Accuracy= 0.640\n",
      "Epoch: 970, Loss= 0.6535, Training Accuracy= 0.631\n",
      "Epoch: 980, Loss= 0.6433, Training Accuracy= 0.637\n",
      "Epoch: 990, Loss= 0.6523, Training Accuracy= 0.628\n",
      "Epoch: 1000, Loss= 0.6588, Training Accuracy= 0.627\n",
      "Epoch: 1010, Loss= 0.6240, Training Accuracy= 0.653\n",
      "Epoch: 1020, Loss= 0.7310, Training Accuracy= 0.531\n",
      "Epoch: 1030, Loss= 0.6792, Training Accuracy= 0.569\n",
      "Epoch: 1040, Loss= 0.6209, Training Accuracy= 0.648\n",
      "Epoch: 1050, Loss= 0.6218, Training Accuracy= 0.654\n",
      "Epoch: 1060, Loss= 0.6329, Training Accuracy= 0.643\n",
      "Epoch: 1070, Loss= 0.6389, Training Accuracy= 0.639\n",
      "Epoch: 1080, Loss= 0.6321, Training Accuracy= 0.646\n",
      "Epoch: 1090, Loss= 0.6145, Training Accuracy= 0.663\n",
      "Epoch: 1100, Loss= 0.6268, Training Accuracy= 0.650\n",
      "Epoch: 1110, Loss= 0.6139, Training Accuracy= 0.658\n",
      "Epoch: 1120, Loss= 0.6178, Training Accuracy= 0.656\n",
      "Epoch: 1130, Loss= 0.6354, Training Accuracy= 0.641\n",
      "Epoch: 1140, Loss= 0.6015, Training Accuracy= 0.673\n",
      "Epoch: 1150, Loss= 0.6520, Training Accuracy= 0.621\n",
      "Epoch: 1160, Loss= 0.6384, Training Accuracy= 0.633\n",
      "Epoch: 1170, Loss= 0.6368, Training Accuracy= 0.646\n",
      "Epoch: 1180, Loss= 0.6562, Training Accuracy= 0.623\n",
      "Epoch: 1190, Loss= 0.6182, Training Accuracy= 0.654\n",
      "Epoch: 1200, Loss= 0.6637, Training Accuracy= 0.596\n",
      "Epoch: 1210, Loss= 0.6077, Training Accuracy= 0.663\n",
      "Epoch: 1220, Loss= 0.6846, Training Accuracy= 0.553\n",
      "Epoch: 1230, Loss= 0.6621, Training Accuracy= 0.593\n",
      "Epoch: 1240, Loss= 0.6378, Training Accuracy= 0.631\n",
      "Epoch: 1250, Loss= 0.6206, Training Accuracy= 0.652\n",
      "Epoch: 1260, Loss= 0.6142, Training Accuracy= 0.664\n",
      "Epoch: 1270, Loss= 0.6123, Training Accuracy= 0.663\n",
      "Epoch: 1280, Loss= 0.5983, Training Accuracy= 0.671\n",
      "Epoch: 1290, Loss= 0.6101, Training Accuracy= 0.668\n",
      "Epoch: 1300, Loss= 0.5987, Training Accuracy= 0.676\n",
      "Epoch: 1310, Loss= 0.5983, Training Accuracy= 0.675\n",
      "Epoch: 1320, Loss= 0.6360, Training Accuracy= 0.630\n",
      "Epoch: 1330, Loss= 0.5859, Training Accuracy= 0.687\n",
      "Epoch: 1340, Loss= 0.6178, Training Accuracy= 0.662\n",
      "Epoch: 1350, Loss= 0.5798, Training Accuracy= 0.689\n",
      "Epoch: 1360, Loss= 0.6005, Training Accuracy= 0.678\n",
      "Epoch: 1370, Loss= 0.6292, Training Accuracy= 0.652\n",
      "Epoch: 1380, Loss= 0.6539, Training Accuracy= 0.626\n",
      "Epoch: 1390, Loss= 0.5889, Training Accuracy= 0.680\n",
      "Epoch: 1400, Loss= 0.5801, Training Accuracy= 0.692\n",
      "Epoch: 1410, Loss= 0.6243, Training Accuracy= 0.654\n",
      "Epoch: 1420, Loss= 0.6085, Training Accuracy= 0.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1430, Loss= 0.5979, Training Accuracy= 0.678\n",
      "Epoch: 1440, Loss= 0.6442, Training Accuracy= 0.633\n",
      "Epoch: 1450, Loss= 0.6138, Training Accuracy= 0.666\n",
      "Epoch: 1460, Loss= 0.6341, Training Accuracy= 0.639\n",
      "Epoch: 1470, Loss= 0.5876, Training Accuracy= 0.684\n",
      "Epoch: 1480, Loss= 0.5824, Training Accuracy= 0.688\n",
      "Epoch: 1490, Loss= 0.6101, Training Accuracy= 0.665\n",
      "Epoch: 1500, Loss= 0.5869, Training Accuracy= 0.682\n",
      "Epoch: 1510, Loss= 0.5794, Training Accuracy= 0.690\n",
      "Epoch: 1520, Loss= 0.7197, Training Accuracy= 0.540\n",
      "Epoch: 1530, Loss= 0.6333, Training Accuracy= 0.634\n",
      "Epoch: 1540, Loss= 0.5829, Training Accuracy= 0.687\n",
      "Epoch: 1550, Loss= 0.5972, Training Accuracy= 0.678\n",
      "Epoch: 1560, Loss= 0.6059, Training Accuracy= 0.671\n",
      "Epoch: 1570, Loss= 0.5838, Training Accuracy= 0.687\n",
      "Epoch: 1580, Loss= 0.5916, Training Accuracy= 0.678\n",
      "Epoch: 1590, Loss= 0.5876, Training Accuracy= 0.686\n",
      "Epoch: 1600, Loss= 0.5903, Training Accuracy= 0.687\n",
      "Epoch: 1610, Loss= 0.6256, Training Accuracy= 0.655\n",
      "Epoch: 1620, Loss= 0.5658, Training Accuracy= 0.703\n",
      "Epoch: 1630, Loss= 0.5698, Training Accuracy= 0.700\n",
      "Epoch: 1640, Loss= 0.6294, Training Accuracy= 0.649\n",
      "Epoch: 1650, Loss= 0.6201, Training Accuracy= 0.661\n",
      "Epoch: 1660, Loss= 0.6068, Training Accuracy= 0.664\n",
      "Epoch: 1670, Loss= 0.5902, Training Accuracy= 0.686\n",
      "Epoch: 1680, Loss= 0.5960, Training Accuracy= 0.676\n",
      "Epoch: 1690, Loss= 0.5960, Training Accuracy= 0.680\n",
      "Epoch: 1700, Loss= 0.5806, Training Accuracy= 0.695\n",
      "Epoch: 1710, Loss= 0.5643, Training Accuracy= 0.706\n",
      "Epoch: 1720, Loss= 0.5949, Training Accuracy= 0.682\n",
      "Epoch: 1730, Loss= 0.5890, Training Accuracy= 0.686\n",
      "Epoch: 1740, Loss= 0.5549, Training Accuracy= 0.711\n",
      "Epoch: 1750, Loss= 0.6032, Training Accuracy= 0.668\n",
      "Epoch: 1760, Loss= 0.5669, Training Accuracy= 0.704\n",
      "Epoch: 1770, Loss= 0.5820, Training Accuracy= 0.689\n",
      "Epoch: 1780, Loss= 0.6108, Training Accuracy= 0.669\n",
      "Epoch: 1790, Loss= 0.6007, Training Accuracy= 0.678\n",
      "Epoch: 1800, Loss= 0.6063, Training Accuracy= 0.672\n",
      "Epoch: 1810, Loss= 0.5810, Training Accuracy= 0.691\n",
      "Epoch: 1820, Loss= 0.5789, Training Accuracy= 0.695\n",
      "Epoch: 1830, Loss= 0.5910, Training Accuracy= 0.681\n",
      "Epoch: 1840, Loss= 0.5757, Training Accuracy= 0.693\n",
      "Epoch: 1850, Loss= 0.5842, Training Accuracy= 0.690\n",
      "Epoch: 1860, Loss= 0.5841, Training Accuracy= 0.696\n",
      "Epoch: 1870, Loss= 0.5764, Training Accuracy= 0.698\n",
      "Epoch: 1880, Loss= 0.5866, Training Accuracy= 0.688\n",
      "Epoch: 1890, Loss= 0.5664, Training Accuracy= 0.707\n",
      "Epoch: 1900, Loss= 0.5471, Training Accuracy= 0.721\n",
      "Epoch: 1910, Loss= 0.6325, Training Accuracy= 0.651\n",
      "Epoch: 1920, Loss= 0.5815, Training Accuracy= 0.692\n",
      "Epoch: 1930, Loss= 0.5973, Training Accuracy= 0.676\n",
      "Epoch: 1940, Loss= 0.5498, Training Accuracy= 0.720\n",
      "Epoch: 1950, Loss= 0.5677, Training Accuracy= 0.700\n",
      "Epoch: 1960, Loss= 0.7012, Training Accuracy= 0.517\n",
      "Epoch: 1970, Loss= 0.6962, Training Accuracy= 0.535\n",
      "Epoch: 1980, Loss= 0.6874, Training Accuracy= 0.551\n",
      "Epoch: 1990, Loss= 0.6876, Training Accuracy= 0.551\n",
      "Epoch: 2000, Loss= 0.6849, Training Accuracy= 0.555\n",
      "Epoch: 2010, Loss= 0.6723, Training Accuracy= 0.578\n",
      "Epoch: 2020, Loss= 0.6618, Training Accuracy= 0.596\n",
      "Epoch: 2030, Loss= 0.6707, Training Accuracy= 0.589\n",
      "Epoch: 2040, Loss= 0.6540, Training Accuracy= 0.607\n",
      "Epoch: 2050, Loss= 0.6720, Training Accuracy= 0.579\n",
      "Epoch: 2060, Loss= 0.6981, Training Accuracy= 0.543\n",
      "Epoch: 2070, Loss= 0.6604, Training Accuracy= 0.603\n",
      "Epoch: 2080, Loss= 0.6557, Training Accuracy= 0.602\n",
      "Epoch: 2090, Loss= 0.6476, Training Accuracy= 0.619\n",
      "Epoch: 2100, Loss= 0.6526, Training Accuracy= 0.611\n",
      "Epoch: 2110, Loss= 0.6408, Training Accuracy= 0.622\n",
      "Epoch: 2120, Loss= 0.6731, Training Accuracy= 0.586\n",
      "Epoch: 2130, Loss= 0.6362, Training Accuracy= 0.632\n",
      "Epoch: 2140, Loss= 0.6350, Training Accuracy= 0.635\n",
      "Epoch: 2150, Loss= 0.6329, Training Accuracy= 0.633\n",
      "Epoch: 2160, Loss= 0.7022, Training Accuracy= 0.535\n",
      "Epoch: 2170, Loss= 0.6831, Training Accuracy= 0.561\n",
      "Epoch: 2180, Loss= 0.6974, Training Accuracy= 0.540\n",
      "Epoch: 2190, Loss= 0.6710, Training Accuracy= 0.586\n",
      "Epoch: 2200, Loss= 0.6693, Training Accuracy= 0.589\n",
      "Epoch: 2210, Loss= 0.6547, Training Accuracy= 0.605\n",
      "Epoch: 2220, Loss= 0.6501, Training Accuracy= 0.607\n",
      "Epoch: 2230, Loss= 0.6712, Training Accuracy= 0.583\n",
      "Epoch: 2240, Loss= 0.6504, Training Accuracy= 0.611\n",
      "Epoch: 2250, Loss= 0.6435, Training Accuracy= 0.623\n",
      "Epoch: 2260, Loss= 0.6390, Training Accuracy= 0.626\n",
      "Epoch: 2270, Loss= 0.6171, Training Accuracy= 0.655\n",
      "Epoch: 2280, Loss= 0.6417, Training Accuracy= 0.627\n",
      "Epoch: 2290, Loss= 0.7057, Training Accuracy= 0.527\n",
      "Epoch: 2300, Loss= 0.6912, Training Accuracy= 0.547\n",
      "Epoch: 2310, Loss= 0.6951, Training Accuracy= 0.548\n",
      "Epoch: 2320, Loss= 0.6751, Training Accuracy= 0.579\n",
      "Epoch: 2330, Loss= 0.6804, Training Accuracy= 0.570\n",
      "Epoch: 2340, Loss= 0.6754, Training Accuracy= 0.572\n",
      "Epoch: 2350, Loss= 0.6831, Training Accuracy= 0.573\n",
      "Epoch: 2360, Loss= 0.6705, Training Accuracy= 0.583\n",
      "Epoch: 2370, Loss= 0.6708, Training Accuracy= 0.587\n",
      "Epoch: 2380, Loss= 0.6540, Training Accuracy= 0.608\n",
      "Epoch: 2390, Loss= 0.6569, Training Accuracy= 0.604\n",
      "Epoch: 2400, Loss= 0.6488, Training Accuracy= 0.611\n",
      "Epoch: 2410, Loss= 0.6859, Training Accuracy= 0.556\n",
      "Epoch: 2420, Loss= 0.6574, Training Accuracy= 0.603\n",
      "Epoch: 2430, Loss= 0.6485, Training Accuracy= 0.612\n",
      "Epoch: 2440, Loss= 0.6397, Training Accuracy= 0.623\n",
      "Epoch: 2450, Loss= 0.6503, Training Accuracy= 0.613\n",
      "Epoch: 2460, Loss= 0.6328, Training Accuracy= 0.632\n",
      "Epoch: 2470, Loss= 0.6416, Training Accuracy= 0.625\n",
      "Epoch: 2480, Loss= 0.6433, Training Accuracy= 0.628\n",
      "Epoch: 2490, Loss= 0.6259, Training Accuracy= 0.649\n",
      "Epoch: 2500, Loss= 0.6211, Training Accuracy= 0.648\n",
      "Epoch: 2510, Loss= 0.6114, Training Accuracy= 0.656\n",
      "Epoch: 2520, Loss= 0.6373, Training Accuracy= 0.626\n",
      "Epoch: 2530, Loss= 0.6132, Training Accuracy= 0.659\n",
      "Epoch: 2540, Loss= 0.6118, Training Accuracy= 0.660\n",
      "Epoch: 2550, Loss= 0.6350, Training Accuracy= 0.636\n",
      "Epoch: 2560, Loss= 0.6071, Training Accuracy= 0.665\n",
      "Epoch: 2570, Loss= 0.6278, Training Accuracy= 0.640\n",
      "Epoch: 2580, Loss= 0.6863, Training Accuracy= 0.574\n",
      "Epoch: 2590, Loss= 0.6411, Training Accuracy= 0.634\n",
      "Epoch: 2600, Loss= 0.6943, Training Accuracy= 0.562\n",
      "Epoch: 2610, Loss= 0.6131, Training Accuracy= 0.659\n",
      "Epoch: 2620, Loss= 0.6214, Training Accuracy= 0.646\n",
      "Epoch: 2630, Loss= 0.6234, Training Accuracy= 0.648\n",
      "Epoch: 2640, Loss= 0.6374, Training Accuracy= 0.637\n",
      "Epoch: 2650, Loss= 0.6033, Training Accuracy= 0.674\n",
      "Epoch: 2660, Loss= 0.6204, Training Accuracy= 0.651\n",
      "Epoch: 2670, Loss= 0.6169, Training Accuracy= 0.657\n",
      "Epoch: 2680, Loss= 0.6305, Training Accuracy= 0.632\n",
      "Epoch: 2690, Loss= 0.6232, Training Accuracy= 0.646\n",
      "Epoch: 2700, Loss= 0.6187, Training Accuracy= 0.642\n",
      "Epoch: 2710, Loss= 0.6020, Training Accuracy= 0.668\n",
      "Epoch: 2720, Loss= 0.6293, Training Accuracy= 0.638\n",
      "Epoch: 2730, Loss= 0.6198, Training Accuracy= 0.652\n",
      "Epoch: 2740, Loss= 0.6104, Training Accuracy= 0.663\n",
      "Epoch: 2750, Loss= 0.5970, Training Accuracy= 0.677\n",
      "Epoch: 2760, Loss= 0.6119, Training Accuracy= 0.657\n",
      "Epoch: 2770, Loss= 0.5966, Training Accuracy= 0.672\n",
      "Epoch: 2780, Loss= 0.6232, Training Accuracy= 0.643\n",
      "Epoch: 2790, Loss= 0.6420, Training Accuracy= 0.631\n",
      "Epoch: 2800, Loss= 0.6177, Training Accuracy= 0.655\n",
      "Epoch: 2810, Loss= 0.7231, Training Accuracy= 0.515\n",
      "Epoch: 2820, Loss= 0.7003, Training Accuracy= 0.542\n",
      "Epoch: 2830, Loss= 0.6867, Training Accuracy= 0.556\n",
      "Epoch: 2840, Loss= 0.6737, Training Accuracy= 0.578\n",
      "Epoch: 2850, Loss= 0.6753, Training Accuracy= 0.579\n",
      "Epoch: 2860, Loss= 0.6540, Training Accuracy= 0.609\n",
      "Epoch: 2870, Loss= 0.6482, Training Accuracy= 0.614\n",
      "Epoch: 2880, Loss= 0.6455, Training Accuracy= 0.620\n",
      "Epoch: 2890, Loss= 0.6406, Training Accuracy= 0.625\n",
      "Epoch: 2900, Loss= 0.6521, Training Accuracy= 0.617\n",
      "Epoch: 2910, Loss= 0.6406, Training Accuracy= 0.626\n",
      "Epoch: 2920, Loss= 0.6248, Training Accuracy= 0.646\n",
      "Epoch: 2930, Loss= 0.6371, Training Accuracy= 0.635\n",
      "Epoch: 2940, Loss= 0.6146, Training Accuracy= 0.657\n",
      "Epoch: 2950, Loss= 0.6062, Training Accuracy= 0.661\n",
      "Epoch: 2960, Loss= 0.6169, Training Accuracy= 0.659\n",
      "Epoch: 2970, Loss= 0.6191, Training Accuracy= 0.651\n",
      "Epoch: 2980, Loss= 0.6069, Training Accuracy= 0.667\n",
      "Epoch: 2990, Loss= 0.6151, Training Accuracy= 0.657\n",
      "Epoch: 3000, Loss= 0.6019, Training Accuracy= 0.669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3010, Loss= 0.6707, Training Accuracy= 0.604\n",
      "Epoch: 3020, Loss= 0.6133, Training Accuracy= 0.657\n",
      "Epoch: 3030, Loss= 0.6467, Training Accuracy= 0.629\n",
      "Epoch: 3040, Loss= 0.5971, Training Accuracy= 0.672\n",
      "Epoch: 3050, Loss= 0.6079, Training Accuracy= 0.664\n",
      "Epoch: 3060, Loss= 0.6459, Training Accuracy= 0.630\n",
      "Epoch: 3070, Loss= 0.6149, Training Accuracy= 0.657\n",
      "Epoch: 3080, Loss= 0.5728, Training Accuracy= 0.698\n",
      "Epoch: 3090, Loss= 0.5853, Training Accuracy= 0.686\n",
      "Epoch: 3100, Loss= 0.6683, Training Accuracy= 0.587\n",
      "Epoch: 3110, Loss= 0.6529, Training Accuracy= 0.612\n",
      "Epoch: 3120, Loss= 0.6152, Training Accuracy= 0.661\n",
      "Epoch: 3130, Loss= 0.5912, Training Accuracy= 0.680\n",
      "Epoch: 3140, Loss= 0.5907, Training Accuracy= 0.682\n",
      "Epoch: 3150, Loss= 0.5684, Training Accuracy= 0.700\n",
      "Epoch: 3160, Loss= 0.5756, Training Accuracy= 0.690\n",
      "Epoch: 3170, Loss= 0.6290, Training Accuracy= 0.654\n",
      "Epoch: 3180, Loss= 0.5779, Training Accuracy= 0.690\n",
      "Epoch: 3190, Loss= 0.5561, Training Accuracy= 0.706\n",
      "Epoch: 3200, Loss= 0.5677, Training Accuracy= 0.702\n",
      "Epoch: 3210, Loss= 0.5724, Training Accuracy= 0.698\n",
      "Epoch: 3220, Loss= 0.5901, Training Accuracy= 0.686\n",
      "Epoch: 3230, Loss= 0.5907, Training Accuracy= 0.684\n",
      "Epoch: 3240, Loss= 0.5551, Training Accuracy= 0.712\n",
      "Epoch: 3250, Loss= 0.6576, Training Accuracy= 0.601\n",
      "Epoch: 3260, Loss= 0.6281, Training Accuracy= 0.643\n",
      "Epoch: 3270, Loss= 0.6208, Training Accuracy= 0.652\n",
      "Epoch: 3280, Loss= 0.6240, Training Accuracy= 0.649\n",
      "Epoch: 3290, Loss= 0.6258, Training Accuracy= 0.645\n",
      "Epoch: 3300, Loss= 0.5996, Training Accuracy= 0.674\n",
      "Epoch: 3310, Loss= 0.6004, Training Accuracy= 0.672\n",
      "Epoch: 3320, Loss= 0.5772, Training Accuracy= 0.697\n",
      "Epoch: 3330, Loss= 0.6633, Training Accuracy= 0.603\n",
      "Epoch: 3340, Loss= 0.6130, Training Accuracy= 0.660\n",
      "Epoch: 3350, Loss= 0.6091, Training Accuracy= 0.658\n",
      "Epoch: 3360, Loss= 0.5996, Training Accuracy= 0.672\n",
      "Epoch: 3370, Loss= 0.5739, Training Accuracy= 0.699\n",
      "Epoch: 3380, Loss= 0.5505, Training Accuracy= 0.717\n",
      "Epoch: 3390, Loss= 0.5790, Training Accuracy= 0.691\n",
      "Epoch: 3400, Loss= 0.6887, Training Accuracy= 0.563\n",
      "Epoch: 3410, Loss= 0.6584, Training Accuracy= 0.604\n",
      "Epoch: 3420, Loss= 0.6414, Training Accuracy= 0.630\n",
      "Epoch: 3430, Loss= 0.6265, Training Accuracy= 0.646\n",
      "Epoch: 3440, Loss= 0.5963, Training Accuracy= 0.670\n",
      "Epoch: 3450, Loss= 0.5751, Training Accuracy= 0.691\n",
      "Epoch: 3460, Loss= 0.5707, Training Accuracy= 0.697\n",
      "Epoch: 3470, Loss= 0.5442, Training Accuracy= 0.719\n",
      "Epoch: 3480, Loss= 0.5698, Training Accuracy= 0.700\n",
      "Epoch: 3490, Loss= 0.5797, Training Accuracy= 0.683\n",
      "Epoch: 3500, Loss= 0.5580, Training Accuracy= 0.707\n",
      "Epoch: 3510, Loss= 0.5556, Training Accuracy= 0.713\n",
      "Epoch: 3520, Loss= 0.5580, Training Accuracy= 0.705\n",
      "Epoch: 3530, Loss= 0.5644, Training Accuracy= 0.699\n",
      "Epoch: 3540, Loss= 0.5705, Training Accuracy= 0.700\n",
      "Epoch: 3550, Loss= 0.5339, Training Accuracy= 0.725\n",
      "Epoch: 3560, Loss= 0.5484, Training Accuracy= 0.719\n",
      "Epoch: 3570, Loss= 0.5225, Training Accuracy= 0.736\n",
      "Epoch: 3580, Loss= 0.5287, Training Accuracy= 0.731\n",
      "Epoch: 3590, Loss= 0.5721, Training Accuracy= 0.696\n",
      "Epoch: 3600, Loss= 0.5581, Training Accuracy= 0.710\n",
      "Epoch: 3610, Loss= 0.5308, Training Accuracy= 0.727\n",
      "Epoch: 3620, Loss= 0.5426, Training Accuracy= 0.724\n",
      "Epoch: 3630, Loss= 0.5476, Training Accuracy= 0.719\n",
      "Epoch: 3640, Loss= 0.5184, Training Accuracy= 0.741\n",
      "Epoch: 3650, Loss= 0.5461, Training Accuracy= 0.719\n",
      "Epoch: 3660, Loss= 0.5618, Training Accuracy= 0.706\n",
      "Epoch: 3670, Loss= 0.5294, Training Accuracy= 0.733\n",
      "Epoch: 3680, Loss= 0.5990, Training Accuracy= 0.677\n",
      "Epoch: 3690, Loss= 0.5816, Training Accuracy= 0.689\n",
      "Epoch: 3700, Loss= 0.5629, Training Accuracy= 0.708\n",
      "Epoch: 3710, Loss= 0.5178, Training Accuracy= 0.739\n",
      "Epoch: 3720, Loss= 0.5136, Training Accuracy= 0.745\n",
      "Epoch: 3730, Loss= 0.5136, Training Accuracy= 0.744\n",
      "Epoch: 3740, Loss= 0.7713, Training Accuracy= 0.506\n",
      "Epoch: 3750, Loss= 0.7669, Training Accuracy= 0.506\n",
      "Epoch: 3760, Loss= 0.7599, Training Accuracy= 0.506\n",
      "Epoch: 3770, Loss= 0.7542, Training Accuracy= 0.506\n",
      "Epoch: 3780, Loss= 0.7530, Training Accuracy= 0.507\n",
      "Epoch: 3790, Loss= 0.7434, Training Accuracy= 0.507\n",
      "Epoch: 3800, Loss= 0.7475, Training Accuracy= 0.507\n",
      "Epoch: 3810, Loss= 0.7338, Training Accuracy= 0.510\n",
      "Epoch: 3820, Loss= 0.7443, Training Accuracy= 0.508\n",
      "Epoch: 3830, Loss= 0.7397, Training Accuracy= 0.506\n",
      "Epoch: 3840, Loss= 0.7377, Training Accuracy= 0.508\n",
      "Epoch: 3850, Loss= 0.7418, Training Accuracy= 0.508\n",
      "Epoch: 3860, Loss= 0.7427, Training Accuracy= 0.508\n",
      "Epoch: 3870, Loss= 0.7356, Training Accuracy= 0.511\n",
      "Epoch: 3880, Loss= 0.7339, Training Accuracy= 0.511\n",
      "Epoch: 3890, Loss= 0.7429, Training Accuracy= 0.511\n",
      "Epoch: 3900, Loss= 0.7565, Training Accuracy= 0.508\n",
      "Epoch: 3910, Loss= 0.7294, Training Accuracy= 0.514\n",
      "Epoch: 3920, Loss= 0.7355, Training Accuracy= 0.512\n",
      "Epoch: 3930, Loss= 0.7323, Training Accuracy= 0.511\n",
      "Epoch: 3940, Loss= 0.7445, Training Accuracy= 0.511\n",
      "Epoch: 3950, Loss= 0.7384, Training Accuracy= 0.511\n",
      "Epoch: 3960, Loss= 0.7576, Training Accuracy= 0.506\n",
      "Epoch: 3970, Loss= 0.7603, Training Accuracy= 0.506\n",
      "Epoch: 3980, Loss= 0.7590, Training Accuracy= 0.506\n",
      "Epoch: 3990, Loss= 0.7543, Training Accuracy= 0.506\n",
      "Epoch: 4000, Loss= 0.7469, Training Accuracy= 0.507\n",
      "Epoch: 4010, Loss= 0.7531, Training Accuracy= 0.506\n",
      "Epoch: 4020, Loss= 0.7749, Training Accuracy= 0.506\n",
      "Epoch: 4030, Loss= 0.7516, Training Accuracy= 0.506\n",
      "Epoch: 4040, Loss= 0.7486, Training Accuracy= 0.506\n",
      "Epoch: 4050, Loss= 0.7452, Training Accuracy= 0.506\n",
      "Epoch: 4060, Loss= 0.7402, Training Accuracy= 0.506\n",
      "Epoch: 4070, Loss= 0.7381, Training Accuracy= 0.506\n",
      "Epoch: 4080, Loss= 0.7354, Training Accuracy= 0.506\n",
      "Epoch: 4090, Loss= 0.7345, Training Accuracy= 0.506\n",
      "Epoch: 4100, Loss= 0.7339, Training Accuracy= 0.506\n",
      "Epoch: 4110, Loss= 0.7334, Training Accuracy= 0.506\n",
      "Epoch: 4120, Loss= 0.7329, Training Accuracy= 0.506\n",
      "Epoch: 4130, Loss= 0.7324, Training Accuracy= 0.506\n",
      "Epoch: 4140, Loss= 0.7322, Training Accuracy= 0.506\n",
      "Epoch: 4150, Loss= 0.7312, Training Accuracy= 0.506\n",
      "Epoch: 4160, Loss= 0.7309, Training Accuracy= 0.506\n",
      "Epoch: 4170, Loss= 0.7307, Training Accuracy= 0.506\n",
      "Epoch: 4180, Loss= 0.7303, Training Accuracy= 0.506\n",
      "Epoch: 4190, Loss= 0.7301, Training Accuracy= 0.506\n",
      "Epoch: 4200, Loss= 0.7296, Training Accuracy= 0.506\n",
      "Epoch: 4210, Loss= 0.7286, Training Accuracy= 0.506\n",
      "Epoch: 4220, Loss= 0.7288, Training Accuracy= 0.506\n",
      "Epoch: 4230, Loss= 0.7285, Training Accuracy= 0.506\n",
      "Epoch: 4240, Loss= 0.7359, Training Accuracy= 0.507\n",
      "Epoch: 4250, Loss= 0.7341, Training Accuracy= 0.506\n",
      "Epoch: 4260, Loss= 0.7270, Training Accuracy= 0.506\n",
      "Epoch: 4270, Loss= 0.7241, Training Accuracy= 0.506\n",
      "Epoch: 4280, Loss= 0.7228, Training Accuracy= 0.507\n",
      "Epoch: 4290, Loss= 0.7220, Training Accuracy= 0.507\n",
      "Epoch: 4300, Loss= 0.7215, Training Accuracy= 0.507\n",
      "Epoch: 4310, Loss= 0.7211, Training Accuracy= 0.508\n",
      "Epoch: 4320, Loss= 0.7200, Training Accuracy= 0.508\n",
      "Epoch: 4330, Loss= 0.7193, Training Accuracy= 0.508\n",
      "Epoch: 4340, Loss= 0.7184, Training Accuracy= 0.509\n",
      "Epoch: 4350, Loss= 0.7177, Training Accuracy= 0.510\n",
      "Epoch: 4360, Loss= 0.7166, Training Accuracy= 0.510\n",
      "Epoch: 4370, Loss= 0.7154, Training Accuracy= 0.511\n",
      "Epoch: 4380, Loss= 0.7131, Training Accuracy= 0.512\n",
      "Epoch: 4390, Loss= 0.7131, Training Accuracy= 0.514\n",
      "Epoch: 4400, Loss= 0.7118, Training Accuracy= 0.514\n",
      "Epoch: 4410, Loss= 0.7108, Training Accuracy= 0.514\n",
      "Epoch: 4420, Loss= 0.7105, Training Accuracy= 0.515\n",
      "Epoch: 4430, Loss= 0.7097, Training Accuracy= 0.514\n",
      "Epoch: 4440, Loss= 0.7136, Training Accuracy= 0.511\n",
      "Epoch: 4450, Loss= 0.7192, Training Accuracy= 0.506\n",
      "Epoch: 4460, Loss= 0.7150, Training Accuracy= 0.509\n",
      "Epoch: 4470, Loss= 0.7097, Training Accuracy= 0.513\n",
      "Epoch: 4480, Loss= 0.7072, Training Accuracy= 0.519\n",
      "Epoch: 4490, Loss= 0.7058, Training Accuracy= 0.524\n",
      "Epoch: 4500, Loss= 0.7057, Training Accuracy= 0.523\n",
      "Epoch: 4510, Loss= 0.7111, Training Accuracy= 0.522\n",
      "Epoch: 4520, Loss= 0.7072, Training Accuracy= 0.524\n",
      "Epoch: 4530, Loss= 0.7046, Training Accuracy= 0.529\n",
      "Epoch: 4540, Loss= 0.7036, Training Accuracy= 0.530\n",
      "Epoch: 4550, Loss= 0.7022, Training Accuracy= 0.532\n",
      "Epoch: 4560, Loss= 0.7000, Training Accuracy= 0.541\n",
      "Epoch: 4570, Loss= 0.7154, Training Accuracy= 0.508\n",
      "Epoch: 4580, Loss= 0.7072, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4590, Loss= 0.7048, Training Accuracy= 0.517\n",
      "Epoch: 4600, Loss= 0.6973, Training Accuracy= 0.528\n",
      "Epoch: 4610, Loss= 0.6962, Training Accuracy= 0.530\n",
      "Epoch: 4620, Loss= 0.7039, Training Accuracy= 0.517\n",
      "Epoch: 4630, Loss= 0.7080, Training Accuracy= 0.514\n",
      "Epoch: 4640, Loss= 0.6988, Training Accuracy= 0.528\n",
      "Epoch: 4650, Loss= 0.6969, Training Accuracy= 0.529\n",
      "Epoch: 4660, Loss= 0.7121, Training Accuracy= 0.515\n",
      "Epoch: 4670, Loss= 0.7071, Training Accuracy= 0.520\n",
      "Epoch: 4680, Loss= 0.7021, Training Accuracy= 0.528\n",
      "Epoch: 4690, Loss= 0.7001, Training Accuracy= 0.537\n",
      "Epoch: 4700, Loss= 0.6989, Training Accuracy= 0.538\n",
      "Epoch: 4710, Loss= 0.6983, Training Accuracy= 0.541\n",
      "Epoch: 4720, Loss= 0.6977, Training Accuracy= 0.539\n",
      "Epoch: 4730, Loss= 0.6954, Training Accuracy= 0.543\n",
      "Epoch: 4740, Loss= 0.7425, Training Accuracy= 0.513\n",
      "Epoch: 4750, Loss= 0.7171, Training Accuracy= 0.507\n",
      "Epoch: 4760, Loss= 0.7242, Training Accuracy= 0.506\n",
      "Epoch: 4770, Loss= 0.7296, Training Accuracy= 0.506\n",
      "Epoch: 4780, Loss= 0.7281, Training Accuracy= 0.507\n",
      "Epoch: 4790, Loss= 0.7257, Training Accuracy= 0.510\n",
      "Epoch: 4800, Loss= 0.7192, Training Accuracy= 0.510\n",
      "Epoch: 4810, Loss= 0.7072, Training Accuracy= 0.515\n",
      "Epoch: 4820, Loss= 0.6802, Training Accuracy= 0.524\n",
      "Epoch: 4830, Loss= 0.6665, Training Accuracy= 0.553\n",
      "Epoch: 4840, Loss= 0.6450, Training Accuracy= 0.584\n",
      "Epoch: 4850, Loss= 0.6166, Training Accuracy= 0.604\n",
      "Epoch: 4860, Loss= 0.5671, Training Accuracy= 0.657\n",
      "Epoch: 4870, Loss= 0.5127, Training Accuracy= 0.715\n",
      "Epoch: 4880, Loss= 0.4328, Training Accuracy= 0.771\n",
      "Epoch: 4890, Loss= 0.3620, Training Accuracy= 0.824\n",
      "Epoch: 4900, Loss= 0.3030, Training Accuracy= 0.861\n",
      "Epoch: 4910, Loss= 0.7456, Training Accuracy= 0.506\n",
      "Epoch: 4920, Loss= 0.7671, Training Accuracy= 0.508\n",
      "Epoch: 4930, Loss= 0.7713, Training Accuracy= 0.518\n",
      "Epoch: 4940, Loss= 0.7448, Training Accuracy= 0.580\n",
      "Epoch: 4950, Loss= 0.7188, Training Accuracy= 0.592\n",
      "Epoch: 4960, Loss= 0.6777, Training Accuracy= 0.628\n",
      "Epoch: 4970, Loss= 0.6137, Training Accuracy= 0.673\n",
      "Epoch: 4980, Loss= 0.6400, Training Accuracy= 0.683\n",
      "Epoch: 4990, Loss= 0.5947, Training Accuracy= 0.702\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7211\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 0.7041, Training Accuracy= 0.495\n",
      "Epoch: 10, Loss= 0.6992, Training Accuracy= 0.495\n",
      "Epoch: 20, Loss= 0.6976, Training Accuracy= 0.495\n",
      "Epoch: 30, Loss= 0.6967, Training Accuracy= 0.495\n",
      "Epoch: 40, Loss= 0.6962, Training Accuracy= 0.495\n",
      "Epoch: 50, Loss= 0.6958, Training Accuracy= 0.495\n",
      "Epoch: 60, Loss= 0.6955, Training Accuracy= 0.495\n",
      "Epoch: 70, Loss= 0.6953, Training Accuracy= 0.495\n",
      "Epoch: 80, Loss= 0.6952, Training Accuracy= 0.495\n",
      "Epoch: 90, Loss= 0.6950, Training Accuracy= 0.495\n",
      "Epoch: 100, Loss= 0.6949, Training Accuracy= 0.495\n",
      "Epoch: 110, Loss= 0.6948, Training Accuracy= 0.495\n",
      "Epoch: 120, Loss= 0.6947, Training Accuracy= 0.495\n",
      "Epoch: 130, Loss= 0.6947, Training Accuracy= 0.495\n",
      "Epoch: 140, Loss= 0.6946, Training Accuracy= 0.495\n",
      "Epoch: 150, Loss= 0.6945, Training Accuracy= 0.495\n",
      "Epoch: 160, Loss= 0.6945, Training Accuracy= 0.495\n",
      "Epoch: 170, Loss= 0.6944, Training Accuracy= 0.495\n",
      "Epoch: 180, Loss= 0.6944, Training Accuracy= 0.496\n",
      "Epoch: 190, Loss= 0.6944, Training Accuracy= 0.497\n",
      "Epoch: 200, Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 210, Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 220, Loss= 0.6943, Training Accuracy= 0.499\n",
      "Epoch: 230, Loss= 0.6942, Training Accuracy= 0.498\n",
      "Epoch: 240, Loss= 0.6942, Training Accuracy= 0.498\n",
      "Epoch: 250, Loss= 0.6942, Training Accuracy= 0.498\n",
      "Epoch: 260, Loss= 0.6941, Training Accuracy= 0.498\n",
      "Epoch: 270, Loss= 0.6941, Training Accuracy= 0.499\n",
      "Epoch: 280, Loss= 0.6940, Training Accuracy= 0.499\n",
      "Epoch: 290, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 0.6939, Training Accuracy= 0.503\n",
      "Epoch: 310, Loss= 0.6938, Training Accuracy= 0.506\n",
      "Epoch: 320, Loss= 0.6938, Training Accuracy= 0.507\n",
      "Epoch: 330, Loss= 0.6940, Training Accuracy= 0.504\n",
      "Epoch: 340, Loss= 0.6953, Training Accuracy= 0.499\n",
      "Epoch: 350, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 360, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 370, Loss= 0.6958, Training Accuracy= 0.496\n",
      "Epoch: 380, Loss= 0.6939, Training Accuracy= 0.501\n",
      "Epoch: 390, Loss= 0.6925, Training Accuracy= 0.506\n",
      "Epoch: 400, Loss= 0.6916, Training Accuracy= 0.506\n",
      "Epoch: 410, Loss= 0.6883, Training Accuracy= 0.523\n",
      "Epoch: 420, Loss= 0.6969, Training Accuracy= 0.499\n",
      "Epoch: 430, Loss= 0.6944, Training Accuracy= 0.496\n",
      "Epoch: 440, Loss= 0.6944, Training Accuracy= 0.506\n",
      "Epoch: 450, Loss= 0.6945, Training Accuracy= 0.507\n",
      "Epoch: 460, Loss= 0.6987, Training Accuracy= 0.501\n",
      "Epoch: 470, Loss= 0.7197, Training Accuracy= 0.480\n",
      "Epoch: 480, Loss= 0.6955, Training Accuracy= 0.504\n",
      "Epoch: 490, Loss= 0.6944, Training Accuracy= 0.506\n",
      "Epoch: 500, Loss= 0.6947, Training Accuracy= 0.533\n",
      "Epoch: 510, Loss= 0.6984, Training Accuracy= 0.501\n",
      "Epoch: 520, Loss= 0.7087, Training Accuracy= 0.483\n",
      "Epoch: 530, Loss= 0.7135, Training Accuracy= 0.481\n",
      "Epoch: 540, Loss= 0.6978, Training Accuracy= 0.500\n",
      "Epoch: 550, Loss= 0.6963, Training Accuracy= 0.503\n",
      "Epoch: 560, Loss= 0.6983, Training Accuracy= 0.501\n",
      "Epoch: 570, Loss= 0.7169, Training Accuracy= 0.477\n",
      "Epoch: 580, Loss= 0.6985, Training Accuracy= 0.499\n",
      "Epoch: 590, Loss= 0.6976, Training Accuracy= 0.500\n",
      "Epoch: 600, Loss= 0.6969, Training Accuracy= 0.501\n",
      "Epoch: 610, Loss= 0.6965, Training Accuracy= 0.502\n",
      "Epoch: 620, Loss= 0.6958, Training Accuracy= 0.503\n",
      "Epoch: 630, Loss= 0.6967, Training Accuracy= 0.503\n",
      "Epoch: 640, Loss= 0.6967, Training Accuracy= 0.501\n",
      "Epoch: 650, Loss= 0.6954, Training Accuracy= 0.502\n",
      "Epoch: 660, Loss= 0.6950, Training Accuracy= 0.502\n",
      "Epoch: 670, Loss= 0.6940, Training Accuracy= 0.505\n",
      "Epoch: 680, Loss= 0.7082, Training Accuracy= 0.481\n",
      "Epoch: 690, Loss= 0.7019, Training Accuracy= 0.501\n",
      "Epoch: 700, Loss= 0.6941, Training Accuracy= 0.502\n",
      "Epoch: 710, Loss= 0.6914, Training Accuracy= 0.506\n",
      "Epoch: 720, Loss= 0.6891, Training Accuracy= 0.509\n",
      "Epoch: 730, Loss= 0.6990, Training Accuracy= 0.496\n",
      "Epoch: 740, Loss= 0.7019, Training Accuracy= 0.495\n",
      "Epoch: 750, Loss= 0.7008, Training Accuracy= 0.495\n",
      "Epoch: 760, Loss= 0.6999, Training Accuracy= 0.495\n",
      "Epoch: 770, Loss= 0.6993, Training Accuracy= 0.495\n",
      "Epoch: 780, Loss= 0.6988, Training Accuracy= 0.495\n",
      "Epoch: 790, Loss= 0.6984, Training Accuracy= 0.495\n",
      "Epoch: 800, Loss= 0.6981, Training Accuracy= 0.495\n",
      "Epoch: 810, Loss= 0.6978, Training Accuracy= 0.495\n",
      "Epoch: 820, Loss= 0.6976, Training Accuracy= 0.495\n",
      "Epoch: 830, Loss= 0.6974, Training Accuracy= 0.495\n",
      "Epoch: 840, Loss= 0.6973, Training Accuracy= 0.495\n",
      "Epoch: 850, Loss= 0.6971, Training Accuracy= 0.495\n",
      "Epoch: 860, Loss= 0.6970, Training Accuracy= 0.495\n",
      "Epoch: 870, Loss= 0.6969, Training Accuracy= 0.495\n",
      "Epoch: 880, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 890, Loss= 0.6967, Training Accuracy= 0.495\n",
      "Epoch: 900, Loss= 0.6966, Training Accuracy= 0.495\n",
      "Epoch: 910, Loss= 0.6965, Training Accuracy= 0.495\n",
      "Epoch: 920, Loss= 0.6964, Training Accuracy= 0.495\n",
      "Epoch: 930, Loss= 0.6963, Training Accuracy= 0.495\n",
      "Epoch: 940, Loss= 0.6962, Training Accuracy= 0.495\n",
      "Epoch: 950, Loss= 0.6962, Training Accuracy= 0.495\n",
      "Epoch: 960, Loss= 0.6961, Training Accuracy= 0.495\n",
      "Epoch: 970, Loss= 0.6960, Training Accuracy= 0.496\n",
      "Epoch: 980, Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 990, Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 1000, Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 1010, Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 1020, Loss= 0.6957, Training Accuracy= 0.497\n",
      "Epoch: 1030, Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 1040, Loss= 0.6956, Training Accuracy= 0.498\n",
      "Epoch: 1050, Loss= 0.6956, Training Accuracy= 0.498\n",
      "Epoch: 1060, Loss= 0.6956, Training Accuracy= 0.498\n",
      "Epoch: 1070, Loss= 0.6955, Training Accuracy= 0.498\n",
      "Epoch: 1080, Loss= 0.6955, Training Accuracy= 0.499\n",
      "Epoch: 1090, Loss= 0.6954, Training Accuracy= 0.499\n",
      "Epoch: 1100, Loss= 0.6954, Training Accuracy= 0.500\n",
      "Epoch: 1110, Loss= 0.6953, Training Accuracy= 0.499\n",
      "Epoch: 1120, Loss= 0.6953, Training Accuracy= 0.499\n",
      "Epoch: 1130, Loss= 0.6953, Training Accuracy= 0.499\n",
      "Epoch: 1140, Loss= 0.6952, Training Accuracy= 0.499\n",
      "Epoch: 1150, Loss= 0.6952, Training Accuracy= 0.499\n",
      "Epoch: 1160, Loss= 0.6952, Training Accuracy= 0.500\n",
      "Epoch: 1170, Loss= 0.6951, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1180, Loss= 0.6951, Training Accuracy= 0.499\n",
      "Epoch: 1190, Loss= 0.6951, Training Accuracy= 0.500\n",
      "Epoch: 1200, Loss= 0.6950, Training Accuracy= 0.499\n",
      "Epoch: 1210, Loss= 0.6950, Training Accuracy= 0.500\n",
      "Epoch: 1220, Loss= 0.6950, Training Accuracy= 0.500\n",
      "Epoch: 1230, Loss= 0.6949, Training Accuracy= 0.501\n",
      "Epoch: 1240, Loss= 0.6949, Training Accuracy= 0.501\n",
      "Epoch: 1250, Loss= 0.6949, Training Accuracy= 0.501\n",
      "Epoch: 1260, Loss= 0.6948, Training Accuracy= 0.501\n",
      "Epoch: 1270, Loss= 0.6948, Training Accuracy= 0.502\n",
      "Epoch: 1280, Loss= 0.6948, Training Accuracy= 0.502\n",
      "Epoch: 1290, Loss= 0.6947, Training Accuracy= 0.502\n",
      "Epoch: 1300, Loss= 0.6947, Training Accuracy= 0.502\n",
      "Epoch: 1310, Loss= 0.6947, Training Accuracy= 0.502\n",
      "Epoch: 1320, Loss= 0.6946, Training Accuracy= 0.502\n",
      "Epoch: 1330, Loss= 0.6946, Training Accuracy= 0.502\n",
      "Epoch: 1340, Loss= 0.6946, Training Accuracy= 0.502\n",
      "Epoch: 1350, Loss= 0.6946, Training Accuracy= 0.503\n",
      "Epoch: 1360, Loss= 0.6946, Training Accuracy= 0.503\n",
      "Epoch: 1370, Loss= 0.6946, Training Accuracy= 0.504\n",
      "Epoch: 1380, Loss= 0.6946, Training Accuracy= 0.504\n",
      "Epoch: 1390, Loss= 0.6946, Training Accuracy= 0.505\n",
      "Epoch: 1400, Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 1410, Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 1420, Loss= 0.6946, Training Accuracy= 0.507\n",
      "Epoch: 1430, Loss= 0.6946, Training Accuracy= 0.507\n",
      "Epoch: 1440, Loss= 0.6946, Training Accuracy= 0.507\n",
      "Epoch: 1450, Loss= 0.6947, Training Accuracy= 0.507\n",
      "Epoch: 1460, Loss= 0.6947, Training Accuracy= 0.506\n",
      "Epoch: 1470, Loss= 0.6947, Training Accuracy= 0.506\n",
      "Epoch: 1480, Loss= 0.6947, Training Accuracy= 0.506\n",
      "Epoch: 1490, Loss= 0.6947, Training Accuracy= 0.507\n",
      "Epoch: 1500, Loss= 0.6947, Training Accuracy= 0.506\n",
      "Epoch: 1510, Loss= 0.6948, Training Accuracy= 0.506\n",
      "Epoch: 1520, Loss= 0.6949, Training Accuracy= 0.508\n",
      "Epoch: 1530, Loss= 0.6948, Training Accuracy= 0.510\n",
      "Epoch: 1540, Loss= 0.6945, Training Accuracy= 0.514\n",
      "Epoch: 1550, Loss= 0.6945, Training Accuracy= 0.513\n",
      "Epoch: 1560, Loss= 0.6946, Training Accuracy= 0.512\n",
      "Epoch: 1570, Loss= 0.6946, Training Accuracy= 0.512\n",
      "Epoch: 1580, Loss= 0.6941, Training Accuracy= 0.515\n",
      "Epoch: 1590, Loss= 0.6935, Training Accuracy= 0.516\n",
      "Epoch: 1600, Loss= 0.6929, Training Accuracy= 0.520\n",
      "Epoch: 1610, Loss= 0.6932, Training Accuracy= 0.520\n",
      "Epoch: 1620, Loss= 0.6926, Training Accuracy= 0.520\n",
      "Epoch: 1630, Loss= 0.6927, Training Accuracy= 0.520\n",
      "Epoch: 1640, Loss= 0.6933, Training Accuracy= 0.521\n",
      "Epoch: 1650, Loss= 0.6952, Training Accuracy= 0.505\n",
      "Epoch: 1660, Loss= 0.6911, Training Accuracy= 0.521\n",
      "Epoch: 1670, Loss= 0.6957, Training Accuracy= 0.509\n",
      "Epoch: 1680, Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1690, Loss= 0.6822, Training Accuracy= 0.498\n",
      "Epoch: 1700, Loss= 0.6711, Training Accuracy= 0.512\n",
      "Epoch: 1710, Loss= 0.6638, Training Accuracy= 0.520\n",
      "Epoch: 1720, Loss= 0.6994, Training Accuracy= 0.495\n",
      "Epoch: 1730, Loss= 0.6986, Training Accuracy= 0.495\n",
      "Epoch: 1740, Loss= 0.6979, Training Accuracy= 0.495\n",
      "Epoch: 1750, Loss= 0.6975, Training Accuracy= 0.495\n",
      "Epoch: 1760, Loss= 0.6971, Training Accuracy= 0.495\n",
      "Epoch: 1770, Loss= 0.6968, Training Accuracy= 0.496\n",
      "Epoch: 1780, Loss= 0.6966, Training Accuracy= 0.498\n",
      "Epoch: 1790, Loss= 0.6964, Training Accuracy= 0.497\n",
      "Epoch: 1800, Loss= 0.6962, Training Accuracy= 0.497\n",
      "Epoch: 1810, Loss= 0.6961, Training Accuracy= 0.497\n",
      "Epoch: 1820, Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 1830, Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 1840, Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 1850, Loss= 0.6956, Training Accuracy= 0.498\n",
      "Epoch: 1860, Loss= 0.6955, Training Accuracy= 0.498\n",
      "Epoch: 1870, Loss= 0.6954, Training Accuracy= 0.498\n",
      "Epoch: 1880, Loss= 0.6954, Training Accuracy= 0.498\n",
      "Epoch: 1890, Loss= 0.6953, Training Accuracy= 0.498\n",
      "Epoch: 1900, Loss= 0.6952, Training Accuracy= 0.498\n",
      "Epoch: 1910, Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 1920, Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 1930, Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 1940, Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 1950, Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 1960, Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 1970, Loss= 0.6948, Training Accuracy= 0.499\n",
      "Epoch: 1980, Loss= 0.6947, Training Accuracy= 0.499\n",
      "Epoch: 1990, Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 2000, Loss= 0.6946, Training Accuracy= 0.499\n",
      "Epoch: 2010, Loss= 0.6945, Training Accuracy= 0.500\n",
      "Epoch: 2020, Loss= 0.6945, Training Accuracy= 0.500\n",
      "Epoch: 2030, Loss= 0.6945, Training Accuracy= 0.500\n",
      "Epoch: 2040, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 2050, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 2060, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 2070, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 2080, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 2090, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 2100, Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 2110, Loss= 0.6947, Training Accuracy= 0.500\n",
      "Epoch: 2120, Loss= 0.6946, Training Accuracy= 0.500\n",
      "Epoch: 2130, Loss= 0.6946, Training Accuracy= 0.501\n",
      "Epoch: 2140, Loss= 0.6945, Training Accuracy= 0.500\n",
      "Epoch: 2150, Loss= 0.6945, Training Accuracy= 0.501\n",
      "Epoch: 2160, Loss= 0.6944, Training Accuracy= 0.501\n",
      "Epoch: 2170, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 2180, Loss= 0.6944, Training Accuracy= 0.501\n",
      "Epoch: 2190, Loss= 0.6943, Training Accuracy= 0.500\n",
      "Epoch: 2200, Loss= 0.6943, Training Accuracy= 0.501\n",
      "Epoch: 2210, Loss= 0.6943, Training Accuracy= 0.502\n",
      "Epoch: 2220, Loss= 0.6942, Training Accuracy= 0.502\n",
      "Epoch: 2230, Loss= 0.6942, Training Accuracy= 0.502\n",
      "Epoch: 2240, Loss= 0.6942, Training Accuracy= 0.501\n",
      "Epoch: 2250, Loss= 0.6942, Training Accuracy= 0.501\n",
      "Epoch: 2260, Loss= 0.6942, Training Accuracy= 0.501\n",
      "Epoch: 2270, Loss= 0.6942, Training Accuracy= 0.500\n",
      "Epoch: 2280, Loss= 0.6941, Training Accuracy= 0.500\n",
      "Epoch: 2290, Loss= 0.6941, Training Accuracy= 0.500\n",
      "Epoch: 2300, Loss= 0.6941, Training Accuracy= 0.501\n",
      "Epoch: 2310, Loss= 0.6941, Training Accuracy= 0.501\n",
      "Epoch: 2320, Loss= 0.6941, Training Accuracy= 0.502\n",
      "Epoch: 2330, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 2340, Loss= 0.6940, Training Accuracy= 0.501\n",
      "Epoch: 2350, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 2360, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 2370, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 2380, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 2390, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 2400, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 2410, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 2420, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 2430, Loss= 0.6938, Training Accuracy= 0.502\n",
      "Epoch: 2440, Loss= 0.6938, Training Accuracy= 0.502\n",
      "Epoch: 2450, Loss= 0.6938, Training Accuracy= 0.502\n",
      "Epoch: 2460, Loss= 0.6938, Training Accuracy= 0.502\n",
      "Epoch: 2470, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2480, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2490, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2500, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2510, Loss= 0.6936, Training Accuracy= 0.503\n",
      "Epoch: 2520, Loss= 0.6936, Training Accuracy= 0.503\n",
      "Epoch: 2530, Loss= 0.6936, Training Accuracy= 0.503\n",
      "Epoch: 2540, Loss= 0.6936, Training Accuracy= 0.504\n",
      "Epoch: 2550, Loss= 0.6935, Training Accuracy= 0.505\n",
      "Epoch: 2560, Loss= 0.6935, Training Accuracy= 0.505\n",
      "Epoch: 2570, Loss= 0.6935, Training Accuracy= 0.505\n",
      "Epoch: 2580, Loss= 0.6935, Training Accuracy= 0.505\n",
      "Epoch: 2590, Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 2600, Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 2610, Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 2620, Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 2630, Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 2640, Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 2650, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 2660, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 2670, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 2680, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 2690, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 2700, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 2710, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2720, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 2730, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 2740, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 2750, Loss= 0.6929, Training Accuracy= 0.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2760, Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 2770, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 2780, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 2790, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 2800, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 2810, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 2820, Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 2830, Loss= 0.6925, Training Accuracy= 0.516\n",
      "Epoch: 2840, Loss= 0.6925, Training Accuracy= 0.518\n",
      "Epoch: 2850, Loss= 0.6925, Training Accuracy= 0.518\n",
      "Epoch: 2860, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 2870, Loss= 0.6927, Training Accuracy= 0.518\n",
      "Epoch: 2880, Loss= 0.6926, Training Accuracy= 0.519\n",
      "Epoch: 2890, Loss= 0.6926, Training Accuracy= 0.520\n",
      "Epoch: 2900, Loss= 0.6925, Training Accuracy= 0.520\n",
      "Epoch: 2910, Loss= 0.6924, Training Accuracy= 0.521\n",
      "Epoch: 2920, Loss= 0.6923, Training Accuracy= 0.521\n",
      "Epoch: 2930, Loss= 0.6922, Training Accuracy= 0.521\n",
      "Epoch: 2940, Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 2950, Loss= 0.6919, Training Accuracy= 0.521\n",
      "Epoch: 2960, Loss= 0.6918, Training Accuracy= 0.521\n",
      "Epoch: 2970, Loss= 0.6918, Training Accuracy= 0.522\n",
      "Epoch: 2980, Loss= 0.6918, Training Accuracy= 0.521\n",
      "Epoch: 2990, Loss= 0.6918, Training Accuracy= 0.522\n",
      "Epoch: 3000, Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 3010, Loss= 0.6917, Training Accuracy= 0.523\n",
      "Epoch: 3020, Loss= 0.6917, Training Accuracy= 0.523\n",
      "Epoch: 3030, Loss= 0.6917, Training Accuracy= 0.525\n",
      "Epoch: 3040, Loss= 0.6917, Training Accuracy= 0.522\n",
      "Epoch: 3050, Loss= 0.6916, Training Accuracy= 0.521\n",
      "Epoch: 3060, Loss= 0.6916, Training Accuracy= 0.522\n",
      "Epoch: 3070, Loss= 0.6915, Training Accuracy= 0.524\n",
      "Epoch: 3080, Loss= 0.6914, Training Accuracy= 0.525\n",
      "Epoch: 3090, Loss= 0.6912, Training Accuracy= 0.524\n",
      "Epoch: 3100, Loss= 0.6911, Training Accuracy= 0.524\n",
      "Epoch: 3110, Loss= 0.6910, Training Accuracy= 0.525\n",
      "Epoch: 3120, Loss= 0.6908, Training Accuracy= 0.526\n",
      "Epoch: 3130, Loss= 0.6907, Training Accuracy= 0.524\n",
      "Epoch: 3140, Loss= 0.6904, Training Accuracy= 0.523\n",
      "Epoch: 3150, Loss= 0.6899, Training Accuracy= 0.525\n",
      "Epoch: 3160, Loss= 0.6896, Training Accuracy= 0.526\n",
      "Epoch: 3170, Loss= 0.6895, Training Accuracy= 0.527\n",
      "Epoch: 3180, Loss= 0.6912, Training Accuracy= 0.525\n",
      "Epoch: 3190, Loss= 0.6906, Training Accuracy= 0.525\n",
      "Epoch: 3200, Loss= 0.6901, Training Accuracy= 0.526\n",
      "Epoch: 3210, Loss= 0.6896, Training Accuracy= 0.526\n",
      "Epoch: 3220, Loss= 0.6895, Training Accuracy= 0.527\n",
      "Epoch: 3230, Loss= 0.6899, Training Accuracy= 0.525\n",
      "Epoch: 3240, Loss= 0.6892, Training Accuracy= 0.528\n",
      "Epoch: 3250, Loss= 0.6888, Training Accuracy= 0.530\n",
      "Epoch: 3260, Loss= 0.6884, Training Accuracy= 0.531\n",
      "Epoch: 3270, Loss= 0.6882, Training Accuracy= 0.531\n",
      "Epoch: 3280, Loss= 0.6882, Training Accuracy= 0.532\n",
      "Epoch: 3290, Loss= 0.6877, Training Accuracy= 0.531\n",
      "Epoch: 3300, Loss= 0.6881, Training Accuracy= 0.534\n",
      "Epoch: 3310, Loss= 0.6897, Training Accuracy= 0.530\n",
      "Epoch: 3320, Loss= 0.6870, Training Accuracy= 0.534\n",
      "Epoch: 3330, Loss= 0.6869, Training Accuracy= 0.536\n",
      "Epoch: 3340, Loss= 0.6869, Training Accuracy= 0.536\n",
      "Epoch: 3350, Loss= 0.6863, Training Accuracy= 0.535\n",
      "Epoch: 3360, Loss= 0.6862, Training Accuracy= 0.534\n",
      "Epoch: 3370, Loss= 0.6862, Training Accuracy= 0.534\n",
      "Epoch: 3380, Loss= 0.6849, Training Accuracy= 0.546\n",
      "Epoch: 3390, Loss= 0.6861, Training Accuracy= 0.533\n",
      "Epoch: 3400, Loss= 0.6848, Training Accuracy= 0.541\n",
      "Epoch: 3410, Loss= 0.6841, Training Accuracy= 0.541\n",
      "Epoch: 3420, Loss= 0.6849, Training Accuracy= 0.538\n",
      "Epoch: 3430, Loss= 0.6854, Training Accuracy= 0.541\n",
      "Epoch: 3440, Loss= 0.6841, Training Accuracy= 0.542\n",
      "Epoch: 3450, Loss= 0.6854, Training Accuracy= 0.536\n",
      "Epoch: 3460, Loss= 0.6838, Training Accuracy= 0.541\n",
      "Epoch: 3470, Loss= 0.6885, Training Accuracy= 0.536\n",
      "Epoch: 3480, Loss= 0.6833, Training Accuracy= 0.545\n",
      "Epoch: 3490, Loss= 0.6836, Training Accuracy= 0.542\n",
      "Epoch: 3500, Loss= 0.6835, Training Accuracy= 0.541\n",
      "Epoch: 3510, Loss= 0.6942, Training Accuracy= 0.507\n",
      "Epoch: 3520, Loss= 0.6937, Training Accuracy= 0.509\n",
      "Epoch: 3530, Loss= 0.6942, Training Accuracy= 0.504\n",
      "Epoch: 3540, Loss= 0.6950, Training Accuracy= 0.507\n",
      "Epoch: 3550, Loss= 0.6923, Training Accuracy= 0.519\n",
      "Epoch: 3560, Loss= 0.6907, Training Accuracy= 0.529\n",
      "Epoch: 3570, Loss= 0.6905, Training Accuracy= 0.531\n",
      "Epoch: 3580, Loss= 0.6894, Training Accuracy= 0.534\n",
      "Epoch: 3590, Loss= 0.6890, Training Accuracy= 0.535\n",
      "Epoch: 3600, Loss= 0.6878, Training Accuracy= 0.539\n",
      "Epoch: 3610, Loss= 0.6894, Training Accuracy= 0.537\n",
      "Epoch: 3620, Loss= 0.6871, Training Accuracy= 0.542\n",
      "Epoch: 3630, Loss= 0.6862, Training Accuracy= 0.543\n",
      "Epoch: 3640, Loss= 0.6872, Training Accuracy= 0.538\n",
      "Epoch: 3650, Loss= 0.6869, Training Accuracy= 0.538\n",
      "Epoch: 3660, Loss= 0.6989, Training Accuracy= 0.513\n",
      "Epoch: 3670, Loss= 0.6861, Training Accuracy= 0.544\n",
      "Epoch: 3680, Loss= 0.6895, Training Accuracy= 0.536\n",
      "Epoch: 3690, Loss= 0.6945, Training Accuracy= 0.515\n",
      "Epoch: 3700, Loss= 0.6899, Training Accuracy= 0.529\n",
      "Epoch: 3710, Loss= 0.6957, Training Accuracy= 0.511\n",
      "Epoch: 3720, Loss= 0.6897, Training Accuracy= 0.532\n",
      "Epoch: 3730, Loss= 0.6876, Training Accuracy= 0.535\n",
      "Epoch: 3740, Loss= 0.6900, Training Accuracy= 0.526\n",
      "Epoch: 3750, Loss= 0.6879, Training Accuracy= 0.532\n",
      "Epoch: 3760, Loss= 0.6877, Training Accuracy= 0.534\n",
      "Epoch: 3770, Loss= 0.6933, Training Accuracy= 0.533\n",
      "Epoch: 3780, Loss= 0.6906, Training Accuracy= 0.529\n",
      "Epoch: 3790, Loss= 0.6855, Training Accuracy= 0.542\n",
      "Epoch: 3800, Loss= 0.6848, Training Accuracy= 0.540\n",
      "Epoch: 3810, Loss= 0.6924, Training Accuracy= 0.524\n",
      "Epoch: 3820, Loss= 0.6857, Training Accuracy= 0.548\n",
      "Epoch: 3830, Loss= 0.6862, Training Accuracy= 0.542\n",
      "Epoch: 3840, Loss= 0.6873, Training Accuracy= 0.550\n",
      "Epoch: 3850, Loss= 0.6835, Training Accuracy= 0.553\n",
      "Epoch: 3860, Loss= 0.6902, Training Accuracy= 0.530\n",
      "Epoch: 3870, Loss= 0.6916, Training Accuracy= 0.527\n",
      "Epoch: 3880, Loss= 0.6826, Training Accuracy= 0.551\n",
      "Epoch: 3890, Loss= 0.6915, Training Accuracy= 0.527\n",
      "Epoch: 3900, Loss= 0.6884, Training Accuracy= 0.529\n",
      "Epoch: 3910, Loss= 0.6885, Training Accuracy= 0.537\n",
      "Epoch: 3920, Loss= 0.6874, Training Accuracy= 0.536\n",
      "Epoch: 3930, Loss= 0.6866, Training Accuracy= 0.541\n",
      "Epoch: 3940, Loss= 0.6864, Training Accuracy= 0.541\n",
      "Epoch: 3950, Loss= 0.6949, Training Accuracy= 0.511\n",
      "Epoch: 3960, Loss= 0.6886, Training Accuracy= 0.535\n",
      "Epoch: 3970, Loss= 0.6903, Training Accuracy= 0.537\n",
      "Epoch: 3980, Loss= 0.6848, Training Accuracy= 0.547\n",
      "Epoch: 3990, Loss= 0.6881, Training Accuracy= 0.542\n",
      "Epoch: 4000, Loss= 0.6870, Training Accuracy= 0.538\n",
      "Epoch: 4010, Loss= 0.6876, Training Accuracy= 0.537\n",
      "Epoch: 4020, Loss= 0.6856, Training Accuracy= 0.547\n",
      "Epoch: 4030, Loss= 0.6840, Training Accuracy= 0.548\n",
      "Epoch: 4040, Loss= 0.6821, Training Accuracy= 0.549\n",
      "Epoch: 4050, Loss= 0.6986, Training Accuracy= 0.533\n",
      "Epoch: 4060, Loss= 0.6884, Training Accuracy= 0.546\n",
      "Epoch: 4070, Loss= 0.6904, Training Accuracy= 0.539\n",
      "Epoch: 4080, Loss= 0.6848, Training Accuracy= 0.552\n",
      "Epoch: 4090, Loss= 0.6843, Training Accuracy= 0.554\n",
      "Epoch: 4100, Loss= 0.6846, Training Accuracy= 0.550\n",
      "Epoch: 4110, Loss= 0.6839, Training Accuracy= 0.552\n",
      "Epoch: 4120, Loss= 0.6828, Training Accuracy= 0.555\n",
      "Epoch: 4130, Loss= 0.6846, Training Accuracy= 0.546\n",
      "Epoch: 4140, Loss= 0.6810, Training Accuracy= 0.555\n",
      "Epoch: 4150, Loss= 0.6815, Training Accuracy= 0.555\n",
      "Epoch: 4160, Loss= 0.6819, Training Accuracy= 0.557\n",
      "Epoch: 4170, Loss= 0.6824, Training Accuracy= 0.555\n",
      "Epoch: 4180, Loss= 0.6831, Training Accuracy= 0.553\n",
      "Epoch: 4190, Loss= 0.6803, Training Accuracy= 0.554\n",
      "Epoch: 4200, Loss= 0.6947, Training Accuracy= 0.539\n",
      "Epoch: 4210, Loss= 0.6804, Training Accuracy= 0.558\n",
      "Epoch: 4220, Loss= 0.6843, Training Accuracy= 0.555\n",
      "Epoch: 4230, Loss= 0.6840, Training Accuracy= 0.554\n",
      "Epoch: 4240, Loss= 0.6826, Training Accuracy= 0.556\n",
      "Epoch: 4250, Loss= 0.7050, Training Accuracy= 0.525\n",
      "Epoch: 4260, Loss= 0.6824, Training Accuracy= 0.556\n",
      "Epoch: 4270, Loss= 0.6726, Training Accuracy= 0.573\n",
      "Epoch: 4280, Loss= 0.6872, Training Accuracy= 0.549\n",
      "Epoch: 4290, Loss= 0.6767, Training Accuracy= 0.570\n",
      "Epoch: 4300, Loss= 0.6784, Training Accuracy= 0.564\n",
      "Epoch: 4310, Loss= 0.6791, Training Accuracy= 0.559\n",
      "Epoch: 4320, Loss= 0.6756, Training Accuracy= 0.567\n",
      "Epoch: 4330, Loss= 0.6717, Training Accuracy= 0.575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4340, Loss= 0.6868, Training Accuracy= 0.549\n",
      "Epoch: 4350, Loss= 0.6747, Training Accuracy= 0.572\n",
      "Epoch: 4360, Loss= 0.6763, Training Accuracy= 0.562\n",
      "Epoch: 4370, Loss= 0.6741, Training Accuracy= 0.568\n",
      "Epoch: 4380, Loss= 0.6930, Training Accuracy= 0.530\n",
      "Epoch: 4390, Loss= 0.6841, Training Accuracy= 0.547\n",
      "Epoch: 4400, Loss= 0.6835, Training Accuracy= 0.557\n",
      "Epoch: 4410, Loss= 0.6794, Training Accuracy= 0.563\n",
      "Epoch: 4420, Loss= 0.6727, Training Accuracy= 0.572\n",
      "Epoch: 4430, Loss= 0.6750, Training Accuracy= 0.570\n",
      "Epoch: 4440, Loss= 0.6752, Training Accuracy= 0.568\n",
      "Epoch: 4450, Loss= 0.6827, Training Accuracy= 0.553\n",
      "Epoch: 4460, Loss= 0.6929, Training Accuracy= 0.527\n",
      "Epoch: 4470, Loss= 0.6790, Training Accuracy= 0.559\n",
      "Epoch: 4480, Loss= 0.6753, Training Accuracy= 0.572\n",
      "Epoch: 4490, Loss= 0.6829, Training Accuracy= 0.559\n",
      "Epoch: 4500, Loss= 0.6733, Training Accuracy= 0.572\n",
      "Epoch: 4510, Loss= 0.6747, Training Accuracy= 0.575\n",
      "Epoch: 4520, Loss= 0.6997, Training Accuracy= 0.531\n",
      "Epoch: 4530, Loss= 0.7001, Training Accuracy= 0.530\n",
      "Epoch: 4540, Loss= 0.6683, Training Accuracy= 0.586\n",
      "Epoch: 4550, Loss= 0.6717, Training Accuracy= 0.576\n",
      "Epoch: 4560, Loss= 0.6927, Training Accuracy= 0.539\n",
      "Epoch: 4570, Loss= 0.6791, Training Accuracy= 0.561\n",
      "Epoch: 4580, Loss= 0.6638, Training Accuracy= 0.589\n",
      "Epoch: 4590, Loss= 0.6824, Training Accuracy= 0.552\n",
      "Epoch: 4600, Loss= 0.6733, Training Accuracy= 0.568\n",
      "Epoch: 4610, Loss= 0.6740, Training Accuracy= 0.571\n",
      "Epoch: 4620, Loss= 0.6763, Training Accuracy= 0.573\n",
      "Epoch: 4630, Loss= 0.6636, Training Accuracy= 0.586\n",
      "Epoch: 4640, Loss= 0.6618, Training Accuracy= 0.593\n",
      "Epoch: 4650, Loss= 0.6611, Training Accuracy= 0.591\n",
      "Epoch: 4660, Loss= 0.6575, Training Accuracy= 0.599\n",
      "Epoch: 4670, Loss= 0.6900, Training Accuracy= 0.556\n",
      "Epoch: 4680, Loss= 0.6616, Training Accuracy= 0.588\n",
      "Epoch: 4690, Loss= 0.6560, Training Accuracy= 0.596\n",
      "Epoch: 4700, Loss= 0.6920, Training Accuracy= 0.541\n",
      "Epoch: 4710, Loss= 0.6710, Training Accuracy= 0.580\n",
      "Epoch: 4720, Loss= 0.6574, Training Accuracy= 0.594\n",
      "Epoch: 4730, Loss= 0.6455, Training Accuracy= 0.619\n",
      "Epoch: 4740, Loss= 0.6471, Training Accuracy= 0.614\n",
      "Epoch: 4750, Loss= 0.6544, Training Accuracy= 0.604\n",
      "Epoch: 4760, Loss= 0.6433, Training Accuracy= 0.622\n",
      "Epoch: 4770, Loss= 0.6550, Training Accuracy= 0.607\n",
      "Epoch: 4780, Loss= 0.6404, Training Accuracy= 0.626\n",
      "Epoch: 4790, Loss= 0.6527, Training Accuracy= 0.607\n",
      "Epoch: 4800, Loss= 0.6468, Training Accuracy= 0.615\n",
      "Epoch: 4810, Loss= 0.6615, Training Accuracy= 0.595\n",
      "Epoch: 4820, Loss= 0.6464, Training Accuracy= 0.615\n",
      "Epoch: 4830, Loss= 0.6521, Training Accuracy= 0.608\n",
      "Epoch: 4840, Loss= 0.6502, Training Accuracy= 0.605\n",
      "Epoch: 4850, Loss= 0.6545, Training Accuracy= 0.607\n",
      "Epoch: 4860, Loss= 0.6641, Training Accuracy= 0.587\n",
      "Epoch: 4870, Loss= 0.6571, Training Accuracy= 0.605\n",
      "Epoch: 4880, Loss= 0.6498, Training Accuracy= 0.612\n",
      "Epoch: 4890, Loss= 0.6446, Training Accuracy= 0.622\n",
      "Epoch: 4900, Loss= 0.6579, Training Accuracy= 0.601\n",
      "Epoch: 4910, Loss= 0.6456, Training Accuracy= 0.618\n",
      "Epoch: 4920, Loss= 0.6539, Training Accuracy= 0.604\n",
      "Epoch: 4930, Loss= 0.6398, Training Accuracy= 0.628\n",
      "Epoch: 4940, Loss= 0.6633, Training Accuracy= 0.591\n",
      "Epoch: 4950, Loss= 0.6959, Training Accuracy= 0.515\n",
      "Epoch: 4960, Loss= 0.6949, Training Accuracy= 0.505\n",
      "Epoch: 4970, Loss= 0.6951, Training Accuracy= 0.502\n",
      "Epoch: 4980, Loss= 0.6923, Training Accuracy= 0.508\n",
      "Epoch: 4990, Loss= 0.6939, Training Accuracy= 0.510\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5039\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.9015, Training Accuracy= 0.505\n",
      "Epoch: 10, Loss= 0.7520, Training Accuracy= 0.505\n",
      "Epoch: 20, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.7246, Training Accuracy= 0.505\n",
      "Epoch: 40, Loss= 0.7197, Training Accuracy= 0.505\n",
      "Epoch: 50, Loss= 0.7165, Training Accuracy= 0.505\n",
      "Epoch: 60, Loss= 0.7143, Training Accuracy= 0.505\n",
      "Epoch: 70, Loss= 0.7127, Training Accuracy= 0.505\n",
      "Epoch: 80, Loss= 0.7114, Training Accuracy= 0.505\n",
      "Epoch: 90, Loss= 0.7104, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.7096, Training Accuracy= 0.505\n",
      "Epoch: 110, Loss= 0.7089, Training Accuracy= 0.505\n",
      "Epoch: 120, Loss= 0.7083, Training Accuracy= 0.505\n",
      "Epoch: 130, Loss= 0.7079, Training Accuracy= 0.505\n",
      "Epoch: 140, Loss= 0.7075, Training Accuracy= 0.505\n",
      "Epoch: 150, Loss= 0.7071, Training Accuracy= 0.505\n",
      "Epoch: 160, Loss= 0.7068, Training Accuracy= 0.505\n",
      "Epoch: 170, Loss= 0.7066, Training Accuracy= 0.505\n",
      "Epoch: 180, Loss= 0.7064, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.7062, Training Accuracy= 0.505\n",
      "Epoch: 200, Loss= 0.7060, Training Accuracy= 0.505\n",
      "Epoch: 210, Loss= 0.7058, Training Accuracy= 0.505\n",
      "Epoch: 220, Loss= 0.7057, Training Accuracy= 0.505\n",
      "Epoch: 230, Loss= 0.7056, Training Accuracy= 0.505\n",
      "Epoch: 240, Loss= 0.7055, Training Accuracy= 0.505\n",
      "Epoch: 250, Loss= 0.7054, Training Accuracy= 0.505\n",
      "Epoch: 260, Loss= 0.7053, Training Accuracy= 0.505\n",
      "Epoch: 270, Loss= 0.7052, Training Accuracy= 0.505\n",
      "Epoch: 280, Loss= 0.7051, Training Accuracy= 0.505\n",
      "Epoch: 290, Loss= 0.7051, Training Accuracy= 0.505\n",
      "Epoch: 300, Loss= 0.7050, Training Accuracy= 0.505\n",
      "Epoch: 310, Loss= 0.7050, Training Accuracy= 0.505\n",
      "Epoch: 320, Loss= 0.7049, Training Accuracy= 0.505\n",
      "Epoch: 330, Loss= 0.7049, Training Accuracy= 0.505\n",
      "Epoch: 340, Loss= 0.7048, Training Accuracy= 0.505\n",
      "Epoch: 350, Loss= 0.7048, Training Accuracy= 0.505\n",
      "Epoch: 360, Loss= 0.7047, Training Accuracy= 0.505\n",
      "Epoch: 370, Loss= 0.7047, Training Accuracy= 0.505\n",
      "Epoch: 380, Loss= 0.7047, Training Accuracy= 0.505\n",
      "Epoch: 390, Loss= 0.7046, Training Accuracy= 0.505\n",
      "Epoch: 400, Loss= 0.7046, Training Accuracy= 0.505\n",
      "Epoch: 410, Loss= 0.7046, Training Accuracy= 0.505\n",
      "Epoch: 420, Loss= 0.7046, Training Accuracy= 0.505\n",
      "Epoch: 430, Loss= 0.7045, Training Accuracy= 0.505\n",
      "Epoch: 440, Loss= 0.7045, Training Accuracy= 0.505\n",
      "Epoch: 450, Loss= 0.7045, Training Accuracy= 0.505\n",
      "Epoch: 460, Loss= 0.7045, Training Accuracy= 0.505\n",
      "Epoch: 470, Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 480, Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 490, Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 500, Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 510, Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 520, Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 530, Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 540, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 550, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 560, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 570, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 580, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 590, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 600, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 610, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 620, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 630, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 640, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 650, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 660, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 670, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 680, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 690, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 700, Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 710, Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 720, Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 730, Loss= 0.7045, Training Accuracy= 0.506\n",
      "Epoch: 740, Loss= 0.7046, Training Accuracy= 0.506\n",
      "Epoch: 750, Loss= 0.7047, Training Accuracy= 0.506\n",
      "Epoch: 760, Loss= 0.7048, Training Accuracy= 0.506\n",
      "Epoch: 770, Loss= 0.7050, Training Accuracy= 0.506\n",
      "Epoch: 780, Loss= 0.7051, Training Accuracy= 0.506\n",
      "Epoch: 790, Loss= 0.7051, Training Accuracy= 0.506\n",
      "Epoch: 800, Loss= 0.7051, Training Accuracy= 0.507\n",
      "Epoch: 810, Loss= 0.7050, Training Accuracy= 0.507\n",
      "Epoch: 820, Loss= 0.7050, Training Accuracy= 0.506\n",
      "Epoch: 830, Loss= 0.7048, Training Accuracy= 0.508\n",
      "Epoch: 840, Loss= 0.7042, Training Accuracy= 0.509\n",
      "Epoch: 850, Loss= 0.7045, Training Accuracy= 0.509\n",
      "Epoch: 860, Loss= 0.7051, Training Accuracy= 0.511\n",
      "Epoch: 870, Loss= 0.7074, Training Accuracy= 0.511\n",
      "Epoch: 880, Loss= 0.7033, Training Accuracy= 0.515\n",
      "Epoch: 890, Loss= 0.7031, Training Accuracy= 0.522\n",
      "Epoch: 900, Loss= 0.7045, Training Accuracy= 0.520\n",
      "Epoch: 910, Loss= 0.7020, Training Accuracy= 0.520\n",
      "Epoch: 920, Loss= 0.7029, Training Accuracy= 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 930, Loss= 0.7014, Training Accuracy= 0.525\n",
      "Epoch: 940, Loss= 0.7010, Training Accuracy= 0.525\n",
      "Epoch: 950, Loss= 0.7007, Training Accuracy= 0.522\n",
      "Epoch: 960, Loss= 0.7233, Training Accuracy= 0.516\n",
      "Epoch: 970, Loss= 0.6953, Training Accuracy= 0.537\n",
      "Epoch: 980, Loss= 0.6977, Training Accuracy= 0.530\n",
      "Epoch: 990, Loss= 0.6971, Training Accuracy= 0.542\n",
      "Epoch: 1000, Loss= 0.6997, Training Accuracy= 0.543\n",
      "Epoch: 1010, Loss= 0.6991, Training Accuracy= 0.542\n",
      "Epoch: 1020, Loss= 0.6949, Training Accuracy= 0.545\n",
      "Epoch: 1030, Loss= 0.6899, Training Accuracy= 0.560\n",
      "Epoch: 1040, Loss= 0.6921, Training Accuracy= 0.554\n",
      "Epoch: 1050, Loss= 0.6826, Training Accuracy= 0.567\n",
      "Epoch: 1060, Loss= 0.6901, Training Accuracy= 0.557\n",
      "Epoch: 1070, Loss= 0.6842, Training Accuracy= 0.577\n",
      "Epoch: 1080, Loss= 0.6714, Training Accuracy= 0.584\n",
      "Epoch: 1090, Loss= 0.6894, Training Accuracy= 0.571\n",
      "Epoch: 1100, Loss= 0.6730, Training Accuracy= 0.584\n",
      "Epoch: 1110, Loss= 0.6676, Training Accuracy= 0.598\n",
      "Epoch: 1120, Loss= 0.6711, Training Accuracy= 0.586\n",
      "Epoch: 1130, Loss= 0.6721, Training Accuracy= 0.589\n",
      "Epoch: 1140, Loss= 0.6816, Training Accuracy= 0.575\n",
      "Epoch: 1150, Loss= 0.6512, Training Accuracy= 0.614\n",
      "Epoch: 1160, Loss= 0.6769, Training Accuracy= 0.586\n",
      "Epoch: 1170, Loss= 0.6563, Training Accuracy= 0.617\n",
      "Epoch: 1180, Loss= 0.6533, Training Accuracy= 0.620\n",
      "Epoch: 1190, Loss= 0.6491, Training Accuracy= 0.616\n",
      "Epoch: 1200, Loss= 0.6509, Training Accuracy= 0.616\n",
      "Epoch: 1210, Loss= 0.6639, Training Accuracy= 0.610\n",
      "Epoch: 1220, Loss= 0.6512, Training Accuracy= 0.619\n",
      "Epoch: 1230, Loss= 0.6830, Training Accuracy= 0.595\n",
      "Epoch: 1240, Loss= 0.6450, Training Accuracy= 0.625\n",
      "Epoch: 1250, Loss= 0.6402, Training Accuracy= 0.630\n",
      "Epoch: 1260, Loss= 0.6306, Training Accuracy= 0.643\n",
      "Epoch: 1270, Loss= 0.6387, Training Accuracy= 0.637\n",
      "Epoch: 1280, Loss= 0.6347, Training Accuracy= 0.636\n",
      "Epoch: 1290, Loss= 0.6356, Training Accuracy= 0.639\n",
      "Epoch: 1300, Loss= 0.6141, Training Accuracy= 0.656\n",
      "Epoch: 1310, Loss= 0.6228, Training Accuracy= 0.646\n",
      "Epoch: 1320, Loss= 0.6215, Training Accuracy= 0.646\n",
      "Epoch: 1330, Loss= 0.6226, Training Accuracy= 0.648\n",
      "Epoch: 1340, Loss= 0.6323, Training Accuracy= 0.638\n",
      "Epoch: 1350, Loss= 0.6324, Training Accuracy= 0.642\n",
      "Epoch: 1360, Loss= 0.8659, Training Accuracy= 0.503\n",
      "Epoch: 1370, Loss= 0.7664, Training Accuracy= 0.505\n",
      "Epoch: 1380, Loss= 0.7457, Training Accuracy= 0.509\n",
      "Epoch: 1390, Loss= 0.7289, Training Accuracy= 0.506\n",
      "Epoch: 1400, Loss= 0.7308, Training Accuracy= 0.506\n",
      "Epoch: 1410, Loss= 0.7217, Training Accuracy= 0.512\n",
      "Epoch: 1420, Loss= 0.7050, Training Accuracy= 0.528\n",
      "Epoch: 1430, Loss= 0.7109, Training Accuracy= 0.528\n",
      "Epoch: 1440, Loss= 0.7146, Training Accuracy= 0.529\n",
      "Epoch: 1450, Loss= 0.7042, Training Accuracy= 0.535\n",
      "Epoch: 1460, Loss= 0.7044, Training Accuracy= 0.538\n",
      "Epoch: 1470, Loss= 0.7089, Training Accuracy= 0.536\n",
      "Epoch: 1480, Loss= 0.7007, Training Accuracy= 0.544\n",
      "Epoch: 1490, Loss= 0.6879, Training Accuracy= 0.555\n",
      "Epoch: 1500, Loss= 0.7352, Training Accuracy= 0.506\n",
      "Epoch: 1510, Loss= 0.7164, Training Accuracy= 0.510\n",
      "Epoch: 1520, Loss= 0.7098, Training Accuracy= 0.521\n",
      "Epoch: 1530, Loss= 0.7030, Training Accuracy= 0.534\n",
      "Epoch: 1540, Loss= 0.7008, Training Accuracy= 0.532\n",
      "Epoch: 1550, Loss= 0.7168, Training Accuracy= 0.521\n",
      "Epoch: 1560, Loss= 0.6964, Training Accuracy= 0.544\n",
      "Epoch: 1570, Loss= 0.7006, Training Accuracy= 0.536\n",
      "Epoch: 1580, Loss= 0.6973, Training Accuracy= 0.539\n",
      "Epoch: 1590, Loss= 0.6929, Training Accuracy= 0.544\n",
      "Epoch: 1600, Loss= 0.6831, Training Accuracy= 0.565\n",
      "Epoch: 1610, Loss= 0.6734, Training Accuracy= 0.580\n",
      "Epoch: 1620, Loss= 0.6696, Training Accuracy= 0.588\n",
      "Epoch: 1630, Loss= 0.6830, Training Accuracy= 0.567\n",
      "Epoch: 1640, Loss= 0.6762, Training Accuracy= 0.577\n",
      "Epoch: 1650, Loss= 0.6742, Training Accuracy= 0.578\n",
      "Epoch: 1660, Loss= 0.6816, Training Accuracy= 0.572\n",
      "Epoch: 1670, Loss= 0.6632, Training Accuracy= 0.592\n",
      "Epoch: 1680, Loss= 0.8097, Training Accuracy= 0.505\n",
      "Epoch: 1690, Loss= 0.7846, Training Accuracy= 0.505\n",
      "Epoch: 1700, Loss= 0.7802, Training Accuracy= 0.504\n",
      "Epoch: 1710, Loss= 0.7553, Training Accuracy= 0.505\n",
      "Epoch: 1720, Loss= 0.7462, Training Accuracy= 0.505\n",
      "Epoch: 1730, Loss= 0.7532, Training Accuracy= 0.505\n",
      "Epoch: 1740, Loss= 0.7552, Training Accuracy= 0.505\n",
      "Epoch: 1750, Loss= 0.7959, Training Accuracy= 0.505\n",
      "Epoch: 1760, Loss= 0.7847, Training Accuracy= 0.505\n",
      "Epoch: 1770, Loss= 0.7806, Training Accuracy= 0.506\n",
      "Epoch: 1780, Loss= 0.7746, Training Accuracy= 0.507\n",
      "Epoch: 1790, Loss= 0.7733, Training Accuracy= 0.508\n",
      "Epoch: 1800, Loss= 1.0150, Training Accuracy= 0.504\n",
      "Epoch: 1810, Loss= 0.9314, Training Accuracy= 0.505\n",
      "Epoch: 1820, Loss= 0.8885, Training Accuracy= 0.505\n",
      "Epoch: 1830, Loss= 0.8637, Training Accuracy= 0.505\n",
      "Epoch: 1840, Loss= 0.8374, Training Accuracy= 0.505\n",
      "Epoch: 1850, Loss= 0.8215, Training Accuracy= 0.505\n",
      "Epoch: 1860, Loss= 0.8074, Training Accuracy= 0.505\n",
      "Epoch: 1870, Loss= 0.7969, Training Accuracy= 0.507\n",
      "Epoch: 1880, Loss= 0.8001, Training Accuracy= 0.507\n",
      "Epoch: 1890, Loss= 0.7862, Training Accuracy= 0.508\n",
      "Epoch: 1900, Loss= 0.8001, Training Accuracy= 0.505\n",
      "Epoch: 1910, Loss= 0.7822, Training Accuracy= 0.507\n",
      "Epoch: 1920, Loss= 0.7678, Training Accuracy= 0.508\n",
      "Epoch: 1930, Loss= 0.7648, Training Accuracy= 0.515\n",
      "Epoch: 1940, Loss= 0.7828, Training Accuracy= 0.506\n",
      "Epoch: 1950, Loss= 0.7701, Training Accuracy= 0.512\n",
      "Epoch: 1960, Loss= 0.7730, Training Accuracy= 0.515\n",
      "Epoch: 1970, Loss= 0.7568, Training Accuracy= 0.524\n",
      "Epoch: 1980, Loss= 0.7539, Training Accuracy= 0.523\n",
      "Epoch: 1990, Loss= 0.7599, Training Accuracy= 0.520\n",
      "Epoch: 2000, Loss= 0.7464, Training Accuracy= 0.524\n",
      "Epoch: 2010, Loss= 0.7326, Training Accuracy= 0.531\n",
      "Epoch: 2020, Loss= 0.7470, Training Accuracy= 0.527\n",
      "Epoch: 2030, Loss= 0.7505, Training Accuracy= 0.531\n",
      "Epoch: 2040, Loss= 0.8043, Training Accuracy= 0.513\n",
      "Epoch: 2050, Loss= 0.7326, Training Accuracy= 0.533\n",
      "Epoch: 2060, Loss= 0.7509, Training Accuracy= 0.527\n",
      "Epoch: 2070, Loss= 0.7204, Training Accuracy= 0.541\n",
      "Epoch: 2080, Loss= 0.7357, Training Accuracy= 0.534\n",
      "Epoch: 2090, Loss= 0.7098, Training Accuracy= 0.546\n",
      "Epoch: 2100, Loss= 0.7309, Training Accuracy= 0.541\n",
      "Epoch: 2110, Loss= 0.7245, Training Accuracy= 0.537\n",
      "Epoch: 2120, Loss= 0.7352, Training Accuracy= 0.537\n",
      "Epoch: 2130, Loss= 0.7435, Training Accuracy= 0.539\n",
      "Epoch: 2140, Loss= 0.7047, Training Accuracy= 0.558\n",
      "Epoch: 2150, Loss= 0.7054, Training Accuracy= 0.558\n",
      "Epoch: 2160, Loss= 0.7135, Training Accuracy= 0.555\n",
      "Epoch: 2170, Loss= 0.6959, Training Accuracy= 0.560\n",
      "Epoch: 2180, Loss= 0.7048, Training Accuracy= 0.560\n",
      "Epoch: 2190, Loss= 0.7314, Training Accuracy= 0.538\n",
      "Epoch: 2200, Loss= 0.7283, Training Accuracy= 0.542\n",
      "Epoch: 2210, Loss= 0.7187, Training Accuracy= 0.553\n",
      "Epoch: 2220, Loss= 0.8347, Training Accuracy= 0.508\n",
      "Epoch: 2230, Loss= 0.7506, Training Accuracy= 0.525\n",
      "Epoch: 2240, Loss= 0.7100, Training Accuracy= 0.554\n",
      "Epoch: 2250, Loss= 0.6927, Training Accuracy= 0.563\n",
      "Epoch: 2260, Loss= 0.6938, Training Accuracy= 0.570\n",
      "Epoch: 2270, Loss= 0.7051, Training Accuracy= 0.558\n",
      "Epoch: 2280, Loss= 0.6940, Training Accuracy= 0.569\n",
      "Epoch: 2290, Loss= 0.6910, Training Accuracy= 0.575\n",
      "Epoch: 2300, Loss= 0.6965, Training Accuracy= 0.569\n",
      "Epoch: 2310, Loss= 0.6926, Training Accuracy= 0.575\n",
      "Epoch: 2320, Loss= 0.7452, Training Accuracy= 0.538\n",
      "Epoch: 2330, Loss= 0.6874, Training Accuracy= 0.572\n",
      "Epoch: 2340, Loss= 0.6884, Training Accuracy= 0.571\n",
      "Epoch: 2350, Loss= 0.6726, Training Accuracy= 0.590\n",
      "Epoch: 2360, Loss= 0.7059, Training Accuracy= 0.548\n",
      "Epoch: 2370, Loss= 0.6783, Training Accuracy= 0.587\n",
      "Epoch: 2380, Loss= 0.6801, Training Accuracy= 0.581\n",
      "Epoch: 2390, Loss= 0.7023, Training Accuracy= 0.554\n",
      "Epoch: 2400, Loss= 0.6964, Training Accuracy= 0.566\n",
      "Epoch: 2410, Loss= 0.6839, Training Accuracy= 0.579\n",
      "Epoch: 2420, Loss= 0.6658, Training Accuracy= 0.598\n",
      "Epoch: 2430, Loss= 0.6576, Training Accuracy= 0.605\n",
      "Epoch: 2440, Loss= 0.6786, Training Accuracy= 0.580\n",
      "Epoch: 2450, Loss= 0.6686, Training Accuracy= 0.595\n",
      "Epoch: 2460, Loss= 0.6769, Training Accuracy= 0.582\n",
      "Epoch: 2470, Loss= 0.7427, Training Accuracy= 0.529\n",
      "Epoch: 2480, Loss= 0.6852, Training Accuracy= 0.580\n",
      "Epoch: 2490, Loss= 0.6889, Training Accuracy= 0.581\n",
      "Epoch: 2500, Loss= 0.6487, Training Accuracy= 0.616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2510, Loss= 0.6427, Training Accuracy= 0.621\n",
      "Epoch: 2520, Loss= 0.6538, Training Accuracy= 0.617\n",
      "Epoch: 2530, Loss= 0.6411, Training Accuracy= 0.626\n",
      "Epoch: 2540, Loss= 0.6511, Training Accuracy= 0.616\n",
      "Epoch: 2550, Loss= 0.6563, Training Accuracy= 0.610\n",
      "Epoch: 2560, Loss= 0.6430, Training Accuracy= 0.624\n",
      "Epoch: 2570, Loss= 0.6627, Training Accuracy= 0.600\n",
      "Epoch: 2580, Loss= 0.6526, Training Accuracy= 0.615\n",
      "Epoch: 2590, Loss= 0.6428, Training Accuracy= 0.628\n",
      "Epoch: 2600, Loss= 0.6654, Training Accuracy= 0.604\n",
      "Epoch: 2610, Loss= 0.6381, Training Accuracy= 0.627\n",
      "Epoch: 2620, Loss= 0.6540, Training Accuracy= 0.615\n",
      "Epoch: 2630, Loss= 0.6272, Training Accuracy= 0.647\n",
      "Epoch: 2640, Loss= 0.6820, Training Accuracy= 0.579\n",
      "Epoch: 2650, Loss= 0.6448, Training Accuracy= 0.623\n",
      "Epoch: 2660, Loss= 0.6311, Training Accuracy= 0.638\n",
      "Epoch: 2670, Loss= 0.6278, Training Accuracy= 0.644\n",
      "Epoch: 2680, Loss= 0.6404, Training Accuracy= 0.629\n",
      "Epoch: 2690, Loss= 0.6721, Training Accuracy= 0.604\n",
      "Epoch: 2700, Loss= 0.6375, Training Accuracy= 0.633\n",
      "Epoch: 2710, Loss= 0.6222, Training Accuracy= 0.644\n",
      "Epoch: 2720, Loss= 0.6333, Training Accuracy= 0.634\n",
      "Epoch: 2730, Loss= 0.6260, Training Accuracy= 0.646\n",
      "Epoch: 2740, Loss= 0.6254, Training Accuracy= 0.644\n",
      "Epoch: 2750, Loss= 0.6409, Training Accuracy= 0.630\n",
      "Epoch: 2760, Loss= 0.6794, Training Accuracy= 0.595\n",
      "Epoch: 2770, Loss= 0.6462, Training Accuracy= 0.616\n",
      "Epoch: 2780, Loss= 0.6106, Training Accuracy= 0.659\n",
      "Epoch: 2790, Loss= 0.6212, Training Accuracy= 0.652\n",
      "Epoch: 2800, Loss= 0.6289, Training Accuracy= 0.634\n",
      "Epoch: 2810, Loss= 0.6327, Training Accuracy= 0.638\n",
      "Epoch: 2820, Loss= 0.6647, Training Accuracy= 0.618\n",
      "Epoch: 2830, Loss= 0.6273, Training Accuracy= 0.645\n",
      "Epoch: 2840, Loss= 0.6282, Training Accuracy= 0.642\n",
      "Epoch: 2850, Loss= 0.6238, Training Accuracy= 0.650\n",
      "Epoch: 2860, Loss= 0.6946, Training Accuracy= 0.585\n",
      "Epoch: 2870, Loss= 0.6715, Training Accuracy= 0.589\n",
      "Epoch: 2880, Loss= 0.6074, Training Accuracy= 0.664\n",
      "Epoch: 2890, Loss= 0.6270, Training Accuracy= 0.645\n",
      "Epoch: 2900, Loss= 0.6616, Training Accuracy= 0.608\n",
      "Epoch: 2910, Loss= 0.6751, Training Accuracy= 0.594\n",
      "Epoch: 2920, Loss= 0.6471, Training Accuracy= 0.617\n",
      "Epoch: 2930, Loss= 0.6130, Training Accuracy= 0.655\n",
      "Epoch: 2940, Loss= 0.7024, Training Accuracy= 0.554\n",
      "Epoch: 2950, Loss= 0.8130, Training Accuracy= 0.505\n",
      "Epoch: 2960, Loss= 0.8034, Training Accuracy= 0.506\n",
      "Epoch: 2970, Loss= 0.7887, Training Accuracy= 0.511\n",
      "Epoch: 2980, Loss= 0.7888, Training Accuracy= 0.513\n",
      "Epoch: 2990, Loss= 0.7681, Training Accuracy= 0.521\n",
      "Epoch: 3000, Loss= 0.7799, Training Accuracy= 0.521\n",
      "Epoch: 3010, Loss= 0.7633, Training Accuracy= 0.529\n",
      "Epoch: 3020, Loss= 0.7952, Training Accuracy= 0.514\n",
      "Epoch: 3030, Loss= 0.7550, Training Accuracy= 0.525\n",
      "Epoch: 3040, Loss= 0.7691, Training Accuracy= 0.528\n",
      "Epoch: 3050, Loss= 0.7659, Training Accuracy= 0.522\n",
      "Epoch: 3060, Loss= 0.8228, Training Accuracy= 0.510\n",
      "Epoch: 3070, Loss= 0.7619, Training Accuracy= 0.523\n",
      "Epoch: 3080, Loss= 0.7854, Training Accuracy= 0.527\n",
      "Epoch: 3090, Loss= 0.7347, Training Accuracy= 0.544\n",
      "Epoch: 3100, Loss= 0.7251, Training Accuracy= 0.548\n",
      "Epoch: 3110, Loss= 0.7642, Training Accuracy= 0.540\n",
      "Epoch: 3120, Loss= 0.7204, Training Accuracy= 0.560\n",
      "Epoch: 3130, Loss= 0.7452, Training Accuracy= 0.542\n",
      "Epoch: 3140, Loss= 0.7549, Training Accuracy= 0.541\n",
      "Epoch: 3150, Loss= 0.7170, Training Accuracy= 0.555\n",
      "Epoch: 3160, Loss= 0.7327, Training Accuracy= 0.557\n",
      "Epoch: 3170, Loss= 0.7916, Training Accuracy= 0.514\n",
      "Epoch: 3180, Loss= 0.7359, Training Accuracy= 0.547\n",
      "Epoch: 3190, Loss= 0.7280, Training Accuracy= 0.556\n",
      "Epoch: 3200, Loss= 0.7490, Training Accuracy= 0.543\n",
      "Epoch: 3210, Loss= 0.7256, Training Accuracy= 0.555\n",
      "Epoch: 3220, Loss= 0.7151, Training Accuracy= 0.566\n",
      "Epoch: 3230, Loss= 0.7253, Training Accuracy= 0.549\n",
      "Epoch: 3240, Loss= 0.7279, Training Accuracy= 0.563\n",
      "Epoch: 3250, Loss= 0.7306, Training Accuracy= 0.567\n",
      "Epoch: 3260, Loss= 0.7155, Training Accuracy= 0.573\n",
      "Epoch: 3270, Loss= 0.7632, Training Accuracy= 0.543\n",
      "Epoch: 3280, Loss= 0.7106, Training Accuracy= 0.572\n",
      "Epoch: 3290, Loss= 0.7654, Training Accuracy= 0.513\n",
      "Epoch: 3300, Loss= 0.7650, Training Accuracy= 0.522\n",
      "Epoch: 3310, Loss= 0.7495, Training Accuracy= 0.529\n",
      "Epoch: 3320, Loss= 0.7444, Training Accuracy= 0.538\n",
      "Epoch: 3330, Loss= 0.7336, Training Accuracy= 0.542\n",
      "Epoch: 3340, Loss= 0.7176, Training Accuracy= 0.556\n",
      "Epoch: 3350, Loss= 0.7267, Training Accuracy= 0.555\n",
      "Epoch: 3360, Loss= 0.7259, Training Accuracy= 0.554\n",
      "Epoch: 3370, Loss= 0.7083, Training Accuracy= 0.565\n",
      "Epoch: 3380, Loss= 0.7022, Training Accuracy= 0.574\n",
      "Epoch: 3390, Loss= 0.7195, Training Accuracy= 0.561\n",
      "Epoch: 3400, Loss= 0.7261, Training Accuracy= 0.560\n",
      "Epoch: 3410, Loss= 0.6891, Training Accuracy= 0.584\n",
      "Epoch: 3420, Loss= 0.7189, Training Accuracy= 0.566\n",
      "Epoch: 3430, Loss= 0.6980, Training Accuracy= 0.582\n",
      "Epoch: 3440, Loss= 0.6957, Training Accuracy= 0.584\n",
      "Epoch: 3450, Loss= 0.7311, Training Accuracy= 0.544\n",
      "Epoch: 3460, Loss= 0.6941, Training Accuracy= 0.581\n",
      "Epoch: 3470, Loss= 0.7310, Training Accuracy= 0.559\n",
      "Epoch: 3480, Loss= 0.7024, Training Accuracy= 0.582\n",
      "Epoch: 3490, Loss= 0.6846, Training Accuracy= 0.592\n",
      "Epoch: 3500, Loss= 0.6701, Training Accuracy= 0.599\n",
      "Epoch: 3510, Loss= 0.7230, Training Accuracy= 0.564\n",
      "Epoch: 3520, Loss= 0.6954, Training Accuracy= 0.584\n",
      "Epoch: 3530, Loss= 0.7308, Training Accuracy= 0.559\n",
      "Epoch: 3540, Loss= 0.7101, Training Accuracy= 0.576\n",
      "Epoch: 3550, Loss= 0.6834, Training Accuracy= 0.598\n",
      "Epoch: 3560, Loss= 0.6947, Training Accuracy= 0.581\n",
      "Epoch: 3570, Loss= 0.8048, Training Accuracy= 0.520\n",
      "Epoch: 3580, Loss= 0.7252, Training Accuracy= 0.555\n",
      "Epoch: 3590, Loss= 0.6773, Training Accuracy= 0.592\n",
      "Epoch: 3600, Loss= 0.6990, Training Accuracy= 0.568\n",
      "Epoch: 3610, Loss= 0.6752, Training Accuracy= 0.595\n",
      "Epoch: 3620, Loss= 0.6820, Training Accuracy= 0.591\n",
      "Epoch: 3630, Loss= 0.6691, Training Accuracy= 0.605\n",
      "Epoch: 3640, Loss= 0.6997, Training Accuracy= 0.587\n",
      "Epoch: 3650, Loss= 0.6949, Training Accuracy= 0.584\n",
      "Epoch: 3660, Loss= 0.7026, Training Accuracy= 0.582\n",
      "Epoch: 3670, Loss= 0.6941, Training Accuracy= 0.581\n",
      "Epoch: 3680, Loss= 0.6705, Training Accuracy= 0.599\n",
      "Epoch: 3690, Loss= 0.7158, Training Accuracy= 0.584\n",
      "Epoch: 3700, Loss= 0.6856, Training Accuracy= 0.598\n",
      "Epoch: 3710, Loss= 0.6460, Training Accuracy= 0.624\n",
      "Epoch: 3720, Loss= 0.6853, Training Accuracy= 0.593\n",
      "Epoch: 3730, Loss= 0.7056, Training Accuracy= 0.570\n",
      "Epoch: 3740, Loss= 0.7732, Training Accuracy= 0.542\n",
      "Epoch: 3750, Loss= 0.6612, Training Accuracy= 0.600\n",
      "Epoch: 3760, Loss= 0.6916, Training Accuracy= 0.588\n",
      "Epoch: 3770, Loss= 0.6574, Training Accuracy= 0.617\n",
      "Epoch: 3780, Loss= 0.6810, Training Accuracy= 0.603\n",
      "Epoch: 3790, Loss= 0.6417, Training Accuracy= 0.628\n",
      "Epoch: 3800, Loss= 0.6506, Training Accuracy= 0.620\n",
      "Epoch: 3810, Loss= 0.6599, Training Accuracy= 0.620\n",
      "Epoch: 3820, Loss= 0.6534, Training Accuracy= 0.619\n",
      "Epoch: 3830, Loss= 0.6757, Training Accuracy= 0.599\n",
      "Epoch: 3840, Loss= 0.6513, Training Accuracy= 0.624\n",
      "Epoch: 3850, Loss= 0.6700, Training Accuracy= 0.612\n",
      "Epoch: 3860, Loss= 0.6833, Training Accuracy= 0.589\n",
      "Epoch: 3870, Loss= 0.7046, Training Accuracy= 0.581\n",
      "Epoch: 3880, Loss= 0.6525, Training Accuracy= 0.619\n",
      "Epoch: 3890, Loss= 0.6565, Training Accuracy= 0.617\n",
      "Epoch: 3900, Loss= 0.6507, Training Accuracy= 0.623\n",
      "Epoch: 3910, Loss= 0.6367, Training Accuracy= 0.637\n",
      "Epoch: 3920, Loss= 0.6302, Training Accuracy= 0.643\n",
      "Epoch: 3930, Loss= 0.6471, Training Accuracy= 0.625\n",
      "Epoch: 3940, Loss= 0.6538, Training Accuracy= 0.622\n",
      "Epoch: 3950, Loss= 0.6308, Training Accuracy= 0.642\n",
      "Epoch: 3960, Loss= 0.7031, Training Accuracy= 0.588\n",
      "Epoch: 3970, Loss= 0.6217, Training Accuracy= 0.650\n",
      "Epoch: 3980, Loss= 0.6549, Training Accuracy= 0.614\n",
      "Epoch: 3990, Loss= 0.6406, Training Accuracy= 0.635\n",
      "Epoch: 4000, Loss= 0.6326, Training Accuracy= 0.632\n",
      "Epoch: 4010, Loss= 0.6396, Training Accuracy= 0.632\n",
      "Epoch: 4020, Loss= 0.6846, Training Accuracy= 0.592\n",
      "Epoch: 4030, Loss= 0.6482, Training Accuracy= 0.623\n",
      "Epoch: 4040, Loss= 0.6388, Training Accuracy= 0.631\n",
      "Epoch: 4050, Loss= 0.6598, Training Accuracy= 0.624\n",
      "Epoch: 4060, Loss= 0.6373, Training Accuracy= 0.633\n",
      "Epoch: 4070, Loss= 0.6643, Training Accuracy= 0.613\n",
      "Epoch: 4080, Loss= 0.6547, Training Accuracy= 0.619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4090, Loss= 0.6323, Training Accuracy= 0.640\n",
      "Epoch: 4100, Loss= 0.6270, Training Accuracy= 0.646\n",
      "Epoch: 4110, Loss= 0.6478, Training Accuracy= 0.629\n",
      "Epoch: 4120, Loss= 0.6235, Training Accuracy= 0.643\n",
      "Epoch: 4130, Loss= 0.6522, Training Accuracy= 0.629\n",
      "Epoch: 4140, Loss= 0.6329, Training Accuracy= 0.637\n",
      "Epoch: 4150, Loss= 0.6257, Training Accuracy= 0.642\n",
      "Epoch: 4160, Loss= 0.6197, Training Accuracy= 0.651\n",
      "Epoch: 4170, Loss= 0.6141, Training Accuracy= 0.654\n",
      "Epoch: 4180, Loss= 0.6500, Training Accuracy= 0.618\n",
      "Epoch: 4190, Loss= 0.6409, Training Accuracy= 0.632\n",
      "Epoch: 4200, Loss= 0.6604, Training Accuracy= 0.618\n",
      "Epoch: 4210, Loss= 0.6314, Training Accuracy= 0.632\n",
      "Epoch: 4220, Loss= 0.8807, Training Accuracy= 0.505\n",
      "Epoch: 4230, Loss= 0.8912, Training Accuracy= 0.505\n",
      "Epoch: 4240, Loss= 0.8121, Training Accuracy= 0.525\n",
      "Epoch: 4250, Loss= 0.6658, Training Accuracy= 0.658\n",
      "Epoch: 4260, Loss= 0.6338, Training Accuracy= 0.679\n",
      "Epoch: 4270, Loss= 0.6460, Training Accuracy= 0.693\n",
      "Epoch: 4280, Loss= 0.5533, Training Accuracy= 0.746\n",
      "Epoch: 4290, Loss= 0.1929, Training Accuracy= 0.918\n",
      "Epoch: 4300, Loss= 0.1522, Training Accuracy= 0.921\n",
      "Epoch: 4310, Loss= 0.1312, Training Accuracy= 0.937\n",
      "Epoch: 4320, Loss= 0.0975, Training Accuracy= 0.959\n",
      "Epoch: 4330, Loss= 0.3029, Training Accuracy= 0.820\n",
      "Epoch: 4340, Loss= 0.1680, Training Accuracy= 0.921\n",
      "Epoch: 4350, Loss= 0.1056, Training Accuracy= 0.965\n",
      "Epoch: 4360, Loss= 1.3349, Training Accuracy= 0.505\n",
      "Epoch: 4370, Loss= 1.2582, Training Accuracy= 0.505\n",
      "Epoch: 4380, Loss= 1.1505, Training Accuracy= 0.505\n",
      "Epoch: 4390, Loss= 1.0828, Training Accuracy= 0.505\n",
      "Epoch: 4400, Loss= 1.0531, Training Accuracy= 0.505\n",
      "Epoch: 4410, Loss= 1.0388, Training Accuracy= 0.505\n",
      "Epoch: 4420, Loss= 1.0321, Training Accuracy= 0.505\n",
      "Epoch: 4430, Loss= 1.0294, Training Accuracy= 0.505\n",
      "Epoch: 4440, Loss= 1.0276, Training Accuracy= 0.505\n",
      "Epoch: 4450, Loss= 1.0261, Training Accuracy= 0.505\n",
      "Epoch: 4460, Loss= 1.0250, Training Accuracy= 0.505\n",
      "Epoch: 4470, Loss= 1.0240, Training Accuracy= 0.505\n",
      "Epoch: 4480, Loss= 1.0229, Training Accuracy= 0.505\n",
      "Epoch: 4490, Loss= 1.0216, Training Accuracy= 0.505\n",
      "Epoch: 4500, Loss= 1.0200, Training Accuracy= 0.505\n",
      "Epoch: 4510, Loss= 1.0182, Training Accuracy= 0.505\n",
      "Epoch: 4520, Loss= 1.0165, Training Accuracy= 0.505\n",
      "Epoch: 4530, Loss= 1.0148, Training Accuracy= 0.505\n",
      "Epoch: 4540, Loss= 1.0129, Training Accuracy= 0.505\n",
      "Epoch: 4550, Loss= 1.0102, Training Accuracy= 0.505\n",
      "Epoch: 4560, Loss= 1.0058, Training Accuracy= 0.505\n",
      "Epoch: 4570, Loss= 0.9998, Training Accuracy= 0.505\n",
      "Epoch: 4580, Loss= 0.9936, Training Accuracy= 0.505\n",
      "Epoch: 4590, Loss= 0.9883, Training Accuracy= 0.505\n",
      "Epoch: 4600, Loss= 0.9838, Training Accuracy= 0.505\n",
      "Epoch: 4610, Loss= 0.9801, Training Accuracy= 0.505\n",
      "Epoch: 4620, Loss= 0.9770, Training Accuracy= 0.505\n",
      "Epoch: 4630, Loss= 0.9745, Training Accuracy= 0.505\n",
      "Epoch: 4640, Loss= 0.9725, Training Accuracy= 0.505\n",
      "Epoch: 4650, Loss= 0.9708, Training Accuracy= 0.505\n",
      "Epoch: 4660, Loss= 0.9691, Training Accuracy= 0.505\n",
      "Epoch: 4670, Loss= 0.9672, Training Accuracy= 0.505\n",
      "Epoch: 4680, Loss= 0.9649, Training Accuracy= 0.505\n",
      "Epoch: 4690, Loss= 0.9622, Training Accuracy= 0.505\n",
      "Epoch: 4700, Loss= 0.9594, Training Accuracy= 0.505\n",
      "Epoch: 4710, Loss= 0.9566, Training Accuracy= 0.505\n",
      "Epoch: 4720, Loss= 0.9540, Training Accuracy= 0.505\n",
      "Epoch: 4730, Loss= 0.9515, Training Accuracy= 0.505\n",
      "Epoch: 4740, Loss= 0.9492, Training Accuracy= 0.505\n",
      "Epoch: 4750, Loss= 0.9465, Training Accuracy= 0.505\n",
      "Epoch: 4760, Loss= 0.9446, Training Accuracy= 0.505\n",
      "Epoch: 4770, Loss= 0.9420, Training Accuracy= 0.505\n",
      "Epoch: 4780, Loss= 0.9385, Training Accuracy= 0.505\n",
      "Epoch: 4790, Loss= 0.9346, Training Accuracy= 0.505\n",
      "Epoch: 4800, Loss= 0.9333, Training Accuracy= 0.505\n",
      "Epoch: 4810, Loss= 0.9306, Training Accuracy= 0.505\n",
      "Epoch: 4820, Loss= 0.9274, Training Accuracy= 0.505\n",
      "Epoch: 4830, Loss= 0.9244, Training Accuracy= 0.505\n",
      "Epoch: 4840, Loss= 0.9199, Training Accuracy= 0.505\n",
      "Epoch: 4850, Loss= 0.9150, Training Accuracy= 0.505\n",
      "Epoch: 4860, Loss= 0.9099, Training Accuracy= 0.506\n",
      "Epoch: 4870, Loss= 0.9045, Training Accuracy= 0.506\n",
      "Epoch: 4880, Loss= 0.8985, Training Accuracy= 0.506\n",
      "Epoch: 4890, Loss= 0.8935, Training Accuracy= 0.506\n",
      "Epoch: 4900, Loss= 0.8885, Training Accuracy= 0.506\n",
      "Epoch: 4910, Loss= 0.8937, Training Accuracy= 0.505\n",
      "Epoch: 4920, Loss= 0.8869, Training Accuracy= 0.506\n",
      "Epoch: 4930, Loss= 0.8724, Training Accuracy= 0.506\n",
      "Epoch: 4940, Loss= 0.8606, Training Accuracy= 0.506\n",
      "Epoch: 4950, Loss= 0.8508, Training Accuracy= 0.507\n",
      "Epoch: 4960, Loss= 0.8371, Training Accuracy= 0.508\n",
      "Epoch: 4970, Loss= 0.8283, Training Accuracy= 0.510\n",
      "Epoch: 4980, Loss= 0.8227, Training Accuracy= 0.511\n",
      "Epoch: 4990, Loss= 0.8389, Training Accuracy= 0.510\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4946\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.45\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 5000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [0.50760001, 0.4903, 0.50169998, 0.49630001, 0.57749999, 0.50129998, 0.50050002, 0.72109997, 0.50389999, 0.4946]\n",
      "mean of test_accuracies_10replications:  0.52948\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.00068128913641\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08b3c95910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
