{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 2\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.7108, Training Accuracy= 0.505\n",
      "Epoch: 10, Loss= 0.7031, Training Accuracy= 0.505\n",
      "Epoch: 20, Loss= 0.6998, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.6978, Training Accuracy= 0.744\n",
      "Epoch: 40, Loss= 0.6962, Training Accuracy= 0.744\n",
      "Epoch: 50, Loss= 0.6949, Training Accuracy= 0.744\n",
      "Epoch: 60, Loss= 0.6936, Training Accuracy= 0.493\n",
      "Epoch: 70, Loss= 0.6924, Training Accuracy= 0.493\n",
      "Epoch: 80, Loss= 0.6912, Training Accuracy= 0.493\n",
      "Epoch: 90, Loss= 0.6901, Training Accuracy= 0.493\n",
      "Epoch: 100, Loss= 0.6890, Training Accuracy= 0.493\n",
      "Epoch: 110, Loss= 0.6879, Training Accuracy= 0.493\n",
      "Epoch: 120, Loss= 0.6867, Training Accuracy= 0.750\n",
      "Epoch: 130, Loss= 0.6856, Training Accuracy= 0.750\n",
      "Epoch: 140, Loss= 0.6845, Training Accuracy= 0.750\n",
      "Epoch: 150, Loss= 0.6833, Training Accuracy= 0.750\n",
      "Epoch: 160, Loss= 0.6822, Training Accuracy= 0.750\n",
      "Epoch: 170, Loss= 0.6809, Training Accuracy= 0.750\n",
      "Epoch: 180, Loss= 0.6796, Training Accuracy= 0.750\n",
      "Epoch: 190, Loss= 0.6783, Training Accuracy= 0.750\n",
      "Epoch: 200, Loss= 0.6769, Training Accuracy= 0.750\n",
      "Epoch: 210, Loss= 0.6755, Training Accuracy= 0.750\n",
      "Epoch: 220, Loss= 0.6739, Training Accuracy= 0.750\n",
      "Epoch: 230, Loss= 0.6723, Training Accuracy= 0.750\n",
      "Epoch: 240, Loss= 0.6706, Training Accuracy= 0.750\n",
      "Epoch: 250, Loss= 0.6688, Training Accuracy= 0.750\n",
      "Epoch: 260, Loss= 0.6668, Training Accuracy= 0.750\n",
      "Epoch: 270, Loss= 0.6648, Training Accuracy= 0.750\n",
      "Epoch: 280, Loss= 0.6626, Training Accuracy= 0.750\n",
      "Epoch: 290, Loss= 0.6603, Training Accuracy= 0.750\n",
      "Epoch: 300, Loss= 0.6578, Training Accuracy= 0.750\n",
      "Epoch: 310, Loss= 0.6552, Training Accuracy= 0.750\n",
      "Epoch: 320, Loss= 0.6525, Training Accuracy= 0.750\n",
      "Epoch: 330, Loss= 0.6495, Training Accuracy= 0.750\n",
      "Epoch: 340, Loss= 0.6464, Training Accuracy= 0.750\n",
      "Epoch: 350, Loss= 0.6431, Training Accuracy= 0.750\n",
      "Epoch: 360, Loss= 0.6395, Training Accuracy= 0.750\n",
      "Epoch: 370, Loss= 0.6358, Training Accuracy= 0.750\n",
      "Epoch: 380, Loss= 0.6318, Training Accuracy= 0.750\n",
      "Epoch: 390, Loss= 0.6277, Training Accuracy= 0.750\n",
      "Epoch: 400, Loss= 0.6232, Training Accuracy= 0.750\n",
      "Epoch: 410, Loss= 0.6185, Training Accuracy= 0.750\n",
      "Epoch: 420, Loss= 0.6136, Training Accuracy= 0.750\n",
      "Epoch: 430, Loss= 0.6084, Training Accuracy= 0.750\n",
      "Epoch: 440, Loss= 0.6029, Training Accuracy= 0.750\n",
      "Epoch: 450, Loss= 0.5971, Training Accuracy= 0.750\n",
      "Epoch: 460, Loss= 0.5910, Training Accuracy= 0.750\n",
      "Epoch: 470, Loss= 0.5846, Training Accuracy= 0.750\n",
      "Epoch: 480, Loss= 0.5778, Training Accuracy= 0.750\n",
      "Epoch: 490, Loss= 0.5708, Training Accuracy= 0.750\n",
      "Epoch: 500, Loss= 0.5635, Training Accuracy= 0.750\n",
      "Epoch: 510, Loss= 0.5558, Training Accuracy= 0.750\n",
      "Epoch: 520, Loss= 0.5479, Training Accuracy= 0.750\n",
      "Epoch: 530, Loss= 0.5396, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.5310, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.5222, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.5131, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.5037, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.4941, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4843, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.4743, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.4642, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.4540, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.4437, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.4333, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.4230, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.4127, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.4024, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.3922, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.3821, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.3722, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.3625, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.3529, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.3435, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.3344, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.3254, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.3167, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.3083, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.3001, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.2921, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.2844, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.2769, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.2696, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.2626, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.2559, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.2493, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.2430, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.2368, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.2309, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.2252, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.2197, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.2144, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.2092, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.2043, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.1995, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.1948, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.1904, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.1860, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.1819, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.1778, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1739, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1701, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1665, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1629, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1595, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1562, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1530, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1499, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1469, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1440, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1412, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1384, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1358, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1332, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1307, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.1283, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.1260, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.1237, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.1215, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.1194, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.1173, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1152, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1133, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1114, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1095, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1077, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1059, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1042, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1026, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1010, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0994, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0978, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0963, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0949, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0935, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0921, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0907, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0894, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0881, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0869, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0857, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0845, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0833, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0822, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0811, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0800, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0789, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0779, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0769, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0759, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.7401, Training Accuracy= 0.503\n",
      "Epoch: 10, Loss= 0.7232, Training Accuracy= 0.503\n",
      "Epoch: 20, Loss= 0.7153, Training Accuracy= 0.503\n",
      "Epoch: 30, Loss= 0.7097, Training Accuracy= 0.503\n",
      "Epoch: 40, Loss= 0.7054, Training Accuracy= 0.503\n",
      "Epoch: 50, Loss= 0.7021, Training Accuracy= 0.503\n",
      "Epoch: 60, Loss= 0.6993, Training Accuracy= 0.253\n",
      "Epoch: 70, Loss= 0.6968, Training Accuracy= 0.253\n",
      "Epoch: 80, Loss= 0.6947, Training Accuracy= 0.253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Loss= 0.6926, Training Accuracy= 0.253\n",
      "Epoch: 100, Loss= 0.6907, Training Accuracy= 0.253\n",
      "Epoch: 110, Loss= 0.6889, Training Accuracy= 0.508\n",
      "Epoch: 120, Loss= 0.6871, Training Accuracy= 0.508\n",
      "Epoch: 130, Loss= 0.6853, Training Accuracy= 0.508\n",
      "Epoch: 140, Loss= 0.6835, Training Accuracy= 0.508\n",
      "Epoch: 150, Loss= 0.6817, Training Accuracy= 0.508\n",
      "Epoch: 160, Loss= 0.6799, Training Accuracy= 0.508\n",
      "Epoch: 170, Loss= 0.6781, Training Accuracy= 0.508\n",
      "Epoch: 180, Loss= 0.6763, Training Accuracy= 0.508\n",
      "Epoch: 190, Loss= 0.6744, Training Accuracy= 0.508\n",
      "Epoch: 200, Loss= 0.6724, Training Accuracy= 0.508\n",
      "Epoch: 210, Loss= 0.6704, Training Accuracy= 0.508\n",
      "Epoch: 220, Loss= 0.6683, Training Accuracy= 0.508\n",
      "Epoch: 230, Loss= 0.6661, Training Accuracy= 0.757\n",
      "Epoch: 240, Loss= 0.6638, Training Accuracy= 0.757\n",
      "Epoch: 250, Loss= 0.6614, Training Accuracy= 0.757\n",
      "Epoch: 260, Loss= 0.6590, Training Accuracy= 0.757\n",
      "Epoch: 270, Loss= 0.6564, Training Accuracy= 0.757\n",
      "Epoch: 280, Loss= 0.6536, Training Accuracy= 0.757\n",
      "Epoch: 290, Loss= 0.6507, Training Accuracy= 0.757\n",
      "Epoch: 300, Loss= 0.6477, Training Accuracy= 0.757\n",
      "Epoch: 310, Loss= 0.6444, Training Accuracy= 0.757\n",
      "Epoch: 320, Loss= 0.6410, Training Accuracy= 0.757\n",
      "Epoch: 330, Loss= 0.6374, Training Accuracy= 0.757\n",
      "Epoch: 340, Loss= 0.6336, Training Accuracy= 0.757\n",
      "Epoch: 350, Loss= 0.6295, Training Accuracy= 0.757\n",
      "Epoch: 360, Loss= 0.6252, Training Accuracy= 0.757\n",
      "Epoch: 370, Loss= 0.6205, Training Accuracy= 0.757\n",
      "Epoch: 380, Loss= 0.6156, Training Accuracy= 0.757\n",
      "Epoch: 390, Loss= 0.6104, Training Accuracy= 0.757\n",
      "Epoch: 400, Loss= 0.6049, Training Accuracy= 0.757\n",
      "Epoch: 410, Loss= 0.5989, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5926, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5859, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5787, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5710, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5629, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5543, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5451, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5354, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.5251, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.5143, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.5028, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.4908, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.4783, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.4652, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.4517, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.4378, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.4235, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4090, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.3944, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.3797, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.3651, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.3507, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.3366, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.3228, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.3095, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.2967, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.2844, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.2726, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.2615, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.2509, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.2409, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.2314, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.2225, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.2141, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.2062, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.1987, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.1916, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.1850, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.1787, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.1728, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.1672, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.1620, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.1570, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.1522, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.1477, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.1435, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.1394, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.1356, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.1320, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.1285, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.1252, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.1220, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.1190, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.1161, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.1134, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.1107, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.1082, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.1058, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1034, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1012, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0991, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0970, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0950, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0931, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0913, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0895, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0878, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0862, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0846, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0830, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0815, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0801, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0787, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0774, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0761, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0748, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0736, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0724, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0712, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0701, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0690, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0680, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0670, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0660, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0650, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0641, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0631, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0623, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0614, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0605, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0597, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0589, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0581, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0574, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0566, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0559, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0552, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0545, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0538, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0531, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0525, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0519, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0513, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0506, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0501, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0495, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0489, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0484, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.7413, Training Accuracy= 0.244\n",
      "Epoch: 10, Loss= 0.6840, Training Accuracy= 0.494\n",
      "Epoch: 20, Loss= 0.6653, Training Accuracy= 0.747\n",
      "Epoch: 30, Loss= 0.6567, Training Accuracy= 0.747\n",
      "Epoch: 40, Loss= 0.6511, Training Accuracy= 0.747\n",
      "Epoch: 50, Loss= 0.6467, Training Accuracy= 0.747\n",
      "Epoch: 60, Loss= 0.6428, Training Accuracy= 0.747\n",
      "Epoch: 70, Loss= 0.6394, Training Accuracy= 0.747\n",
      "Epoch: 80, Loss= 0.6362, Training Accuracy= 0.747\n",
      "Epoch: 90, Loss= 0.6332, Training Accuracy= 0.747\n",
      "Epoch: 100, Loss= 0.6304, Training Accuracy= 0.747\n",
      "Epoch: 110, Loss= 0.6277, Training Accuracy= 0.747\n",
      "Epoch: 120, Loss= 0.6252, Training Accuracy= 0.747\n",
      "Epoch: 130, Loss= 0.6227, Training Accuracy= 0.747\n",
      "Epoch: 140, Loss= 0.6202, Training Accuracy= 0.747\n",
      "Epoch: 150, Loss= 0.6178, Training Accuracy= 0.747\n",
      "Epoch: 160, Loss= 0.6154, Training Accuracy= 0.747\n",
      "Epoch: 170, Loss= 0.6129, Training Accuracy= 0.747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, Loss= 0.6105, Training Accuracy= 0.747\n",
      "Epoch: 190, Loss= 0.6080, Training Accuracy= 0.747\n",
      "Epoch: 200, Loss= 0.6055, Training Accuracy= 0.747\n",
      "Epoch: 210, Loss= 0.6030, Training Accuracy= 0.747\n",
      "Epoch: 220, Loss= 0.6004, Training Accuracy= 0.747\n",
      "Epoch: 230, Loss= 0.5978, Training Accuracy= 0.747\n",
      "Epoch: 240, Loss= 0.5951, Training Accuracy= 0.747\n",
      "Epoch: 250, Loss= 0.5924, Training Accuracy= 0.747\n",
      "Epoch: 260, Loss= 0.5896, Training Accuracy= 0.747\n",
      "Epoch: 270, Loss= 0.5868, Training Accuracy= 0.747\n",
      "Epoch: 280, Loss= 0.5839, Training Accuracy= 0.747\n",
      "Epoch: 290, Loss= 0.5809, Training Accuracy= 0.747\n",
      "Epoch: 300, Loss= 0.5778, Training Accuracy= 0.747\n",
      "Epoch: 310, Loss= 0.5747, Training Accuracy= 0.747\n",
      "Epoch: 320, Loss= 0.5715, Training Accuracy= 0.747\n",
      "Epoch: 330, Loss= 0.5682, Training Accuracy= 0.747\n",
      "Epoch: 340, Loss= 0.5648, Training Accuracy= 0.747\n",
      "Epoch: 350, Loss= 0.5614, Training Accuracy= 0.747\n",
      "Epoch: 360, Loss= 0.5578, Training Accuracy= 0.747\n",
      "Epoch: 370, Loss= 0.5542, Training Accuracy= 0.747\n",
      "Epoch: 380, Loss= 0.5504, Training Accuracy= 0.747\n",
      "Epoch: 390, Loss= 0.5466, Training Accuracy= 0.747\n",
      "Epoch: 400, Loss= 0.5426, Training Accuracy= 0.747\n",
      "Epoch: 410, Loss= 0.5385, Training Accuracy= 0.747\n",
      "Epoch: 420, Loss= 0.5344, Training Accuracy= 0.747\n",
      "Epoch: 430, Loss= 0.5301, Training Accuracy= 0.747\n",
      "Epoch: 440, Loss= 0.5257, Training Accuracy= 0.747\n",
      "Epoch: 450, Loss= 0.5212, Training Accuracy= 0.747\n",
      "Epoch: 460, Loss= 0.5165, Training Accuracy= 0.747\n",
      "Epoch: 470, Loss= 0.5118, Training Accuracy= 0.747\n",
      "Epoch: 480, Loss= 0.5069, Training Accuracy= 0.747\n",
      "Epoch: 490, Loss= 0.5019, Training Accuracy= 0.747\n",
      "Epoch: 500, Loss= 0.4968, Training Accuracy= 0.747\n",
      "Epoch: 510, Loss= 0.4916, Training Accuracy= 0.747\n",
      "Epoch: 520, Loss= 0.4862, Training Accuracy= 0.747\n",
      "Epoch: 530, Loss= 0.4808, Training Accuracy= 0.747\n",
      "Epoch: 540, Loss= 0.4752, Training Accuracy= 0.747\n",
      "Epoch: 550, Loss= 0.4695, Training Accuracy= 0.747\n",
      "Epoch: 560, Loss= 0.4637, Training Accuracy= 0.747\n",
      "Epoch: 570, Loss= 0.4578, Training Accuracy= 0.747\n",
      "Epoch: 580, Loss= 0.4518, Training Accuracy= 0.747\n",
      "Epoch: 590, Loss= 0.4457, Training Accuracy= 0.747\n",
      "Epoch: 600, Loss= 0.4396, Training Accuracy= 0.747\n",
      "Epoch: 610, Loss= 0.4333, Training Accuracy= 0.747\n",
      "Epoch: 620, Loss= 0.4270, Training Accuracy= 0.747\n",
      "Epoch: 630, Loss= 0.4206, Training Accuracy= 0.747\n",
      "Epoch: 640, Loss= 0.4142, Training Accuracy= 0.747\n",
      "Epoch: 650, Loss= 0.4077, Training Accuracy= 0.747\n",
      "Epoch: 660, Loss= 0.4011, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.3945, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.3879, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.3812, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.3746, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.3679, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.3612, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.3545, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.3478, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.3412, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.3345, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.3279, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.3214, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.3149, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.3084, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.3020, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.2957, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.2895, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.2833, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.2772, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.2712, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.2654, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.2596, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.2539, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.2484, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.2429, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.2376, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.2324, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.2273, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.2223, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.2175, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.2128, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.2082, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.2037, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1994, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1951, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1910, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1870, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1832, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1794, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1757, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1722, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1687, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1654, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1621, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1590, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1559, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1530, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1501, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.1473, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.1446, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.1419, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.1394, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.1369, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.1345, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1321, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1299, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1277, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1255, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1234, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1214, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1194, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1175, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1156, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.1138, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.1120, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.1103, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.1087, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.1070, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.1054, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.1039, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.1024, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.1009, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0995, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0981, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0967, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0954, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0941, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0928, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0915, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0903, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0891, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0880, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0869, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 1.3392, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 1.0403, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.8348, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.7407, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.7071, Training Accuracy= 0.497\n",
      "Epoch: 50, Loss= 0.6956, Training Accuracy= 0.249\n",
      "Epoch: 60, Loss= 0.6913, Training Accuracy= 0.249\n",
      "Epoch: 70, Loss= 0.6894, Training Accuracy= 0.498\n",
      "Epoch: 80, Loss= 0.6884, Training Accuracy= 0.498\n",
      "Epoch: 90, Loss= 0.6876, Training Accuracy= 0.498\n",
      "Epoch: 100, Loss= 0.6870, Training Accuracy= 0.498\n",
      "Epoch: 110, Loss= 0.6864, Training Accuracy= 0.498\n",
      "Epoch: 120, Loss= 0.6858, Training Accuracy= 0.498\n",
      "Epoch: 130, Loss= 0.6852, Training Accuracy= 0.498\n",
      "Epoch: 140, Loss= 0.6845, Training Accuracy= 0.498\n",
      "Epoch: 150, Loss= 0.6839, Training Accuracy= 0.498\n",
      "Epoch: 160, Loss= 0.6832, Training Accuracy= 0.498\n",
      "Epoch: 170, Loss= 0.6826, Training Accuracy= 0.498\n",
      "Epoch: 180, Loss= 0.6819, Training Accuracy= 0.498\n",
      "Epoch: 190, Loss= 0.6811, Training Accuracy= 0.498\n",
      "Epoch: 200, Loss= 0.6804, Training Accuracy= 0.498\n",
      "Epoch: 210, Loss= 0.6796, Training Accuracy= 0.498\n",
      "Epoch: 220, Loss= 0.6788, Training Accuracy= 0.498\n",
      "Epoch: 230, Loss= 0.6780, Training Accuracy= 0.498\n",
      "Epoch: 240, Loss= 0.6771, Training Accuracy= 0.498\n",
      "Epoch: 250, Loss= 0.6762, Training Accuracy= 0.498\n",
      "Epoch: 260, Loss= 0.6752, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270, Loss= 0.6743, Training Accuracy= 0.498\n",
      "Epoch: 280, Loss= 0.6732, Training Accuracy= 0.498\n",
      "Epoch: 290, Loss= 0.6722, Training Accuracy= 0.498\n",
      "Epoch: 300, Loss= 0.6710, Training Accuracy= 0.498\n",
      "Epoch: 310, Loss= 0.6698, Training Accuracy= 0.498\n",
      "Epoch: 320, Loss= 0.6686, Training Accuracy= 0.498\n",
      "Epoch: 330, Loss= 0.6673, Training Accuracy= 0.752\n",
      "Epoch: 340, Loss= 0.6659, Training Accuracy= 0.752\n",
      "Epoch: 350, Loss= 0.6645, Training Accuracy= 0.752\n",
      "Epoch: 360, Loss= 0.6629, Training Accuracy= 0.752\n",
      "Epoch: 370, Loss= 0.6614, Training Accuracy= 0.752\n",
      "Epoch: 380, Loss= 0.6597, Training Accuracy= 0.752\n",
      "Epoch: 390, Loss= 0.6579, Training Accuracy= 0.752\n",
      "Epoch: 400, Loss= 0.6561, Training Accuracy= 0.752\n",
      "Epoch: 410, Loss= 0.6541, Training Accuracy= 0.752\n",
      "Epoch: 420, Loss= 0.6521, Training Accuracy= 0.752\n",
      "Epoch: 430, Loss= 0.6499, Training Accuracy= 0.752\n",
      "Epoch: 440, Loss= 0.6477, Training Accuracy= 0.752\n",
      "Epoch: 450, Loss= 0.6453, Training Accuracy= 0.752\n",
      "Epoch: 460, Loss= 0.6428, Training Accuracy= 0.752\n",
      "Epoch: 470, Loss= 0.6401, Training Accuracy= 0.752\n",
      "Epoch: 480, Loss= 0.6374, Training Accuracy= 0.752\n",
      "Epoch: 490, Loss= 0.6345, Training Accuracy= 0.752\n",
      "Epoch: 500, Loss= 0.6314, Training Accuracy= 0.752\n",
      "Epoch: 510, Loss= 0.6282, Training Accuracy= 0.752\n",
      "Epoch: 520, Loss= 0.6249, Training Accuracy= 0.752\n",
      "Epoch: 530, Loss= 0.6213, Training Accuracy= 0.752\n",
      "Epoch: 540, Loss= 0.6176, Training Accuracy= 0.752\n",
      "Epoch: 550, Loss= 0.6137, Training Accuracy= 0.752\n",
      "Epoch: 560, Loss= 0.6097, Training Accuracy= 0.752\n",
      "Epoch: 570, Loss= 0.6055, Training Accuracy= 0.752\n",
      "Epoch: 580, Loss= 0.6010, Training Accuracy= 0.752\n",
      "Epoch: 590, Loss= 0.5964, Training Accuracy= 0.752\n",
      "Epoch: 600, Loss= 0.5915, Training Accuracy= 0.752\n",
      "Epoch: 610, Loss= 0.5865, Training Accuracy= 0.752\n",
      "Epoch: 620, Loss= 0.5813, Training Accuracy= 0.752\n",
      "Epoch: 630, Loss= 0.5758, Training Accuracy= 0.752\n",
      "Epoch: 640, Loss= 0.5702, Training Accuracy= 0.752\n",
      "Epoch: 650, Loss= 0.5643, Training Accuracy= 0.752\n",
      "Epoch: 660, Loss= 0.5582, Training Accuracy= 0.752\n",
      "Epoch: 670, Loss= 0.5520, Training Accuracy= 0.752\n",
      "Epoch: 680, Loss= 0.5455, Training Accuracy= 0.752\n",
      "Epoch: 690, Loss= 0.5389, Training Accuracy= 0.752\n",
      "Epoch: 700, Loss= 0.5320, Training Accuracy= 0.752\n",
      "Epoch: 710, Loss= 0.5250, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.5178, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.5105, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.5030, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.4954, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.4877, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.4798, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.4719, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.4639, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.4558, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.4477, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.4396, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.4315, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.4233, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.4152, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.4072, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.3991, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.3912, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.3833, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.3755, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.3679, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.3603, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.3528, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.3454, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.3382, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.3311, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.3242, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.3173, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.3107, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.3041, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.2978, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.2915, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.2854, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.2795, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.2737, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.2680, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.2625, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.2571, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.2519, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.2468, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.2418, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.2369, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.2322, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.2276, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.2232, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.2188, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.2146, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.2105, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.2065, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.2026, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1988, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1952, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1916, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1881, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1847, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1814, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1782, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1750, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1720, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.1690, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.1661, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.1633, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.1605, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.1579, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.1553, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.1527, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.1502, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.1478, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.1455, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.1431, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.1409, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.1387, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.1366, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.1345, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.1325, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.1305, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.1285, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.1266, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.1248, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.9243, Training Accuracy= 0.496\n",
      "Epoch: 10, Loss= 0.7961, Training Accuracy= 0.496\n",
      "Epoch: 20, Loss= 0.7338, Training Accuracy= 0.743\n",
      "Epoch: 30, Loss= 0.7051, Training Accuracy= 0.491\n",
      "Epoch: 40, Loss= 0.6906, Training Accuracy= 0.491\n",
      "Epoch: 50, Loss= 0.6817, Training Accuracy= 0.491\n",
      "Epoch: 60, Loss= 0.6753, Training Accuracy= 0.491\n",
      "Epoch: 70, Loss= 0.6703, Training Accuracy= 0.491\n",
      "Epoch: 80, Loss= 0.6660, Training Accuracy= 0.748\n",
      "Epoch: 90, Loss= 0.6623, Training Accuracy= 0.748\n",
      "Epoch: 100, Loss= 0.6590, Training Accuracy= 0.748\n",
      "Epoch: 110, Loss= 0.6558, Training Accuracy= 0.748\n",
      "Epoch: 120, Loss= 0.6528, Training Accuracy= 0.748\n",
      "Epoch: 130, Loss= 0.6498, Training Accuracy= 0.748\n",
      "Epoch: 140, Loss= 0.6469, Training Accuracy= 0.501\n",
      "Epoch: 150, Loss= 0.6439, Training Accuracy= 0.501\n",
      "Epoch: 160, Loss= 0.6409, Training Accuracy= 0.501\n",
      "Epoch: 170, Loss= 0.6378, Training Accuracy= 0.501\n",
      "Epoch: 180, Loss= 0.6347, Training Accuracy= 0.501\n",
      "Epoch: 190, Loss= 0.6314, Training Accuracy= 0.501\n",
      "Epoch: 200, Loss= 0.6280, Training Accuracy= 0.501\n",
      "Epoch: 210, Loss= 0.6245, Training Accuracy= 0.501\n",
      "Epoch: 220, Loss= 0.6208, Training Accuracy= 0.501\n",
      "Epoch: 230, Loss= 0.6170, Training Accuracy= 0.748\n",
      "Epoch: 240, Loss= 0.6130, Training Accuracy= 0.748\n",
      "Epoch: 250, Loss= 0.6088, Training Accuracy= 0.748\n",
      "Epoch: 260, Loss= 0.6045, Training Accuracy= 0.748\n",
      "Epoch: 270, Loss= 0.5999, Training Accuracy= 0.748\n",
      "Epoch: 280, Loss= 0.5952, Training Accuracy= 0.748\n",
      "Epoch: 290, Loss= 0.5903, Training Accuracy= 0.748\n",
      "Epoch: 300, Loss= 0.5851, Training Accuracy= 0.748\n",
      "Epoch: 310, Loss= 0.5798, Training Accuracy= 0.748\n",
      "Epoch: 320, Loss= 0.5743, Training Accuracy= 0.748\n",
      "Epoch: 330, Loss= 0.5685, Training Accuracy= 0.748\n",
      "Epoch: 340, Loss= 0.5626, Training Accuracy= 0.748\n",
      "Epoch: 350, Loss= 0.5565, Training Accuracy= 0.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, Loss= 0.5501, Training Accuracy= 0.748\n",
      "Epoch: 370, Loss= 0.5436, Training Accuracy= 0.748\n",
      "Epoch: 380, Loss= 0.5368, Training Accuracy= 0.748\n",
      "Epoch: 390, Loss= 0.5299, Training Accuracy= 0.748\n",
      "Epoch: 400, Loss= 0.5228, Training Accuracy= 0.748\n",
      "Epoch: 410, Loss= 0.5155, Training Accuracy= 0.748\n",
      "Epoch: 420, Loss= 0.5081, Training Accuracy= 0.748\n",
      "Epoch: 430, Loss= 0.5005, Training Accuracy= 0.748\n",
      "Epoch: 440, Loss= 0.4927, Training Accuracy= 0.748\n",
      "Epoch: 450, Loss= 0.4848, Training Accuracy= 0.748\n",
      "Epoch: 460, Loss= 0.4768, Training Accuracy= 0.748\n",
      "Epoch: 470, Loss= 0.4686, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.4604, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.4520, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.4435, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.4350, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.4264, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.4177, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.4090, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.4003, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.3916, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.3829, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.3741, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.3654, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.3568, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.3482, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.3397, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.3312, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.3229, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.3146, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.3065, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.2985, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.2907, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.2830, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.2755, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.2681, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.2609, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.2539, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.2471, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.2404, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.2340, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.2277, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.2216, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.2158, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.2101, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.2045, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.1992, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.1941, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.1891, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.1843, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.1797, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.1752, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.1709, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.1667, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.1627, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.1588, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.1551, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.1515, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.1480, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.1447, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.1414, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.1383, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.1353, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.1324, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1296, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1268, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1242, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1217, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1192, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1168, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1146, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1123, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1102, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1081, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1061, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1041, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1022, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1004, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0986, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0969, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0952, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0936, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0920, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0905, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0890, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0876, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0862, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0848, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0835, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0822, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0809, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0797, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0785, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0773, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0762, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0751, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0740, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0730, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0720, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0710, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0700, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0690, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0681, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0672, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0663, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0655, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0646, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0638, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0630, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0622, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0614, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0607, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0600, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0592, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 0.8231, Training Accuracy= 0.252\n",
      "Epoch: 10, Loss= 0.7243, Training Accuracy= 0.504\n",
      "Epoch: 20, Loss= 0.6956, Training Accuracy= 0.504\n",
      "Epoch: 30, Loss= 0.6805, Training Accuracy= 0.504\n",
      "Epoch: 40, Loss= 0.6681, Training Accuracy= 0.504\n",
      "Epoch: 50, Loss= 0.6561, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6439, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6313, Training Accuracy= 0.753\n",
      "Epoch: 80, Loss= 0.6183, Training Accuracy= 0.753\n",
      "Epoch: 90, Loss= 0.6048, Training Accuracy= 0.753\n",
      "Epoch: 100, Loss= 0.5908, Training Accuracy= 0.753\n",
      "Epoch: 110, Loss= 0.5766, Training Accuracy= 0.753\n",
      "Epoch: 120, Loss= 0.5619, Training Accuracy= 0.753\n",
      "Epoch: 130, Loss= 0.5470, Training Accuracy= 0.753\n",
      "Epoch: 140, Loss= 0.5319, Training Accuracy= 1.000\n",
      "Epoch: 150, Loss= 0.5166, Training Accuracy= 1.000\n",
      "Epoch: 160, Loss= 0.5012, Training Accuracy= 1.000\n",
      "Epoch: 170, Loss= 0.4857, Training Accuracy= 1.000\n",
      "Epoch: 180, Loss= 0.4702, Training Accuracy= 1.000\n",
      "Epoch: 190, Loss= 0.4547, Training Accuracy= 1.000\n",
      "Epoch: 200, Loss= 0.4392, Training Accuracy= 1.000\n",
      "Epoch: 210, Loss= 0.4237, Training Accuracy= 1.000\n",
      "Epoch: 220, Loss= 0.4083, Training Accuracy= 1.000\n",
      "Epoch: 230, Loss= 0.3931, Training Accuracy= 1.000\n",
      "Epoch: 240, Loss= 0.3781, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.3632, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.3487, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.3345, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.3207, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.3072, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.2943, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.2818, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.2698, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.2584, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.2475, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.2371, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.2272, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.2179, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.2091, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.2007, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.1929, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.1854, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.1784, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.1718, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.1655, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 450, Loss= 0.1596, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.1541, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.1488, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.1438, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.1391, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.1347, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.1305, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.1265, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.1227, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.1191, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.1157, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.1124, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.1093, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.1064, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.1036, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.1009, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0983, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0959, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0935, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0913, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0891, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0871, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0851, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0832, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0814, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0797, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0780, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0764, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0748, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0733, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0719, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0705, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0692, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0679, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0666, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0654, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0642, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0631, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0620, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0610, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0599, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0589, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0580, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0570, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0561, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0552, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0544, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0536, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0528, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0520, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0512, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0505, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0497, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0490, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0484, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0477, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0470, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0464, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0458, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0452, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0446, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0440, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0435, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0429, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0424, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0419, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0413, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0408, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0404, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0399, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0394, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0390, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0385, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0381, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0377, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0372, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0368, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0364, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0360, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0356, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0353, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0349, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0345, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0342, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0338, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0335, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0332, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0328, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0325, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0322, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0319, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0316, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0313, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0310, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0307, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0304, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0301, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0298, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0296, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0293, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0291, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0288, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0285, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0283, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0280, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.7770, Training Accuracy= 0.747\n",
      "Epoch: 10, Loss= 0.7188, Training Accuracy= 0.747\n",
      "Epoch: 20, Loss= 0.7110, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.7054, Training Accuracy= 0.505\n",
      "Epoch: 40, Loss= 0.7004, Training Accuracy= 0.505\n",
      "Epoch: 50, Loss= 0.6958, Training Accuracy= 0.505\n",
      "Epoch: 60, Loss= 0.6917, Training Accuracy= 0.505\n",
      "Epoch: 70, Loss= 0.6878, Training Accuracy= 0.505\n",
      "Epoch: 80, Loss= 0.6843, Training Accuracy= 0.505\n",
      "Epoch: 90, Loss= 0.6809, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.6778, Training Accuracy= 0.505\n",
      "Epoch: 110, Loss= 0.6748, Training Accuracy= 0.505\n",
      "Epoch: 120, Loss= 0.6719, Training Accuracy= 0.505\n",
      "Epoch: 130, Loss= 0.6691, Training Accuracy= 0.505\n",
      "Epoch: 140, Loss= 0.6664, Training Accuracy= 0.505\n",
      "Epoch: 150, Loss= 0.6638, Training Accuracy= 0.505\n",
      "Epoch: 160, Loss= 0.6612, Training Accuracy= 0.505\n",
      "Epoch: 170, Loss= 0.6586, Training Accuracy= 0.505\n",
      "Epoch: 180, Loss= 0.6560, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.6534, Training Accuracy= 0.757\n",
      "Epoch: 200, Loss= 0.6507, Training Accuracy= 0.757\n",
      "Epoch: 210, Loss= 0.6481, Training Accuracy= 0.757\n",
      "Epoch: 220, Loss= 0.6453, Training Accuracy= 0.757\n",
      "Epoch: 230, Loss= 0.6425, Training Accuracy= 0.757\n",
      "Epoch: 240, Loss= 0.6395, Training Accuracy= 0.757\n",
      "Epoch: 250, Loss= 0.6365, Training Accuracy= 0.757\n",
      "Epoch: 260, Loss= 0.6333, Training Accuracy= 0.757\n",
      "Epoch: 270, Loss= 0.6300, Training Accuracy= 0.757\n",
      "Epoch: 280, Loss= 0.6266, Training Accuracy= 0.757\n",
      "Epoch: 290, Loss= 0.6230, Training Accuracy= 0.757\n",
      "Epoch: 300, Loss= 0.6192, Training Accuracy= 0.757\n",
      "Epoch: 310, Loss= 0.6153, Training Accuracy= 0.757\n",
      "Epoch: 320, Loss= 0.6111, Training Accuracy= 0.757\n",
      "Epoch: 330, Loss= 0.6068, Training Accuracy= 0.757\n",
      "Epoch: 340, Loss= 0.6022, Training Accuracy= 0.757\n",
      "Epoch: 350, Loss= 0.5974, Training Accuracy= 0.757\n",
      "Epoch: 360, Loss= 0.5924, Training Accuracy= 0.757\n",
      "Epoch: 370, Loss= 0.5871, Training Accuracy= 0.757\n",
      "Epoch: 380, Loss= 0.5816, Training Accuracy= 0.757\n",
      "Epoch: 390, Loss= 0.5758, Training Accuracy= 0.757\n",
      "Epoch: 400, Loss= 0.5698, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.5635, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5569, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5500, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5429, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5355, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5279, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5200, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5118, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5034, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.4948, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.4860, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.4770, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.4679, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 540, Loss= 0.4586, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.4492, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.4397, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.4301, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.4205, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4108, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.4011, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.3915, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.3819, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.3724, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.3629, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.3535, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.3442, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.3350, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.3260, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.3171, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.3084, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.2998, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.2913, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.2830, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.2750, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.2670, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.2593, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.2518, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.2444, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.2373, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.2303, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.2235, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.2170, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.2106, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.2044, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.1984, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.1926, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.1870, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.1816, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.1764, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.1714, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.1665, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.1618, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.1573, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.1529, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.1487, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.1446, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.1407, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.1370, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.1334, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1299, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1265, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1233, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1202, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1172, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1143, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1116, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1089, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1063, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1038, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1014, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0991, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0969, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0947, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0926, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0906, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0887, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0868, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0850, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0833, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0816, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0799, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0784, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0768, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0753, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0739, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0725, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0712, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0699, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0686, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0674, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0662, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0650, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0639, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0628, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0617, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0607, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0597, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0587, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0578, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0568, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0560, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0551, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0542, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0534, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0526, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0518, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0510, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0503, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0496, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 0.7033, Training Accuracy= 0.249\n",
      "Epoch: 10, Loss= 0.6934, Training Accuracy= 0.249\n",
      "Epoch: 20, Loss= 0.6884, Training Accuracy= 0.503\n",
      "Epoch: 30, Loss= 0.6856, Training Accuracy= 0.758\n",
      "Epoch: 40, Loss= 0.6837, Training Accuracy= 0.758\n",
      "Epoch: 50, Loss= 0.6822, Training Accuracy= 0.758\n",
      "Epoch: 60, Loss= 0.6808, Training Accuracy= 0.758\n",
      "Epoch: 70, Loss= 0.6795, Training Accuracy= 0.758\n",
      "Epoch: 80, Loss= 0.6781, Training Accuracy= 0.758\n",
      "Epoch: 90, Loss= 0.6767, Training Accuracy= 0.758\n",
      "Epoch: 100, Loss= 0.6752, Training Accuracy= 0.758\n",
      "Epoch: 110, Loss= 0.6737, Training Accuracy= 0.758\n",
      "Epoch: 120, Loss= 0.6720, Training Accuracy= 0.758\n",
      "Epoch: 130, Loss= 0.6703, Training Accuracy= 0.758\n",
      "Epoch: 140, Loss= 0.6685, Training Accuracy= 0.758\n",
      "Epoch: 150, Loss= 0.6666, Training Accuracy= 0.758\n",
      "Epoch: 160, Loss= 0.6646, Training Accuracy= 0.758\n",
      "Epoch: 170, Loss= 0.6624, Training Accuracy= 0.758\n",
      "Epoch: 180, Loss= 0.6602, Training Accuracy= 0.758\n",
      "Epoch: 190, Loss= 0.6579, Training Accuracy= 0.758\n",
      "Epoch: 200, Loss= 0.6554, Training Accuracy= 0.758\n",
      "Epoch: 210, Loss= 0.6528, Training Accuracy= 0.758\n",
      "Epoch: 220, Loss= 0.6500, Training Accuracy= 0.758\n",
      "Epoch: 230, Loss= 0.6472, Training Accuracy= 0.758\n",
      "Epoch: 240, Loss= 0.6442, Training Accuracy= 0.758\n",
      "Epoch: 250, Loss= 0.6411, Training Accuracy= 0.758\n",
      "Epoch: 260, Loss= 0.6378, Training Accuracy= 0.758\n",
      "Epoch: 270, Loss= 0.6344, Training Accuracy= 0.758\n",
      "Epoch: 280, Loss= 0.6308, Training Accuracy= 0.758\n",
      "Epoch: 290, Loss= 0.6271, Training Accuracy= 0.758\n",
      "Epoch: 300, Loss= 0.6232, Training Accuracy= 0.758\n",
      "Epoch: 310, Loss= 0.6192, Training Accuracy= 0.758\n",
      "Epoch: 320, Loss= 0.6150, Training Accuracy= 0.758\n",
      "Epoch: 330, Loss= 0.6107, Training Accuracy= 0.758\n",
      "Epoch: 340, Loss= 0.6061, Training Accuracy= 0.758\n",
      "Epoch: 350, Loss= 0.6015, Training Accuracy= 0.758\n",
      "Epoch: 360, Loss= 0.5966, Training Accuracy= 0.758\n",
      "Epoch: 370, Loss= 0.5916, Training Accuracy= 0.758\n",
      "Epoch: 380, Loss= 0.5864, Training Accuracy= 0.758\n",
      "Epoch: 390, Loss= 0.5811, Training Accuracy= 0.758\n",
      "Epoch: 400, Loss= 0.5755, Training Accuracy= 0.758\n",
      "Epoch: 410, Loss= 0.5698, Training Accuracy= 0.758\n",
      "Epoch: 420, Loss= 0.5640, Training Accuracy= 0.758\n",
      "Epoch: 430, Loss= 0.5579, Training Accuracy= 0.758\n",
      "Epoch: 440, Loss= 0.5518, Training Accuracy= 0.758\n",
      "Epoch: 450, Loss= 0.5454, Training Accuracy= 0.758\n",
      "Epoch: 460, Loss= 0.5389, Training Accuracy= 0.758\n",
      "Epoch: 470, Loss= 0.5323, Training Accuracy= 0.758\n",
      "Epoch: 480, Loss= 0.5256, Training Accuracy= 0.758\n",
      "Epoch: 490, Loss= 0.5188, Training Accuracy= 0.758\n",
      "Epoch: 500, Loss= 0.5118, Training Accuracy= 0.758\n",
      "Epoch: 510, Loss= 0.5048, Training Accuracy= 0.758\n",
      "Epoch: 520, Loss= 0.4977, Training Accuracy= 0.758\n",
      "Epoch: 530, Loss= 0.4905, Training Accuracy= 0.758\n",
      "Epoch: 540, Loss= 0.4832, Training Accuracy= 0.758\n",
      "Epoch: 550, Loss= 0.4760, Training Accuracy= 0.758\n",
      "Epoch: 560, Loss= 0.4686, Training Accuracy= 0.758\n",
      "Epoch: 570, Loss= 0.4613, Training Accuracy= 0.758\n",
      "Epoch: 580, Loss= 0.4540, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4466, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.4393, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.4320, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.4247, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 630, Loss= 0.4175, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.4103, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.4031, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.3960, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.3890, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.3820, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.3751, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.3683, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.3616, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.3549, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.3484, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.3419, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.3355, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.3292, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.3230, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.3169, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.3109, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.3050, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.2992, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.2935, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.2879, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.2824, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.2770, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.2717, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.2665, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.2614, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.2564, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.2515, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.2467, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.2420, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.2375, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.2330, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.2286, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.2242, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.2200, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.2159, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.2119, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.2080, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.2041, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.2004, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1967, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1931, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1896, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1862, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1829, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1796, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1764, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1733, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1703, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1673, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1645, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1616, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.1589, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.1562, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.1536, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.1510, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.1485, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.1461, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1437, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1414, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1391, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1369, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1347, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1326, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1305, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1285, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1265, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.1246, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.1227, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.1209, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.1191, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.1174, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.1156, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.1140, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.1123, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.1107, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.1092, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.1076, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.1061, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.1047, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.1032, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.1018, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.1005, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0991, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0978, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0965, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0952, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 1.3752, Training Accuracy= 0.494\n",
      "Epoch: 10, Loss= 0.9601, Training Accuracy= 0.494\n",
      "Epoch: 20, Loss= 0.8127, Training Accuracy= 0.491\n",
      "Epoch: 30, Loss= 0.7760, Training Accuracy= 0.491\n",
      "Epoch: 40, Loss= 0.7632, Training Accuracy= 0.491\n",
      "Epoch: 50, Loss= 0.7547, Training Accuracy= 0.491\n",
      "Epoch: 60, Loss= 0.7477, Training Accuracy= 0.491\n",
      "Epoch: 70, Loss= 0.7414, Training Accuracy= 0.491\n",
      "Epoch: 80, Loss= 0.7358, Training Accuracy= 0.491\n",
      "Epoch: 90, Loss= 0.7308, Training Accuracy= 0.491\n",
      "Epoch: 100, Loss= 0.7261, Training Accuracy= 0.491\n",
      "Epoch: 110, Loss= 0.7218, Training Accuracy= 0.491\n",
      "Epoch: 120, Loss= 0.7178, Training Accuracy= 0.491\n",
      "Epoch: 130, Loss= 0.7141, Training Accuracy= 0.491\n",
      "Epoch: 140, Loss= 0.7105, Training Accuracy= 0.491\n",
      "Epoch: 150, Loss= 0.7071, Training Accuracy= 0.491\n",
      "Epoch: 160, Loss= 0.7038, Training Accuracy= 0.491\n",
      "Epoch: 170, Loss= 0.7007, Training Accuracy= 0.491\n",
      "Epoch: 180, Loss= 0.6975, Training Accuracy= 0.491\n",
      "Epoch: 190, Loss= 0.6944, Training Accuracy= 0.491\n",
      "Epoch: 200, Loss= 0.6913, Training Accuracy= 0.491\n",
      "Epoch: 210, Loss= 0.6883, Training Accuracy= 0.491\n",
      "Epoch: 220, Loss= 0.6851, Training Accuracy= 0.491\n",
      "Epoch: 230, Loss= 0.6819, Training Accuracy= 0.491\n",
      "Epoch: 240, Loss= 0.6787, Training Accuracy= 0.491\n",
      "Epoch: 250, Loss= 0.6754, Training Accuracy= 0.491\n",
      "Epoch: 260, Loss= 0.6720, Training Accuracy= 0.491\n",
      "Epoch: 270, Loss= 0.6684, Training Accuracy= 0.491\n",
      "Epoch: 280, Loss= 0.6648, Training Accuracy= 0.491\n",
      "Epoch: 290, Loss= 0.6610, Training Accuracy= 0.491\n",
      "Epoch: 300, Loss= 0.6571, Training Accuracy= 0.491\n",
      "Epoch: 310, Loss= 0.6530, Training Accuracy= 0.491\n",
      "Epoch: 320, Loss= 0.6487, Training Accuracy= 0.491\n",
      "Epoch: 330, Loss= 0.6442, Training Accuracy= 0.491\n",
      "Epoch: 340, Loss= 0.6395, Training Accuracy= 0.491\n",
      "Epoch: 350, Loss= 0.6346, Training Accuracy= 0.491\n",
      "Epoch: 360, Loss= 0.6295, Training Accuracy= 0.746\n",
      "Epoch: 370, Loss= 0.6241, Training Accuracy= 0.746\n",
      "Epoch: 380, Loss= 0.6184, Training Accuracy= 0.746\n",
      "Epoch: 390, Loss= 0.6124, Training Accuracy= 0.746\n",
      "Epoch: 400, Loss= 0.6061, Training Accuracy= 0.746\n",
      "Epoch: 410, Loss= 0.5994, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5924, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5850, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5773, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5691, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5605, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5515, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5421, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5323, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.5221, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.5115, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.5006, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.4895, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.4780, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.4664, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.4546, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.4426, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.4307, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4187, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.4068, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.3950, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.3833, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.3718, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.3605, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.3494, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.3387, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.3281, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.3180, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.3081, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.2985, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.2893, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 720, Loss= 0.2803, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.2717, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.2635, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.2555, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.2478, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.2405, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.2334, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.2266, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.2201, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.2138, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.2078, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.2021, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.1965, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.1912, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.1861, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.1812, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.1765, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.1720, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.1676, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.1635, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.1595, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.1556, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.1519, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.1483, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.1449, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.1416, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.1384, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.1353, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1323, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1295, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1267, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1241, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1215, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1190, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1166, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1143, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1121, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1099, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1078, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1058, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1038, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1019, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1001, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0983, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0966, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0949, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0933, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0917, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0902, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0887, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0872, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0858, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0845, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0831, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0819, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0806, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0794, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0782, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0770, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0759, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0748, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0738, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0727, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0717, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0707, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0697, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0688, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0679, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0670, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0661, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0653, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0644, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0636, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0628, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0620, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0613, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0605, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0598, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 1.4585, Training Accuracy= 0.503\n",
      "Epoch: 10, Loss= 1.0166, Training Accuracy= 0.503\n",
      "Epoch: 20, Loss= 0.8159, Training Accuracy= 0.503\n",
      "Epoch: 30, Loss= 0.7531, Training Accuracy= 0.503\n",
      "Epoch: 40, Loss= 0.7316, Training Accuracy= 0.750\n",
      "Epoch: 50, Loss= 0.7223, Training Accuracy= 0.750\n",
      "Epoch: 60, Loss= 0.7168, Training Accuracy= 0.750\n",
      "Epoch: 70, Loss= 0.7129, Training Accuracy= 0.498\n",
      "Epoch: 80, Loss= 0.7097, Training Accuracy= 0.498\n",
      "Epoch: 90, Loss= 0.7070, Training Accuracy= 0.498\n",
      "Epoch: 100, Loss= 0.7046, Training Accuracy= 0.750\n",
      "Epoch: 110, Loss= 0.7025, Training Accuracy= 0.750\n",
      "Epoch: 120, Loss= 0.7006, Training Accuracy= 0.750\n",
      "Epoch: 130, Loss= 0.6989, Training Accuracy= 0.750\n",
      "Epoch: 140, Loss= 0.6974, Training Accuracy= 0.750\n",
      "Epoch: 150, Loss= 0.6960, Training Accuracy= 0.750\n",
      "Epoch: 160, Loss= 0.6947, Training Accuracy= 0.750\n",
      "Epoch: 170, Loss= 0.6935, Training Accuracy= 0.750\n",
      "Epoch: 180, Loss= 0.6925, Training Accuracy= 0.750\n",
      "Epoch: 190, Loss= 0.6915, Training Accuracy= 0.750\n",
      "Epoch: 200, Loss= 0.6905, Training Accuracy= 0.750\n",
      "Epoch: 210, Loss= 0.6896, Training Accuracy= 0.499\n",
      "Epoch: 220, Loss= 0.6887, Training Accuracy= 0.499\n",
      "Epoch: 230, Loss= 0.6878, Training Accuracy= 0.499\n",
      "Epoch: 240, Loss= 0.6870, Training Accuracy= 0.499\n",
      "Epoch: 250, Loss= 0.6862, Training Accuracy= 0.499\n",
      "Epoch: 260, Loss= 0.6854, Training Accuracy= 0.499\n",
      "Epoch: 270, Loss= 0.6845, Training Accuracy= 0.499\n",
      "Epoch: 280, Loss= 0.6837, Training Accuracy= 0.499\n",
      "Epoch: 290, Loss= 0.6829, Training Accuracy= 0.499\n",
      "Epoch: 300, Loss= 0.6820, Training Accuracy= 0.499\n",
      "Epoch: 310, Loss= 0.6812, Training Accuracy= 0.499\n",
      "Epoch: 320, Loss= 0.6803, Training Accuracy= 0.499\n",
      "Epoch: 330, Loss= 0.6793, Training Accuracy= 0.499\n",
      "Epoch: 340, Loss= 0.6784, Training Accuracy= 0.499\n",
      "Epoch: 350, Loss= 0.6773, Training Accuracy= 0.499\n",
      "Epoch: 360, Loss= 0.6763, Training Accuracy= 0.499\n",
      "Epoch: 370, Loss= 0.6752, Training Accuracy= 0.499\n",
      "Epoch: 380, Loss= 0.6740, Training Accuracy= 0.499\n",
      "Epoch: 390, Loss= 0.6727, Training Accuracy= 0.499\n",
      "Epoch: 400, Loss= 0.6714, Training Accuracy= 0.749\n",
      "Epoch: 410, Loss= 0.6700, Training Accuracy= 0.749\n",
      "Epoch: 420, Loss= 0.6685, Training Accuracy= 0.749\n",
      "Epoch: 430, Loss= 0.6669, Training Accuracy= 0.749\n",
      "Epoch: 440, Loss= 0.6652, Training Accuracy= 0.749\n",
      "Epoch: 450, Loss= 0.6634, Training Accuracy= 0.749\n",
      "Epoch: 460, Loss= 0.6615, Training Accuracy= 0.749\n",
      "Epoch: 470, Loss= 0.6594, Training Accuracy= 0.749\n",
      "Epoch: 480, Loss= 0.6573, Training Accuracy= 0.749\n",
      "Epoch: 490, Loss= 0.6549, Training Accuracy= 0.749\n",
      "Epoch: 500, Loss= 0.6524, Training Accuracy= 0.749\n",
      "Epoch: 510, Loss= 0.6497, Training Accuracy= 0.749\n",
      "Epoch: 520, Loss= 0.6468, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.6437, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.6404, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.6370, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.6332, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.6292, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.6249, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.6204, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.6156, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.6104, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.6050, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.5993, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.5932, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.5868, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.5800, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.5729, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.5654, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.5576, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.5495, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.5411, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.5323, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.5232, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.5139, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.5043, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.4945, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.4845, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.4743, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.4640, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.4535, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 810, Loss= 0.4431, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.4326, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.4220, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.4116, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.4012, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.3909, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.3807, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.3706, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.3607, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.3511, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.3416, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.3323, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.3232, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.3144, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.3058, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.2974, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.2893, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.2814, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.2738, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.2664, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.2593, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.2524, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.2457, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.2392, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.2330, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.2270, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.2211, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.2155, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.2101, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.2049, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1998, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1949, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1902, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1857, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.1813, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.1771, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.1730, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.1690, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.1652, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.1615, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1580, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1545, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1512, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1480, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1448, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1418, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1389, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1361, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1334, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.1307, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.1281, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.1256, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.1232, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.1209, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.1186, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.1164, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.1143, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.1122, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.1102, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.1082, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.1063, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.1045, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.1027, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.1009, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0992, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0976, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0960, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0944, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0929, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.000275\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 1500\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a RNN cell with tensorflow\n",
    "    rnn_cell = rnn.BasicRNNCell(num_hidden)\n",
    "\n",
    "    # Get RNN cell output\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  1.0\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.0\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd4FVX6wPHvm4QeWmihh0AAQQUk\nAioqCBYQddW1oCi2RbG3VbH/XNddy7q7ig17QSysIjZQEVFUei8CoYcaei9J3t8fMwmXcMsk3Jbk\n/TzPfe6dmTNz31y4894558w5oqoYY4wxAAmxDsAYY0z8sKRgjDGmkCUFY4wxhSwpGGOMKWRJwRhj\nTCFLCsYYYwpZUjAmTESkh4hk+yzPF5EeEXifb0VkYLiPawxYUjClgIjcKiLTRGS/iLxTjP1WiEjv\nCIYWlKq2V9WfjuYYIvK4iHxQ5Lh9VPXdowrOmACSYh2AMR6sBZ4EzgaqROpNRCRJVXMjdXxjSgO7\nUjBxT1U/U9VRwOai20Skroh8JSLbRGSLiPwiIgki8j7QDPhSRHaJyH1+9u0hItkicr+IrAfedtf3\nE5FZ7jF/E5HjffZZISJDRGSBiGwVkbdFpLK/uH2vVEQkUUQeFJGlIrJTRKaLSFN3239FZLWI7HDX\nn+quPwd4ELjM/Rtmu+t/EpEb3NcJIvKwiKwUkY0i8p6I1HS3pYmIishAEVklIptE5KGS/0uY8sCS\ngint7gGygXpAA5yTqKrqVcAq4DxVTVbVZwLsnwqkAM2BQSJyAvAWcCNQB3gNGC0ilXz2uRLnqqUl\n0Bp42EOcdwP9gb5ADeA6YI+7bSrQ0Y3jQ+BTEamsqmOAp4CP3b+hg5/jXuM+egLpQDIwtEiZ7kAb\noBfwqIgc4yFeU05ZUjCl3UGgIdBcVQ+q6i9avAG98oHHVHW/qu4F/gK8pqqTVTXPrbvfD3Tz2Weo\nqq5W1S3A33FO9qHcADysqovUMVtVNwOo6gequllVc1X1X0AlnJO4F1cCz6vqMlXdBQwBLhcR36rh\n/1PVvao6G5gN+EsuxgCWFEzp9yyQBXwnIstE5IFi7p+jqvt8lpsD97hVR9tEZBvQFGjkU2a1z+uV\nRbYF0hRY6m+DiNwjIgtFZLv7fjWBuh7jb+TG4BtPEs5VU4H1Pq/34FxNGOOXJQVTqqnqTlW9R1XT\ngfOAu0WkV8FmL4cosrwa+Luq1vJ5VFXVET5lmvq8bobTEB7KapzqpsO47Qf3A5cCtVW1FrAdEI9/\nw1qcROYbTy6wwUNMxhzBkoKJeyKS5DbmJgKJIlK5oHrEbRRuJSIC7ADy3Ac4J8b0Yr7d68BNItJV\nHNVE5FwRqe5T5hYRaSIiKThtGB97OO4bwN9EJMM97vEiUgeojnMSzwGSRORRnDaHAhuANBEJ9F0d\nAdwlIi1EJJlDbRDWi8qUiCUFUxo8DOwFHgAGuK8LGnczgB+AXcDvwMs+9wb8A3jYrQa618sbqeo0\nnHaFocBWnKqpa4oU+xD4DljmPp70cOjngU/c/XYAb+J0rx0LfAssxqn62cfh1VOfus+bRWSGn+O+\nBbwP/Awsd/e/zUM8xvglNsmOMd6JyArgBlX9IdaxGBMJdqVgjDGmUMikICKniMj3IrLY7d2xXESW\nedjvLfdmmnkBtl8pInPcx28iYt3kjDEmxkJWH4nIH8BdwHQONeBR0Mc6yH6n4dTzvqeqx/rZfjKw\nUFW3ikgf4HFV7Vr8P8EYY0y4eBn7aLuqflvcA6vqzyKSFmT7bz6Lk4AmxX0PY4wx4eUlKYwXkWeB\nz3Du7ARAVf31hCip63F6YPglIoOAQQDVqlXr3LZt2zC+tTHGlH3Tp0/fpKr1QpXzkhQKqnQyfdYp\ncEZJAitKRHriJIXugcqo6jBgGEBmZqZOmzYtHG9tjDHlhoisDF3KQ1JQ1Z5HH45/7uiTbwB9QrVR\nGGOMiTwvvY8aiMibIvKtu9xORK4/2jcWkWY4VVJXqerioz2eMcaYo+flPoV3cO66LBj0azFwZ6id\nRGQEzh2mbdwx668XkZtE5Ca3yKM4QxO/7I5db3VCxhgTY17aFOqq6iciMgRAVXNFJC/UTqoadDhh\nVb0BZzhhY4wxccLLlcJud+AuBRCRbjijOBpjjCljvFwp3A2MBlqKyK84M1z9OaJRGWOMiQkvvY9m\niMjpODNBCbBIVQ9GPDJjjDFR56X3UVWcIYvvVNV5OGO794t4ZMYYY6LOS5vC28AB4CR3ORtv48cb\nY4wpZbwkhZaq+gzOBOm4k5tL8F2MMcaURl6SwgERqcKh3kct8RkDyRhjTNnhpffRY8AYoKmIDAdO\n4cjpCY0xxpQBQZOCOxn6H8BFQDecaqM7VHVTFGIzxhgTZUGTgqqqiIxS1c7A11GKyRhjTIx4aVOY\nJCInRjwSY4wxMeelTaEncKM7FvdunCokVdXjIxqZMcaYqPOSFPpEPApjjDFxwUtS2OlxnTHGmFLO\nS5vCDCAHZx6FJe7r5SIyQ0Q6RzI4Y4wx0eUlKYwB+qpqXVWtg1Od9AlwM/ByJIMzxhgTXV6SQqaq\nji1YUNXvgNNUdRJQKWKRGWOMiTovbQpbROR+4CN3+TJgq4gkAvkRi8wYY0zUeblSuAJoAoxyH03d\ndYnApZELzRhjTLR5mWRnE3BbgM1Z4Q3HGGNMLHm5UjDGGFNOWFIwxhhTyJKCMcaYQiHbFESkHvAX\nIM23vKpeF7mwjDHGxIKXLqlfAL8APwB5kQ3HGGNMLHlJClVV9f6IR2KMMSbmvLQpfCUifSMeiTHG\nmJjzcqVwB/CgiOwHDnJoPoUawXYSkbeAfsBGVT3Wz3YB/gv0BfYA16jqjGLGb0q5yZNh6FD49VfY\nty/W0RhjvNy8Vr2Ex34HGAq8F2B7HyDDfXQFXnGfTTnx669w9tmwe3esIzHGFAiYFESkrar+ISIn\n+Nse6le9qv4sImlBilwAvKeqijPlZy0Raaiq6zzEbcqAJ590EsJA3uFBniKZXbEOyZgyq7HHcsGu\nFO4GBgH/8rNNgTOKG1QRjYHVPsvZ7jpLCuWAKvz8M4DyPHeTwtZYh2SMIUhSUNVB7nPPCL23+Htb\nvwVFBuEkKJo1axahcEw05efDnj2QQL4lBGPiiJeG5kjJxhlxtUATYK2/gqo6DBgGkJmZ6TdxmNJF\n3X9F8fkdkEcCTQ+7eDTGhI+3CqRYJoXRwK0i8hFOA/N2a08oP/LdmTgSfKbkyCeBdTSKUUTGGIhg\nUhCREUAPoK6IZAOPARUAVPVV4Buc7qhZOF1Sr41ULCb++LtSULdGMSkJVq6MRVTGlF2NPbY0exn7\n6BRglqruFpEBwAnAf1U16NdWVfuH2K7ALd7CNGVNsKSQkACN7ILBmJjwckfzK8AeEekA3AesJPC9\nB8Z44i8p5Lv/HcVfFwRjTFR4SQq57q/6C3CuEP4LlPSGNmMA/20KBVcKlhSMiR0vbQo7RWQIMAA4\nTUQScdsGjCmpUNVHxpjY8PL1uwzYD1yvqutx+jU9G9GoTJln1UfGxCdPVwo41UZ5ItIaaAuMiGxY\npqwrSApWfWRMfPFypfAzUElEGgPjcLqOvhPJoEzZV9Cm4K/6yJKCMbHjJSmIqu4BLgJeVNULgfaR\nDcuUddamYEx88pQUROQk4Erga3ddYuRCMuWBtSkYE5+8JIU7gSHA56o6X0TSgfGRDcuUddamYEx8\n8jLJzgRggohUF5FkVV0G3B750ExZFqxNwaqPjImdkF8/ETlORGYC84AFIjJdRKxNwRwVqz4yJj55\n+U32GnC3qjZX1WbAPcDrkQ3LlHVWfWRMfPKSFKqpamEbgqr+BFSLWESmXLAuqcbEJy83ry0TkUeA\n993lAcDyyIVkygPrkmpMfPLy9bsOqAd8Bnzuvra5D8xRsTYFY+KTl95HW7HeRibMrE3BmPgUMCmI\nyJfg8zOuCFU9PyIRmXLB2hSMiU/BrhSei1oUptwJVn1kbQrGxE7ApODetGZMRARraLYrBWNix36T\nmZiwNgVj4pMlBRMT1qZgTHyypGBiwtoUjIlPXm5eO4yIPAVsB95Q1c3hD8mUB1Z9ZEx8KslvsilA\nLvDvMMdiyhFraDYmPhX7SkFVR0UiEFO++GtTsOojY2Iv2M1rLxL85jW7y9mUmF0pGBOfgv0mmwZM\nByoDJwBL3EdHIC/yoZmyzNoUjIlPwW5eexdARK4BeqrqQXf5VeC7qERnyizrkmpMfPJSe9sIqO6z\nnOyuC0lEzhGRRSKSJSIP+NneTETGi8hMEZkjIn29hW1KO+uSakx88tLQ/E9gpogUTLRzOvB4qJ1E\nJBF4CTgTyAamishoVV3gU+xh4BNVfUVE2gHfAGnewzellVUfGROfvAyd/baIfAt0dVc9oKrrPRy7\nC5ClqssAROQj4ALANykoUMN9XRNY6zVwU7pZQ7Mx8SnkhbqICNAb6KCqXwAVRaSLh2M3Blb7LGe7\n63w9DgwQkWycq4TbAsQwSESmici0nJwcD29t4p21KRgTn7zU3r4MnAT0d5d34lQLheLvq120i2t/\n4B1VbQL0Bd4XkSNiUtVhqpqpqpn16tXz8NYm3lmbgjHxycvXr6uq3gLsg8KZ2Cp62C8baOqz3IQj\nq4euBz5xj/s7TvfXuh6ObUo5a1MwJj55SQoH3UZjBRCReuDzTQ5sKpAhIi1EpCJwOTC6SJlVQC/3\nuMfgJAWrHyoHrE3BmPjkJSm8AHwO1BeRvwMTgadC7aSqucCtwFhgIU4vo/ki8oSIFEzleQ/wFxGZ\nDYwArlHVgHdRm7Ij2DAXlhSMiR0vvY+Gi8h0nF/0AvxJVRd6ObiqfoPTgOy77lGf1wuAU4oVcYTN\nmQPffw/r1sU6krKt4PP1V31kbQrGxE7QpOA2+s5R1WOBP6ITUvGsXQvjxsGmTYHLVK8OPXpAy5bB\nf4U+/TQ8+EAeffmGNiwKe6zmkIY4l4nNWVm4zqqPjIm9oElBVfNFZLaINFPVVdEKyqvnn4d77vFe\nfvBgGDrU/y/RX3+FBx6AmxjGK9wcviCNZ5YUjIk9L3c0NwTmi8gUYHfBSlU9P/Aukff9905COI45\nvMDtpLEiYNlN1OUB/skrr/SmfXu45ZYjy3z7rfN8Mr9FJmAT0iw6ApYUjIklL0nh/yIeRQmMdvsx\n3ccz9GBC0LJprOQpHqQrvfnyS/9JYcUK59m3jvsb+rCAdmGK2ASzhsa8zbUAtG4d42CMKce8NDQH\nP+PGyOLFznN9NnoqX8/t6booQFOBvy6Sw7mSD7myxDGakjnvvFhHYEz5VeyZ1+KFvy6NV/Eev3Bq\n4XITspnoLheUC9ThNdgdtiZ6HnkELr441lEYU36VuqRwMP8g4P8kvo6GrPQZZFV9RtooqBYqTlIo\n2P+KK6BTp6ON3ASTkgI9e0KLFrGOxJjyrdQlhYU5C5m2dhqqmYD/fu5nnuk0RPsmhVBXCgVXHv6O\n168f9O/vby9jjClbvIySeoqIfC8ii0VkmYgsF5Fl0QjOn4N5Bzn17VPJ3u4Mo+Tvl/2AAc6yb/VP\nQbn8AAN0BLtSsJupjDHlhZcrhTeBu3Dma46LuZn35e5j8abFQCO/bQCJic5yuKqPrIukMaa88PIb\neLuqfquqG1V1c8Ej4pGF5P6K91Pdc98P9xy27JR2Tva5+bnsz91/xNGCNTRbUjDGlBderhTGi8iz\nwGdA4dlUVWdELCov1D1h+/llv3bX6sOWfctt3JVD5b83onbl2jSs3pDU5FQaJjdkzob7geNsKGdj\nTLnmJSkUTMOZ6bNOgTPCH04xqHvC9pMUEOfE7q9NoSCZbN23la37trIgx50ddNPFwHF+j3fXd3fw\n2t4FNKreiIbJDWlUvdFhj4bJDamUVCkSf6UxxkSVl5vXekYjEK/a1G1DRusMviYBJUBSSMg7fBmf\naiYN8LM/SJLJ3rGK7GU/BI0rpUrK4ckiuRENqx+eQFKTU6mY6GV+ImOMiY2ASUFEBqjqByJyt7/t\nqvp85MIKLLliMl/2/5Iu/8ll6urD2xQKrwzkyKRw6GQfqC7oyKRw6Eoj9BQPW/ZuYcveLczbOC9o\nubpV69KkRhMyUjJoXaf1YY+UKikh38cYYyIp2JVCNfe5ejQCKa4EcUL398v+332e566P/FcfCQnu\nUpETvQZuuEbCN+/Ppj2b2LRnE7PWzzpiW50qdcio4yaLlEPJom3dtlY9ZYyJioBJQVVfc5/jckC8\nYF1I29RrddgyHDrZ16pUh42PHGDTnk2s37WetTvXsm7nOp4Z05bFAY5X0EYRaZv3bmZz9mYmZU86\nbH1SQhJt67alQ4MOziO1A51SO1GvWr2oxGWMKT9K3R3NBfyNfVT0ZrNAdzQnJSSRmpxKanIqHVOd\n4Zo/SyFgUvj3Of+mVbcbWbdzHWt3rnUeu9YWvt64eyP5GrnEkZufy7yN85i3cR7D5w4vXJ9eO52u\njbvSrUk3ujbuSsfUjnZFYYw5KqU2KRRcKfhrUyi4ec1f9VFJBsTLqNOKc1u3ChhLbn4uG3dvPJQw\n3Me6neuOSB7htGzrMpZtXcaIeSMAqJhYkRMansApTU+hZ1pPTm1+KjUq1QjrexpjyrZSnxS8XilE\n8o7mpISkwh5GwRzMO8i6XetYvnU5izcvZvHmxSzZsoTFmxeTtSWrcLC/kjqQd4BJ2ZOYlD2Jf/3+\nLxIkgc4NO9MzrSdntjyT05qfZr2fjDFBhUwKIvIU8IyqbnOXawP3qOrDkQ4umGDVR/6GuQg19lGw\nAfHCdfNahcQKNKvZjGY1m3F62umHbcvNz2XV9lVOotjsJIpFmxcxP2c+a3euLdH75Ws+U9dOZera\nqTzz2zMkV0ymd3pvzs04lz6t+tC4RuNw/FnGmDLEy5VCH1V9sGBBVbeKSF8gpkkh2C/7YEmhJFcK\n0RgQLykhifTa6aTXTuecVuccti1ndw5zNsxh9obZzN4wm5nrZjI/Z36x2zF2HdjFqD9GMeqPUQB0\nSu3En9v9mUvaXUJGnYyw/S3GmNLLS1JIFJFKqrofQESqADFvzQzWplBwEg9Xm0Ksh7moV60evdJ7\n0Su9V+G6nft3Mm3tNCavmVxYZbRh94ZiHXfm+pnMXD+Th358iI6pHbm03aVc0v4SWqUEbj8xxpRt\nXpLCB8A4EXkb5y6u64B3IxqVB8WtPipro6RWr1Sdni160rOFc8O5qrJy+0omrprI+OXjGb9iPMu3\nLfd8vFnrZzFr/Swe/PFBTm56Mtd2vJZL219qDdXGlDNehrl4RkTmAL1xbvv9m6qOjXhkIRS3odnr\nfAqldUA8ESGtVhpptdIYcLwzocSKbSsYv3w8Y5eOZezSsWzbt83TsX5b/Ru/rf6NO8bcwcXHXMx1\nna7jtOankSA2sYQxZZ2XhuYWwE+qOsZdriIiaaq6ItLBBeOlTaE41Ude7nsobdJqpXFtp2u5ttO1\n5Obn8vvq3/lmyTd8veRr5m6cG3L/PQf38P6c93l/zvtkpGRwW5fbGNhxoF09GFOGeTndfQr4/r7O\nc9fFVLDeQuWh+qi4khKSOLX5qfyj9z+YM3gOS29fyj97/ZPODTt72n/JliXcPuZ2mjzfhDu+vYMl\nm5dEOGJjTCx4SQpJqnqgYMF97amzu4icIyKLRCRLRB4IUOZSEVkgIvNF5ENvYQdvGD6a6qN4bGiO\nhPTa6dzf/X6mDZpG1m1Z/LPXPzm2/rEh99t5YCcvTHmBNkPbcNHHFzF97fQoRGuMiRYvSSFHRM4v\nWBCRC4BNoXYSkUTgJaAP0A7oLyLtipTJAIYAp6hqe+BOr4GHu/qotLcpHI2WKS25v/v9zLlpDlP/\nMpWbM2+mVuVaQfdRlM//+JzM1zPpM7wPE1dNjFK0xphI8pIUbgIeFJFVIrIauB+40cN+XYAsVV3m\nXl18BFxQpMxfgJdUdSuAqnoeB6L4vY/KX5tCcYkImY0yeencl1h3zzpGXDyCXi16hdxvTNYYTn37\nVHq804Pxy8dHIVJjTKSEPN2p6lJV7Ybza7+dqp6sqlkejt0YWO2znO2u89UaaC0iv4rIJBE5Bz9E\nZJCITBORaTk5OW5cBX/Akb/sD53Ei/7E13LbplBclZMqc/mxl/PD1T8w/+b53NT5JqpWqBp0nwkr\nJ3DGe2dw9gdnM3PdzChFaowJJ0+/gUXkXOBm4C4ReVREHvWym591RU/JSUAG0APoD7whIkfUW6jq\nMFXNVNXMevXquesK3iR4G0C+x7uay1ubQnG0q9eOV/q9QvZd2Tx75rM0qdEkaPnvln7HCcNOoP//\n+pO1xcvvB2NMvAiZFETkVeAy4DacE/0lQHMPx84GmvosNwGKDuKTDXyhqgdVdTmwCCdJhBSquqfg\nRO61B5JdKYRWu0pt7j35XpbevpTXz3udlrVbBi3/0byPOOalY7j3u3vZsX9HlKI0xhwNL1cKJ6vq\n1cBWd8Kdkzj8ZB/IVCBDRFqISEXgcmB0kTKjgJ4AIlIXpzppmZfAQ53E/SWFYFcK0RgQr6yomFiR\nG064gT9u/YMPLvyAdvXaBSybm5/Lv37/F22GtuG92e9FdN4JY8zR85IU9rrPe0SkEXAQaBFqJ1XN\nBW4FxgILgU9Udb6IPOHTm2kssFlEFgDjgb+q6mYvgYfqLVTcpBDrAfFKo6SEJK48/krmDp7Lhxd9\nSHrt9IBl1+9az8BRA+n+VndmrJsRxSiNMcXh5XT3lVvP/ywwA1gBjPBycFX9RlVbq2pLVf27u+5R\nVR3tvlZVvVtV26nqcar6kdfA/VUf+d6nEGxQPH/3KlibQsklSAL9j+vPwlsWMrTPUOpXqx+w7O/Z\nv5M5LJPbv72dnft3RjFKY4wXXnof/U1Vt6nq/3DaEtqqqpeG5ogqSfWRtSlEVsXEitzS5RaW3r6U\nx05/jMpJlf2WU5QXp7zIsa8cy7dLvo1ylMaYYIpVMaKq+1V1e6SCKQ5rU4hfyRWTebzH4yy8ZSEX\nH3NxwHKrtq+i74d9GfDZAHJ250QxQmNMIKW2tjzYSdy395HXu5qtTSH80mqlMfLSkXx/1fccU/eY\ngOWGzx3Osa8cy1eLv4pidMYYf0rt6S7UlUKweZqtTSG6eqf3ZvZNs3n2zGepklTFb5mNuzdy3ojz\nuPHLG9l1YFeUIzTGFPByn8I4L+uiLdRJPJy9jywpHL0KiRW49+R7mXfzPHqn9w5YbtiMYXR8tSO/\nr/49itEZYwoETAoiUllEUoC6IlJbRFLcRxrQKFoBBhLs5jXfpFDc6iNrU4is9NrpfDfgO96+4G1q\nV67tt8zSrUvp/nZ3HvnxEXLzc6McoTHlW7ArhRuB6UBb97ng8QXO6KcxFWrso2C9j/xVH9mAeNEj\nIlzT8Rrm3zyfPq36+C2Tr/k8+cuT9Hy3J2t2rIlyhMaUXwFPd6r6X1VtAdyrqumq2sJ9dFDVoVGM\n8TD79sGiRZDr/oAsTpuCVR/Fl4bVG/L1FV/zct+XA7Y1TFw1kY6vdWRsVsxngDWmXPDyG3i9iFQH\nEJGHReQzETkhwnEFNH8+tG0L292OsZFsU7CG5sgTEQafOJhZN83ixEYn+i2zac8mzhl+Dg+Ne8iq\nk4yJMC9J4RFV3Ski3YGzgXeBVyIblnehBsTz16awceORj4MHnTLWphAbreu05tfrfuWx0x8jQfz/\nt3xq4lP0fq83a3cWHVfRGBMuSR7K5LnP5wKvqOoXIvJ45EIqnuKMfTSIYeykOkPbHnmcgokcarP1\niONZm0J0VEiswOM9HqdnWk/6/68/63atO6LMhJUT6PhqRz7+88f0bNEzBlEaU7Z5SQprROQ1oDfw\ntIhUIo7ubyh6pVChAlSu7L9N4SkeKtax7UohNk5PO52ZN85kwOcD+GHZD0dsz9mTw5nvn8lzZz3H\nHV3vQOwfyJiw8XJyvxRnNNNzVHUbkAL8NaJRBZHBEsZwduEjmUM3OuWTwCmnOEmh4Dwxh+NL9D5b\nqUU2zmQyds6JvgbJDRhz5Rj+1vNvfquT8jSPu8bexcBRA9l7cK+fIxhjSkI00PyUvoWc9oQMVX1b\nROoBye6kOFGXKaLTAmxLrbqDkWOr0707pKfD8uXQhNXcwBuksMXzexygIiPoz3QyAVizBhrF/M6M\n8mv88vFc8dkVrN+13u/2zg0789lln9GsZrMoR2ZM6SEi01U1M2S5UElBRB4DMoE2qtranVPhU1U9\nJTyhFk+gpLCwcW92j/qeTPdPvvZaeOedo3+/jAxYvPjoj2OOzoZdG7hs5GVMWDnB7/Z6Vevx6SWf\ncnra6VGOzJjSIZxJYRbQCZihqp3cdXNUtWT1Mkcps3Vrnfbii4evrFoVTj4ZEhMLV82dCz16wBbv\nFwhHSEiA4cPh8stLfgwTPgfzDnLPd/fw4pQX/W5PlET+ffa/ubXLrdbOYEwRXpOCl4bmA6qqIqLu\ngasddXRHo0YNOPvskMWOOw5++gmefx4mTIBdxRhjLSkJunaF66+Hfv1KHqoJrwqJFXihzwt0btiZ\nG7+6kf15+w/bnqd53D7mduZunMvQvkOpmFgxRpEaU3p5uVK4F8gAzgT+AVwHjFDVFyIf3pEyMzN1\n2rRArQqmvJi6ZioXfXIR2Tuy/W7vkdaDkZeMpE7VOlGOzJj45PVKwcvMa88BI4H/AW2AR2OVEIwp\ncGLjE5n2l2mc2uxUv9t/WvETXd/oysKchVGOzJjSzcvQ2U+r6veq+ldVvVdVvxeRp6MRnDHBNEhu\nwA9X/8DNmTf73b5061K6vdnNxk0yphi83Kdwpp91/oe2NCbKKiZW5KVzX+Llvi+TKIlHbN+xfwd9\nP+zLi5NfxEv3a2PKu2DzKQwWkblAGxGZ4/NYDsyJXojGhDb4xMGMGTCGWpVrHbEtX/O5fcztDP56\nMAfzDsYgOmNKj4ANzSJSE6iN07j8gM+mnap6FB09j441NJtgFm9eTL8P+7FkyxK/289ocQafXvIp\nKVVSohyZMbF11A3NqrpdVVeoan9VXenziFlCMCaU1nVaM/mGyfRq0cvv9h+X/0jXN7qyaNOiKEdm\nTOkQNwPbGRMutavU5tsrv2Vw5mC/27O2ZNH1ja58t/S7KEdmTPyzpGDKpAqJFXj53JcZ2meo3wbo\n7fu302d4H/476b/WAG2MD0tmuK83AAAYqklEQVQKpky7pcstfHPlN9SsVPOIbfmaz51j72TQl4M4\nkHcgBtEZE3+KnRRE5AcR+VZEQg4AISLniMgiEckSkQeClPuziKiIhGwEMaa4zmp5FpNumESrlFZ+\nt78x8w16v9ebnN05UY7MmPhTkiuFq4GHgebBColIIvASzj0N7YD+ItLOT7nqwO3A5BLEYownbeu2\nZfINkzmjxRl+t/+y6hdOfP1E5myw3tamfPOUFESkioi0AVDVtao6XVVfCrFbFyBLVZep6gHgI+AC\nP+X+BjwD7CtG3MYUW0qVFMZcOYZbTrzF7/aV21dy8psn88UfX0Q5MmPih5dhLs4DZgFj3OWOIjLa\nw7EbA6t9lrPddb7H7gQ0VdWvQsQwSESmici0nBy7xDclVyGxAkP7DuWVc18hKeHIQYJ3H9zNnz7+\nE0/98pQ1QJtyycuVwuM4v/q3AajqLCDNw37+BrQv/JaJSALwb+CeUAdS1WGqmqmqmfXq1fPw1sYE\nd1PmTXw34LuAN7E99ONDXPnZlTbVpyl3vCSFXFXdXoJjZwNNfZabAGt9lqsDxwI/icgKoBsw2hqb\nTbT0bNGTKTdMoV29I5q6ABgxbwSnvXMaa3asiXJkxsSOl6QwT0SuABJFJENEXgR+87DfVCBDRFqI\nSEXgcqCw2sm9Y7quqqapahowCThfNeAUzMaEXcuUlvx+/e/0a+2/M920tdM4YdgJ/LTip+gGZkyM\neEkKtwHtgf3ACGAHcGeonVQ1F7gVGAssBD5R1fki8oSInF/ykI0JrxqVajDqslHcd/J9frdv3L2R\n3u/15tlfn7V2BlPmhZx5Ld7YgHgmkt6f/T43fHlDwJvZLmx7IW9f8DY1Kx95M5wx8SxsM6+JyHgR\n+bHoIzxhGhNfrupwFROumUBqcqrf7Z//8Tknvn4iczfMjXJkxkSHl+qje4G/uo9HcLqn2k91U2Z1\na9KNGYNmBJzqc8mWJXR9oysfzPkgypEZE3le5mie7vP4VVXvBrpGITZjYqZh9YaMu3oc9550r9/t\ne3P3ctXnV3Hz1zezP3d/lKMzJnK8VB+l+DzqisjZgP9ra2PKkAqJFXj2rGcZeclIqles7rfMK9Ne\n4bR3TmPZ1mVRjs6YyPBSfTQdp7poOvA7zs1m10cyKGPiycXtLmbqX6bSvl57v9unrJlCx1c7MnzO\n8ChHZkz4eak+aqGq6e5zhqqepaoToxGcMfGiTd02TL5hMlccd4Xf7TsP7GTA5wO46vOr2LF/R5Sj\nMyZ8gs3RfFGwHVX1s4hEFIJ1STWxpKq8PPVl7hp7FwfzD/ot06JWCz68+EO6NekW5eiMCcxrl9Rg\nSeHtIPupql5X0uCOhiUFEw8mZ0/m8v9dzoptK/xuT5REHjv9MYacOsTvwHvGRNtRJ4V4ZUnBxIvt\n+7Yz+OvBjJg3ImCZzEaZvHPBO7Sv7789wphoCefNa3VE5AURmSEi00XkvyJSJzxhGlN61axck+EX\nDee9P71HcsVkv2UKxk7658R/kpufG+UIjSk+L72PPgJygIuBP7uvP45kUMaUFiLCVR2uYtaNs+jS\nuIvfMgfyDjBk3BBOeesUFuYsjHKExhSPl6SQoqp/U9Xl7uNJoFakAzOmNGmZ0pKJ107kwe4PkiD+\nv1ZT1kyh42sdeWLCE3bDm4lbXpLCeBG5XEQS3MelwNeRDsyY0qZCYgX+3uvv/Hbdb7St29ZvmQN5\nB3jsp8fo8GoHG47bxKVgvY924syUJkA1IM/dlAjsUtUaUYmwCGtoNqXBvtx9PDr+UZ777TmUwJ05\nBnYYyHNnPUfdqnWjGJ0pj466oVlVq6tqDfc5QVUruI+EWCUEY0qLykmVeebMZ5h43URa12kdsNy7\ns9+lzdA2vD79dfLy8wKWMyZavFQfGWNK6OSmJzPrxlncd/J9Ae9X2LJ3C4O+GkTm65n8vPLnKEdo\nzOEsKRgTYVUqVOHpM59mxqAZnNTkpIDlZq2fxenvnM4ln17C8q3LoxihMYdYUjAmSo5rcBwTr5vI\na/1eo1blwB34Ri4YyTEvHcOD4x5k+77tUYzQGI9JQUQSRaSRiDQreEQ6MGPKogRJYFDnQfxxyx8B\nB9cD2J+3n39M/AfpL6Tzr9/+xb7cfVGM0pRnXu5ovg3YAHyP0xX1a+CrCMdlTJnWILkBwy8azi/X\n/kLnhp0Dltuydwv3fn8vGS9m8OaMN+2uaBNxIcc+EpEsoKuqbo5OSMFZl1RT1uRrPu/Nfo8h44aw\nftf6oGVb12nNw6c+TP/j+ttAe6ZYwjb2EbAasIpNYyIkQRK4puM1LL51MUO6D6FSYqWAZRdvXszV\no66m7dC2vDXzLQ7m+R++25iS8nKl8CbQBqfaqPDefFV9PrKh+WdXCqasW7ltJY9PeJz3Zr9HvuYH\nLdu8ZnOGdB/CwI4DqZxUOUoRmtIonFcKq3DaEyoC1X0expgIaF6rOW9f8DZzB8/lwrYXBi27cvtK\nbvr6Jpr/pzlPTHiCTXs2RSlKU1bZfArGxLnJ2ZN56MeHGLd8XMiylZMqM7DDQO7qdhdt6raJQnSm\ntAjHzGv/UdU7ReRLOHLwFlU9/+jDLD5LCqa8+m31b/zt578xJmuMp/L9Wvfj9i630yu9V8CRW035\nEY6k0FlVp4vI6f62q+qEo4yxRCwpmPJuypopPPnzk3y5+EtP5VultOLGzjdyTcdrbOC9ciwupuMU\nkXOA/+KMrPqGqv6zyPa7gRuAXJzJe65T1ZXBjmlJwRjHzHUzefa3Z/lk/ifkaejB9ComVuSSdpdw\nU+ZNnNL0FEQkClGaeBHzpCAiicBi4EwgG5gK9FfVBT5legKTVXWPiAwGeqjqZcGOa0nBmMOt3r6a\nFya/wLAZw9ixf4enfdrUacPVHa5mwPEDaFbTBigoD+IhKZwEPK6qZ7vLQwBU9R8ByncChqrqKcGO\na0nBGP927N/BWzPf4j+T/sPK7UEvuA/TM60nV3e4mouPuZjqlaxjYVkVzi6pJdUY58a3AtnuukCu\nB76NYDzGlGk1KtXgzm53knV7Fp9d+hlntTzL037jV4zn2i+upcFzDRjw2QC+WfINB/IORDhaE6+8\njH30vYjU8lmuLSJjPRzbX4Wl38sSERkAZALPBtg+SESmici0nJwcD29tTPmVlJDEhcdcyNgBY1ly\n2xL+evJfqVOlTsj99ubuZfjc4Zz74bnUf7Y+A0cN5MtFX9p80uWMlzuaZ6pqp1Dr/OznqfpIRHoD\nLwKnq+rGUAFb9ZExxbc/dz//W/g/Xp/xerHnhq5RqQbntT6PS9pdwpktz6RqhaqRCdJEVNjaFERk\nOnChqq5yl5sDn6vqCSH2S8JpaO4FrMFpaL5CVef7lOkEjATOUdUloYIFSwrGHK2V21bywZwPeHf2\nuyzZ4ulrV6hyUmV6tehFv9b9ODfjXJrWbBqhKE24hTMpnAMMAwruSzgNGKSqIauQRKQv8B+cLqlv\nqerfReQJYJqqjhaRH4DjgHXuLqtC3RRnScGY8FBVpqyZwruz3+WjeR+xdd/WYh/j+AbH0y+jH/1a\n96NL4y4kJiRGIFITDmHtfSQidYFuOO0Ev6tqzAZYsaRgTPjtz93PN0u+4dMFn/Ll4i/ZdWBXsY+R\nUiWFM1qcQa8Wveid3puWtVvavRBxJJxXChcCP6rqdne5Fs79BKPCEmkxWVIwJrL25e5jbNZYRi4c\nyehFoz3f+1BUs5rN6N2iN73Se3FGizNITU4Nc6SmOMKZFGapasci60I2NEeKJQVjomd/7n6+X/Y9\nIxeM5Jsl35Czp+S9/9rXa89pzU+je7PudG/W3W6ai7JwJoU5qnp8kXVzVfW4o4yxRCwpGBMbefl5\nTF07la8Xf81XS75i1vpZR3W8ZjWbOQmiqZMk2tdvbwP3RVA4k8JbwDbgJZz7DG4DaqvqNWGIs9gs\nKRgTH7J3ZPPNkm/4avFXjFs+jj0H9xzV8apXrE5mo0xObHQiXRp3oUvjLjSp0cTaJcIknEmhGvAI\n0Bunofk74ElV3R2OQIvLkoIx8edA3gEmZU9i3LJx/LD8ByZnT/Y0SF8oDao1KEwQJzY6kU4NO1G/\nWv0wRFz+xHzso0ixpGBM/Nu5fyc/r/yZH5b9wLjl45i7cW7Yjt0wuSEdUjvQsUFH5zm1IxkpGdYd\nNoRwXinUA+4D2gOFk8Cq6hlHG2RJWFIwpvTZuHsjv676lYmrJjJx9URmrJtBbn5u2I5fJakKx9Y/\nlo6pHTmu/nG0q9eOdvXakZqcatVPrnAmhe+Aj4F7gZuAgUCOqt4fjkCLy5KCMaXf7gO7mbJmCr+s\n+oWJqyYyec3kEnd9DaZmpZqFCeKYuscUvm5as2m5a9QO6zAXqtrZtxeSiExQVb8zskWaJQVjyp58\nzWfx5sVMXTOVKWumMGXtFGatnxWx0VqrVqhK27ptaV2nNa1qtyKjTgatUlqRkZJB3ap1y+TVRTiT\nwiRV7eaOjPoCsBYYqaotwxNq8VhSMKZ82J+7n7kb5zpJYs0UZq6fyYKcBWGtdvKnZqWaToKok1GY\nMNJrp5NWK42GyQ1LbdtFOJNCP+AXoCnOaKY1gP9T1dHhCLS4LCkYU37tz93PgpwFzN4wm1nrZxU+\nb9u3LSrvXyGhAs1qNiOtVprfRzwnDet9ZIwpF1SV1TtWM2v9LOZsmMPCTQtZkLOAPzb9wb7cfVGN\npUJCBZrWbErj6o1pUqNJ4XOTGk1oXMN5nZqcSlJCUlTjAksKxphyLi8/j5XbV7IgZwELcxayYNOC\nwtc7D+yMWVwJkkBqcurhCcN93bB6QxpUa0BqciopVVLC2rZhScEYY/xQVbJ3ZLNkyxKWbF5C1pYs\nsrZmsWTzEpZuXRr1q4tAKiRUoH61+qQmp5KanFqYLFKTU2mQfOh1/Wr1qVmpZsgE4jUpRP8axhhj\nYkhEaFqzKU1rNuWMFoffbpWv+azZsYasLVks2eImjC1ZrNi2ghXbVpRozomSOph/kDU717Bm55qQ\nZSskVKBu1brUq1aPelXrHXr2ee1VyKQgIpWAi4E03/Kq+oTndzHGmFIgQRIKE0bPFj2P2L5933ZW\nbl9ZmCSKPqKZNHwdzD/Iul3rWLdrXejCIXi5UvgC2A5MB2wGb2NMuVWzck2Or3w8xzc43u/27fu2\nk70jm+wd2azZucZ53rGG7J3u845sNu/dHOWoi8dLUmiiqudEPBJjjCnlalauSc3KNWlfv33AMnsP\n7mXtzrV+E8eGXRvYsHsD63etL9Hsd+HgJSn8JiLHqWr4RrQyxphyqkqFKrRMaUnLlOD3/+4+sLsw\nQWzY5Tyv37W+cF3BI2dPzlEPW+7LS1LoDlwjIstxqo8E0KIT7xhjjAmfahWrkV4xnfTa6SHL7jm4\nh5zdOeTsyQn4/CVfenpfL0mhj6cjGWOMiYmqFarSvFZzmtdqHrCMXOHtnoeASUFEaqjqDiB2d3kY\nY4yJqmBXCh8C/XB6HSlOtVEBBUJf0xhjjClVAiYFVe3nPreIXjjGGGNiydMdzSJSG8jg8JnXfo5U\nUMYYY2LDyx3NNwB3AE2AWUA34HcgJtNxGmOMiRwv89HdAZwIrFTVnkAnICeiURljjIkJL0lhn6ru\nA2ccJFX9A2gT2bCMMcbEgpekkC0itYBRwPci8gXOlJwhicg5IrJIRLJE5AE/2yuJyMfu9skiklac\n4I0xxoRXyDYFVb3Qffm4iIwHagJjQu0nIonAS8CZQDYwVURGq+oCn2LXA1tVtZWIXA48DVxWzL/B\nGGNMmAS9UhCRBBGZV7CsqhNUdbSqHvBw7C5Alqouc8t/BFxQpMwFwLvu65FALwnnVEPGGGOKJeiV\ngqrmi8hsEWmmqquKeezGwGqf5Wyga6AyqporItuBOsAm30IiMggY5C7u901UpURdivxNca60xQsW\nczSUtnjBYvYVeAwMH17uU2gIzBeRKcDugpWqen6I/fz94i8696eXMqjqMGAYgIhM8zKlXDwpbTGX\ntnjBYo6G0hYvWMwl4SUp/F8Jj50NNPVZbsKRDdQFZbJFJAmnvWJLCd/PGGPMUfLS+6iv25ZQ+AD6\nethvKpAhIi1EpCJwOTC6SJnRwED39Z+BH1X1iCsFY4wx0eElKZzpZ13I4bRVNRe4FRgLLAQ+UdX5\nIvKEiBRUPb0J1BGRLOBu4Ihuq34M81Am3pS2mEtbvGAxR0Npixcs5mKTQD/MRWQwcDPOaKhLfTZV\nB35V1QGRD88YY0w0BUsKNYHawD84/Bf8TlW1en9jjCmDAiYFY4wx5Y+XNoW4EWrYjFgQkaYiMl5E\nForIfBG5w12fIiLfi8gS97m2u15E5AX3b5gjIifEMPZEEZkpIl+5yy3c4UaWuMOPVHTXx3w4EhGp\nJSIjReQP97M+Kd4/YxG5y/0/MU9ERohI5Xj7jEXkLRHZ6HvvT0k+VxEZ6JZfIiID/b1XhGN+1v2/\nMUdEPhdnaJ6CbUPcmBeJyNk+66NyPvEXr8+2e0VERaSuuxz7z1hVS8UDSMRp20gHKgKzgXZxEFdD\n4AT3dXVgMdAOeAZ4wF3/APC0+7ov8C3OPRrdgMkxjP1unBn2vnKXPwEud1+/Cgx2X98MvOq+vhz4\nOAaxvgvc4L6uCNSK588Y58bM5UAVn8/2mnj7jIHTgBOAeT7rivW5AinAMve5tvu6dpRjPgtIcl8/\n7RNzO/dcUQlo4Z5DEqN5PvEXr7u+KU5HnJVA3Xj5jKP6RTnKD/YkYKzP8hBgSKzj8hPnFzg9thYB\nDd11DYFF7uvXgP4+5QvLRTnOJsA4nHkxvnL/E27y+WIVft7uf9yT3NdJbjmJYqw13BOsFFkft58x\nh+7WT3E/s6+As+PxMwbSipxgi/W5Av2B13zWH1YuGjEX2XYhMNx9fdh5ouBzjvb5xF+8OEP7dABW\ncCgpxPwzLk3VR/6GzWgco1j8ci/5OwGTgQaqug7Afa7vFouXv+M/wH1AvrtcB9imTlfionEdNhwJ\nUDAcSbSk48zh8bZb3fWGiFQjjj9jVV0DPAesAtbhfGbTid/P2FdxP9eYf95FXIfzaxviNGZxuuWv\nUdXZRTbFPN7SlBQ8DYkRKyKSDPwPuFNVdwQr6mddVP8OEekHbFTV6b6r/RRVD9uiIQnn8vsVVe2E\nM9xKsDrgWMdbMIXtBThVFo2Aavi/vydePmMvAsUYN7GLyENALjC8YJWfYjGNWUSqAg8Bj/rb7Gdd\nVOMtTUnBy7AZMSEiFXASwnBV/cxdvUFEGrrbGwIb3fXx8HecApwvIitwRq89A+fKoZY4w40Ujasw\nZonNcCTZQLaqTnaXR+IkiXj+jHsDy1U1R1UPAp8BJxO/n7Gv4n6u8fB54za+9gOuVLeOJUhssYy5\nJc6Phdnud7AJMENEUoPEFbV4S1NS8DJsRtSJiODcmb1QVZ/32eQ7hMdAnLaGgvVXu70MugHbCy7V\no0VVh6hqE1VNw/kcf1TVK4HxOMON+Is5ZsORqOp6YLWIFMz41wtYQBx/xjjVRt1EpKr7f6Qg5rj8\njIso7uc6FjhLRGq7V0hnueuiRkTOAe4HzlfVPT6bRgOXu727WgAZwBRieD5R1bmqWl9V09zvYDZO\nZ5X1xMNnHMnGoAg01vTF6d2zFHgo1vG4MXXHuYybA8xyH31x6oPHAUvc5xS3vOBMPrQUmAtkxjj+\nHhzqfZSO84XJAj4FKrnrK7vLWe729BjE2RGY5n7Oo3B6YMT1Z4wzmOQfwDzgfZweMHH1GQMjcNo8\nDuKcnK4vyeeKU4+f5T6ujUHMWTh17gXfwVd9yj/kxrwI6OOzPirnE3/xFtm+gkMNzTH/jO3mNWOM\nMYVKU/WRMcaYCLOkYIwxppAlBWOMMYUsKRhjjClkScEYY0whSwrGRJGI9BB3VFpj4pElBWOMMYUs\nKRjjh4gMEJEpIjJLRF4TZ+6JXSLyLxGZISLjRKSeW7ajiEzyGcu/YP6BViLyg4jMdvdp6R4+WQ7N\nDTHcvePZmLhgScGYIkTkGOAy4BRV7QjkAVfiDGo3Q1VPACYAj7m7vAfcr6rH49yFWrB+OPCSqnbA\nGfeoYKiNTsCdOGP9p+OMRWVMXEgKXcSYcqcX0BmY6v6Ir4IzKFw+8LFb5gPgM3HmMq+lqhPc9e8C\nn4pIdaCxqn4OoKr7ANzjTVHVbHd5Fs5Y+xMj/2cZE5olBWOOJMC7qjrksJUijxQpF2yMmGBVQvt9\nXudh30MTR6z6yJgjjQP+LCL1oXDO4uY435eCEU6vACaq6nZgq4ic6q6/Cpigzpwa2SLyJ/cYldxx\n9I2Ja/YLxZgiVHWBiDwMfCciCTijW96CM7lPexGZjjMz2mXuLgOBV92T/jLgWnf9VcBrIvKEe4xL\novhnGFMiNkqqMR6JyC5VTY51HMZEklUfGWOMKWRXCsYYYwrZlYIxxphClhSMMcYUsqRgjDGmkCUF\nY4wxhSwpGGOMKfT/JnhTPoHb+PwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a3589e310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
