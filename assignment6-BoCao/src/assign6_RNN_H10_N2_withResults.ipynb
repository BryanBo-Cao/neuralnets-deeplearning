{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 10\n",
    "N = 2\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 1.9643, Training Accuracy= 0.493\n",
      "Epoch: 10, Loss= 1.6992, Training Accuracy= 0.493\n",
      "Epoch: 20, Loss= 1.4543, Training Accuracy= 0.493\n",
      "Epoch: 30, Loss= 1.2390, Training Accuracy= 0.493\n",
      "Epoch: 40, Loss= 1.0633, Training Accuracy= 0.493\n",
      "Epoch: 50, Loss= 0.9325, Training Accuracy= 0.493\n",
      "Epoch: 60, Loss= 0.8436, Training Accuracy= 0.493\n",
      "Epoch: 70, Loss= 0.7876, Training Accuracy= 0.493\n",
      "Epoch: 80, Loss= 0.7540, Training Accuracy= 0.493\n",
      "Epoch: 90, Loss= 0.7343, Training Accuracy= 0.244\n",
      "Epoch: 100, Loss= 0.7227, Training Accuracy= 0.244\n",
      "Epoch: 110, Loss= 0.7155, Training Accuracy= 0.244\n",
      "Epoch: 120, Loss= 0.7109, Training Accuracy= 0.244\n",
      "Epoch: 130, Loss= 0.7077, Training Accuracy= 0.244\n",
      "Epoch: 140, Loss= 0.7052, Training Accuracy= 0.244\n",
      "Epoch: 150, Loss= 0.7032, Training Accuracy= 0.244\n",
      "Epoch: 160, Loss= 0.7014, Training Accuracy= 0.244\n",
      "Epoch: 170, Loss= 0.6997, Training Accuracy= 0.244\n",
      "Epoch: 180, Loss= 0.6982, Training Accuracy= 0.244\n",
      "Epoch: 190, Loss= 0.6967, Training Accuracy= 0.491\n",
      "Epoch: 200, Loss= 0.6953, Training Accuracy= 0.491\n",
      "Epoch: 210, Loss= 0.6939, Training Accuracy= 0.491\n",
      "Epoch: 220, Loss= 0.6925, Training Accuracy= 0.491\n",
      "Epoch: 230, Loss= 0.6912, Training Accuracy= 0.751\n",
      "Epoch: 240, Loss= 0.6899, Training Accuracy= 0.751\n",
      "Epoch: 250, Loss= 0.6887, Training Accuracy= 0.751\n",
      "Epoch: 260, Loss= 0.6875, Training Accuracy= 0.751\n",
      "Epoch: 270, Loss= 0.6863, Training Accuracy= 0.751\n",
      "Epoch: 280, Loss= 0.6851, Training Accuracy= 0.751\n",
      "Epoch: 290, Loss= 0.6840, Training Accuracy= 0.751\n",
      "Epoch: 300, Loss= 0.6828, Training Accuracy= 0.751\n",
      "Epoch: 310, Loss= 0.6818, Training Accuracy= 0.751\n",
      "Epoch: 320, Loss= 0.6807, Training Accuracy= 0.751\n",
      "Epoch: 330, Loss= 0.6796, Training Accuracy= 0.751\n",
      "Epoch: 340, Loss= 0.6785, Training Accuracy= 0.751\n",
      "Epoch: 350, Loss= 0.6775, Training Accuracy= 0.751\n",
      "Epoch: 360, Loss= 0.6765, Training Accuracy= 0.751\n",
      "Epoch: 370, Loss= 0.6755, Training Accuracy= 0.751\n",
      "Epoch: 380, Loss= 0.6745, Training Accuracy= 0.751\n",
      "Epoch: 390, Loss= 0.6735, Training Accuracy= 0.751\n",
      "Epoch: 400, Loss= 0.6726, Training Accuracy= 0.751\n",
      "Epoch: 410, Loss= 0.6716, Training Accuracy= 0.751\n",
      "Epoch: 420, Loss= 0.6707, Training Accuracy= 0.751\n",
      "Epoch: 430, Loss= 0.6697, Training Accuracy= 0.751\n",
      "Epoch: 440, Loss= 0.6688, Training Accuracy= 0.751\n",
      "Epoch: 450, Loss= 0.6679, Training Accuracy= 0.751\n",
      "Epoch: 460, Loss= 0.6670, Training Accuracy= 0.751\n",
      "Epoch: 470, Loss= 0.6660, Training Accuracy= 0.751\n",
      "Epoch: 480, Loss= 0.6651, Training Accuracy= 0.751\n",
      "Epoch: 490, Loss= 0.6642, Training Accuracy= 0.751\n",
      "Epoch: 500, Loss= 0.6633, Training Accuracy= 0.751\n",
      "Epoch: 510, Loss= 0.6624, Training Accuracy= 0.751\n",
      "Epoch: 520, Loss= 0.6615, Training Accuracy= 0.751\n",
      "Epoch: 530, Loss= 0.6606, Training Accuracy= 0.751\n",
      "Epoch: 540, Loss= 0.6597, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.6588, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.6579, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.6570, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.6560, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.6551, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.6542, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.6533, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.6523, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.6514, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.6504, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.6495, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.6485, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.6475, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.6465, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.6455, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.6446, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.6435, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.6425, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.6415, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.6404, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.6394, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.6383, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.6372, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.6361, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.6350, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.6338, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.6327, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.6315, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.6303, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.6291, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.6279, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.6267, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.6254, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.6241, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.6228, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.6215, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.6202, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.6188, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.6174, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.6160, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.6146, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.6132, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.6117, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.6102, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.6087, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.6072, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.6056, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.6040, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.6024, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.6008, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.5991, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.5974, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.5957, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.5939, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.5922, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.5904, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.5885, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.5867, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.5848, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.5829, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.5810, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.5790, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.5770, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.5750, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.5729, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.5708, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.5687, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.5666, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.5644, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.5622, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.5600, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.5577, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.5554, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.5531, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.5507, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.5484, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.5460, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.5435, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.5411, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.5386, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.5361, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.5335, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.5310, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.5284, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.5257, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.5231, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.5204, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.5177, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.5150, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.5123, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.5095, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.5067, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.5039, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.5011, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.4982, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.4954, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.4925, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.4896, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.4867, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.4837, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.4808, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.4778, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.4748, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.4718, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.4688, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss= 0.4658, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.4628, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.4598, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.4567, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.4537, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.4506, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.4475, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.4445, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.4414, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.4383, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.4353, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.4322, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.4291, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.4260, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.4229, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.4199, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.4168, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.4137, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.4107, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.4076, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.4046, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.4015, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.3985, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.3955, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.3925, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.3894, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.3864, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.3835, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.3805, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.3775, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.3746, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.3717, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.3687, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.3658, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.3629, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.3601, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.3572, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.3544, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.3515, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.3487, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.8133, Training Accuracy= 0.506\n",
      "Epoch: 10, Loss= 0.7763, Training Accuracy= 0.506\n",
      "Epoch: 20, Loss= 0.7469, Training Accuracy= 0.506\n",
      "Epoch: 30, Loss= 0.7241, Training Accuracy= 0.506\n",
      "Epoch: 40, Loss= 0.7067, Training Accuracy= 0.506\n",
      "Epoch: 50, Loss= 0.6934, Training Accuracy= 0.506\n",
      "Epoch: 60, Loss= 0.6833, Training Accuracy= 0.506\n",
      "Epoch: 70, Loss= 0.6755, Training Accuracy= 0.248\n",
      "Epoch: 80, Loss= 0.6693, Training Accuracy= 0.248\n",
      "Epoch: 90, Loss= 0.6642, Training Accuracy= 0.495\n",
      "Epoch: 100, Loss= 0.6599, Training Accuracy= 0.495\n",
      "Epoch: 110, Loss= 0.6562, Training Accuracy= 0.495\n",
      "Epoch: 120, Loss= 0.6529, Training Accuracy= 0.495\n",
      "Epoch: 130, Loss= 0.6499, Training Accuracy= 0.752\n",
      "Epoch: 140, Loss= 0.6470, Training Accuracy= 0.752\n",
      "Epoch: 150, Loss= 0.6442, Training Accuracy= 1.000\n",
      "Epoch: 160, Loss= 0.6416, Training Accuracy= 1.000\n",
      "Epoch: 170, Loss= 0.6390, Training Accuracy= 1.000\n",
      "Epoch: 180, Loss= 0.6364, Training Accuracy= 1.000\n",
      "Epoch: 190, Loss= 0.6338, Training Accuracy= 1.000\n",
      "Epoch: 200, Loss= 0.6313, Training Accuracy= 1.000\n",
      "Epoch: 210, Loss= 0.6287, Training Accuracy= 1.000\n",
      "Epoch: 220, Loss= 0.6261, Training Accuracy= 1.000\n",
      "Epoch: 230, Loss= 0.6236, Training Accuracy= 1.000\n",
      "Epoch: 240, Loss= 0.6210, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.6183, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.6157, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.6131, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.6104, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.6077, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.6049, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.6021, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.5993, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.5965, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.5936, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.5907, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.5878, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.5848, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.5818, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.5788, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.5757, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.5726, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5695, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5663, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5631, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5599, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5566, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5533, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5500, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5467, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.5433, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.5399, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.5364, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.5329, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.5294, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.5259, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.5224, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.5188, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.5152, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.5116, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.5079, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.5043, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.5006, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.4969, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.4932, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.4895, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.4857, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.4820, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.4783, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.4745, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.4707, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.4669, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.4632, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.4594, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.4556, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.4518, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.4480, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.4442, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.4404, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.4367, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.4329, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.4291, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.4254, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.4216, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.4179, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.4141, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.4104, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.4067, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.4030, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.3994, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.3957, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.3921, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.3884, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.3848, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.3813, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.3777, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.3741, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.3706, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.3671, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.3636, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.3602, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.3568, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.3533, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.3500, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.3466, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.3433, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.3400, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.3367, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.3335, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.3302, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.3271, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.3239, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.3208, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.3176, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.3146, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.3115, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.3085, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.3055, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.3025, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1190, Loss= 0.2996, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.2967, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.2938, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.2910, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.2882, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.2854, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.2826, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.2799, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.2772, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.2745, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.2719, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.2693, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.2667, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.2641, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.2616, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.2591, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.2566, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.2542, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.2518, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.2494, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.2470, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.2447, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.2424, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.2401, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.2379, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.2356, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.2334, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.2313, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.2291, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.2270, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.2249, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.2228, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.2208, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.2188, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.2168, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.2148, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.2128, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.2109, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.2090, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.2071, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.2052, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.2034, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.2016, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.1998, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.1980, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.1963, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.1946, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.1928, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.1912, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.1895, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.1878, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.1862, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.1846, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.1830, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.1815, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.1799, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.1784, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.1769, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.1754, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.1739, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.1724, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.1710, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.1696, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.1682, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.1668, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.1654, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.1640, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.1627, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.1614, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.1601, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.1588, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.1575, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.1562, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.1550, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.1537, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.1525, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.1513, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.1501, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.1489, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.1478, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.1466, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 1.2986, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 1.0494, Training Accuracy= 0.255\n",
      "Epoch: 20, Loss= 0.9080, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.8351, Training Accuracy= 0.505\n",
      "Epoch: 40, Loss= 0.7987, Training Accuracy= 0.505\n",
      "Epoch: 50, Loss= 0.7789, Training Accuracy= 0.505\n",
      "Epoch: 60, Loss= 0.7660, Training Accuracy= 0.505\n",
      "Epoch: 70, Loss= 0.7562, Training Accuracy= 0.505\n",
      "Epoch: 80, Loss= 0.7481, Training Accuracy= 0.505\n",
      "Epoch: 90, Loss= 0.7412, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.7352, Training Accuracy= 0.505\n",
      "Epoch: 110, Loss= 0.7300, Training Accuracy= 0.505\n",
      "Epoch: 120, Loss= 0.7255, Training Accuracy= 0.505\n",
      "Epoch: 130, Loss= 0.7215, Training Accuracy= 0.505\n",
      "Epoch: 140, Loss= 0.7181, Training Accuracy= 0.505\n",
      "Epoch: 150, Loss= 0.7150, Training Accuracy= 0.505\n",
      "Epoch: 160, Loss= 0.7124, Training Accuracy= 0.505\n",
      "Epoch: 170, Loss= 0.7101, Training Accuracy= 0.505\n",
      "Epoch: 180, Loss= 0.7081, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.7063, Training Accuracy= 0.505\n",
      "Epoch: 200, Loss= 0.7047, Training Accuracy= 0.505\n",
      "Epoch: 210, Loss= 0.7034, Training Accuracy= 0.505\n",
      "Epoch: 220, Loss= 0.7022, Training Accuracy= 0.505\n",
      "Epoch: 230, Loss= 0.7011, Training Accuracy= 0.505\n",
      "Epoch: 240, Loss= 0.7001, Training Accuracy= 0.505\n",
      "Epoch: 250, Loss= 0.6993, Training Accuracy= 0.505\n",
      "Epoch: 260, Loss= 0.6985, Training Accuracy= 0.505\n",
      "Epoch: 270, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 280, Loss= 0.6972, Training Accuracy= 0.505\n",
      "Epoch: 290, Loss= 0.6967, Training Accuracy= 0.505\n",
      "Epoch: 300, Loss= 0.6962, Training Accuracy= 0.505\n",
      "Epoch: 310, Loss= 0.6957, Training Accuracy= 0.505\n",
      "Epoch: 320, Loss= 0.6953, Training Accuracy= 0.505\n",
      "Epoch: 330, Loss= 0.6949, Training Accuracy= 0.505\n",
      "Epoch: 340, Loss= 0.6946, Training Accuracy= 0.505\n",
      "Epoch: 350, Loss= 0.6942, Training Accuracy= 0.505\n",
      "Epoch: 360, Loss= 0.6939, Training Accuracy= 0.505\n",
      "Epoch: 370, Loss= 0.6936, Training Accuracy= 0.505\n",
      "Epoch: 380, Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 390, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 400, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 410, Loss= 0.6927, Training Accuracy= 0.505\n",
      "Epoch: 420, Loss= 0.6924, Training Accuracy= 0.505\n",
      "Epoch: 430, Loss= 0.6922, Training Accuracy= 0.505\n",
      "Epoch: 440, Loss= 0.6921, Training Accuracy= 0.505\n",
      "Epoch: 450, Loss= 0.6919, Training Accuracy= 0.505\n",
      "Epoch: 460, Loss= 0.6917, Training Accuracy= 0.505\n",
      "Epoch: 470, Loss= 0.6915, Training Accuracy= 0.505\n",
      "Epoch: 480, Loss= 0.6913, Training Accuracy= 0.505\n",
      "Epoch: 490, Loss= 0.6912, Training Accuracy= 0.505\n",
      "Epoch: 500, Loss= 0.6910, Training Accuracy= 0.505\n",
      "Epoch: 510, Loss= 0.6908, Training Accuracy= 0.505\n",
      "Epoch: 520, Loss= 0.6907, Training Accuracy= 0.505\n",
      "Epoch: 530, Loss= 0.6905, Training Accuracy= 0.505\n",
      "Epoch: 540, Loss= 0.6904, Training Accuracy= 0.505\n",
      "Epoch: 550, Loss= 0.6902, Training Accuracy= 0.505\n",
      "Epoch: 560, Loss= 0.6901, Training Accuracy= 0.505\n",
      "Epoch: 570, Loss= 0.6899, Training Accuracy= 0.505\n",
      "Epoch: 580, Loss= 0.6898, Training Accuracy= 0.505\n",
      "Epoch: 590, Loss= 0.6896, Training Accuracy= 0.505\n",
      "Epoch: 600, Loss= 0.6895, Training Accuracy= 0.505\n",
      "Epoch: 610, Loss= 0.6893, Training Accuracy= 0.505\n",
      "Epoch: 620, Loss= 0.6892, Training Accuracy= 0.505\n",
      "Epoch: 630, Loss= 0.6890, Training Accuracy= 0.505\n",
      "Epoch: 640, Loss= 0.6889, Training Accuracy= 0.505\n",
      "Epoch: 650, Loss= 0.6887, Training Accuracy= 0.505\n",
      "Epoch: 660, Loss= 0.6886, Training Accuracy= 0.505\n",
      "Epoch: 670, Loss= 0.6884, Training Accuracy= 0.505\n",
      "Epoch: 680, Loss= 0.6882, Training Accuracy= 0.505\n",
      "Epoch: 690, Loss= 0.6881, Training Accuracy= 0.505\n",
      "Epoch: 700, Loss= 0.6879, Training Accuracy= 0.505\n",
      "Epoch: 710, Loss= 0.6878, Training Accuracy= 0.505\n",
      "Epoch: 720, Loss= 0.6876, Training Accuracy= 0.505\n",
      "Epoch: 730, Loss= 0.6874, Training Accuracy= 0.505\n",
      "Epoch: 740, Loss= 0.6873, Training Accuracy= 0.505\n",
      "Epoch: 750, Loss= 0.6871, Training Accuracy= 0.505\n",
      "Epoch: 760, Loss= 0.6869, Training Accuracy= 0.505\n",
      "Epoch: 770, Loss= 0.6868, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 780, Loss= 0.6866, Training Accuracy= 0.752\n",
      "Epoch: 790, Loss= 0.6864, Training Accuracy= 0.752\n",
      "Epoch: 800, Loss= 0.6862, Training Accuracy= 0.752\n",
      "Epoch: 810, Loss= 0.6860, Training Accuracy= 0.752\n",
      "Epoch: 820, Loss= 0.6858, Training Accuracy= 0.752\n",
      "Epoch: 830, Loss= 0.6856, Training Accuracy= 0.752\n",
      "Epoch: 840, Loss= 0.6854, Training Accuracy= 0.752\n",
      "Epoch: 850, Loss= 0.6852, Training Accuracy= 0.752\n",
      "Epoch: 860, Loss= 0.6850, Training Accuracy= 0.752\n",
      "Epoch: 870, Loss= 0.6848, Training Accuracy= 0.752\n",
      "Epoch: 880, Loss= 0.6845, Training Accuracy= 0.752\n",
      "Epoch: 890, Loss= 0.6843, Training Accuracy= 0.752\n",
      "Epoch: 900, Loss= 0.6841, Training Accuracy= 0.752\n",
      "Epoch: 910, Loss= 0.6839, Training Accuracy= 0.752\n",
      "Epoch: 920, Loss= 0.6836, Training Accuracy= 0.752\n",
      "Epoch: 930, Loss= 0.6834, Training Accuracy= 0.752\n",
      "Epoch: 940, Loss= 0.6831, Training Accuracy= 0.752\n",
      "Epoch: 950, Loss= 0.6829, Training Accuracy= 0.752\n",
      "Epoch: 960, Loss= 0.6826, Training Accuracy= 0.752\n",
      "Epoch: 970, Loss= 0.6823, Training Accuracy= 0.752\n",
      "Epoch: 980, Loss= 0.6820, Training Accuracy= 0.752\n",
      "Epoch: 990, Loss= 0.6817, Training Accuracy= 0.752\n",
      "Epoch: 1000, Loss= 0.6815, Training Accuracy= 0.752\n",
      "Epoch: 1010, Loss= 0.6811, Training Accuracy= 0.752\n",
      "Epoch: 1020, Loss= 0.6808, Training Accuracy= 0.752\n",
      "Epoch: 1030, Loss= 0.6805, Training Accuracy= 0.752\n",
      "Epoch: 1040, Loss= 0.6802, Training Accuracy= 0.752\n",
      "Epoch: 1050, Loss= 0.6799, Training Accuracy= 0.752\n",
      "Epoch: 1060, Loss= 0.6795, Training Accuracy= 0.752\n",
      "Epoch: 1070, Loss= 0.6792, Training Accuracy= 0.752\n",
      "Epoch: 1080, Loss= 0.6788, Training Accuracy= 0.752\n",
      "Epoch: 1090, Loss= 0.6784, Training Accuracy= 0.752\n",
      "Epoch: 1100, Loss= 0.6780, Training Accuracy= 0.752\n",
      "Epoch: 1110, Loss= 0.6776, Training Accuracy= 0.752\n",
      "Epoch: 1120, Loss= 0.6773, Training Accuracy= 0.752\n",
      "Epoch: 1130, Loss= 0.6768, Training Accuracy= 0.752\n",
      "Epoch: 1140, Loss= 0.6764, Training Accuracy= 0.752\n",
      "Epoch: 1150, Loss= 0.6760, Training Accuracy= 0.752\n",
      "Epoch: 1160, Loss= 0.6755, Training Accuracy= 0.752\n",
      "Epoch: 1170, Loss= 0.6750, Training Accuracy= 0.752\n",
      "Epoch: 1180, Loss= 0.6746, Training Accuracy= 0.752\n",
      "Epoch: 1190, Loss= 0.6741, Training Accuracy= 0.752\n",
      "Epoch: 1200, Loss= 0.6736, Training Accuracy= 0.752\n",
      "Epoch: 1210, Loss= 0.6731, Training Accuracy= 0.752\n",
      "Epoch: 1220, Loss= 0.6725, Training Accuracy= 0.752\n",
      "Epoch: 1230, Loss= 0.6720, Training Accuracy= 0.752\n",
      "Epoch: 1240, Loss= 0.6714, Training Accuracy= 0.752\n",
      "Epoch: 1250, Loss= 0.6708, Training Accuracy= 0.752\n",
      "Epoch: 1260, Loss= 0.6702, Training Accuracy= 0.752\n",
      "Epoch: 1270, Loss= 0.6696, Training Accuracy= 0.752\n",
      "Epoch: 1280, Loss= 0.6690, Training Accuracy= 0.752\n",
      "Epoch: 1290, Loss= 0.6683, Training Accuracy= 0.752\n",
      "Epoch: 1300, Loss= 0.6677, Training Accuracy= 0.752\n",
      "Epoch: 1310, Loss= 0.6670, Training Accuracy= 0.752\n",
      "Epoch: 1320, Loss= 0.6663, Training Accuracy= 0.752\n",
      "Epoch: 1330, Loss= 0.6656, Training Accuracy= 0.752\n",
      "Epoch: 1340, Loss= 0.6648, Training Accuracy= 0.752\n",
      "Epoch: 1350, Loss= 0.6641, Training Accuracy= 0.752\n",
      "Epoch: 1360, Loss= 0.6633, Training Accuracy= 0.752\n",
      "Epoch: 1370, Loss= 0.6625, Training Accuracy= 0.752\n",
      "Epoch: 1380, Loss= 0.6616, Training Accuracy= 0.752\n",
      "Epoch: 1390, Loss= 0.6608, Training Accuracy= 0.752\n",
      "Epoch: 1400, Loss= 0.6599, Training Accuracy= 0.752\n",
      "Epoch: 1410, Loss= 0.6590, Training Accuracy= 0.752\n",
      "Epoch: 1420, Loss= 0.6580, Training Accuracy= 0.752\n",
      "Epoch: 1430, Loss= 0.6571, Training Accuracy= 0.752\n",
      "Epoch: 1440, Loss= 0.6561, Training Accuracy= 0.752\n",
      "Epoch: 1450, Loss= 0.6551, Training Accuracy= 0.752\n",
      "Epoch: 1460, Loss= 0.6540, Training Accuracy= 0.752\n",
      "Epoch: 1470, Loss= 0.6529, Training Accuracy= 0.752\n",
      "Epoch: 1480, Loss= 0.6518, Training Accuracy= 0.752\n",
      "Epoch: 1490, Loss= 0.6507, Training Accuracy= 0.752\n",
      "Epoch: 1500, Loss= 0.6495, Training Accuracy= 0.752\n",
      "Epoch: 1510, Loss= 0.6483, Training Accuracy= 0.752\n",
      "Epoch: 1520, Loss= 0.6471, Training Accuracy= 0.752\n",
      "Epoch: 1530, Loss= 0.6458, Training Accuracy= 0.752\n",
      "Epoch: 1540, Loss= 0.6445, Training Accuracy= 0.752\n",
      "Epoch: 1550, Loss= 0.6431, Training Accuracy= 0.752\n",
      "Epoch: 1560, Loss= 0.6417, Training Accuracy= 0.752\n",
      "Epoch: 1570, Loss= 0.6403, Training Accuracy= 0.752\n",
      "Epoch: 1580, Loss= 0.6388, Training Accuracy= 0.752\n",
      "Epoch: 1590, Loss= 0.6373, Training Accuracy= 0.752\n",
      "Epoch: 1600, Loss= 0.6358, Training Accuracy= 0.752\n",
      "Epoch: 1610, Loss= 0.6342, Training Accuracy= 0.752\n",
      "Epoch: 1620, Loss= 0.6325, Training Accuracy= 0.752\n",
      "Epoch: 1630, Loss= 0.6309, Training Accuracy= 0.752\n",
      "Epoch: 1640, Loss= 0.6291, Training Accuracy= 0.752\n",
      "Epoch: 1650, Loss= 0.6274, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.6255, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.6237, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.6217, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.6198, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.6177, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.6157, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.6135, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.6113, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.6091, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.6068, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.6044, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.6020, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.5996, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.5970, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.5944, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.5918, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.5891, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.5863, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.5835, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.5806, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.5777, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.5746, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.5716, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.5684, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.5652, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.5619, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.5586, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.5552, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.5518, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.5483, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.5447, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.5410, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.5373, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.5336, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.7528, Training Accuracy= 0.505\n",
      "Epoch: 10, Loss= 0.7426, Training Accuracy= 0.505\n",
      "Epoch: 20, Loss= 0.7355, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.7303, Training Accuracy= 0.505\n",
      "Epoch: 40, Loss= 0.7261, Training Accuracy= 0.505\n",
      "Epoch: 50, Loss= 0.7225, Training Accuracy= 0.505\n",
      "Epoch: 60, Loss= 0.7194, Training Accuracy= 0.505\n",
      "Epoch: 70, Loss= 0.7166, Training Accuracy= 0.505\n",
      "Epoch: 80, Loss= 0.7141, Training Accuracy= 0.505\n",
      "Epoch: 90, Loss= 0.7118, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.7097, Training Accuracy= 0.505\n",
      "Epoch: 110, Loss= 0.7077, Training Accuracy= 0.505\n",
      "Epoch: 120, Loss= 0.7058, Training Accuracy= 0.505\n",
      "Epoch: 130, Loss= 0.7041, Training Accuracy= 0.505\n",
      "Epoch: 140, Loss= 0.7025, Training Accuracy= 0.505\n",
      "Epoch: 150, Loss= 0.7010, Training Accuracy= 0.505\n",
      "Epoch: 160, Loss= 0.6996, Training Accuracy= 0.505\n",
      "Epoch: 170, Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 180, Loss= 0.6969, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.6957, Training Accuracy= 0.505\n",
      "Epoch: 200, Loss= 0.6945, Training Accuracy= 0.505\n",
      "Epoch: 210, Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 220, Loss= 0.6923, Training Accuracy= 0.505\n",
      "Epoch: 230, Loss= 0.6912, Training Accuracy= 0.505\n",
      "Epoch: 240, Loss= 0.6901, Training Accuracy= 0.505\n",
      "Epoch: 250, Loss= 0.6891, Training Accuracy= 0.505\n",
      "Epoch: 260, Loss= 0.6881, Training Accuracy= 0.505\n",
      "Epoch: 270, Loss= 0.6872, Training Accuracy= 0.505\n",
      "Epoch: 280, Loss= 0.6862, Training Accuracy= 0.505\n",
      "Epoch: 290, Loss= 0.6853, Training Accuracy= 0.505\n",
      "Epoch: 300, Loss= 0.6844, Training Accuracy= 0.505\n",
      "Epoch: 310, Loss= 0.6835, Training Accuracy= 0.505\n",
      "Epoch: 320, Loss= 0.6826, Training Accuracy= 0.505\n",
      "Epoch: 330, Loss= 0.6816, Training Accuracy= 0.505\n",
      "Epoch: 340, Loss= 0.6808, Training Accuracy= 0.505\n",
      "Epoch: 350, Loss= 0.6799, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, Loss= 0.6790, Training Accuracy= 0.505\n",
      "Epoch: 370, Loss= 0.6781, Training Accuracy= 0.505\n",
      "Epoch: 380, Loss= 0.6772, Training Accuracy= 0.505\n",
      "Epoch: 390, Loss= 0.6763, Training Accuracy= 0.754\n",
      "Epoch: 400, Loss= 0.6755, Training Accuracy= 0.754\n",
      "Epoch: 410, Loss= 0.6746, Training Accuracy= 0.754\n",
      "Epoch: 420, Loss= 0.6737, Training Accuracy= 0.754\n",
      "Epoch: 430, Loss= 0.6728, Training Accuracy= 0.754\n",
      "Epoch: 440, Loss= 0.6719, Training Accuracy= 0.754\n",
      "Epoch: 450, Loss= 0.6710, Training Accuracy= 0.754\n",
      "Epoch: 460, Loss= 0.6701, Training Accuracy= 0.754\n",
      "Epoch: 470, Loss= 0.6692, Training Accuracy= 0.754\n",
      "Epoch: 480, Loss= 0.6682, Training Accuracy= 0.754\n",
      "Epoch: 490, Loss= 0.6673, Training Accuracy= 0.754\n",
      "Epoch: 500, Loss= 0.6664, Training Accuracy= 0.754\n",
      "Epoch: 510, Loss= 0.6655, Training Accuracy= 0.754\n",
      "Epoch: 520, Loss= 0.6645, Training Accuracy= 0.754\n",
      "Epoch: 530, Loss= 0.6636, Training Accuracy= 0.754\n",
      "Epoch: 540, Loss= 0.6626, Training Accuracy= 0.754\n",
      "Epoch: 550, Loss= 0.6616, Training Accuracy= 0.754\n",
      "Epoch: 560, Loss= 0.6606, Training Accuracy= 0.754\n",
      "Epoch: 570, Loss= 0.6596, Training Accuracy= 0.754\n",
      "Epoch: 580, Loss= 0.6586, Training Accuracy= 0.754\n",
      "Epoch: 590, Loss= 0.6576, Training Accuracy= 0.754\n",
      "Epoch: 600, Loss= 0.6566, Training Accuracy= 0.754\n",
      "Epoch: 610, Loss= 0.6556, Training Accuracy= 0.754\n",
      "Epoch: 620, Loss= 0.6545, Training Accuracy= 0.754\n",
      "Epoch: 630, Loss= 0.6535, Training Accuracy= 0.754\n",
      "Epoch: 640, Loss= 0.6524, Training Accuracy= 0.754\n",
      "Epoch: 650, Loss= 0.6513, Training Accuracy= 0.754\n",
      "Epoch: 660, Loss= 0.6502, Training Accuracy= 0.754\n",
      "Epoch: 670, Loss= 0.6491, Training Accuracy= 0.754\n",
      "Epoch: 680, Loss= 0.6480, Training Accuracy= 0.754\n",
      "Epoch: 690, Loss= 0.6468, Training Accuracy= 0.754\n",
      "Epoch: 700, Loss= 0.6456, Training Accuracy= 0.754\n",
      "Epoch: 710, Loss= 0.6445, Training Accuracy= 0.754\n",
      "Epoch: 720, Loss= 0.6433, Training Accuracy= 0.754\n",
      "Epoch: 730, Loss= 0.6421, Training Accuracy= 0.754\n",
      "Epoch: 740, Loss= 0.6408, Training Accuracy= 0.754\n",
      "Epoch: 750, Loss= 0.6396, Training Accuracy= 0.754\n",
      "Epoch: 760, Loss= 0.6383, Training Accuracy= 0.754\n",
      "Epoch: 770, Loss= 0.6370, Training Accuracy= 0.754\n",
      "Epoch: 780, Loss= 0.6357, Training Accuracy= 0.754\n",
      "Epoch: 790, Loss= 0.6344, Training Accuracy= 0.754\n",
      "Epoch: 800, Loss= 0.6331, Training Accuracy= 0.754\n",
      "Epoch: 810, Loss= 0.6317, Training Accuracy= 0.754\n",
      "Epoch: 820, Loss= 0.6303, Training Accuracy= 0.754\n",
      "Epoch: 830, Loss= 0.6289, Training Accuracy= 0.754\n",
      "Epoch: 840, Loss= 0.6275, Training Accuracy= 0.754\n",
      "Epoch: 850, Loss= 0.6261, Training Accuracy= 0.754\n",
      "Epoch: 860, Loss= 0.6246, Training Accuracy= 0.754\n",
      "Epoch: 870, Loss= 0.6231, Training Accuracy= 0.754\n",
      "Epoch: 880, Loss= 0.6216, Training Accuracy= 0.754\n",
      "Epoch: 890, Loss= 0.6201, Training Accuracy= 0.754\n",
      "Epoch: 900, Loss= 0.6185, Training Accuracy= 0.754\n",
      "Epoch: 910, Loss= 0.6169, Training Accuracy= 0.754\n",
      "Epoch: 920, Loss= 0.6153, Training Accuracy= 0.754\n",
      "Epoch: 930, Loss= 0.6137, Training Accuracy= 0.754\n",
      "Epoch: 940, Loss= 0.6120, Training Accuracy= 0.754\n",
      "Epoch: 950, Loss= 0.6103, Training Accuracy= 0.754\n",
      "Epoch: 960, Loss= 0.6086, Training Accuracy= 0.754\n",
      "Epoch: 970, Loss= 0.6069, Training Accuracy= 0.754\n",
      "Epoch: 980, Loss= 0.6051, Training Accuracy= 0.754\n",
      "Epoch: 990, Loss= 0.6033, Training Accuracy= 0.754\n",
      "Epoch: 1000, Loss= 0.6015, Training Accuracy= 0.754\n",
      "Epoch: 1010, Loss= 0.5997, Training Accuracy= 0.754\n",
      "Epoch: 1020, Loss= 0.5978, Training Accuracy= 0.754\n",
      "Epoch: 1030, Loss= 0.5959, Training Accuracy= 0.754\n",
      "Epoch: 1040, Loss= 0.5940, Training Accuracy= 0.754\n",
      "Epoch: 1050, Loss= 0.5921, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.5901, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.5881, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.5861, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.5840, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.5819, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.5798, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.5777, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.5756, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.5734, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.5711, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.5689, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.5666, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.5643, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.5620, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.5597, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.5573, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.5549, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.5525, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.5500, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.5475, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.5450, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.5425, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.5399, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.5373, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.5347, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.5321, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.5295, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.5268, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.5241, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.5214, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.5186, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.5159, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.5131, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.5103, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.5075, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.5046, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.5018, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.4989, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.4960, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.4931, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.4902, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.4872, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.4843, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.4813, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.4783, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.4753, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.4723, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.4693, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.4662, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.4632, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.4601, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.4571, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.4540, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.4509, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.4478, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.4447, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.4416, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.4385, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.4354, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.4323, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.4292, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.4260, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.4229, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.4198, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.4166, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.4135, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.4104, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.4073, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.4041, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.4010, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.3979, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.3948, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.3917, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.3886, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.3855, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.3824, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.3793, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.3762, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.3731, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.3701, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.3670, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.3640, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.3609, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.3579, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.3549, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.3519, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.3489, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.3459, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.3430, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1950, Loss= 0.3400, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.3371, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.3342, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.3313, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.3284, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.9484, Training Accuracy= 0.501\n",
      "Epoch: 10, Loss= 0.8456, Training Accuracy= 0.501\n",
      "Epoch: 20, Loss= 0.7751, Training Accuracy= 0.501\n",
      "Epoch: 30, Loss= 0.7285, Training Accuracy= 0.501\n",
      "Epoch: 40, Loss= 0.6983, Training Accuracy= 0.501\n",
      "Epoch: 50, Loss= 0.6785, Training Accuracy= 0.501\n",
      "Epoch: 60, Loss= 0.6651, Training Accuracy= 0.748\n",
      "Epoch: 70, Loss= 0.6556, Training Accuracy= 0.748\n",
      "Epoch: 80, Loss= 0.6484, Training Accuracy= 0.748\n",
      "Epoch: 90, Loss= 0.6426, Training Accuracy= 0.748\n",
      "Epoch: 100, Loss= 0.6376, Training Accuracy= 0.748\n",
      "Epoch: 110, Loss= 0.6330, Training Accuracy= 0.748\n",
      "Epoch: 120, Loss= 0.6288, Training Accuracy= 0.748\n",
      "Epoch: 130, Loss= 0.6248, Training Accuracy= 0.748\n",
      "Epoch: 140, Loss= 0.6210, Training Accuracy= 0.748\n",
      "Epoch: 150, Loss= 0.6172, Training Accuracy= 0.748\n",
      "Epoch: 160, Loss= 0.6136, Training Accuracy= 0.748\n",
      "Epoch: 170, Loss= 0.6100, Training Accuracy= 1.000\n",
      "Epoch: 180, Loss= 0.6064, Training Accuracy= 1.000\n",
      "Epoch: 190, Loss= 0.6029, Training Accuracy= 1.000\n",
      "Epoch: 200, Loss= 0.5995, Training Accuracy= 1.000\n",
      "Epoch: 210, Loss= 0.5960, Training Accuracy= 1.000\n",
      "Epoch: 220, Loss= 0.5927, Training Accuracy= 1.000\n",
      "Epoch: 230, Loss= 0.5893, Training Accuracy= 1.000\n",
      "Epoch: 240, Loss= 0.5859, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.5826, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.5793, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.5760, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.5727, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.5694, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.5661, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.5628, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.5595, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.5562, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.5530, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.5497, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.5464, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.5431, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.5398, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.5365, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.5332, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.5299, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5266, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5233, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5200, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5167, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5133, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5100, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5067, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5033, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.5000, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.4967, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.4933, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.4900, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.4866, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.4833, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.4799, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.4766, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.4732, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4699, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.4665, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.4632, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.4599, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.4565, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.4532, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.4499, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.4466, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.4433, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.4400, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.4367, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.4334, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.4302, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.4269, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.4237, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.4205, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.4172, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.4140, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.4109, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.4077, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.4045, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.4014, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.3983, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.3951, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.3920, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.3890, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.3859, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.3829, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.3798, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.3768, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.3739, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.3709, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.3679, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.3650, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.3621, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.3592, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.3564, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.3535, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.3507, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.3479, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.3451, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.3423, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.3396, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.3369, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.3342, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.3315, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.3288, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.3262, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.3236, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.3210, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.3184, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.3159, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.3134, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.3109, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.3084, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.3059, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.3035, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.3010, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.2986, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.2963, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.2939, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.2916, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.2893, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.2870, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.2847, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.2824, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.2802, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.2780, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.2758, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.2736, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.2715, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.2693, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.2672, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.2651, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.2631, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.2610, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.2590, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.2570, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.2550, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.2530, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.2510, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.2491, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.2472, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.2453, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.2434, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.2415, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.2397, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.2378, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.2360, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.2342, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.2324, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.2307, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.2289, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.2272, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.2255, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1540, Loss= 0.2238, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.2221, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.2204, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.2188, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.2171, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.2155, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.2139, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.2123, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.2108, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.2092, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.2077, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.2061, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.2046, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.2031, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.2016, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.2002, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.1987, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.1973, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.1958, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.1944, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.1930, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.1916, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.1903, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.1889, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.1876, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.1862, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.1849, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.1836, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.1823, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.1810, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.1797, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.1785, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.1772, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.1760, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.1748, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.1736, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.1724, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.1712, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.1700, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.1688, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.1677, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.1665, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.1654, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.1643, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.1631, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.1620, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 1.0593, Training Accuracy= 0.501\n",
      "Epoch: 10, Loss= 0.9117, Training Accuracy= 0.501\n",
      "Epoch: 20, Loss= 0.8147, Training Accuracy= 0.501\n",
      "Epoch: 30, Loss= 0.7575, Training Accuracy= 0.501\n",
      "Epoch: 40, Loss= 0.7263, Training Accuracy= 0.501\n",
      "Epoch: 50, Loss= 0.7098, Training Accuracy= 0.501\n",
      "Epoch: 60, Loss= 0.7011, Training Accuracy= 0.748\n",
      "Epoch: 70, Loss= 0.6964, Training Accuracy= 0.501\n",
      "Epoch: 80, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 90, Loss= 0.6920, Training Accuracy= 0.501\n",
      "Epoch: 100, Loss= 0.6908, Training Accuracy= 0.501\n",
      "Epoch: 110, Loss= 0.6898, Training Accuracy= 0.501\n",
      "Epoch: 120, Loss= 0.6890, Training Accuracy= 0.501\n",
      "Epoch: 130, Loss= 0.6883, Training Accuracy= 0.501\n",
      "Epoch: 140, Loss= 0.6877, Training Accuracy= 0.501\n",
      "Epoch: 150, Loss= 0.6871, Training Accuracy= 0.501\n",
      "Epoch: 160, Loss= 0.6866, Training Accuracy= 0.501\n",
      "Epoch: 170, Loss= 0.6860, Training Accuracy= 0.501\n",
      "Epoch: 180, Loss= 0.6855, Training Accuracy= 0.501\n",
      "Epoch: 190, Loss= 0.6851, Training Accuracy= 0.501\n",
      "Epoch: 200, Loss= 0.6846, Training Accuracy= 0.501\n",
      "Epoch: 210, Loss= 0.6842, Training Accuracy= 0.501\n",
      "Epoch: 220, Loss= 0.6838, Training Accuracy= 0.501\n",
      "Epoch: 230, Loss= 0.6834, Training Accuracy= 0.501\n",
      "Epoch: 240, Loss= 0.6830, Training Accuracy= 0.501\n",
      "Epoch: 250, Loss= 0.6826, Training Accuracy= 0.501\n",
      "Epoch: 260, Loss= 0.6822, Training Accuracy= 0.501\n",
      "Epoch: 270, Loss= 0.6819, Training Accuracy= 0.501\n",
      "Epoch: 280, Loss= 0.6815, Training Accuracy= 0.501\n",
      "Epoch: 290, Loss= 0.6812, Training Accuracy= 0.501\n",
      "Epoch: 300, Loss= 0.6808, Training Accuracy= 0.501\n",
      "Epoch: 310, Loss= 0.6805, Training Accuracy= 0.501\n",
      "Epoch: 320, Loss= 0.6802, Training Accuracy= 0.501\n",
      "Epoch: 330, Loss= 0.6799, Training Accuracy= 0.501\n",
      "Epoch: 340, Loss= 0.6796, Training Accuracy= 0.501\n",
      "Epoch: 350, Loss= 0.6793, Training Accuracy= 0.501\n",
      "Epoch: 360, Loss= 0.6789, Training Accuracy= 0.501\n",
      "Epoch: 370, Loss= 0.6786, Training Accuracy= 0.501\n",
      "Epoch: 380, Loss= 0.6783, Training Accuracy= 0.501\n",
      "Epoch: 390, Loss= 0.6780, Training Accuracy= 0.501\n",
      "Epoch: 400, Loss= 0.6777, Training Accuracy= 0.501\n",
      "Epoch: 410, Loss= 0.6774, Training Accuracy= 0.501\n",
      "Epoch: 420, Loss= 0.6771, Training Accuracy= 0.501\n",
      "Epoch: 430, Loss= 0.6768, Training Accuracy= 0.501\n",
      "Epoch: 440, Loss= 0.6765, Training Accuracy= 0.501\n",
      "Epoch: 450, Loss= 0.6762, Training Accuracy= 0.501\n",
      "Epoch: 460, Loss= 0.6759, Training Accuracy= 0.501\n",
      "Epoch: 470, Loss= 0.6756, Training Accuracy= 0.501\n",
      "Epoch: 480, Loss= 0.6753, Training Accuracy= 0.501\n",
      "Epoch: 490, Loss= 0.6750, Training Accuracy= 0.501\n",
      "Epoch: 500, Loss= 0.6746, Training Accuracy= 0.501\n",
      "Epoch: 510, Loss= 0.6743, Training Accuracy= 0.753\n",
      "Epoch: 520, Loss= 0.6740, Training Accuracy= 0.753\n",
      "Epoch: 530, Loss= 0.6737, Training Accuracy= 0.753\n",
      "Epoch: 540, Loss= 0.6733, Training Accuracy= 0.753\n",
      "Epoch: 550, Loss= 0.6730, Training Accuracy= 0.753\n",
      "Epoch: 560, Loss= 0.6727, Training Accuracy= 0.753\n",
      "Epoch: 570, Loss= 0.6723, Training Accuracy= 0.753\n",
      "Epoch: 580, Loss= 0.6720, Training Accuracy= 0.753\n",
      "Epoch: 590, Loss= 0.6716, Training Accuracy= 0.753\n",
      "Epoch: 600, Loss= 0.6713, Training Accuracy= 0.753\n",
      "Epoch: 610, Loss= 0.6710, Training Accuracy= 0.753\n",
      "Epoch: 620, Loss= 0.6706, Training Accuracy= 0.753\n",
      "Epoch: 630, Loss= 0.6702, Training Accuracy= 0.753\n",
      "Epoch: 640, Loss= 0.6698, Training Accuracy= 0.753\n",
      "Epoch: 650, Loss= 0.6694, Training Accuracy= 0.753\n",
      "Epoch: 660, Loss= 0.6691, Training Accuracy= 0.753\n",
      "Epoch: 670, Loss= 0.6686, Training Accuracy= 0.753\n",
      "Epoch: 680, Loss= 0.6683, Training Accuracy= 0.753\n",
      "Epoch: 690, Loss= 0.6679, Training Accuracy= 0.753\n",
      "Epoch: 700, Loss= 0.6674, Training Accuracy= 0.753\n",
      "Epoch: 710, Loss= 0.6670, Training Accuracy= 0.753\n",
      "Epoch: 720, Loss= 0.6666, Training Accuracy= 0.753\n",
      "Epoch: 730, Loss= 0.6661, Training Accuracy= 0.753\n",
      "Epoch: 740, Loss= 0.6657, Training Accuracy= 0.753\n",
      "Epoch: 750, Loss= 0.6652, Training Accuracy= 0.753\n",
      "Epoch: 760, Loss= 0.6648, Training Accuracy= 0.753\n",
      "Epoch: 770, Loss= 0.6643, Training Accuracy= 0.753\n",
      "Epoch: 780, Loss= 0.6638, Training Accuracy= 0.753\n",
      "Epoch: 790, Loss= 0.6633, Training Accuracy= 0.753\n",
      "Epoch: 800, Loss= 0.6629, Training Accuracy= 0.753\n",
      "Epoch: 810, Loss= 0.6623, Training Accuracy= 0.753\n",
      "Epoch: 820, Loss= 0.6618, Training Accuracy= 0.753\n",
      "Epoch: 830, Loss= 0.6613, Training Accuracy= 0.753\n",
      "Epoch: 840, Loss= 0.6608, Training Accuracy= 0.753\n",
      "Epoch: 850, Loss= 0.6602, Training Accuracy= 0.753\n",
      "Epoch: 860, Loss= 0.6596, Training Accuracy= 0.753\n",
      "Epoch: 870, Loss= 0.6591, Training Accuracy= 0.753\n",
      "Epoch: 880, Loss= 0.6585, Training Accuracy= 0.753\n",
      "Epoch: 890, Loss= 0.6579, Training Accuracy= 0.753\n",
      "Epoch: 900, Loss= 0.6573, Training Accuracy= 0.753\n",
      "Epoch: 910, Loss= 0.6567, Training Accuracy= 0.753\n",
      "Epoch: 920, Loss= 0.6561, Training Accuracy= 0.753\n",
      "Epoch: 930, Loss= 0.6555, Training Accuracy= 0.753\n",
      "Epoch: 940, Loss= 0.6548, Training Accuracy= 0.753\n",
      "Epoch: 950, Loss= 0.6541, Training Accuracy= 0.753\n",
      "Epoch: 960, Loss= 0.6535, Training Accuracy= 0.753\n",
      "Epoch: 970, Loss= 0.6528, Training Accuracy= 0.753\n",
      "Epoch: 980, Loss= 0.6521, Training Accuracy= 0.753\n",
      "Epoch: 990, Loss= 0.6513, Training Accuracy= 0.753\n",
      "Epoch: 1000, Loss= 0.6506, Training Accuracy= 0.753\n",
      "Epoch: 1010, Loss= 0.6498, Training Accuracy= 0.753\n",
      "Epoch: 1020, Loss= 0.6491, Training Accuracy= 0.753\n",
      "Epoch: 1030, Loss= 0.6483, Training Accuracy= 0.753\n",
      "Epoch: 1040, Loss= 0.6475, Training Accuracy= 0.753\n",
      "Epoch: 1050, Loss= 0.6467, Training Accuracy= 0.753\n",
      "Epoch: 1060, Loss= 0.6458, Training Accuracy= 0.753\n",
      "Epoch: 1070, Loss= 0.6450, Training Accuracy= 0.753\n",
      "Epoch: 1080, Loss= 0.6441, Training Accuracy= 0.753\n",
      "Epoch: 1090, Loss= 0.6432, Training Accuracy= 0.753\n",
      "Epoch: 1100, Loss= 0.6423, Training Accuracy= 0.753\n",
      "Epoch: 1110, Loss= 0.6414, Training Accuracy= 0.753\n",
      "Epoch: 1120, Loss= 0.6405, Training Accuracy= 0.753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1130, Loss= 0.6395, Training Accuracy= 0.753\n",
      "Epoch: 1140, Loss= 0.6385, Training Accuracy= 0.753\n",
      "Epoch: 1150, Loss= 0.6375, Training Accuracy= 0.753\n",
      "Epoch: 1160, Loss= 0.6365, Training Accuracy= 0.753\n",
      "Epoch: 1170, Loss= 0.6355, Training Accuracy= 0.753\n",
      "Epoch: 1180, Loss= 0.6344, Training Accuracy= 0.753\n",
      "Epoch: 1190, Loss= 0.6333, Training Accuracy= 0.753\n",
      "Epoch: 1200, Loss= 0.6322, Training Accuracy= 0.753\n",
      "Epoch: 1210, Loss= 0.6311, Training Accuracy= 0.753\n",
      "Epoch: 1220, Loss= 0.6299, Training Accuracy= 0.753\n",
      "Epoch: 1230, Loss= 0.6288, Training Accuracy= 0.753\n",
      "Epoch: 1240, Loss= 0.6276, Training Accuracy= 0.753\n",
      "Epoch: 1250, Loss= 0.6263, Training Accuracy= 0.753\n",
      "Epoch: 1260, Loss= 0.6251, Training Accuracy= 0.753\n",
      "Epoch: 1270, Loss= 0.6238, Training Accuracy= 0.753\n",
      "Epoch: 1280, Loss= 0.6225, Training Accuracy= 0.753\n",
      "Epoch: 1290, Loss= 0.6212, Training Accuracy= 0.753\n",
      "Epoch: 1300, Loss= 0.6198, Training Accuracy= 0.753\n",
      "Epoch: 1310, Loss= 0.6184, Training Accuracy= 0.753\n",
      "Epoch: 1320, Loss= 0.6171, Training Accuracy= 0.753\n",
      "Epoch: 1330, Loss= 0.6156, Training Accuracy= 0.753\n",
      "Epoch: 1340, Loss= 0.6142, Training Accuracy= 0.753\n",
      "Epoch: 1350, Loss= 0.6127, Training Accuracy= 0.753\n",
      "Epoch: 1360, Loss= 0.6111, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.6096, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.6080, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.6064, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.6048, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.6031, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.6014, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.5997, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.5979, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.5961, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.5943, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.5925, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.5906, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.5887, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.5867, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.5847, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.5827, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.5806, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.5786, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.5764, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.5743, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.5721, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.5699, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.5676, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.5653, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.5630, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.5607, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.5583, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.5558, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.5534, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.5509, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.5484, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.5458, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.5433, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.5406, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.5380, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.5353, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.5326, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.5299, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.5271, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.5243, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.5215, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.5186, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.5158, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.5129, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.5099, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.5070, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.5040, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.5010, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.4980, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.4949, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.4919, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.4888, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.4857, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.4826, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.4795, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.4763, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.4732, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.4700, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.4668, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.4636, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.4604, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.4572, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.4540, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.7080, Training Accuracy= 0.498\n",
      "Epoch: 10, Loss= 0.6927, Training Accuracy= 0.498\n",
      "Epoch: 20, Loss= 0.6845, Training Accuracy= 0.498\n",
      "Epoch: 30, Loss= 0.6791, Training Accuracy= 0.498\n",
      "Epoch: 40, Loss= 0.6749, Training Accuracy= 0.498\n",
      "Epoch: 50, Loss= 0.6711, Training Accuracy= 0.498\n",
      "Epoch: 60, Loss= 0.6676, Training Accuracy= 0.498\n",
      "Epoch: 70, Loss= 0.6643, Training Accuracy= 0.498\n",
      "Epoch: 80, Loss= 0.6611, Training Accuracy= 0.498\n",
      "Epoch: 90, Loss= 0.6580, Training Accuracy= 0.498\n",
      "Epoch: 100, Loss= 0.6549, Training Accuracy= 0.498\n",
      "Epoch: 110, Loss= 0.6519, Training Accuracy= 0.751\n",
      "Epoch: 120, Loss= 0.6490, Training Accuracy= 0.751\n",
      "Epoch: 130, Loss= 0.6460, Training Accuracy= 0.751\n",
      "Epoch: 140, Loss= 0.6431, Training Accuracy= 1.000\n",
      "Epoch: 150, Loss= 0.6402, Training Accuracy= 1.000\n",
      "Epoch: 160, Loss= 0.6373, Training Accuracy= 1.000\n",
      "Epoch: 170, Loss= 0.6344, Training Accuracy= 1.000\n",
      "Epoch: 180, Loss= 0.6315, Training Accuracy= 1.000\n",
      "Epoch: 190, Loss= 0.6286, Training Accuracy= 1.000\n",
      "Epoch: 200, Loss= 0.6257, Training Accuracy= 1.000\n",
      "Epoch: 210, Loss= 0.6228, Training Accuracy= 1.000\n",
      "Epoch: 220, Loss= 0.6198, Training Accuracy= 1.000\n",
      "Epoch: 230, Loss= 0.6168, Training Accuracy= 1.000\n",
      "Epoch: 240, Loss= 0.6138, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.6108, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.6078, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.6047, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.6016, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.5984, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.5953, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.5921, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.5889, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.5856, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.5824, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.5791, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.5757, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.5724, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.5690, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.5655, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.5621, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.5586, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5551, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5516, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5480, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5444, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5408, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5371, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5335, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5298, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.5261, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.5223, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.5186, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.5148, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.5110, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.5071, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.5033, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.4994, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.4956, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4917, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.4878, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.4839, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.4800, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.4760, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.4721, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.4682, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.4642, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.4603, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.4564, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.4524, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.4485, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 710, Loss= 0.4446, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.4407, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.4367, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.4328, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.4290, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.4251, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.4212, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.4174, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.4135, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.4097, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.4059, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.4021, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.3984, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.3946, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.3909, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.3872, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.3836, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.3799, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.3763, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.3727, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.3691, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.3656, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.3621, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.3586, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.3551, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.3517, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.3483, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.3449, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.3416, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.3383, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.3350, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.3318, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.3286, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.3254, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.3222, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.3191, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.3160, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.3130, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.3099, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.3069, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.3040, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.3010, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.2981, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.2953, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.2924, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.2896, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.2868, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.2841, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.2814, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.2787, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.2760, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.2734, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.2708, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.2682, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.2657, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.2631, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.2606, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.2582, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.2557, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.2533, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.2510, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.2486, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.2463, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.2440, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.2417, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.2395, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.2373, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.2351, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.2329, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.2308, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.2286, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.2265, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.2245, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.2224, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.2204, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.2184, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.2164, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.2145, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.2125, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.2106, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.2087, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.2069, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.2050, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.2032, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.2014, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.1996, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.1979, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.1961, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.1944, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.1927, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.1910, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.1893, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.1877, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.1861, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.1845, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.1829, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.1813, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.1798, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.1782, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.1767, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.1752, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.1737, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.1723, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.1708, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.1694, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.1680, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.1666, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.1652, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.1638, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.1624, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.1611, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.1598, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.1585, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.1572, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.1559, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.1546, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.1534, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.1521, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.1509, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.1497, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.1485, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.1473, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.1462, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.1450, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.1439, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.1427, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.1416, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.1405, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.1394, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 1.4737, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 1.2824, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 1.1221, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.9950, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.8999, Training Accuracy= 0.497\n",
      "Epoch: 50, Loss= 0.8327, Training Accuracy= 0.497\n",
      "Epoch: 60, Loss= 0.7872, Training Accuracy= 0.497\n",
      "Epoch: 70, Loss= 0.7574, Training Accuracy= 0.497\n",
      "Epoch: 80, Loss= 0.7382, Training Accuracy= 0.497\n",
      "Epoch: 90, Loss= 0.7259, Training Accuracy= 0.497\n",
      "Epoch: 100, Loss= 0.7180, Training Accuracy= 0.497\n",
      "Epoch: 110, Loss= 0.7128, Training Accuracy= 0.497\n",
      "Epoch: 120, Loss= 0.7094, Training Accuracy= 0.497\n",
      "Epoch: 130, Loss= 0.7069, Training Accuracy= 0.250\n",
      "Epoch: 140, Loss= 0.7051, Training Accuracy= 0.497\n",
      "Epoch: 150, Loss= 0.7037, Training Accuracy= 0.497\n",
      "Epoch: 160, Loss= 0.7026, Training Accuracy= 0.497\n",
      "Epoch: 170, Loss= 0.7016, Training Accuracy= 0.497\n",
      "Epoch: 180, Loss= 0.7008, Training Accuracy= 0.497\n",
      "Epoch: 190, Loss= 0.7000, Training Accuracy= 0.497\n",
      "Epoch: 200, Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 210, Loss= 0.6985, Training Accuracy= 0.497\n",
      "Epoch: 220, Loss= 0.6978, Training Accuracy= 0.497\n",
      "Epoch: 230, Loss= 0.6971, Training Accuracy= 0.497\n",
      "Epoch: 240, Loss= 0.6964, Training Accuracy= 0.497\n",
      "Epoch: 250, Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 260, Loss= 0.6951, Training Accuracy= 0.497\n",
      "Epoch: 270, Loss= 0.6945, Training Accuracy= 0.497\n",
      "Epoch: 280, Loss= 0.6939, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 290, Loss= 0.6933, Training Accuracy= 0.497\n",
      "Epoch: 300, Loss= 0.6927, Training Accuracy= 0.497\n",
      "Epoch: 310, Loss= 0.6921, Training Accuracy= 0.497\n",
      "Epoch: 320, Loss= 0.6916, Training Accuracy= 0.497\n",
      "Epoch: 330, Loss= 0.6910, Training Accuracy= 0.497\n",
      "Epoch: 340, Loss= 0.6904, Training Accuracy= 0.753\n",
      "Epoch: 350, Loss= 0.6899, Training Accuracy= 0.753\n",
      "Epoch: 360, Loss= 0.6893, Training Accuracy= 0.753\n",
      "Epoch: 370, Loss= 0.6888, Training Accuracy= 0.753\n",
      "Epoch: 380, Loss= 0.6883, Training Accuracy= 0.753\n",
      "Epoch: 390, Loss= 0.6877, Training Accuracy= 0.507\n",
      "Epoch: 400, Loss= 0.6872, Training Accuracy= 0.507\n",
      "Epoch: 410, Loss= 0.6867, Training Accuracy= 0.507\n",
      "Epoch: 420, Loss= 0.6861, Training Accuracy= 0.507\n",
      "Epoch: 430, Loss= 0.6856, Training Accuracy= 0.507\n",
      "Epoch: 440, Loss= 0.6851, Training Accuracy= 0.507\n",
      "Epoch: 450, Loss= 0.6846, Training Accuracy= 0.507\n",
      "Epoch: 460, Loss= 0.6840, Training Accuracy= 0.507\n",
      "Epoch: 470, Loss= 0.6835, Training Accuracy= 0.507\n",
      "Epoch: 480, Loss= 0.6830, Training Accuracy= 0.507\n",
      "Epoch: 490, Loss= 0.6825, Training Accuracy= 0.507\n",
      "Epoch: 500, Loss= 0.6820, Training Accuracy= 0.753\n",
      "Epoch: 510, Loss= 0.6814, Training Accuracy= 0.753\n",
      "Epoch: 520, Loss= 0.6809, Training Accuracy= 0.753\n",
      "Epoch: 530, Loss= 0.6804, Training Accuracy= 0.753\n",
      "Epoch: 540, Loss= 0.6799, Training Accuracy= 0.753\n",
      "Epoch: 550, Loss= 0.6793, Training Accuracy= 0.753\n",
      "Epoch: 560, Loss= 0.6788, Training Accuracy= 0.753\n",
      "Epoch: 570, Loss= 0.6783, Training Accuracy= 0.753\n",
      "Epoch: 580, Loss= 0.6777, Training Accuracy= 0.753\n",
      "Epoch: 590, Loss= 0.6772, Training Accuracy= 0.753\n",
      "Epoch: 600, Loss= 0.6767, Training Accuracy= 0.753\n",
      "Epoch: 610, Loss= 0.6761, Training Accuracy= 0.753\n",
      "Epoch: 620, Loss= 0.6756, Training Accuracy= 0.753\n",
      "Epoch: 630, Loss= 0.6750, Training Accuracy= 0.753\n",
      "Epoch: 640, Loss= 0.6744, Training Accuracy= 0.753\n",
      "Epoch: 650, Loss= 0.6739, Training Accuracy= 0.753\n",
      "Epoch: 660, Loss= 0.6733, Training Accuracy= 0.753\n",
      "Epoch: 670, Loss= 0.6727, Training Accuracy= 0.753\n",
      "Epoch: 680, Loss= 0.6722, Training Accuracy= 0.753\n",
      "Epoch: 690, Loss= 0.6716, Training Accuracy= 0.753\n",
      "Epoch: 700, Loss= 0.6710, Training Accuracy= 0.753\n",
      "Epoch: 710, Loss= 0.6704, Training Accuracy= 0.753\n",
      "Epoch: 720, Loss= 0.6698, Training Accuracy= 0.753\n",
      "Epoch: 730, Loss= 0.6692, Training Accuracy= 0.753\n",
      "Epoch: 740, Loss= 0.6685, Training Accuracy= 0.753\n",
      "Epoch: 750, Loss= 0.6679, Training Accuracy= 0.753\n",
      "Epoch: 760, Loss= 0.6673, Training Accuracy= 0.753\n",
      "Epoch: 770, Loss= 0.6666, Training Accuracy= 0.753\n",
      "Epoch: 780, Loss= 0.6660, Training Accuracy= 0.753\n",
      "Epoch: 790, Loss= 0.6653, Training Accuracy= 0.753\n",
      "Epoch: 800, Loss= 0.6646, Training Accuracy= 0.753\n",
      "Epoch: 810, Loss= 0.6640, Training Accuracy= 0.753\n",
      "Epoch: 820, Loss= 0.6633, Training Accuracy= 0.753\n",
      "Epoch: 830, Loss= 0.6626, Training Accuracy= 0.753\n",
      "Epoch: 840, Loss= 0.6619, Training Accuracy= 0.753\n",
      "Epoch: 850, Loss= 0.6611, Training Accuracy= 0.753\n",
      "Epoch: 860, Loss= 0.6604, Training Accuracy= 0.753\n",
      "Epoch: 870, Loss= 0.6597, Training Accuracy= 0.753\n",
      "Epoch: 880, Loss= 0.6589, Training Accuracy= 0.753\n",
      "Epoch: 890, Loss= 0.6582, Training Accuracy= 0.753\n",
      "Epoch: 900, Loss= 0.6574, Training Accuracy= 0.753\n",
      "Epoch: 910, Loss= 0.6566, Training Accuracy= 0.753\n",
      "Epoch: 920, Loss= 0.6558, Training Accuracy= 0.753\n",
      "Epoch: 930, Loss= 0.6550, Training Accuracy= 0.753\n",
      "Epoch: 940, Loss= 0.6541, Training Accuracy= 0.753\n",
      "Epoch: 950, Loss= 0.6533, Training Accuracy= 0.753\n",
      "Epoch: 960, Loss= 0.6524, Training Accuracy= 0.753\n",
      "Epoch: 970, Loss= 0.6515, Training Accuracy= 0.753\n",
      "Epoch: 980, Loss= 0.6506, Training Accuracy= 0.753\n",
      "Epoch: 990, Loss= 0.6498, Training Accuracy= 0.753\n",
      "Epoch: 1000, Loss= 0.6488, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.6479, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.6469, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.6460, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.6450, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.6440, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.6430, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.6419, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.6408, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.6398, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.6387, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.6375, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.6364, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.6352, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.6340, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.6328, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.6316, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.6304, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.6291, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.6278, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.6265, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.6251, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.6238, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.6224, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.6209, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.6195, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.6180, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.6165, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.6150, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.6134, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.6118, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.6102, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.6086, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.6069, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.6052, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.6035, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.6017, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.5999, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.5981, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.5962, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.5944, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.5924, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.5905, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.5885, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.5865, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.5845, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.5824, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.5803, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.5781, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.5760, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.5738, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.5715, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.5692, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.5669, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.5646, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.5622, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.5599, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.5574, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.5550, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.5525, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.5499, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.5474, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.5448, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.5422, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.5396, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.5369, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.5342, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.5315, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.5287, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.5259, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.5231, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.5203, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.5175, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.5146, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.5117, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.5088, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.5058, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.5029, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.4999, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.4969, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.4939, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.4908, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.4878, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.4847, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.4816, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.4786, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.4755, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.4723, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1880, Loss= 0.4692, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.4661, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.4629, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.4598, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.4567, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.4535, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.4503, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.4472, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.4440, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.4409, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.4377, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.4345, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 0.8893, Training Accuracy= 0.495\n",
      "Epoch: 10, Loss= 0.7404, Training Accuracy= 0.747\n",
      "Epoch: 20, Loss= 0.7155, Training Accuracy= 0.499\n",
      "Epoch: 30, Loss= 0.7054, Training Accuracy= 0.499\n",
      "Epoch: 40, Loss= 0.6979, Training Accuracy= 0.499\n",
      "Epoch: 50, Loss= 0.6915, Training Accuracy= 0.499\n",
      "Epoch: 60, Loss= 0.6860, Training Accuracy= 0.499\n",
      "Epoch: 70, Loss= 0.6810, Training Accuracy= 0.499\n",
      "Epoch: 80, Loss= 0.6766, Training Accuracy= 0.499\n",
      "Epoch: 90, Loss= 0.6724, Training Accuracy= 0.499\n",
      "Epoch: 100, Loss= 0.6686, Training Accuracy= 0.499\n",
      "Epoch: 110, Loss= 0.6649, Training Accuracy= 0.499\n",
      "Epoch: 120, Loss= 0.6615, Training Accuracy= 0.752\n",
      "Epoch: 130, Loss= 0.6581, Training Accuracy= 0.752\n",
      "Epoch: 140, Loss= 0.6549, Training Accuracy= 0.752\n",
      "Epoch: 150, Loss= 0.6517, Training Accuracy= 0.752\n",
      "Epoch: 160, Loss= 0.6487, Training Accuracy= 0.752\n",
      "Epoch: 170, Loss= 0.6457, Training Accuracy= 0.752\n",
      "Epoch: 180, Loss= 0.6427, Training Accuracy= 0.752\n",
      "Epoch: 190, Loss= 0.6398, Training Accuracy= 0.752\n",
      "Epoch: 200, Loss= 0.6369, Training Accuracy= 0.752\n",
      "Epoch: 210, Loss= 0.6340, Training Accuracy= 0.752\n",
      "Epoch: 220, Loss= 0.6312, Training Accuracy= 0.752\n",
      "Epoch: 230, Loss= 0.6284, Training Accuracy= 0.752\n",
      "Epoch: 240, Loss= 0.6255, Training Accuracy= 0.752\n",
      "Epoch: 250, Loss= 0.6227, Training Accuracy= 0.752\n",
      "Epoch: 260, Loss= 0.6199, Training Accuracy= 0.752\n",
      "Epoch: 270, Loss= 0.6172, Training Accuracy= 0.752\n",
      "Epoch: 280, Loss= 0.6144, Training Accuracy= 0.752\n",
      "Epoch: 290, Loss= 0.6116, Training Accuracy= 0.752\n",
      "Epoch: 300, Loss= 0.6088, Training Accuracy= 0.752\n",
      "Epoch: 310, Loss= 0.6060, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.6032, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.6003, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.5975, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.5946, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.5918, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.5889, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.5860, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.5831, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.5801, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.5772, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5742, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5712, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5682, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5652, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5621, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5590, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5559, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5527, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.5496, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.5464, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.5432, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.5399, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.5367, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.5334, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.5301, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.5268, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.5234, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.5200, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.5166, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.5132, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.5098, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.5063, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.5028, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.4993, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.4958, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.4923, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.4888, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.4852, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.4816, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.4781, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.4745, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.4709, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.4672, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.4636, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.4600, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.4563, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.4527, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.4491, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.4454, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.4418, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.4381, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.4345, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.4308, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.4272, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.4235, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.4199, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.4162, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.4126, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.4090, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.4053, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.4017, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.3981, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.3946, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.3910, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.3874, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.3839, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.3803, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.3768, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.3733, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.3698, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.3663, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.3629, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.3594, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.3560, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.3526, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.3492, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.3459, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.3426, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.3392, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.3359, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.3327, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.3294, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.3262, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.3230, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.3198, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.3167, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.3136, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.3105, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.3074, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.3044, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.3014, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.2984, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.2954, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.2925, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.2896, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.2867, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.2839, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.2810, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.2782, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.2755, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.2727, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.2700, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.2674, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.2647, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.2621, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.2595, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.2569, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.2544, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.2519, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.2494, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.2469, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.2445, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.2421, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.2398, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.2374, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1470, Loss= 0.2351, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.2328, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.2305, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.2283, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.2261, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.2239, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.2218, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.2196, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.2175, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.2155, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.2134, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.2114, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.2094, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.2074, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.2055, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.2035, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.2016, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.1998, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.1979, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.1961, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.1942, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.1925, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.1907, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.1889, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.1872, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.1855, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.1838, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.1822, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.1805, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.1789, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.1773, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.1758, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.1742, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.1727, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.1711, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.1696, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.1682, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.1667, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.1653, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.1638, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.1624, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.1610, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.1597, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.1583, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.1570, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.1556, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.1543, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.1530, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.1518, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.1505, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.1493, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.1480, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.1468, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.8083, Training Accuracy= 0.504\n",
      "Epoch: 10, Loss= 0.7301, Training Accuracy= 0.504\n",
      "Epoch: 20, Loss= 0.7030, Training Accuracy= 0.504\n",
      "Epoch: 30, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 40, Loss= 0.6887, Training Accuracy= 0.751\n",
      "Epoch: 50, Loss= 0.6858, Training Accuracy= 0.751\n",
      "Epoch: 60, Loss= 0.6835, Training Accuracy= 0.751\n",
      "Epoch: 70, Loss= 0.6812, Training Accuracy= 0.499\n",
      "Epoch: 80, Loss= 0.6791, Training Accuracy= 0.499\n",
      "Epoch: 90, Loss= 0.6769, Training Accuracy= 0.499\n",
      "Epoch: 100, Loss= 0.6748, Training Accuracy= 0.499\n",
      "Epoch: 110, Loss= 0.6727, Training Accuracy= 0.499\n",
      "Epoch: 120, Loss= 0.6706, Training Accuracy= 0.499\n",
      "Epoch: 130, Loss= 0.6685, Training Accuracy= 0.499\n",
      "Epoch: 140, Loss= 0.6663, Training Accuracy= 0.499\n",
      "Epoch: 150, Loss= 0.6642, Training Accuracy= 0.749\n",
      "Epoch: 160, Loss= 0.6620, Training Accuracy= 0.749\n",
      "Epoch: 170, Loss= 0.6598, Training Accuracy= 1.000\n",
      "Epoch: 180, Loss= 0.6576, Training Accuracy= 1.000\n",
      "Epoch: 190, Loss= 0.6553, Training Accuracy= 1.000\n",
      "Epoch: 200, Loss= 0.6530, Training Accuracy= 1.000\n",
      "Epoch: 210, Loss= 0.6506, Training Accuracy= 1.000\n",
      "Epoch: 220, Loss= 0.6482, Training Accuracy= 1.000\n",
      "Epoch: 230, Loss= 0.6457, Training Accuracy= 1.000\n",
      "Epoch: 240, Loss= 0.6432, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.6406, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.6379, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.6352, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.6324, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.6295, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.6265, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.6234, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.6203, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.6170, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.6136, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.6102, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.6066, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.6029, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.5991, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.5952, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.5912, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.5870, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5828, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5784, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5739, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5694, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5647, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5598, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5549, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5499, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.5448, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.5396, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.5343, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.5289, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.5234, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.5179, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.5122, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.5065, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.5008, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4950, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.4891, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.4832, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.4773, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.4713, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.4653, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.4593, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.4532, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.4472, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.4411, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.4350, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.4290, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.4229, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.4169, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.4109, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.4049, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.3989, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.3929, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.3870, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.3812, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.3753, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.3696, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.3638, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.3582, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.3526, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.3470, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.3415, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.3361, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.3307, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.3254, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.3202, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.3150, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.3100, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.3049, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.3000, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.2952, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.2904, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.2857, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.2811, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.2766, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.2721, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.2677, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.2634, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.2592, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.2551, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.2510, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.2471, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1060, Loss= 0.2432, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.2393, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.2356, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.2319, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.2283, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.2248, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.2213, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.2180, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.2146, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.2114, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.2082, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.2051, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.2021, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.1991, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.1962, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1933, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1905, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1878, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1851, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1825, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1799, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1774, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1749, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1725, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.1701, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.1678, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.1656, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.1633, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.1612, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.1591, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.1570, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.1549, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.1529, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.1510, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.1491, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.1472, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.1453, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.1435, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.1418, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.1400, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.1383, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.1367, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.1350, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.1334, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.1319, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.1303, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.1288, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.1274, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.1259, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.1245, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.1231, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.1217, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.1204, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.1190, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.1177, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.1165, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.1152, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.1140, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.1128, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.1116, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.1104, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.1093, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.1082, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.1071, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.1060, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.1049, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.1039, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.1028, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.1018, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.1008, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0999, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0989, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0980, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0970, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0961, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0952, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0943, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0935, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0926, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0918, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0909, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0901, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0893, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0885, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0877, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0870, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0862, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0855, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0847, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0840, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0833, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0826, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0819, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0812, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.000075\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 2000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a RNN cell with tensorflow\n",
    "    rnn_cell = rnn.BasicRNNCell(num_hidden)\n",
    "\n",
    "    # Get RNN cell output\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  1.0\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.0\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwxhjTFgscRhjjAmLJQ5jjDFh+X/1PlEumVBFDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb98d616790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
