{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 50\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.8097, Training Accuracy= 0.505\n",
      "Epoch: 10, Loss= 0.7421, Training Accuracy= 0.505\n",
      "Epoch: 20, Loss= 0.7379, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.7366, Training Accuracy= 0.505\n",
      "Epoch: 40, Loss= 0.7359, Training Accuracy= 0.505\n",
      "Epoch: 50, Loss= 0.7355, Training Accuracy= 0.505\n",
      "Epoch: 60, Loss= 0.7352, Training Accuracy= 0.505\n",
      "Epoch: 70, Loss= 0.7349, Training Accuracy= 0.505\n",
      "Epoch: 80, Loss= 0.7347, Training Accuracy= 0.505\n",
      "Epoch: 90, Loss= 0.7345, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.7343, Training Accuracy= 0.505\n",
      "Epoch: 110, Loss= 0.7342, Training Accuracy= 0.505\n",
      "Epoch: 120, Loss= 0.7340, Training Accuracy= 0.505\n",
      "Epoch: 130, Loss= 0.7339, Training Accuracy= 0.505\n",
      "Epoch: 140, Loss= 0.7338, Training Accuracy= 0.505\n",
      "Epoch: 150, Loss= 0.7337, Training Accuracy= 0.505\n",
      "Epoch: 160, Loss= 0.7335, Training Accuracy= 0.505\n",
      "Epoch: 170, Loss= 0.7334, Training Accuracy= 0.505\n",
      "Epoch: 180, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 200, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 210, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 220, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 230, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 240, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 250, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 260, Loss= 0.7322, Training Accuracy= 0.505\n",
      "Epoch: 270, Loss= 0.7319, Training Accuracy= 0.505\n",
      "Epoch: 280, Loss= 0.7317, Training Accuracy= 0.505\n",
      "Epoch: 290, Loss= 0.7313, Training Accuracy= 0.505\n",
      "Epoch: 300, Loss= 0.7306, Training Accuracy= 0.505\n",
      "Epoch: 310, Loss= 0.7302, Training Accuracy= 0.505\n",
      "Epoch: 320, Loss= 0.7280, Training Accuracy= 0.505\n",
      "Epoch: 330, Loss= 0.7284, Training Accuracy= 0.505\n",
      "Epoch: 340, Loss= 0.7285, Training Accuracy= 0.505\n",
      "Epoch: 350, Loss= 0.7285, Training Accuracy= 0.505\n",
      "Epoch: 360, Loss= 0.7281, Training Accuracy= 0.505\n",
      "Epoch: 370, Loss= 0.7289, Training Accuracy= 0.505\n",
      "Epoch: 380, Loss= 0.7285, Training Accuracy= 0.505\n",
      "Epoch: 390, Loss= 0.7285, Training Accuracy= 0.505\n",
      "Epoch: 400, Loss= 0.7278, Training Accuracy= 0.505\n",
      "Epoch: 410, Loss= 0.7285, Training Accuracy= 0.505\n",
      "Epoch: 420, Loss= 0.7273, Training Accuracy= 0.505\n",
      "Epoch: 430, Loss= 0.7278, Training Accuracy= 0.505\n",
      "Epoch: 440, Loss= 0.7276, Training Accuracy= 0.505\n",
      "Epoch: 450, Loss= 0.7297, Training Accuracy= 0.505\n",
      "Epoch: 460, Loss= 0.7284, Training Accuracy= 0.505\n",
      "Epoch: 470, Loss= 0.7290, Training Accuracy= 0.505\n",
      "Epoch: 480, Loss= 0.7289, Training Accuracy= 0.505\n",
      "Epoch: 490, Loss= 0.7280, Training Accuracy= 0.505\n",
      "Epoch: 500, Loss= 0.7279, Training Accuracy= 0.505\n",
      "Epoch: 510, Loss= 0.7322, Training Accuracy= 0.505\n",
      "Epoch: 520, Loss= 0.7287, Training Accuracy= 0.505\n",
      "Epoch: 530, Loss= 0.7362, Training Accuracy= 0.505\n",
      "Epoch: 540, Loss= 0.7388, Training Accuracy= 0.505\n",
      "Epoch: 550, Loss= 0.7267, Training Accuracy= 0.505\n",
      "Epoch: 560, Loss= 0.7275, Training Accuracy= 0.505\n",
      "Epoch: 570, Loss= 0.7277, Training Accuracy= 0.505\n",
      "Epoch: 580, Loss= 0.7259, Training Accuracy= 0.505\n",
      "Epoch: 590, Loss= 0.7468, Training Accuracy= 0.505\n",
      "Epoch: 600, Loss= 0.7360, Training Accuracy= 0.505\n",
      "Epoch: 610, Loss= 0.7341, Training Accuracy= 0.505\n",
      "Epoch: 620, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 630, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 640, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 650, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 660, Loss= 0.7321, Training Accuracy= 0.505\n",
      "Epoch: 670, Loss= 0.7320, Training Accuracy= 0.505\n",
      "Epoch: 680, Loss= 0.7318, Training Accuracy= 0.505\n",
      "Epoch: 690, Loss= 0.7317, Training Accuracy= 0.505\n",
      "Epoch: 700, Loss= 0.7315, Training Accuracy= 0.505\n",
      "Epoch: 710, Loss= 0.7313, Training Accuracy= 0.505\n",
      "Epoch: 720, Loss= 0.7311, Training Accuracy= 0.505\n",
      "Epoch: 730, Loss= 0.7307, Training Accuracy= 0.505\n",
      "Epoch: 740, Loss= 0.7302, Training Accuracy= 0.505\n",
      "Epoch: 750, Loss= 0.7300, Training Accuracy= 0.505\n",
      "Epoch: 760, Loss= 0.7302, Training Accuracy= 0.505\n",
      "Epoch: 770, Loss= 0.7304, Training Accuracy= 0.505\n",
      "Epoch: 780, Loss= 0.7300, Training Accuracy= 0.505\n",
      "Epoch: 790, Loss= 0.7296, Training Accuracy= 0.505\n",
      "Epoch: 800, Loss= 0.7304, Training Accuracy= 0.505\n",
      "Epoch: 810, Loss= 0.7300, Training Accuracy= 0.505\n",
      "Epoch: 820, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 830, Loss= 0.7304, Training Accuracy= 0.505\n",
      "Epoch: 840, Loss= 0.7301, Training Accuracy= 0.505\n",
      "Epoch: 850, Loss= 0.7304, Training Accuracy= 0.505\n",
      "Epoch: 860, Loss= 0.7302, Training Accuracy= 0.505\n",
      "Epoch: 870, Loss= 0.7297, Training Accuracy= 0.505\n",
      "Epoch: 880, Loss= 0.7303, Training Accuracy= 0.505\n",
      "Epoch: 890, Loss= 0.7311, Training Accuracy= 0.505\n",
      "Epoch: 900, Loss= 0.7307, Training Accuracy= 0.505\n",
      "Epoch: 910, Loss= 0.7343, Training Accuracy= 0.505\n",
      "Epoch: 920, Loss= 0.7313, Training Accuracy= 0.505\n",
      "Epoch: 930, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 940, Loss= 0.7384, Training Accuracy= 0.505\n",
      "Epoch: 950, Loss= 0.7352, Training Accuracy= 0.505\n",
      "Epoch: 960, Loss= 0.7337, Training Accuracy= 0.505\n",
      "Epoch: 970, Loss= 0.7311, Training Accuracy= 0.505\n",
      "Epoch: 980, Loss= 0.7310, Training Accuracy= 0.505\n",
      "Epoch: 990, Loss= 0.7287, Training Accuracy= 0.505\n",
      "Epoch: 1000, Loss= 0.7275, Training Accuracy= 0.505\n",
      "Epoch: 1010, Loss= 0.7273, Training Accuracy= 0.505\n",
      "Epoch: 1020, Loss= 0.7283, Training Accuracy= 0.505\n",
      "Epoch: 1030, Loss= 0.7285, Training Accuracy= 0.505\n",
      "Epoch: 1040, Loss= 0.7299, Training Accuracy= 0.505\n",
      "Epoch: 1050, Loss= 0.7304, Training Accuracy= 0.505\n",
      "Epoch: 1060, Loss= 0.7447, Training Accuracy= 0.505\n",
      "Epoch: 1070, Loss= 0.7294, Training Accuracy= 0.505\n",
      "Epoch: 1080, Loss= 0.7376, Training Accuracy= 0.505\n",
      "Epoch: 1090, Loss= 0.7347, Training Accuracy= 0.505\n",
      "Epoch: 1100, Loss= 0.7385, Training Accuracy= 0.505\n",
      "Epoch: 1110, Loss= 0.7340, Training Accuracy= 0.505\n",
      "Epoch: 1120, Loss= 0.7354, Training Accuracy= 0.505\n",
      "Epoch: 1130, Loss= 0.7361, Training Accuracy= 0.505\n",
      "Epoch: 1140, Loss= 0.7403, Training Accuracy= 0.505\n",
      "Epoch: 1150, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 1160, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 1170, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 1180, Loss= 0.7363, Training Accuracy= 0.505\n",
      "Epoch: 1190, Loss= 0.7371, Training Accuracy= 0.505\n",
      "Epoch: 1200, Loss= 0.7369, Training Accuracy= 0.505\n",
      "Epoch: 1210, Loss= 0.7305, Training Accuracy= 0.505\n",
      "Epoch: 1220, Loss= 0.7320, Training Accuracy= 0.505\n",
      "Epoch: 1230, Loss= 0.7320, Training Accuracy= 0.505\n",
      "Epoch: 1240, Loss= 0.7337, Training Accuracy= 0.505\n",
      "Epoch: 1250, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 1260, Loss= 0.7295, Training Accuracy= 0.505\n",
      "Epoch: 1270, Loss= 0.7305, Training Accuracy= 0.505\n",
      "Epoch: 1280, Loss= 0.7417, Training Accuracy= 0.505\n",
      "Epoch: 1290, Loss= 0.7338, Training Accuracy= 0.505\n",
      "Epoch: 1300, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 1310, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 1320, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 1330, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 1340, Loss= 0.7316, Training Accuracy= 0.505\n",
      "Epoch: 1350, Loss= 0.7302, Training Accuracy= 0.505\n",
      "Epoch: 1360, Loss= 0.7296, Training Accuracy= 0.505\n",
      "Epoch: 1370, Loss= 0.7292, Training Accuracy= 0.505\n",
      "Epoch: 1380, Loss= 0.7285, Training Accuracy= 0.505\n",
      "Epoch: 1390, Loss= 0.7289, Training Accuracy= 0.505\n",
      "Epoch: 1400, Loss= 0.7307, Training Accuracy= 0.505\n",
      "Epoch: 1410, Loss= 0.7289, Training Accuracy= 0.505\n",
      "Epoch: 1420, Loss= 0.7287, Training Accuracy= 0.505\n",
      "Epoch: 1430, Loss= 0.7293, Training Accuracy= 0.505\n",
      "Epoch: 1440, Loss= 0.7374, Training Accuracy= 0.505\n",
      "Epoch: 1450, Loss= 0.7305, Training Accuracy= 0.505\n",
      "Epoch: 1460, Loss= 0.7290, Training Accuracy= 0.505\n",
      "Epoch: 1470, Loss= 0.7287, Training Accuracy= 0.505\n",
      "Epoch: 1480, Loss= 0.7287, Training Accuracy= 0.505\n",
      "Epoch: 1490, Loss= 0.7295, Training Accuracy= 0.505\n",
      "Epoch: 1500, Loss= 0.7288, Training Accuracy= 0.505\n",
      "Epoch: 1510, Loss= 0.7285, Training Accuracy= 0.505\n",
      "Epoch: 1520, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 1530, Loss= 0.7287, Training Accuracy= 0.505\n",
      "Epoch: 1540, Loss= 0.7282, Training Accuracy= 0.505\n",
      "Epoch: 1550, Loss= 0.7290, Training Accuracy= 0.505\n",
      "Epoch: 1560, Loss= 0.7284, Training Accuracy= 0.505\n",
      "Epoch: 1570, Loss= 0.7400, Training Accuracy= 0.505\n",
      "Epoch: 1580, Loss= 0.7291, Training Accuracy= 0.505\n",
      "Epoch: 1590, Loss= 0.7288, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss= 0.7290, Training Accuracy= 0.505\n",
      "Epoch: 1610, Loss= 0.7386, Training Accuracy= 0.505\n",
      "Epoch: 1620, Loss= 0.7360, Training Accuracy= 0.505\n",
      "Epoch: 1630, Loss= 0.7352, Training Accuracy= 0.505\n",
      "Epoch: 1640, Loss= 0.7348, Training Accuracy= 0.505\n",
      "Epoch: 1650, Loss= 0.7345, Training Accuracy= 0.505\n",
      "Epoch: 1660, Loss= 0.7343, Training Accuracy= 0.505\n",
      "Epoch: 1670, Loss= 0.7342, Training Accuracy= 0.505\n",
      "Epoch: 1680, Loss= 0.7341, Training Accuracy= 0.505\n",
      "Epoch: 1690, Loss= 0.7340, Training Accuracy= 0.505\n",
      "Epoch: 1700, Loss= 0.7339, Training Accuracy= 0.505\n",
      "Epoch: 1710, Loss= 0.7338, Training Accuracy= 0.505\n",
      "Epoch: 1720, Loss= 0.7338, Training Accuracy= 0.505\n",
      "Epoch: 1730, Loss= 0.7337, Training Accuracy= 0.505\n",
      "Epoch: 1740, Loss= 0.7337, Training Accuracy= 0.505\n",
      "Epoch: 1750, Loss= 0.7337, Training Accuracy= 0.505\n",
      "Epoch: 1760, Loss= 0.7336, Training Accuracy= 0.505\n",
      "Epoch: 1770, Loss= 0.7336, Training Accuracy= 0.505\n",
      "Epoch: 1780, Loss= 0.7336, Training Accuracy= 0.505\n",
      "Epoch: 1790, Loss= 0.7335, Training Accuracy= 0.505\n",
      "Epoch: 1800, Loss= 0.7335, Training Accuracy= 0.505\n",
      "Epoch: 1810, Loss= 0.7335, Training Accuracy= 0.505\n",
      "Epoch: 1820, Loss= 0.7335, Training Accuracy= 0.505\n",
      "Epoch: 1830, Loss= 0.7335, Training Accuracy= 0.505\n",
      "Epoch: 1840, Loss= 0.7335, Training Accuracy= 0.505\n",
      "Epoch: 1850, Loss= 0.7334, Training Accuracy= 0.505\n",
      "Epoch: 1860, Loss= 0.7334, Training Accuracy= 0.505\n",
      "Epoch: 1870, Loss= 0.7334, Training Accuracy= 0.505\n",
      "Epoch: 1880, Loss= 0.7334, Training Accuracy= 0.505\n",
      "Epoch: 1890, Loss= 0.7334, Training Accuracy= 0.505\n",
      "Epoch: 1900, Loss= 0.7334, Training Accuracy= 0.505\n",
      "Epoch: 1910, Loss= 0.7334, Training Accuracy= 0.505\n",
      "Epoch: 1920, Loss= 0.7334, Training Accuracy= 0.505\n",
      "Epoch: 1930, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 1940, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 1950, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 1960, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 1970, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 1980, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 1990, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 2000, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 2010, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 2020, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 2030, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 2040, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 2050, Loss= 0.7333, Training Accuracy= 0.505\n",
      "Epoch: 2060, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2070, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2080, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2090, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2100, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2110, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2120, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2130, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2140, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2150, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2160, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2170, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2180, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2190, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2200, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2210, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2220, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2230, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2240, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2250, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2260, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2270, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2280, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2290, Loss= 0.7332, Training Accuracy= 0.505\n",
      "Epoch: 2300, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2310, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2320, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2330, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2340, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2350, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2360, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2370, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2380, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2390, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2400, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2410, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2420, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2430, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2440, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2450, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2460, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2470, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2480, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2490, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2500, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2510, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2520, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2530, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2540, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2550, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2560, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2570, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2580, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2590, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2600, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2610, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2620, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2630, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2640, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2650, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2660, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2670, Loss= 0.7331, Training Accuracy= 0.505\n",
      "Epoch: 2680, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2690, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2700, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2710, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2720, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2730, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2740, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2750, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2760, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2770, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2780, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2790, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2800, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2810, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2820, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2830, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2840, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2850, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2860, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2870, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2880, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2890, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2900, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2910, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2920, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2930, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2940, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2950, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2960, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2970, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2980, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 2990, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3000, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3010, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3020, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3030, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3040, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3050, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3060, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3070, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3080, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3090, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3100, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3110, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3120, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 3130, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3140, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3150, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3160, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3170, Loss= 0.7329, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3180, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3190, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3200, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3210, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3220, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3230, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3240, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3250, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3260, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3270, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3280, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3290, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3300, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3310, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3320, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3330, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3340, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3350, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3360, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3370, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3380, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3390, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3400, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3410, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3420, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3430, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3440, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3450, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3460, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3470, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3480, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 3490, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3500, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3510, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3520, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3530, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3540, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3550, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3560, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3570, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3580, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3590, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3600, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3610, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3620, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3630, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3640, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3650, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3660, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3670, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3680, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3690, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3700, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3710, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3720, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3730, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3740, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3750, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3760, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3770, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3780, Loss= 0.7328, Training Accuracy= 0.505\n",
      "Epoch: 3790, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3800, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3810, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3820, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3830, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3840, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3850, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3860, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3870, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3880, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3890, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3900, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3910, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3920, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3930, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3940, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3950, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3960, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3970, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3980, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 3990, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 4000, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 4010, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 4020, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 4030, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 4040, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 4050, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 4060, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 4070, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4080, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4090, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4100, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4110, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4120, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4130, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4140, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4150, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4160, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4170, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4180, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4190, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4200, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4210, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4220, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4230, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4240, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4250, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4260, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4270, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4280, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4290, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4300, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4310, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4320, Loss= 0.7326, Training Accuracy= 0.505\n",
      "Epoch: 4330, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4340, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4350, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4360, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4370, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4380, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4390, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4400, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4410, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4420, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4430, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4440, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4450, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4460, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4470, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4480, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4490, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4500, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4510, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4520, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4530, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4540, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4550, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4560, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4570, Loss= 0.7325, Training Accuracy= 0.505\n",
      "Epoch: 4580, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4590, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4600, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4610, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4620, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4630, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4640, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4650, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4660, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4670, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4680, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4690, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4700, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4710, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4720, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4730, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4740, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4750, Loss= 0.7324, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4760, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4770, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4780, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4790, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4800, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4810, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4820, Loss= 0.7324, Training Accuracy= 0.505\n",
      "Epoch: 4830, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4840, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4850, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4860, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4870, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4880, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4890, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4900, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4910, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4920, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4930, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4940, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4950, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4960, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4970, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4980, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 4990, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4935\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.7030, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.7018, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.7018, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.7019, Training Accuracy= 0.502\n",
      "Epoch: 40, Loss= 0.7020, Training Accuracy= 0.502\n",
      "Epoch: 50, Loss= 0.7022, Training Accuracy= 0.502\n",
      "Epoch: 60, Loss= 0.7025, Training Accuracy= 0.502\n",
      "Epoch: 70, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 80, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 90, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 100, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 120, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 130, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 150, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 160, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 170, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 180, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 190, Loss= 0.7029, Training Accuracy= 0.502\n",
      "Epoch: 200, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 230, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 240, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 250, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 260, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 270, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 280, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 290, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 310, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 320, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 330, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 340, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 350, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 360, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 370, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 380, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 390, Loss= 0.7026, Training Accuracy= 0.502\n",
      "Epoch: 400, Loss= 0.7026, Training Accuracy= 0.502\n",
      "Epoch: 410, Loss= 0.7026, Training Accuracy= 0.502\n",
      "Epoch: 420, Loss= 0.7026, Training Accuracy= 0.502\n",
      "Epoch: 430, Loss= 0.7026, Training Accuracy= 0.502\n",
      "Epoch: 440, Loss= 0.7025, Training Accuracy= 0.502\n",
      "Epoch: 450, Loss= 0.7025, Training Accuracy= 0.502\n",
      "Epoch: 460, Loss= 0.7025, Training Accuracy= 0.502\n",
      "Epoch: 470, Loss= 0.7024, Training Accuracy= 0.502\n",
      "Epoch: 480, Loss= 0.7024, Training Accuracy= 0.502\n",
      "Epoch: 490, Loss= 0.7024, Training Accuracy= 0.502\n",
      "Epoch: 500, Loss= 0.7023, Training Accuracy= 0.502\n",
      "Epoch: 510, Loss= 0.7023, Training Accuracy= 0.502\n",
      "Epoch: 520, Loss= 0.7022, Training Accuracy= 0.502\n",
      "Epoch: 530, Loss= 0.7022, Training Accuracy= 0.502\n",
      "Epoch: 540, Loss= 0.7021, Training Accuracy= 0.502\n",
      "Epoch: 550, Loss= 0.7021, Training Accuracy= 0.502\n",
      "Epoch: 560, Loss= 0.7021, Training Accuracy= 0.502\n",
      "Epoch: 570, Loss= 0.7019, Training Accuracy= 0.502\n",
      "Epoch: 580, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 590, Loss= 0.7011, Training Accuracy= 0.502\n",
      "Epoch: 600, Loss= 0.7005, Training Accuracy= 0.503\n",
      "Epoch: 610, Loss= 0.7013, Training Accuracy= 0.502\n",
      "Epoch: 620, Loss= 0.7011, Training Accuracy= 0.502\n",
      "Epoch: 630, Loss= 0.7018, Training Accuracy= 0.502\n",
      "Epoch: 640, Loss= 0.7013, Training Accuracy= 0.502\n",
      "Epoch: 650, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 660, Loss= 0.7012, Training Accuracy= 0.502\n",
      "Epoch: 670, Loss= 0.7013, Training Accuracy= 0.502\n",
      "Epoch: 680, Loss= 0.7019, Training Accuracy= 0.502\n",
      "Epoch: 690, Loss= 0.7022, Training Accuracy= 0.502\n",
      "Epoch: 700, Loss= 0.7019, Training Accuracy= 0.502\n",
      "Epoch: 710, Loss= 0.7020, Training Accuracy= 0.502\n",
      "Epoch: 720, Loss= 0.7017, Training Accuracy= 0.502\n",
      "Epoch: 730, Loss= 0.7019, Training Accuracy= 0.502\n",
      "Epoch: 740, Loss= 0.7020, Training Accuracy= 0.502\n",
      "Epoch: 750, Loss= 0.7030, Training Accuracy= 0.502\n",
      "Epoch: 760, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 770, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 780, Loss= 0.7026, Training Accuracy= 0.502\n",
      "Epoch: 790, Loss= 0.7020, Training Accuracy= 0.502\n",
      "Epoch: 800, Loss= 0.7012, Training Accuracy= 0.502\n",
      "Epoch: 810, Loss= 0.7025, Training Accuracy= 0.502\n",
      "Epoch: 820, Loss= 0.7024, Training Accuracy= 0.502\n",
      "Epoch: 830, Loss= 0.7024, Training Accuracy= 0.502\n",
      "Epoch: 840, Loss= 0.7024, Training Accuracy= 0.502\n",
      "Epoch: 850, Loss= 0.7024, Training Accuracy= 0.502\n",
      "Epoch: 860, Loss= 0.7025, Training Accuracy= 0.502\n",
      "Epoch: 870, Loss= 0.7026, Training Accuracy= 0.502\n",
      "Epoch: 880, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 890, Loss= 0.7033, Training Accuracy= 0.502\n",
      "Epoch: 900, Loss= 0.7045, Training Accuracy= 0.503\n",
      "Epoch: 910, Loss= 0.7043, Training Accuracy= 0.506\n",
      "Epoch: 920, Loss= 0.7042, Training Accuracy= 0.506\n",
      "Epoch: 930, Loss= 0.7040, Training Accuracy= 0.506\n",
      "Epoch: 940, Loss= 0.7035, Training Accuracy= 0.506\n",
      "Epoch: 950, Loss= 0.7034, Training Accuracy= 0.508\n",
      "Epoch: 960, Loss= 0.7037, Training Accuracy= 0.505\n",
      "Epoch: 970, Loss= 0.7024, Training Accuracy= 0.510\n",
      "Epoch: 980, Loss= 0.7023, Training Accuracy= 0.510\n",
      "Epoch: 990, Loss= 0.7027, Training Accuracy= 0.510\n",
      "Epoch: 1000, Loss= 0.7042, Training Accuracy= 0.506\n",
      "Epoch: 1010, Loss= 0.7016, Training Accuracy= 0.513\n",
      "Epoch: 1020, Loss= 0.7054, Training Accuracy= 0.507\n",
      "Epoch: 1030, Loss= 0.7050, Training Accuracy= 0.510\n",
      "Epoch: 1040, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1050, Loss= 0.7030, Training Accuracy= 0.504\n",
      "Epoch: 1060, Loss= 0.7009, Training Accuracy= 0.512\n",
      "Epoch: 1070, Loss= 0.7012, Training Accuracy= 0.513\n",
      "Epoch: 1080, Loss= 0.7003, Training Accuracy= 0.516\n",
      "Epoch: 1090, Loss= 0.7006, Training Accuracy= 0.516\n",
      "Epoch: 1100, Loss= 0.7008, Training Accuracy= 0.516\n",
      "Epoch: 1110, Loss= 0.7003, Training Accuracy= 0.516\n",
      "Epoch: 1120, Loss= 0.6990, Training Accuracy= 0.517\n",
      "Epoch: 1130, Loss= 0.6997, Training Accuracy= 0.518\n",
      "Epoch: 1140, Loss= 0.6969, Training Accuracy= 0.520\n",
      "Epoch: 1150, Loss= 0.6969, Training Accuracy= 0.520\n",
      "Epoch: 1160, Loss= 0.6959, Training Accuracy= 0.521\n",
      "Epoch: 1170, Loss= 0.6968, Training Accuracy= 0.518\n",
      "Epoch: 1180, Loss= 0.6972, Training Accuracy= 0.520\n",
      "Epoch: 1190, Loss= 0.6960, Training Accuracy= 0.522\n",
      "Epoch: 1200, Loss= 0.6971, Training Accuracy= 0.518\n",
      "Epoch: 1210, Loss= 0.7115, Training Accuracy= 0.502\n",
      "Epoch: 1220, Loss= 0.6964, Training Accuracy= 0.522\n",
      "Epoch: 1230, Loss= 0.6969, Training Accuracy= 0.524\n",
      "Epoch: 1240, Loss= 0.6953, Training Accuracy= 0.515\n",
      "Epoch: 1250, Loss= 0.6983, Training Accuracy= 0.518\n",
      "Epoch: 1260, Loss= 0.6951, Training Accuracy= 0.524\n",
      "Epoch: 1270, Loss= 0.6976, Training Accuracy= 0.511\n",
      "Epoch: 1280, Loss= 0.6971, Training Accuracy= 0.513\n",
      "Epoch: 1290, Loss= 0.6997, Training Accuracy= 0.518\n",
      "Epoch: 1300, Loss= 0.6969, Training Accuracy= 0.521\n",
      "Epoch: 1310, Loss= 0.7042, Training Accuracy= 0.502\n",
      "Epoch: 1320, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 1330, Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 1340, Loss= 0.7048, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1350, Loss= 0.7061, Training Accuracy= 0.502\n",
      "Epoch: 1360, Loss= 0.7062, Training Accuracy= 0.502\n",
      "Epoch: 1370, Loss= 0.7077, Training Accuracy= 0.502\n",
      "Epoch: 1380, Loss= 0.7061, Training Accuracy= 0.502\n",
      "Epoch: 1390, Loss= 0.7064, Training Accuracy= 0.502\n",
      "Epoch: 1400, Loss= 0.7064, Training Accuracy= 0.502\n",
      "Epoch: 1410, Loss= 0.7062, Training Accuracy= 0.502\n",
      "Epoch: 1420, Loss= 0.7080, Training Accuracy= 0.502\n",
      "Epoch: 1430, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 1440, Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 1450, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 1460, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1470, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1480, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1490, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 1500, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 1510, Loss= 0.7055, Training Accuracy= 0.502\n",
      "Epoch: 1520, Loss= 0.7048, Training Accuracy= 0.504\n",
      "Epoch: 1530, Loss= 0.7040, Training Accuracy= 0.503\n",
      "Epoch: 1540, Loss= 0.7044, Training Accuracy= 0.502\n",
      "Epoch: 1550, Loss= 0.7037, Training Accuracy= 0.503\n",
      "Epoch: 1560, Loss= 0.7044, Training Accuracy= 0.503\n",
      "Epoch: 1570, Loss= 0.7028, Training Accuracy= 0.502\n",
      "Epoch: 1580, Loss= 0.7009, Training Accuracy= 0.501\n",
      "Epoch: 1590, Loss= 0.7097, Training Accuracy= 0.504\n",
      "Epoch: 1600, Loss= 0.7089, Training Accuracy= 0.504\n",
      "Epoch: 1610, Loss= 0.7099, Training Accuracy= 0.505\n",
      "Epoch: 1620, Loss= 0.7095, Training Accuracy= 0.506\n",
      "Epoch: 1630, Loss= 0.7083, Training Accuracy= 0.506\n",
      "Epoch: 1640, Loss= 0.7078, Training Accuracy= 0.506\n",
      "Epoch: 1650, Loss= 0.7078, Training Accuracy= 0.507\n",
      "Epoch: 1660, Loss= 0.7078, Training Accuracy= 0.507\n",
      "Epoch: 1670, Loss= 0.7065, Training Accuracy= 0.508\n",
      "Epoch: 1680, Loss= 0.7058, Training Accuracy= 0.510\n",
      "Epoch: 1690, Loss= 0.7058, Training Accuracy= 0.511\n",
      "Epoch: 1700, Loss= 0.7043, Training Accuracy= 0.508\n",
      "Epoch: 1710, Loss= 0.7039, Training Accuracy= 0.509\n",
      "Epoch: 1720, Loss= 0.7042, Training Accuracy= 0.507\n",
      "Epoch: 1730, Loss= 0.7057, Training Accuracy= 0.510\n",
      "Epoch: 1740, Loss= 0.7062, Training Accuracy= 0.510\n",
      "Epoch: 1750, Loss= 0.7062, Training Accuracy= 0.510\n",
      "Epoch: 1760, Loss= 0.7066, Training Accuracy= 0.511\n",
      "Epoch: 1770, Loss= 0.7068, Training Accuracy= 0.511\n",
      "Epoch: 1780, Loss= 0.7065, Training Accuracy= 0.511\n",
      "Epoch: 1790, Loss= 0.7060, Training Accuracy= 0.512\n",
      "Epoch: 1800, Loss= 0.7056, Training Accuracy= 0.511\n",
      "Epoch: 1810, Loss= 0.7051, Training Accuracy= 0.511\n",
      "Epoch: 1820, Loss= 0.7042, Training Accuracy= 0.511\n",
      "Epoch: 1830, Loss= 0.7036, Training Accuracy= 0.510\n",
      "Epoch: 1840, Loss= 0.7033, Training Accuracy= 0.511\n",
      "Epoch: 1850, Loss= 0.7031, Training Accuracy= 0.511\n",
      "Epoch: 1860, Loss= 0.7029, Training Accuracy= 0.511\n",
      "Epoch: 1870, Loss= 0.7031, Training Accuracy= 0.511\n",
      "Epoch: 1880, Loss= 0.7029, Training Accuracy= 0.512\n",
      "Epoch: 1890, Loss= 0.7030, Training Accuracy= 0.514\n",
      "Epoch: 1900, Loss= 0.7026, Training Accuracy= 0.513\n",
      "Epoch: 1910, Loss= 0.7027, Training Accuracy= 0.513\n",
      "Epoch: 1920, Loss= 0.7026, Training Accuracy= 0.514\n",
      "Epoch: 1930, Loss= 0.7026, Training Accuracy= 0.513\n",
      "Epoch: 1940, Loss= 0.7026, Training Accuracy= 0.514\n",
      "Epoch: 1950, Loss= 0.7025, Training Accuracy= 0.514\n",
      "Epoch: 1960, Loss= 0.7025, Training Accuracy= 0.513\n",
      "Epoch: 1970, Loss= 0.7024, Training Accuracy= 0.514\n",
      "Epoch: 1980, Loss= 0.7024, Training Accuracy= 0.513\n",
      "Epoch: 1990, Loss= 0.7024, Training Accuracy= 0.513\n",
      "Epoch: 2000, Loss= 0.7022, Training Accuracy= 0.513\n",
      "Epoch: 2010, Loss= 0.7024, Training Accuracy= 0.512\n",
      "Epoch: 2020, Loss= 0.7020, Training Accuracy= 0.511\n",
      "Epoch: 2030, Loss= 0.7020, Training Accuracy= 0.511\n",
      "Epoch: 2040, Loss= 0.7019, Training Accuracy= 0.512\n",
      "Epoch: 2050, Loss= 0.7018, Training Accuracy= 0.511\n",
      "Epoch: 2060, Loss= 0.7017, Training Accuracy= 0.512\n",
      "Epoch: 2070, Loss= 0.7016, Training Accuracy= 0.512\n",
      "Epoch: 2080, Loss= 0.7015, Training Accuracy= 0.511\n",
      "Epoch: 2090, Loss= 0.7013, Training Accuracy= 0.511\n",
      "Epoch: 2100, Loss= 0.7007, Training Accuracy= 0.511\n",
      "Epoch: 2110, Loss= 0.7005, Training Accuracy= 0.511\n",
      "Epoch: 2120, Loss= 0.7003, Training Accuracy= 0.512\n",
      "Epoch: 2130, Loss= 0.7001, Training Accuracy= 0.512\n",
      "Epoch: 2140, Loss= 0.7000, Training Accuracy= 0.513\n",
      "Epoch: 2150, Loss= 0.6998, Training Accuracy= 0.514\n",
      "Epoch: 2160, Loss= 0.6997, Training Accuracy= 0.513\n",
      "Epoch: 2170, Loss= 0.6995, Training Accuracy= 0.513\n",
      "Epoch: 2180, Loss= 0.6995, Training Accuracy= 0.512\n",
      "Epoch: 2190, Loss= 0.6994, Training Accuracy= 0.512\n",
      "Epoch: 2200, Loss= 0.6996, Training Accuracy= 0.516\n",
      "Epoch: 2210, Loss= 0.6994, Training Accuracy= 0.514\n",
      "Epoch: 2220, Loss= 0.6994, Training Accuracy= 0.515\n",
      "Epoch: 2230, Loss= 0.6992, Training Accuracy= 0.513\n",
      "Epoch: 2240, Loss= 0.6990, Training Accuracy= 0.514\n",
      "Epoch: 2250, Loss= 0.6990, Training Accuracy= 0.513\n",
      "Epoch: 2260, Loss= 0.6991, Training Accuracy= 0.515\n",
      "Epoch: 2270, Loss= 0.6992, Training Accuracy= 0.513\n",
      "Epoch: 2280, Loss= 0.6993, Training Accuracy= 0.515\n",
      "Epoch: 2290, Loss= 0.6993, Training Accuracy= 0.513\n",
      "Epoch: 2300, Loss= 0.6987, Training Accuracy= 0.515\n",
      "Epoch: 2310, Loss= 0.6988, Training Accuracy= 0.515\n",
      "Epoch: 2320, Loss= 0.6996, Training Accuracy= 0.515\n",
      "Epoch: 2330, Loss= 0.6993, Training Accuracy= 0.516\n",
      "Epoch: 2340, Loss= 0.6992, Training Accuracy= 0.514\n",
      "Epoch: 2350, Loss= 0.6991, Training Accuracy= 0.516\n",
      "Epoch: 2360, Loss= 0.6988, Training Accuracy= 0.515\n",
      "Epoch: 2370, Loss= 0.6988, Training Accuracy= 0.515\n",
      "Epoch: 2380, Loss= 0.6989, Training Accuracy= 0.517\n",
      "Epoch: 2390, Loss= 0.6993, Training Accuracy= 0.518\n",
      "Epoch: 2400, Loss= 0.6978, Training Accuracy= 0.510\n",
      "Epoch: 2410, Loss= 0.6991, Training Accuracy= 0.516\n",
      "Epoch: 2420, Loss= 0.6985, Training Accuracy= 0.509\n",
      "Epoch: 2430, Loss= 0.6989, Training Accuracy= 0.517\n",
      "Epoch: 2440, Loss= 0.6987, Training Accuracy= 0.519\n",
      "Epoch: 2450, Loss= 0.6991, Training Accuracy= 0.518\n",
      "Epoch: 2460, Loss= 0.6986, Training Accuracy= 0.518\n",
      "Epoch: 2470, Loss= 0.6990, Training Accuracy= 0.520\n",
      "Epoch: 2480, Loss= 0.6993, Training Accuracy= 0.518\n",
      "Epoch: 2490, Loss= 0.6992, Training Accuracy= 0.519\n",
      "Epoch: 2500, Loss= 0.6992, Training Accuracy= 0.519\n",
      "Epoch: 2510, Loss= 0.6993, Training Accuracy= 0.518\n",
      "Epoch: 2520, Loss= 0.7045, Training Accuracy= 0.507\n",
      "Epoch: 2530, Loss= 0.7017, Training Accuracy= 0.511\n",
      "Epoch: 2540, Loss= 0.7016, Training Accuracy= 0.512\n",
      "Epoch: 2550, Loss= 0.7021, Training Accuracy= 0.509\n",
      "Epoch: 2560, Loss= 0.7030, Training Accuracy= 0.509\n",
      "Epoch: 2570, Loss= 0.7031, Training Accuracy= 0.509\n",
      "Epoch: 2580, Loss= 0.6980, Training Accuracy= 0.512\n",
      "Epoch: 2590, Loss= 0.6983, Training Accuracy= 0.516\n",
      "Epoch: 2600, Loss= 0.6987, Training Accuracy= 0.517\n",
      "Epoch: 2610, Loss= 0.6981, Training Accuracy= 0.516\n",
      "Epoch: 2620, Loss= 0.7041, Training Accuracy= 0.503\n",
      "Epoch: 2630, Loss= 0.6572, Training Accuracy= 0.558\n",
      "Epoch: 2640, Loss= 0.6446, Training Accuracy= 0.557\n",
      "Epoch: 2650, Loss= 0.7986, Training Accuracy= 0.498\n",
      "Epoch: 2660, Loss= 1.0394, Training Accuracy= 0.502\n",
      "Epoch: 2670, Loss= 1.0377, Training Accuracy= 0.502\n",
      "Epoch: 2680, Loss= 1.0372, Training Accuracy= 0.502\n",
      "Epoch: 2690, Loss= 1.0369, Training Accuracy= 0.502\n",
      "Epoch: 2700, Loss= 1.0368, Training Accuracy= 0.502\n",
      "Epoch: 2710, Loss= 1.0367, Training Accuracy= 0.502\n",
      "Epoch: 2720, Loss= 1.0366, Training Accuracy= 0.502\n",
      "Epoch: 2730, Loss= 1.0366, Training Accuracy= 0.502\n",
      "Epoch: 2740, Loss= 1.0365, Training Accuracy= 0.502\n",
      "Epoch: 2750, Loss= 1.0365, Training Accuracy= 0.502\n",
      "Epoch: 2760, Loss= 1.0364, Training Accuracy= 0.502\n",
      "Epoch: 2770, Loss= 1.0364, Training Accuracy= 0.502\n",
      "Epoch: 2780, Loss= 1.0364, Training Accuracy= 0.502\n",
      "Epoch: 2790, Loss= 1.0364, Training Accuracy= 0.502\n",
      "Epoch: 2800, Loss= 1.0364, Training Accuracy= 0.502\n",
      "Epoch: 2810, Loss= 1.0364, Training Accuracy= 0.502\n",
      "Epoch: 2820, Loss= 1.0363, Training Accuracy= 0.502\n",
      "Epoch: 2830, Loss= 1.0363, Training Accuracy= 0.502\n",
      "Epoch: 2840, Loss= 1.0363, Training Accuracy= 0.502\n",
      "Epoch: 2850, Loss= 1.0363, Training Accuracy= 0.502\n",
      "Epoch: 2860, Loss= 1.0363, Training Accuracy= 0.502\n",
      "Epoch: 2870, Loss= 1.0363, Training Accuracy= 0.502\n",
      "Epoch: 2880, Loss= 1.0363, Training Accuracy= 0.502\n",
      "Epoch: 2890, Loss= 1.0363, Training Accuracy= 0.502\n",
      "Epoch: 2900, Loss= 1.0363, Training Accuracy= 0.502\n",
      "Epoch: 2910, Loss= 1.0363, Training Accuracy= 0.502\n",
      "Epoch: 2920, Loss= 1.0362, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2930, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 2940, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 2950, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 2960, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 2970, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 2980, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 2990, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3000, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3010, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3020, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3030, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3040, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3050, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3060, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3070, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3080, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3090, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3100, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3110, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3120, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3130, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3140, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3150, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3160, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3170, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3180, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3190, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3200, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3210, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3220, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3230, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3240, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3250, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3260, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3270, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3280, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3290, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3300, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3310, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3320, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3330, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3340, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3350, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3360, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3370, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3380, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3390, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3400, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3410, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3420, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3430, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3440, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3450, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3460, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3470, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3480, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3490, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3500, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3510, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3520, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3530, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3540, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3550, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3560, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3570, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3580, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3590, Loss= 1.0362, Training Accuracy= 0.502\n",
      "Epoch: 3600, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3610, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3620, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3630, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3640, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3650, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3660, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3670, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3680, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3690, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3700, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3710, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3720, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3730, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3740, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3750, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3760, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3770, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3780, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3790, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3800, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3810, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3820, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3830, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3840, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3850, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3860, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3870, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3880, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3890, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3900, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3910, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3920, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3930, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3940, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3950, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3960, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3970, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3980, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 3990, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4000, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4010, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4020, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4030, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4040, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4050, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4060, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4070, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4080, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4090, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4100, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4110, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4120, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4130, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4140, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4150, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4160, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4170, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4180, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4190, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4200, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4210, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4220, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4230, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4240, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4250, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4260, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4270, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4280, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4290, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4300, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4310, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4320, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4330, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4340, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4350, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4360, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4370, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4380, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4390, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4400, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4410, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4420, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4430, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4440, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4450, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4460, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4470, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4480, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4490, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4500, Loss= 1.0361, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4510, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4520, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4530, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4540, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4550, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4560, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4570, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4580, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4590, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4600, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4610, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4620, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4630, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4640, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4650, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4660, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4670, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4680, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4690, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4700, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4710, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4720, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4730, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4740, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4750, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4760, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4770, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4780, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4790, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4800, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4810, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4820, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4830, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4840, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4850, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4860, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4870, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4880, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4890, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4900, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4910, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4920, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4930, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4940, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4950, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4960, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4970, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4980, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Epoch: 4990, Loss= 1.0361, Training Accuracy= 0.502\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4928\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.7856, Training Accuracy= 0.500\n",
      "Epoch: 10, Loss= 0.7752, Training Accuracy= 0.500\n",
      "Epoch: 20, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 30, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 40, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 60, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 100, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 110, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 120, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 140, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 150, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 160, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 190, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 200, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 210, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 220, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 230, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 250, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 260, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 270, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 280, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 290, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 300, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 310, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 320, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 330, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 340, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 350, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 360, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 370, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 380, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 390, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 400, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 410, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 420, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 430, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 440, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 450, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 460, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 470, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 480, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 490, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 500, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 510, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 520, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 530, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 540, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 550, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 560, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 570, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 580, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 590, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 600, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 610, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 620, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 630, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 640, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 650, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 660, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 670, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 680, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 690, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 700, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 710, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 720, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 730, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 740, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 750, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 760, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 770, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 780, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 790, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 800, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 810, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 820, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 830, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 840, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 850, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 860, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 870, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 880, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 890, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 900, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 910, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 920, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 930, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 940, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 950, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 960, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 970, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 980, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 990, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1000, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1010, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1020, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1030, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1040, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1050, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1060, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1070, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1080, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1090, Loss= 0.7739, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1100, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1110, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1120, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1130, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1140, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1150, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1160, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1170, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1180, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1190, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1200, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1210, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1220, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1230, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1240, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1250, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1260, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1270, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1280, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1290, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1300, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1310, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1320, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1330, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1340, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1350, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1360, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1370, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1380, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1390, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1400, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1410, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1420, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1430, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1440, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1450, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1460, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1470, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1480, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1490, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1500, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1510, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1520, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1530, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1540, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1550, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1560, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1570, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1580, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1590, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1600, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1610, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1620, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1630, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1640, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1650, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1660, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1670, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1680, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1690, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1700, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1710, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1720, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1730, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1740, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1750, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1760, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1770, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1780, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1790, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1800, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1810, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1820, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1830, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1840, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1850, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1860, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1870, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 1880, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1890, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1900, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1910, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1920, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1930, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1940, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1950, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1960, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1970, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1980, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 1990, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2000, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2010, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2020, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2030, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2040, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2050, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2060, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2070, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2080, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2090, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2100, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2110, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2120, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2130, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2140, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2150, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2160, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2170, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2180, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2190, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2200, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2210, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2220, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2230, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2240, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2250, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2260, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2270, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2280, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2290, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2300, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2310, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2320, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2330, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2340, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2350, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2360, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2370, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2380, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2390, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2400, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2410, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2420, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2430, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2440, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2450, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2460, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2470, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2480, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2490, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2500, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2510, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2520, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2530, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2540, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2550, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2560, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2570, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2580, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2590, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2600, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2610, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2620, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2630, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2640, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2650, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2660, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2670, Loss= 0.7743, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2680, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2690, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2700, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2710, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 2720, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2730, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2740, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2750, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2760, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2770, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2780, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2790, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2800, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2810, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2820, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 2830, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2840, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2850, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2860, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2870, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2880, Loss= 0.7741, Training Accuracy= 0.500\n",
      "Epoch: 2890, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2900, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2910, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2920, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2930, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2940, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2950, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2960, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2970, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2980, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 2990, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 3000, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 3010, Loss= 0.7740, Training Accuracy= 0.500\n",
      "Epoch: 3020, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 3030, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 3040, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 3050, Loss= 0.7738, Training Accuracy= 0.500\n",
      "Epoch: 3060, Loss= 0.7737, Training Accuracy= 0.500\n",
      "Epoch: 3070, Loss= 0.7734, Training Accuracy= 0.500\n",
      "Epoch: 3080, Loss= 0.7730, Training Accuracy= 0.500\n",
      "Epoch: 3090, Loss= 0.7727, Training Accuracy= 0.500\n",
      "Epoch: 3100, Loss= 0.7746, Training Accuracy= 0.500\n",
      "Epoch: 3110, Loss= 0.7764, Training Accuracy= 0.500\n",
      "Epoch: 3120, Loss= 0.7694, Training Accuracy= 0.500\n",
      "Epoch: 3130, Loss= 0.7778, Training Accuracy= 0.500\n",
      "Epoch: 3140, Loss= 0.7768, Training Accuracy= 0.500\n",
      "Epoch: 3150, Loss= 0.7761, Training Accuracy= 0.500\n",
      "Epoch: 3160, Loss= 0.7762, Training Accuracy= 0.500\n",
      "Epoch: 3170, Loss= 0.7754, Training Accuracy= 0.500\n",
      "Epoch: 3180, Loss= 0.7750, Training Accuracy= 0.500\n",
      "Epoch: 3190, Loss= 0.7748, Training Accuracy= 0.500\n",
      "Epoch: 3200, Loss= 0.7746, Training Accuracy= 0.500\n",
      "Epoch: 3210, Loss= 0.7745, Training Accuracy= 0.500\n",
      "Epoch: 3220, Loss= 0.7745, Training Accuracy= 0.500\n",
      "Epoch: 3230, Loss= 0.7744, Training Accuracy= 0.500\n",
      "Epoch: 3240, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 3250, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 3260, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 3270, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 3280, Loss= 0.7742, Training Accuracy= 0.500\n",
      "Epoch: 3290, Loss= 0.7742, Training Accuracy= 0.501\n",
      "Epoch: 3300, Loss= 0.7741, Training Accuracy= 0.501\n",
      "Epoch: 3310, Loss= 0.7740, Training Accuracy= 0.501\n",
      "Epoch: 3320, Loss= 0.7740, Training Accuracy= 0.501\n",
      "Epoch: 3330, Loss= 0.7739, Training Accuracy= 0.501\n",
      "Epoch: 3340, Loss= 0.7739, Training Accuracy= 0.501\n",
      "Epoch: 3350, Loss= 0.7738, Training Accuracy= 0.500\n",
      "Epoch: 3360, Loss= 0.7739, Training Accuracy= 0.500\n",
      "Epoch: 3370, Loss= 0.7746, Training Accuracy= 0.500\n",
      "Epoch: 3380, Loss= 0.7746, Training Accuracy= 0.500\n",
      "Epoch: 3390, Loss= 0.7746, Training Accuracy= 0.500\n",
      "Epoch: 3400, Loss= 0.7746, Training Accuracy= 0.500\n",
      "Epoch: 3410, Loss= 0.7747, Training Accuracy= 0.500\n",
      "Epoch: 3420, Loss= 0.7747, Training Accuracy= 0.500\n",
      "Epoch: 3430, Loss= 0.7747, Training Accuracy= 0.500\n",
      "Epoch: 3440, Loss= 0.7748, Training Accuracy= 0.500\n",
      "Epoch: 3450, Loss= 0.7749, Training Accuracy= 0.500\n",
      "Epoch: 3460, Loss= 0.7750, Training Accuracy= 0.500\n",
      "Epoch: 3470, Loss= 0.7751, Training Accuracy= 0.500\n",
      "Epoch: 3480, Loss= 0.7753, Training Accuracy= 0.500\n",
      "Epoch: 3490, Loss= 0.7756, Training Accuracy= 0.500\n",
      "Epoch: 3500, Loss= 0.7760, Training Accuracy= 0.500\n",
      "Epoch: 3510, Loss= 0.7764, Training Accuracy= 0.500\n",
      "Epoch: 3520, Loss= 0.7769, Training Accuracy= 0.500\n",
      "Epoch: 3530, Loss= 0.7775, Training Accuracy= 0.500\n",
      "Epoch: 3540, Loss= 0.7781, Training Accuracy= 0.500\n",
      "Epoch: 3550, Loss= 0.7788, Training Accuracy= 0.500\n",
      "Epoch: 3560, Loss= 0.7801, Training Accuracy= 0.500\n",
      "Epoch: 3570, Loss= 0.7812, Training Accuracy= 0.500\n",
      "Epoch: 3580, Loss= 0.7820, Training Accuracy= 0.500\n",
      "Epoch: 3590, Loss= 0.7854, Training Accuracy= 0.500\n",
      "Epoch: 3600, Loss= 0.7787, Training Accuracy= 0.500\n",
      "Epoch: 3610, Loss= 0.7825, Training Accuracy= 0.500\n",
      "Epoch: 3620, Loss= 0.7746, Training Accuracy= 0.500\n",
      "Epoch: 3630, Loss= 0.7737, Training Accuracy= 0.500\n",
      "Epoch: 3640, Loss= 0.7726, Training Accuracy= 0.500\n",
      "Epoch: 3650, Loss= 0.7729, Training Accuracy= 0.500\n",
      "Epoch: 3660, Loss= 0.7724, Training Accuracy= 0.500\n",
      "Epoch: 3670, Loss= 0.7729, Training Accuracy= 0.500\n",
      "Epoch: 3680, Loss= 0.7759, Training Accuracy= 0.500\n",
      "Epoch: 3690, Loss= 0.7716, Training Accuracy= 0.500\n",
      "Epoch: 3700, Loss= 0.7761, Training Accuracy= 0.500\n",
      "Epoch: 3710, Loss= 0.7713, Training Accuracy= 0.500\n",
      "Epoch: 3720, Loss= 0.7743, Training Accuracy= 0.500\n",
      "Epoch: 3730, Loss= 0.7728, Training Accuracy= 0.500\n",
      "Epoch: 3740, Loss= 0.7760, Training Accuracy= 0.500\n",
      "Epoch: 3750, Loss= 0.7736, Training Accuracy= 0.500\n",
      "Epoch: 3760, Loss= 0.7999, Training Accuracy= 0.500\n",
      "Epoch: 3770, Loss= 0.7972, Training Accuracy= 0.500\n",
      "Epoch: 3780, Loss= 0.7905, Training Accuracy= 0.500\n",
      "Epoch: 3790, Loss= 0.7847, Training Accuracy= 0.500\n",
      "Epoch: 3800, Loss= 0.7816, Training Accuracy= 0.500\n",
      "Epoch: 3810, Loss= 0.7803, Training Accuracy= 0.500\n",
      "Epoch: 3820, Loss= 0.7797, Training Accuracy= 0.500\n",
      "Epoch: 3830, Loss= 0.7792, Training Accuracy= 0.500\n",
      "Epoch: 3840, Loss= 0.7790, Training Accuracy= 0.500\n",
      "Epoch: 3850, Loss= 0.7797, Training Accuracy= 0.500\n",
      "Epoch: 3860, Loss= 0.7812, Training Accuracy= 0.500\n",
      "Epoch: 3870, Loss= 0.7825, Training Accuracy= 0.500\n",
      "Epoch: 3880, Loss= 0.7838, Training Accuracy= 0.500\n",
      "Epoch: 3890, Loss= 0.7852, Training Accuracy= 0.500\n",
      "Epoch: 3900, Loss= 0.7867, Training Accuracy= 0.500\n",
      "Epoch: 3910, Loss= 0.7884, Training Accuracy= 0.500\n",
      "Epoch: 3920, Loss= 0.7897, Training Accuracy= 0.500\n",
      "Epoch: 3930, Loss= 0.7915, Training Accuracy= 0.500\n",
      "Epoch: 3940, Loss= 0.7931, Training Accuracy= 0.500\n",
      "Epoch: 3950, Loss= 0.7940, Training Accuracy= 0.500\n",
      "Epoch: 3960, Loss= 0.7950, Training Accuracy= 0.500\n",
      "Epoch: 3970, Loss= 0.7940, Training Accuracy= 0.500\n",
      "Epoch: 3980, Loss= 0.7936, Training Accuracy= 0.500\n",
      "Epoch: 3990, Loss= 0.7950, Training Accuracy= 0.500\n",
      "Epoch: 4000, Loss= 0.7953, Training Accuracy= 0.500\n",
      "Epoch: 4010, Loss= 0.7935, Training Accuracy= 0.500\n",
      "Epoch: 4020, Loss= 0.7935, Training Accuracy= 0.500\n",
      "Epoch: 4030, Loss= 0.7905, Training Accuracy= 0.500\n",
      "Epoch: 4040, Loss= 0.7833, Training Accuracy= 0.500\n",
      "Epoch: 4050, Loss= 0.7852, Training Accuracy= 0.500\n",
      "Epoch: 4060, Loss= 0.7849, Training Accuracy= 0.500\n",
      "Epoch: 4070, Loss= 0.7827, Training Accuracy= 0.500\n",
      "Epoch: 4080, Loss= 0.7869, Training Accuracy= 0.500\n",
      "Epoch: 4090, Loss= 0.7845, Training Accuracy= 0.500\n",
      "Epoch: 4100, Loss= 0.7798, Training Accuracy= 0.500\n",
      "Epoch: 4110, Loss= 0.7817, Training Accuracy= 0.500\n",
      "Epoch: 4120, Loss= 0.7886, Training Accuracy= 0.500\n",
      "Epoch: 4130, Loss= 0.7886, Training Accuracy= 0.500\n",
      "Epoch: 4140, Loss= 0.7848, Training Accuracy= 0.500\n",
      "Epoch: 4150, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4160, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4170, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4180, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4190, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4200, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4210, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4220, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4230, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4240, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4250, Loss= 1.5853, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4260, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4270, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4280, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4290, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4300, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4310, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4320, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4330, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4340, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4350, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4360, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4370, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4380, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4390, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4400, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4410, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4420, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4430, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4440, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4450, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4460, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4470, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4480, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4490, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4500, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4510, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4520, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4530, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4540, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4550, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4560, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4570, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4580, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4590, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4600, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4610, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4620, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4630, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4640, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4650, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4660, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4670, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4680, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4690, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4700, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4710, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4720, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4730, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4740, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4750, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4760, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4770, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4780, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4790, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4800, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4810, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4820, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4830, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4840, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4850, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4860, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4870, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4880, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4890, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4900, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4910, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4920, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4930, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4940, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4950, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4960, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4970, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4980, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Epoch: 4990, Loss= 1.5853, Training Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4959\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.7010, Training Accuracy= 0.508\n",
      "Epoch: 10, Loss= 0.6992, Training Accuracy= 0.508\n",
      "Epoch: 20, Loss= 0.6991, Training Accuracy= 0.508\n",
      "Epoch: 30, Loss= 0.6991, Training Accuracy= 0.508\n",
      "Epoch: 40, Loss= 0.6991, Training Accuracy= 0.508\n",
      "Epoch: 50, Loss= 0.6991, Training Accuracy= 0.508\n",
      "Epoch: 60, Loss= 0.6991, Training Accuracy= 0.508\n",
      "Epoch: 70, Loss= 0.6990, Training Accuracy= 0.508\n",
      "Epoch: 80, Loss= 0.6990, Training Accuracy= 0.508\n",
      "Epoch: 90, Loss= 0.6990, Training Accuracy= 0.508\n",
      "Epoch: 100, Loss= 0.6990, Training Accuracy= 0.508\n",
      "Epoch: 110, Loss= 0.6990, Training Accuracy= 0.508\n",
      "Epoch: 120, Loss= 0.6989, Training Accuracy= 0.508\n",
      "Epoch: 130, Loss= 0.6989, Training Accuracy= 0.508\n",
      "Epoch: 140, Loss= 0.6989, Training Accuracy= 0.508\n",
      "Epoch: 150, Loss= 0.6988, Training Accuracy= 0.508\n",
      "Epoch: 160, Loss= 0.6988, Training Accuracy= 0.508\n",
      "Epoch: 170, Loss= 0.6987, Training Accuracy= 0.508\n",
      "Epoch: 180, Loss= 0.6986, Training Accuracy= 0.508\n",
      "Epoch: 190, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 200, Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 210, Loss= 0.6982, Training Accuracy= 0.508\n",
      "Epoch: 220, Loss= 0.6980, Training Accuracy= 0.508\n",
      "Epoch: 230, Loss= 0.6978, Training Accuracy= 0.508\n",
      "Epoch: 240, Loss= 0.6978, Training Accuracy= 0.508\n",
      "Epoch: 250, Loss= 0.6979, Training Accuracy= 0.508\n",
      "Epoch: 260, Loss= 0.6981, Training Accuracy= 0.508\n",
      "Epoch: 270, Loss= 0.6981, Training Accuracy= 0.508\n",
      "Epoch: 280, Loss= 0.6982, Training Accuracy= 0.508\n",
      "Epoch: 290, Loss= 0.6982, Training Accuracy= 0.508\n",
      "Epoch: 300, Loss= 0.6983, Training Accuracy= 0.508\n",
      "Epoch: 310, Loss= 0.6983, Training Accuracy= 0.508\n",
      "Epoch: 320, Loss= 0.6983, Training Accuracy= 0.508\n",
      "Epoch: 330, Loss= 0.6983, Training Accuracy= 0.508\n",
      "Epoch: 340, Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 350, Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 360, Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 370, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 380, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 390, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 400, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 410, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 420, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 430, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 440, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 450, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 460, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 470, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 480, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 490, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 500, Loss= 0.6984, Training Accuracy= 0.509\n",
      "Epoch: 510, Loss= 0.6984, Training Accuracy= 0.509\n",
      "Epoch: 520, Loss= 0.6984, Training Accuracy= 0.509\n",
      "Epoch: 530, Loss= 0.6983, Training Accuracy= 0.510\n",
      "Epoch: 540, Loss= 0.6981, Training Accuracy= 0.512\n",
      "Epoch: 550, Loss= 0.6978, Training Accuracy= 0.512\n",
      "Epoch: 560, Loss= 0.6975, Training Accuracy= 0.512\n",
      "Epoch: 570, Loss= 0.6973, Training Accuracy= 0.512\n",
      "Epoch: 580, Loss= 0.6974, Training Accuracy= 0.511\n",
      "Epoch: 590, Loss= 0.6974, Training Accuracy= 0.511\n",
      "Epoch: 600, Loss= 0.6973, Training Accuracy= 0.510\n",
      "Epoch: 610, Loss= 0.6970, Training Accuracy= 0.512\n",
      "Epoch: 620, Loss= 0.6973, Training Accuracy= 0.511\n",
      "Epoch: 630, Loss= 0.6982, Training Accuracy= 0.513\n",
      "Epoch: 640, Loss= 0.6983, Training Accuracy= 0.516\n",
      "Epoch: 650, Loss= 0.6983, Training Accuracy= 0.514\n",
      "Epoch: 660, Loss= 0.6982, Training Accuracy= 0.515\n",
      "Epoch: 670, Loss= 0.6977, Training Accuracy= 0.516\n",
      "Epoch: 680, Loss= 0.6976, Training Accuracy= 0.515\n",
      "Epoch: 690, Loss= 0.6974, Training Accuracy= 0.518\n",
      "Epoch: 700, Loss= 0.6978, Training Accuracy= 0.517\n",
      "Epoch: 710, Loss= 0.6981, Training Accuracy= 0.520\n",
      "Epoch: 720, Loss= 0.6979, Training Accuracy= 0.522\n",
      "Epoch: 730, Loss= 0.6990, Training Accuracy= 0.518\n",
      "Epoch: 740, Loss= 0.6959, Training Accuracy= 0.519\n",
      "Epoch: 750, Loss= 0.6977, Training Accuracy= 0.507\n",
      "Epoch: 760, Loss= 0.6971, Training Accuracy= 0.508\n",
      "Epoch: 770, Loss= 0.6982, Training Accuracy= 0.508\n",
      "Epoch: 780, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 790, Loss= 0.6980, Training Accuracy= 0.510\n",
      "Epoch: 800, Loss= 0.6977, Training Accuracy= 0.512\n",
      "Epoch: 810, Loss= 0.6965, Training Accuracy= 0.514\n",
      "Epoch: 820, Loss= 0.6955, Training Accuracy= 0.517\n",
      "Epoch: 830, Loss= 0.6958, Training Accuracy= 0.517\n",
      "Epoch: 840, Loss= 0.6956, Training Accuracy= 0.520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 850, Loss= 0.6947, Training Accuracy= 0.524\n",
      "Epoch: 860, Loss= 0.6960, Training Accuracy= 0.522\n",
      "Epoch: 870, Loss= 0.6958, Training Accuracy= 0.526\n",
      "Epoch: 880, Loss= 0.6954, Training Accuracy= 0.523\n",
      "Epoch: 890, Loss= 0.6954, Training Accuracy= 0.522\n",
      "Epoch: 900, Loss= 0.6997, Training Accuracy= 0.508\n",
      "Epoch: 910, Loss= 0.6989, Training Accuracy= 0.508\n",
      "Epoch: 920, Loss= 0.6988, Training Accuracy= 0.508\n",
      "Epoch: 930, Loss= 0.6988, Training Accuracy= 0.508\n",
      "Epoch: 940, Loss= 0.6989, Training Accuracy= 0.508\n",
      "Epoch: 950, Loss= 0.6989, Training Accuracy= 0.508\n",
      "Epoch: 960, Loss= 0.6990, Training Accuracy= 0.508\n",
      "Epoch: 970, Loss= 0.6990, Training Accuracy= 0.508\n",
      "Epoch: 980, Loss= 0.6989, Training Accuracy= 0.508\n",
      "Epoch: 990, Loss= 0.6988, Training Accuracy= 0.508\n",
      "Epoch: 1000, Loss= 0.6987, Training Accuracy= 0.508\n",
      "Epoch: 1010, Loss= 0.6986, Training Accuracy= 0.508\n",
      "Epoch: 1020, Loss= 0.6986, Training Accuracy= 0.508\n",
      "Epoch: 1030, Loss= 0.6986, Training Accuracy= 0.508\n",
      "Epoch: 1040, Loss= 0.6987, Training Accuracy= 0.508\n",
      "Epoch: 1050, Loss= 0.6986, Training Accuracy= 0.508\n",
      "Epoch: 1060, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 1070, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 1080, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 1090, Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 1100, Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 1110, Loss= 0.6983, Training Accuracy= 0.508\n",
      "Epoch: 1120, Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 1130, Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 1140, Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 1150, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 1160, Loss= 0.6986, Training Accuracy= 0.508\n",
      "Epoch: 1170, Loss= 0.6986, Training Accuracy= 0.508\n",
      "Epoch: 1180, Loss= 0.6986, Training Accuracy= 0.508\n",
      "Epoch: 1190, Loss= 0.6987, Training Accuracy= 0.508\n",
      "Epoch: 1200, Loss= 0.6987, Training Accuracy= 0.508\n",
      "Epoch: 1210, Loss= 0.6987, Training Accuracy= 0.508\n",
      "Epoch: 1220, Loss= 0.6987, Training Accuracy= 0.508\n",
      "Epoch: 1230, Loss= 0.6982, Training Accuracy= 0.508\n",
      "Epoch: 1240, Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 1250, Loss= 0.6982, Training Accuracy= 0.508\n",
      "Epoch: 1260, Loss= 0.6983, Training Accuracy= 0.508\n",
      "Epoch: 1270, Loss= 0.6982, Training Accuracy= 0.508\n",
      "Epoch: 1280, Loss= 0.6982, Training Accuracy= 0.508\n",
      "Epoch: 1290, Loss= 0.6977, Training Accuracy= 0.508\n",
      "Epoch: 1300, Loss= 0.6971, Training Accuracy= 0.508\n",
      "Epoch: 1310, Loss= 0.6970, Training Accuracy= 0.508\n",
      "Epoch: 1320, Loss= 0.6972, Training Accuracy= 0.508\n",
      "Epoch: 1330, Loss= 0.6971, Training Accuracy= 0.508\n",
      "Epoch: 1340, Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 1350, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 1360, Loss= 0.6969, Training Accuracy= 0.509\n",
      "Epoch: 1370, Loss= 0.6959, Training Accuracy= 0.509\n",
      "Epoch: 1380, Loss= 0.6967, Training Accuracy= 0.509\n",
      "Epoch: 1390, Loss= 0.6963, Training Accuracy= 0.509\n",
      "Epoch: 1400, Loss= 0.6962, Training Accuracy= 0.509\n",
      "Epoch: 1410, Loss= 0.6966, Training Accuracy= 0.508\n",
      "Epoch: 1420, Loss= 0.6976, Training Accuracy= 0.509\n",
      "Epoch: 1430, Loss= 0.6992, Training Accuracy= 0.508\n",
      "Epoch: 1440, Loss= 0.7013, Training Accuracy= 0.509\n",
      "Epoch: 1450, Loss= 0.7004, Training Accuracy= 0.512\n",
      "Epoch: 1460, Loss= 0.7008, Training Accuracy= 0.511\n",
      "Epoch: 1470, Loss= 0.7011, Training Accuracy= 0.512\n",
      "Epoch: 1480, Loss= 0.7027, Training Accuracy= 0.509\n",
      "Epoch: 1490, Loss= 0.6986, Training Accuracy= 0.508\n",
      "Epoch: 1500, Loss= 0.6978, Training Accuracy= 0.508\n",
      "Epoch: 1510, Loss= 0.6976, Training Accuracy= 0.508\n",
      "Epoch: 1520, Loss= 0.6976, Training Accuracy= 0.508\n",
      "Epoch: 1530, Loss= 0.6976, Training Accuracy= 0.508\n",
      "Epoch: 1540, Loss= 0.6976, Training Accuracy= 0.508\n",
      "Epoch: 1550, Loss= 0.6976, Training Accuracy= 0.508\n",
      "Epoch: 1560, Loss= 0.6976, Training Accuracy= 0.508\n",
      "Epoch: 1570, Loss= 0.6975, Training Accuracy= 0.508\n",
      "Epoch: 1580, Loss= 0.6975, Training Accuracy= 0.508\n",
      "Epoch: 1590, Loss= 0.6975, Training Accuracy= 0.508\n",
      "Epoch: 1600, Loss= 0.6974, Training Accuracy= 0.508\n",
      "Epoch: 1610, Loss= 0.6974, Training Accuracy= 0.508\n",
      "Epoch: 1620, Loss= 0.6974, Training Accuracy= 0.508\n",
      "Epoch: 1630, Loss= 0.6974, Training Accuracy= 0.508\n",
      "Epoch: 1640, Loss= 0.6974, Training Accuracy= 0.508\n",
      "Epoch: 1650, Loss= 0.6974, Training Accuracy= 0.508\n",
      "Epoch: 1660, Loss= 0.6975, Training Accuracy= 0.508\n",
      "Epoch: 1670, Loss= 0.6975, Training Accuracy= 0.508\n",
      "Epoch: 1680, Loss= 0.6975, Training Accuracy= 0.508\n",
      "Epoch: 1690, Loss= 0.6976, Training Accuracy= 0.508\n",
      "Epoch: 1700, Loss= 0.6976, Training Accuracy= 0.508\n",
      "Epoch: 1710, Loss= 0.6976, Training Accuracy= 0.508\n",
      "Epoch: 1720, Loss= 0.6976, Training Accuracy= 0.508\n",
      "Epoch: 1730, Loss= 0.6975, Training Accuracy= 0.508\n",
      "Epoch: 1740, Loss= 0.6974, Training Accuracy= 0.508\n",
      "Epoch: 1750, Loss= 0.6973, Training Accuracy= 0.508\n",
      "Epoch: 1760, Loss= 0.6972, Training Accuracy= 0.508\n",
      "Epoch: 1770, Loss= 0.6970, Training Accuracy= 0.508\n",
      "Epoch: 1780, Loss= 0.6969, Training Accuracy= 0.508\n",
      "Epoch: 1790, Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 1800, Loss= 0.6966, Training Accuracy= 0.508\n",
      "Epoch: 1810, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 1820, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 1830, Loss= 0.6964, Training Accuracy= 0.508\n",
      "Epoch: 1840, Loss= 0.6964, Training Accuracy= 0.508\n",
      "Epoch: 1850, Loss= 0.6963, Training Accuracy= 0.508\n",
      "Epoch: 1860, Loss= 0.6963, Training Accuracy= 0.507\n",
      "Epoch: 1870, Loss= 0.6963, Training Accuracy= 0.507\n",
      "Epoch: 1880, Loss= 0.6963, Training Accuracy= 0.508\n",
      "Epoch: 1890, Loss= 0.6962, Training Accuracy= 0.507\n",
      "Epoch: 1900, Loss= 0.6962, Training Accuracy= 0.507\n",
      "Epoch: 1910, Loss= 0.6962, Training Accuracy= 0.507\n",
      "Epoch: 1920, Loss= 0.6962, Training Accuracy= 0.507\n",
      "Epoch: 1930, Loss= 0.6962, Training Accuracy= 0.507\n",
      "Epoch: 1940, Loss= 0.6962, Training Accuracy= 0.507\n",
      "Epoch: 1950, Loss= 0.6961, Training Accuracy= 0.507\n",
      "Epoch: 1960, Loss= 0.6961, Training Accuracy= 0.507\n",
      "Epoch: 1970, Loss= 0.6961, Training Accuracy= 0.507\n",
      "Epoch: 1980, Loss= 0.6961, Training Accuracy= 0.507\n",
      "Epoch: 1990, Loss= 0.6961, Training Accuracy= 0.508\n",
      "Epoch: 2000, Loss= 0.6960, Training Accuracy= 0.508\n",
      "Epoch: 2010, Loss= 0.6960, Training Accuracy= 0.508\n",
      "Epoch: 2020, Loss= 0.6960, Training Accuracy= 0.508\n",
      "Epoch: 2030, Loss= 0.6960, Training Accuracy= 0.508\n",
      "Epoch: 2040, Loss= 0.6959, Training Accuracy= 0.508\n",
      "Epoch: 2050, Loss= 0.6959, Training Accuracy= 0.508\n",
      "Epoch: 2060, Loss= 0.6959, Training Accuracy= 0.508\n",
      "Epoch: 2070, Loss= 0.6959, Training Accuracy= 0.508\n",
      "Epoch: 2080, Loss= 0.6958, Training Accuracy= 0.508\n",
      "Epoch: 2090, Loss= 0.6958, Training Accuracy= 0.508\n",
      "Epoch: 2100, Loss= 0.6958, Training Accuracy= 0.508\n",
      "Epoch: 2110, Loss= 0.6957, Training Accuracy= 0.508\n",
      "Epoch: 2120, Loss= 0.6957, Training Accuracy= 0.509\n",
      "Epoch: 2130, Loss= 0.6957, Training Accuracy= 0.510\n",
      "Epoch: 2140, Loss= 0.6956, Training Accuracy= 0.509\n",
      "Epoch: 2150, Loss= 0.6956, Training Accuracy= 0.509\n",
      "Epoch: 2160, Loss= 0.6955, Training Accuracy= 0.510\n",
      "Epoch: 2170, Loss= 0.6954, Training Accuracy= 0.510\n",
      "Epoch: 2180, Loss= 0.6954, Training Accuracy= 0.510\n",
      "Epoch: 2190, Loss= 0.6953, Training Accuracy= 0.510\n",
      "Epoch: 2200, Loss= 0.6953, Training Accuracy= 0.510\n",
      "Epoch: 2210, Loss= 0.6953, Training Accuracy= 0.510\n",
      "Epoch: 2220, Loss= 0.6923, Training Accuracy= 0.520\n",
      "Epoch: 2230, Loss= 0.6582, Training Accuracy= 0.498\n",
      "Epoch: 2240, Loss= 0.6356, Training Accuracy= 0.570\n",
      "Epoch: 2250, Loss= 0.6298, Training Accuracy= 0.555\n",
      "Epoch: 2260, Loss= 0.6699, Training Accuracy= 0.559\n",
      "Epoch: 2270, Loss= 0.6675, Training Accuracy= 0.608\n",
      "Epoch: 2280, Loss= 0.6732, Training Accuracy= 0.594\n",
      "Epoch: 2290, Loss= 0.6166, Training Accuracy= 0.567\n",
      "Epoch: 2300, Loss= 0.6368, Training Accuracy= 0.593\n",
      "Epoch: 2310, Loss= 0.6485, Training Accuracy= 0.578\n",
      "Epoch: 2320, Loss= 0.6465, Training Accuracy= 0.532\n",
      "Epoch: 2330, Loss= 0.6370, Training Accuracy= 0.583\n",
      "Epoch: 2340, Loss= 0.6327, Training Accuracy= 0.564\n",
      "Epoch: 2350, Loss= 0.6302, Training Accuracy= 0.546\n",
      "Epoch: 2360, Loss= 0.6378, Training Accuracy= 0.561\n",
      "Epoch: 2370, Loss= 0.6136, Training Accuracy= 0.567\n",
      "Epoch: 2380, Loss= 0.6724, Training Accuracy= 0.545\n",
      "Epoch: 2390, Loss= 0.6433, Training Accuracy= 0.571\n",
      "Epoch: 2400, Loss= 0.6230, Training Accuracy= 0.568\n",
      "Epoch: 2410, Loss= 0.6599, Training Accuracy= 0.571\n",
      "Epoch: 2420, Loss= 0.6446, Training Accuracy= 0.542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2430, Loss= 0.6459, Training Accuracy= 0.544\n",
      "Epoch: 2440, Loss= 0.6374, Training Accuracy= 0.566\n",
      "Epoch: 2450, Loss= 0.6373, Training Accuracy= 0.565\n",
      "Epoch: 2460, Loss= 0.6398, Training Accuracy= 0.566\n",
      "Epoch: 2470, Loss= 0.6365, Training Accuracy= 0.565\n",
      "Epoch: 2480, Loss= 0.6359, Training Accuracy= 0.565\n",
      "Epoch: 2490, Loss= 0.6357, Training Accuracy= 0.565\n",
      "Epoch: 2500, Loss= 0.6345, Training Accuracy= 0.565\n",
      "Epoch: 2510, Loss= 0.6236, Training Accuracy= 0.584\n",
      "Epoch: 2520, Loss= 0.6220, Training Accuracy= 0.572\n",
      "Epoch: 2530, Loss= 0.6114, Training Accuracy= 0.567\n",
      "Epoch: 2540, Loss= 0.6098, Training Accuracy= 0.587\n",
      "Epoch: 2550, Loss= 0.6093, Training Accuracy= 0.590\n",
      "Epoch: 2560, Loss= 0.6085, Training Accuracy= 0.595\n",
      "Epoch: 2570, Loss= 0.6345, Training Accuracy= 0.596\n",
      "Epoch: 2580, Loss= 0.5706, Training Accuracy= 0.612\n",
      "Epoch: 2590, Loss= 0.5576, Training Accuracy= 0.623\n",
      "Epoch: 2600, Loss= 0.6251, Training Accuracy= 0.586\n",
      "Epoch: 2610, Loss= 0.9861, Training Accuracy= 0.492\n",
      "Epoch: 2620, Loss= 0.7849, Training Accuracy= 0.492\n",
      "Epoch: 2630, Loss= 0.7838, Training Accuracy= 0.492\n",
      "Epoch: 2640, Loss= 0.7835, Training Accuracy= 0.492\n",
      "Epoch: 2650, Loss= 0.7833, Training Accuracy= 0.492\n",
      "Epoch: 2660, Loss= 0.7832, Training Accuracy= 0.492\n",
      "Epoch: 2670, Loss= 0.7831, Training Accuracy= 0.492\n",
      "Epoch: 2680, Loss= 0.7830, Training Accuracy= 0.492\n",
      "Epoch: 2690, Loss= 0.7830, Training Accuracy= 0.492\n",
      "Epoch: 2700, Loss= 0.7829, Training Accuracy= 0.492\n",
      "Epoch: 2710, Loss= 0.7829, Training Accuracy= 0.492\n",
      "Epoch: 2720, Loss= 0.7829, Training Accuracy= 0.492\n",
      "Epoch: 2730, Loss= 0.7828, Training Accuracy= 0.492\n",
      "Epoch: 2740, Loss= 0.7828, Training Accuracy= 0.492\n",
      "Epoch: 2750, Loss= 0.7828, Training Accuracy= 0.492\n",
      "Epoch: 2760, Loss= 0.7828, Training Accuracy= 0.492\n",
      "Epoch: 2770, Loss= 0.7828, Training Accuracy= 0.492\n",
      "Epoch: 2780, Loss= 0.7828, Training Accuracy= 0.492\n",
      "Epoch: 2790, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2800, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2810, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2820, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2830, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2840, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2850, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2860, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2870, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2880, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2890, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2900, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2910, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2920, Loss= 0.7827, Training Accuracy= 0.492\n",
      "Epoch: 2930, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 2940, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 2950, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 2960, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 2970, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 2980, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 2990, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3000, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3010, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3020, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3030, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3040, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3050, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3060, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3070, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3080, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3090, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3100, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3110, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3120, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3130, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3140, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3150, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3160, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3170, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3180, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3190, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3200, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3210, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3220, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3230, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3240, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3250, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3260, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3270, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3280, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3290, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3300, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3310, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3320, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3330, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3340, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3350, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3360, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3370, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3380, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3390, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3400, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3410, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3420, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3430, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3440, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3450, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3460, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3470, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3480, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3490, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3500, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3510, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3520, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3530, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3540, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3550, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3560, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3570, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3580, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3590, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3600, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3610, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3620, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3630, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3640, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3650, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3660, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3670, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3680, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3690, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3700, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3710, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3720, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3730, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3740, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3750, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3760, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3770, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3780, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3790, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3800, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3810, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3820, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3830, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3840, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3850, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3860, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3870, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3880, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3890, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3900, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3910, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3920, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3930, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3940, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3950, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3960, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3970, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3980, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 3990, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4000, Loss= 0.7826, Training Accuracy= 0.492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4010, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4020, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4030, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4040, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4050, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4060, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4070, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4080, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4090, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4100, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4110, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4120, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4130, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4140, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4150, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4160, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4170, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4180, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4190, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4200, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4210, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4220, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4230, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4240, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4250, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4260, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4270, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4280, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4290, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4300, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4310, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4320, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4330, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4340, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4350, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4360, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4370, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4380, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4390, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4400, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4410, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4420, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4430, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4440, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4450, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4460, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4470, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4480, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4490, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4500, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4510, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4520, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4530, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4540, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4550, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4560, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4570, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4580, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4590, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4600, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4610, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4620, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4630, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4640, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4650, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4660, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4670, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4680, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4690, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4700, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4710, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4720, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4730, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4740, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4750, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4760, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4770, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4780, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4790, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4800, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4810, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4820, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4830, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4840, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4850, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4860, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4870, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4880, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4890, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4900, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4910, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4920, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4930, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4940, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4950, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4960, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4970, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4980, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Epoch: 4990, Loss= 0.7826, Training Accuracy= 0.492\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4987\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.7034, Training Accuracy= 0.499\n",
      "Epoch: 10, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 20, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 30, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 40, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 50, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 60, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 70, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 80, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 90, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 100, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 110, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 120, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 130, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 140, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 150, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 160, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 170, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 180, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 190, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 200, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 210, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 220, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 230, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 240, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 250, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 260, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 270, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 280, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 290, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 300, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 310, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 320, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 330, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 340, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 350, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 360, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 370, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 380, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 390, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 400, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 410, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 420, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 430, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 440, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 450, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 460, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 470, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 480, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 490, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 500, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 510, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 520, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 530, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 540, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 550, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 560, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 570, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 580, Loss= 0.7020, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 590, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 600, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 610, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 620, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 630, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 640, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 650, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 660, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 670, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 680, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 690, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 700, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 710, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 720, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 730, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 740, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 750, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 760, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 770, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 780, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 790, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 800, Loss= 0.7016, Training Accuracy= 0.500\n",
      "Epoch: 810, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 820, Loss= 0.7007, Training Accuracy= 0.499\n",
      "Epoch: 830, Loss= 0.7006, Training Accuracy= 0.499\n",
      "Epoch: 840, Loss= 0.7005, Training Accuracy= 0.499\n",
      "Epoch: 850, Loss= 0.7002, Training Accuracy= 0.499\n",
      "Epoch: 860, Loss= 0.7002, Training Accuracy= 0.499\n",
      "Epoch: 870, Loss= 0.6999, Training Accuracy= 0.499\n",
      "Epoch: 880, Loss= 0.6990, Training Accuracy= 0.500\n",
      "Epoch: 890, Loss= 0.6991, Training Accuracy= 0.499\n",
      "Epoch: 900, Loss= 0.6983, Training Accuracy= 0.500\n",
      "Epoch: 910, Loss= 0.6978, Training Accuracy= 0.500\n",
      "Epoch: 920, Loss= 0.6981, Training Accuracy= 0.499\n",
      "Epoch: 930, Loss= 0.6976, Training Accuracy= 0.501\n",
      "Epoch: 940, Loss= 0.6984, Training Accuracy= 0.499\n",
      "Epoch: 950, Loss= 0.6983, Training Accuracy= 0.501\n",
      "Epoch: 960, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 970, Loss= 0.7026, Training Accuracy= 0.499\n",
      "Epoch: 980, Loss= 0.7022, Training Accuracy= 0.499\n",
      "Epoch: 990, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 1000, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1010, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1020, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1030, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1040, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1050, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1060, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1070, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1080, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1090, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1100, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1110, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1120, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1130, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1140, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1150, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1160, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1170, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1180, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1190, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1200, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1210, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1220, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1230, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1240, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1250, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1260, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1270, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1280, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1290, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1300, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1310, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1320, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1330, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1340, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1350, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1360, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1370, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1380, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1390, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1400, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1410, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1420, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1430, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1440, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1450, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1460, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1470, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1480, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1490, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1500, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1510, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1520, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1530, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1540, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 1550, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 1560, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 1570, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 1580, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 1590, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 1600, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 1610, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 1620, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 1630, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 1640, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 1650, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 1660, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 1670, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 1680, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 1690, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 1700, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 1710, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 1720, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 1730, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 1740, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 1750, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 1760, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 1770, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 1780, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 1790, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 1800, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 1810, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 1820, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 1830, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1840, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1850, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1860, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1870, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1880, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1890, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1900, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1910, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1920, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1930, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 1940, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 1950, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 1960, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 1970, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 1980, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 1990, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 2000, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 2010, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 2020, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 2030, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 2040, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 2050, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 2060, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 2070, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 2080, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 2090, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 2100, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 2110, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 2120, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 2130, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 2140, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 2150, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 2160, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 2170, Loss= 0.7012, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2180, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 2190, Loss= 0.7009, Training Accuracy= 0.499\n",
      "Epoch: 2200, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 2210, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 2220, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 2230, Loss= 0.7008, Training Accuracy= 0.499\n",
      "Epoch: 2240, Loss= 0.7005, Training Accuracy= 0.498\n",
      "Epoch: 2250, Loss= 0.6999, Training Accuracy= 0.498\n",
      "Epoch: 2260, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 2270, Loss= 0.7013, Training Accuracy= 0.500\n",
      "Epoch: 2280, Loss= 0.7032, Training Accuracy= 0.499\n",
      "Epoch: 2290, Loss= 0.7037, Training Accuracy= 0.499\n",
      "Epoch: 2300, Loss= 0.7003, Training Accuracy= 0.500\n",
      "Epoch: 2310, Loss= 0.7011, Training Accuracy= 0.500\n",
      "Epoch: 2320, Loss= 0.7034, Training Accuracy= 0.499\n",
      "Epoch: 2330, Loss= 0.7015, Training Accuracy= 0.500\n",
      "Epoch: 2340, Loss= 0.6988, Training Accuracy= 0.499\n",
      "Epoch: 2350, Loss= 0.7019, Training Accuracy= 0.500\n",
      "Epoch: 2360, Loss= 0.7029, Training Accuracy= 0.500\n",
      "Epoch: 2370, Loss= 0.7014, Training Accuracy= 0.501\n",
      "Epoch: 2380, Loss= 0.7015, Training Accuracy= 0.501\n",
      "Epoch: 2390, Loss= 0.7029, Training Accuracy= 0.500\n",
      "Epoch: 2400, Loss= 0.7007, Training Accuracy= 0.500\n",
      "Epoch: 2410, Loss= 0.6998, Training Accuracy= 0.501\n",
      "Epoch: 2420, Loss= 0.7000, Training Accuracy= 0.500\n",
      "Epoch: 2430, Loss= 0.6998, Training Accuracy= 0.502\n",
      "Epoch: 2440, Loss= 0.6986, Training Accuracy= 0.500\n",
      "Epoch: 2450, Loss= 0.7004, Training Accuracy= 0.500\n",
      "Epoch: 2460, Loss= 0.7015, Training Accuracy= 0.501\n",
      "Epoch: 2470, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 2480, Loss= 0.7025, Training Accuracy= 0.500\n",
      "Epoch: 2490, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 2500, Loss= 0.7009, Training Accuracy= 0.500\n",
      "Epoch: 2510, Loss= 0.7011, Training Accuracy= 0.501\n",
      "Epoch: 2520, Loss= 0.7022, Training Accuracy= 0.500\n",
      "Epoch: 2530, Loss= 0.7007, Training Accuracy= 0.500\n",
      "Epoch: 2540, Loss= 0.6994, Training Accuracy= 0.500\n",
      "Epoch: 2550, Loss= 0.7009, Training Accuracy= 0.500\n",
      "Epoch: 2560, Loss= 0.7008, Training Accuracy= 0.500\n",
      "Epoch: 2570, Loss= 0.7005, Training Accuracy= 0.502\n",
      "Epoch: 2580, Loss= 0.7012, Training Accuracy= 0.500\n",
      "Epoch: 2590, Loss= 0.7007, Training Accuracy= 0.503\n",
      "Epoch: 2600, Loss= 0.7028, Training Accuracy= 0.500\n",
      "Epoch: 2610, Loss= 0.6999, Training Accuracy= 0.500\n",
      "Epoch: 2620, Loss= 0.7033, Training Accuracy= 0.501\n",
      "Epoch: 2630, Loss= 0.7017, Training Accuracy= 0.500\n",
      "Epoch: 2640, Loss= 0.7019, Training Accuracy= 0.503\n",
      "Epoch: 2650, Loss= 0.6994, Training Accuracy= 0.501\n",
      "Epoch: 2660, Loss= 0.6980, Training Accuracy= 0.508\n",
      "Epoch: 2670, Loss= 0.7018, Training Accuracy= 0.502\n",
      "Epoch: 2680, Loss= 0.7018, Training Accuracy= 0.500\n",
      "Epoch: 2690, Loss= 0.6992, Training Accuracy= 0.501\n",
      "Epoch: 2700, Loss= 0.7005, Training Accuracy= 0.499\n",
      "Epoch: 2710, Loss= 0.7020, Training Accuracy= 0.501\n",
      "Epoch: 2720, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 2730, Loss= 0.6989, Training Accuracy= 0.499\n",
      "Epoch: 2740, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 2750, Loss= 0.7027, Training Accuracy= 0.502\n",
      "Epoch: 2760, Loss= 0.7031, Training Accuracy= 0.502\n",
      "Epoch: 2770, Loss= 0.7008, Training Accuracy= 0.502\n",
      "Epoch: 2780, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2790, Loss= 0.6979, Training Accuracy= 0.506\n",
      "Epoch: 2800, Loss= 0.6995, Training Accuracy= 0.500\n",
      "Epoch: 2810, Loss= 0.7020, Training Accuracy= 0.503\n",
      "Epoch: 2820, Loss= 0.7032, Training Accuracy= 0.502\n",
      "Epoch: 2830, Loss= 0.6975, Training Accuracy= 0.508\n",
      "Epoch: 2840, Loss= 0.6977, Training Accuracy= 0.507\n",
      "Epoch: 2850, Loss= 0.6990, Training Accuracy= 0.504\n",
      "Epoch: 2860, Loss= 0.6980, Training Accuracy= 0.504\n",
      "Epoch: 2870, Loss= 0.6985, Training Accuracy= 0.504\n",
      "Epoch: 2880, Loss= 0.7040, Training Accuracy= 0.501\n",
      "Epoch: 2890, Loss= 0.6983, Training Accuracy= 0.504\n",
      "Epoch: 2900, Loss= 0.6996, Training Accuracy= 0.502\n",
      "Epoch: 2910, Loss= 0.7056, Training Accuracy= 0.504\n",
      "Epoch: 2920, Loss= 0.6997, Training Accuracy= 0.503\n",
      "Epoch: 2930, Loss= 0.7002, Training Accuracy= 0.499\n",
      "Epoch: 2940, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 2950, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 2960, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 2970, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 2980, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 2990, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 3000, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 3010, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 3020, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 3030, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3040, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3050, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3060, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3070, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3080, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3090, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 3100, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 3110, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 3120, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 3130, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3140, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3150, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3160, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3170, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3180, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3190, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 3200, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 3210, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 3220, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 3230, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3240, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3250, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3260, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3270, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3280, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 3290, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 3300, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 3310, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 3320, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 3330, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 3340, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 3350, Loss= 0.7010, Training Accuracy= 0.500\n",
      "Epoch: 3360, Loss= 0.7009, Training Accuracy= 0.500\n",
      "Epoch: 3370, Loss= 0.7009, Training Accuracy= 0.500\n",
      "Epoch: 3380, Loss= 0.7008, Training Accuracy= 0.500\n",
      "Epoch: 3390, Loss= 0.7007, Training Accuracy= 0.500\n",
      "Epoch: 3400, Loss= 0.7007, Training Accuracy= 0.500\n",
      "Epoch: 3410, Loss= 0.7006, Training Accuracy= 0.500\n",
      "Epoch: 3420, Loss= 0.7005, Training Accuracy= 0.500\n",
      "Epoch: 3430, Loss= 0.7005, Training Accuracy= 0.500\n",
      "Epoch: 3440, Loss= 0.7004, Training Accuracy= 0.501\n",
      "Epoch: 3450, Loss= 0.7004, Training Accuracy= 0.501\n",
      "Epoch: 3460, Loss= 0.7003, Training Accuracy= 0.501\n",
      "Epoch: 3470, Loss= 0.7003, Training Accuracy= 0.501\n",
      "Epoch: 3480, Loss= 0.7003, Training Accuracy= 0.500\n",
      "Epoch: 3490, Loss= 0.7002, Training Accuracy= 0.500\n",
      "Epoch: 3500, Loss= 0.7002, Training Accuracy= 0.500\n",
      "Epoch: 3510, Loss= 0.7002, Training Accuracy= 0.500\n",
      "Epoch: 3520, Loss= 0.7002, Training Accuracy= 0.500\n",
      "Epoch: 3530, Loss= 0.7001, Training Accuracy= 0.500\n",
      "Epoch: 3540, Loss= 0.7001, Training Accuracy= 0.500\n",
      "Epoch: 3550, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3560, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3570, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3580, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3590, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3600, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3610, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3620, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3630, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3640, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3650, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3660, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3670, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3680, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3690, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3700, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3710, Loss= 0.7000, Training Accuracy= 0.501\n",
      "Epoch: 3720, Loss= 0.7000, Training Accuracy= 0.501\n",
      "Epoch: 3730, Loss= 0.7000, Training Accuracy= 0.501\n",
      "Epoch: 3740, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3750, Loss= 0.7001, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3760, Loss= 0.7001, Training Accuracy= 0.501\n",
      "Epoch: 3770, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3780, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3790, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3800, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3810, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3820, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3830, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3840, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3850, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3860, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3870, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3880, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3890, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3900, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 3910, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 3920, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 3930, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 3940, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 3950, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 3960, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 3970, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 3980, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 3990, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 4000, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 4010, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 4020, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 4030, Loss= 0.7000, Training Accuracy= 0.502\n",
      "Epoch: 4040, Loss= 0.7000, Training Accuracy= 0.502\n",
      "Epoch: 4050, Loss= 0.7000, Training Accuracy= 0.502\n",
      "Epoch: 4060, Loss= 0.7000, Training Accuracy= 0.502\n",
      "Epoch: 4070, Loss= 0.7000, Training Accuracy= 0.503\n",
      "Epoch: 4080, Loss= 0.7001, Training Accuracy= 0.503\n",
      "Epoch: 4090, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 4100, Loss= 0.7000, Training Accuracy= 0.502\n",
      "Epoch: 4110, Loss= 0.7001, Training Accuracy= 0.502\n",
      "Epoch: 4120, Loss= 0.7019, Training Accuracy= 0.499\n",
      "Epoch: 4130, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 4140, Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 4150, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 4160, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 4170, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 4180, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 4190, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4200, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4210, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 4220, Loss= 0.7014, Training Accuracy= 0.499\n",
      "Epoch: 4230, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 4240, Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 4250, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 4260, Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 4270, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 4280, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 4290, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 4300, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 4310, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 4320, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 4330, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 4340, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 4350, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 4360, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 4370, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 4380, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 4390, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 4400, Loss= 0.7010, Training Accuracy= 0.499\n",
      "Epoch: 4410, Loss= 0.7010, Training Accuracy= 0.500\n",
      "Epoch: 4420, Loss= 0.7010, Training Accuracy= 0.500\n",
      "Epoch: 4430, Loss= 0.7011, Training Accuracy= 0.501\n",
      "Epoch: 4440, Loss= 0.7007, Training Accuracy= 0.502\n",
      "Epoch: 4450, Loss= 0.7011, Training Accuracy= 0.499\n",
      "Epoch: 4460, Loss= 0.7009, Training Accuracy= 0.500\n",
      "Epoch: 4470, Loss= 0.7009, Training Accuracy= 0.502\n",
      "Epoch: 4480, Loss= 0.7009, Training Accuracy= 0.501\n",
      "Epoch: 4490, Loss= 0.7007, Training Accuracy= 0.502\n",
      "Epoch: 4500, Loss= 0.7004, Training Accuracy= 0.502\n",
      "Epoch: 4510, Loss= 0.7007, Training Accuracy= 0.501\n",
      "Epoch: 4520, Loss= 0.6999, Training Accuracy= 0.501\n",
      "Epoch: 4530, Loss= 0.6999, Training Accuracy= 0.499\n",
      "Epoch: 4540, Loss= 0.7040, Training Accuracy= 0.499\n",
      "Epoch: 4550, Loss= 0.7029, Training Accuracy= 0.499\n",
      "Epoch: 4560, Loss= 0.7024, Training Accuracy= 0.499\n",
      "Epoch: 4570, Loss= 0.7023, Training Accuracy= 0.499\n",
      "Epoch: 4580, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 4590, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 4600, Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 4610, Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 4620, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 4630, Loss= 0.7016, Training Accuracy= 0.499\n",
      "Epoch: 4640, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4650, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4660, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4670, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4680, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4690, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4700, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4710, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4720, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4730, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4740, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4750, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4760, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4770, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4780, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4790, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4800, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4810, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4820, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4830, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4840, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4850, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4860, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4870, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4880, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4890, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4900, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4910, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4920, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4930, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4940, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4950, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4960, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4970, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4980, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Epoch: 4990, Loss= 0.7015, Training Accuracy= 0.499\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4933\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 0.7038, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.7017, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 40, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 50, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 60, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 70, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 80, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 90, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 100, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 120, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 130, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 150, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 160, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 170, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 180, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 190, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 200, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 230, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 240, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 250, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 260, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 270, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 280, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 290, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 310, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 320, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 330, Loss= 0.7016, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 350, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 360, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 370, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 380, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 390, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 400, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 410, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 420, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 430, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 440, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 450, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 460, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 470, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 480, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 490, Loss= 0.7016, Training Accuracy= 0.502\n",
      "Epoch: 500, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 510, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 520, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 530, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 540, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 550, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 560, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 570, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 580, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 590, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 600, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 610, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 620, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 630, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 640, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 650, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 660, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 670, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 680, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 690, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 700, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 710, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 720, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 730, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 740, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 750, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 760, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 770, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 780, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 790, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 800, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 810, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 820, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 830, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 840, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 850, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 860, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 870, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 880, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 890, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 900, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 910, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 920, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 930, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 940, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 950, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 960, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 970, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 980, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 990, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1000, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1010, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1020, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1030, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1040, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1050, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1060, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1070, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1080, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1090, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1100, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1110, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1120, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1130, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1140, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1150, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1160, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1170, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1180, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1190, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1200, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1210, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1220, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1230, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1240, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1250, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1260, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1270, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1280, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1290, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1300, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1310, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1320, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1330, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1340, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1350, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1360, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1370, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1380, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1390, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1400, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1410, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1420, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1430, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1440, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1450, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1460, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1470, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1480, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1490, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1500, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1510, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1520, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1530, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1540, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1550, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1560, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1570, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1580, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1590, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1600, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1610, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1620, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1630, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1640, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1650, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1660, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1670, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1680, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1690, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1700, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1710, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1720, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1730, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1740, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1750, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1760, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1770, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1780, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1790, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1800, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1810, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1820, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1830, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1840, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1850, Loss= 0.7015, Training Accuracy= 0.502\n",
      "Epoch: 1860, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1870, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1880, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1890, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1900, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1910, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1920, Loss= 0.7014, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1930, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1940, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1950, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1960, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1970, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1980, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1990, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2000, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2010, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2020, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2030, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2040, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2050, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2060, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2070, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2080, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2090, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2100, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2110, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2120, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2130, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2140, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2150, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2160, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2170, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2180, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2190, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2200, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2210, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2220, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2230, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2240, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2250, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2260, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2270, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2280, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2290, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2300, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2310, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2320, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2330, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2340, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2350, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2360, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2370, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2380, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2390, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2400, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2410, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2420, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2430, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2440, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2450, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2460, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2470, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2480, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2490, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2500, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2510, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2520, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2530, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2540, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2550, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2560, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2570, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2580, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2590, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2600, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2610, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2620, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2630, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2640, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2650, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2660, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2670, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2680, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2690, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2700, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2710, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2720, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2730, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2740, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2750, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2760, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2770, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2780, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2790, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2800, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2810, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2820, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2830, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2840, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2850, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2860, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2870, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2880, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2890, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2900, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2910, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2920, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2930, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2940, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2950, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2960, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2970, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2980, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 2990, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3000, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3010, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3020, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3030, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3040, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3050, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3060, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3070, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3080, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3090, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3100, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3110, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3120, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3130, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3140, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3150, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3160, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3170, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3180, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3190, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3200, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3210, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3220, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3230, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3240, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3250, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3260, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3270, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3280, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3290, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3300, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3310, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3320, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3330, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3340, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3350, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3360, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3370, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3380, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3390, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3400, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3410, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3420, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3430, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3440, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3450, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3460, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3470, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3480, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3490, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3500, Loss= 0.7014, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3510, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3520, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3530, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3540, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3550, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3560, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3570, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3580, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3590, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3600, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3610, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3620, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3630, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3640, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3650, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3660, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3670, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3680, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3690, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3700, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3710, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3720, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3730, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3740, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3750, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3760, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3770, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3780, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3790, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3800, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3810, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3820, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3830, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3840, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3850, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3860, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3870, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3880, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3890, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3900, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3910, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3920, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3930, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3940, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3950, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3960, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3970, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3980, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 3990, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4000, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4010, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4020, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4030, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4040, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4050, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4060, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4070, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4080, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4090, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4100, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4110, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4120, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4130, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4140, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4150, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4160, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4170, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4180, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4190, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4200, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4210, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4220, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4230, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4240, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4250, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4260, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4270, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4280, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4290, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4300, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4310, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4320, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4330, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4340, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4350, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4360, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4370, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4380, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4390, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4400, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4410, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4420, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4430, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4440, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4450, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4460, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4470, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4480, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4490, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4500, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4510, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4520, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4530, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4540, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4550, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4560, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4570, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4580, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4590, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4600, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4610, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4620, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4630, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4640, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4650, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4660, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4670, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4680, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4690, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4700, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4710, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4720, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4730, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4740, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4750, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4760, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4770, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4780, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4790, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4800, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4810, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4820, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4830, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4840, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4850, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4860, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4870, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4880, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4890, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4900, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4910, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4920, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4930, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4940, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4950, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4960, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4970, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4980, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 4990, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4944\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.8253, Training Accuracy= 0.495\n",
      "Epoch: 10, Loss= 0.7982, Training Accuracy= 0.495\n",
      "Epoch: 20, Loss= 0.7952, Training Accuracy= 0.495\n",
      "Epoch: 30, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 40, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 50, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 60, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 70, Loss= 0.7931, Training Accuracy= 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Loss= 0.7930, Training Accuracy= 0.495\n",
      "Epoch: 90, Loss= 0.7929, Training Accuracy= 0.495\n",
      "Epoch: 100, Loss= 0.7929, Training Accuracy= 0.495\n",
      "Epoch: 110, Loss= 0.7929, Training Accuracy= 0.495\n",
      "Epoch: 120, Loss= 0.7929, Training Accuracy= 0.495\n",
      "Epoch: 130, Loss= 0.7929, Training Accuracy= 0.495\n",
      "Epoch: 140, Loss= 0.7930, Training Accuracy= 0.495\n",
      "Epoch: 150, Loss= 0.7930, Training Accuracy= 0.495\n",
      "Epoch: 160, Loss= 0.7930, Training Accuracy= 0.495\n",
      "Epoch: 170, Loss= 0.7930, Training Accuracy= 0.495\n",
      "Epoch: 180, Loss= 0.7931, Training Accuracy= 0.495\n",
      "Epoch: 190, Loss= 0.7931, Training Accuracy= 0.495\n",
      "Epoch: 200, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 210, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 220, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 230, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 240, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 250, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 260, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 270, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 280, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 290, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 300, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 310, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 320, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 330, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 340, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 350, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 360, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 370, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 380, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 390, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 400, Loss= 0.7942, Training Accuracy= 0.495\n",
      "Epoch: 410, Loss= 0.7942, Training Accuracy= 0.495\n",
      "Epoch: 420, Loss= 0.7943, Training Accuracy= 0.495\n",
      "Epoch: 430, Loss= 0.7944, Training Accuracy= 0.495\n",
      "Epoch: 440, Loss= 0.7944, Training Accuracy= 0.495\n",
      "Epoch: 450, Loss= 0.7945, Training Accuracy= 0.495\n",
      "Epoch: 460, Loss= 0.7945, Training Accuracy= 0.495\n",
      "Epoch: 470, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 480, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 490, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 500, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 510, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 520, Loss= 0.7947, Training Accuracy= 0.495\n",
      "Epoch: 530, Loss= 0.7947, Training Accuracy= 0.495\n",
      "Epoch: 540, Loss= 0.7947, Training Accuracy= 0.495\n",
      "Epoch: 550, Loss= 0.7947, Training Accuracy= 0.495\n",
      "Epoch: 560, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 570, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 580, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 590, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 600, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 610, Loss= 0.7946, Training Accuracy= 0.495\n",
      "Epoch: 620, Loss= 0.7945, Training Accuracy= 0.495\n",
      "Epoch: 630, Loss= 0.7945, Training Accuracy= 0.495\n",
      "Epoch: 640, Loss= 0.7945, Training Accuracy= 0.495\n",
      "Epoch: 650, Loss= 0.7945, Training Accuracy= 0.495\n",
      "Epoch: 660, Loss= 0.7945, Training Accuracy= 0.495\n",
      "Epoch: 670, Loss= 0.7944, Training Accuracy= 0.495\n",
      "Epoch: 680, Loss= 0.7944, Training Accuracy= 0.495\n",
      "Epoch: 690, Loss= 0.7944, Training Accuracy= 0.495\n",
      "Epoch: 700, Loss= 0.7944, Training Accuracy= 0.495\n",
      "Epoch: 710, Loss= 0.7944, Training Accuracy= 0.495\n",
      "Epoch: 720, Loss= 0.7944, Training Accuracy= 0.495\n",
      "Epoch: 730, Loss= 0.7943, Training Accuracy= 0.495\n",
      "Epoch: 740, Loss= 0.7943, Training Accuracy= 0.495\n",
      "Epoch: 750, Loss= 0.7943, Training Accuracy= 0.495\n",
      "Epoch: 760, Loss= 0.7943, Training Accuracy= 0.495\n",
      "Epoch: 770, Loss= 0.7943, Training Accuracy= 0.495\n",
      "Epoch: 780, Loss= 0.7943, Training Accuracy= 0.495\n",
      "Epoch: 790, Loss= 0.7942, Training Accuracy= 0.495\n",
      "Epoch: 800, Loss= 0.7942, Training Accuracy= 0.495\n",
      "Epoch: 810, Loss= 0.7942, Training Accuracy= 0.495\n",
      "Epoch: 820, Loss= 0.7942, Training Accuracy= 0.495\n",
      "Epoch: 830, Loss= 0.7942, Training Accuracy= 0.495\n",
      "Epoch: 840, Loss= 0.7942, Training Accuracy= 0.495\n",
      "Epoch: 850, Loss= 0.7942, Training Accuracy= 0.495\n",
      "Epoch: 860, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 870, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 880, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 890, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 900, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 910, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 920, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 930, Loss= 0.7941, Training Accuracy= 0.495\n",
      "Epoch: 940, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 950, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 960, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 970, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 980, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 990, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 1000, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 1010, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 1020, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 1030, Loss= 0.7940, Training Accuracy= 0.495\n",
      "Epoch: 1040, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1050, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1060, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1070, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1080, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1090, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1100, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1110, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1120, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1130, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1140, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1150, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1160, Loss= 0.7939, Training Accuracy= 0.495\n",
      "Epoch: 1170, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1180, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1190, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1200, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1210, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1220, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1230, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1240, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1250, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1260, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1270, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1280, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1290, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1300, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1310, Loss= 0.7938, Training Accuracy= 0.495\n",
      "Epoch: 1320, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1330, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1340, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1350, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1360, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1370, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1380, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1390, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1400, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1410, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1420, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1430, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1440, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1450, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1460, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1470, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1480, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1490, Loss= 0.7937, Training Accuracy= 0.495\n",
      "Epoch: 1500, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1510, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1520, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1530, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1540, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1550, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1560, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1570, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1580, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1590, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1600, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1610, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1620, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1630, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1640, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1650, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1660, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1670, Loss= 0.7936, Training Accuracy= 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1680, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1690, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1700, Loss= 0.7936, Training Accuracy= 0.495\n",
      "Epoch: 1710, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1720, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1730, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1740, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1750, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1760, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1770, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1780, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1790, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1800, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1810, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1820, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1830, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1840, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1850, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1860, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1870, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1880, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1890, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1900, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1910, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1920, Loss= 0.7935, Training Accuracy= 0.495\n",
      "Epoch: 1930, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 1940, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 1950, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 1960, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 1970, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 1980, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 1990, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2000, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2010, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2020, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2030, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2040, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2050, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2060, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2070, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2080, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2090, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2100, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2110, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2120, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2130, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2140, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2150, Loss= 0.7934, Training Accuracy= 0.495\n",
      "Epoch: 2160, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2170, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2180, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2190, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2200, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2210, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2220, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2230, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2240, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2250, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2260, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2270, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2280, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2290, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2300, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2310, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2320, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2330, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2340, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2350, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2360, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2370, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2380, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2390, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2400, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2410, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2420, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2430, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2440, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2450, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2460, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2470, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2480, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2490, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2500, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2510, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2520, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2530, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2540, Loss= 0.7933, Training Accuracy= 0.495\n",
      "Epoch: 2550, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2560, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2570, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2580, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2590, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2600, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2610, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2620, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2630, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2640, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2650, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2660, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2670, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2680, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2690, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2700, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2710, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2720, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2730, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2740, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2750, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2760, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2770, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2780, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2790, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2800, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2810, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2820, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2830, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2840, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2850, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2860, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2870, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2880, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2890, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2900, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2910, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2920, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2930, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2940, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2950, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2960, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2970, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2980, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 2990, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3000, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3010, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3020, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3030, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3040, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3050, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3060, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3070, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3080, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3090, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3100, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3110, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3120, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3130, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3140, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3150, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3160, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3170, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3180, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3190, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3200, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3210, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3220, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3230, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3240, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3250, Loss= 0.7932, Training Accuracy= 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3260, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3270, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3280, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3290, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3300, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3310, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3320, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3330, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3340, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3350, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3360, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3370, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3380, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3390, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3400, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3410, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3420, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3430, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3440, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3450, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3460, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3470, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3480, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3490, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3500, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3510, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3520, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3530, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3540, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3550, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3560, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3570, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3580, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3590, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3600, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3610, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3620, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3630, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3640, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3650, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3660, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3670, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3680, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3690, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3700, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3710, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3720, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3730, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3740, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3750, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3760, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3770, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3780, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3790, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3800, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3810, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3820, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3830, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3840, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3850, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3860, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3870, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3880, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3890, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3900, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3910, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3920, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3930, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3940, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3950, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3960, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3970, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3980, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 3990, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4000, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4010, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4020, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4030, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4040, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4050, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4060, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4070, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4080, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4090, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4100, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4110, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4120, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4130, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4140, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4150, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4160, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4170, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4180, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4190, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4200, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4210, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4220, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4230, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4240, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4250, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4260, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4270, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4280, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4290, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4300, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4310, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4320, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4330, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4340, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4350, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4360, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4370, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4380, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4390, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4400, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4410, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4420, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4430, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4440, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4450, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4460, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4470, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4480, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4490, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4500, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4510, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4520, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4530, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4540, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4550, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4560, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4570, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4580, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4590, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4600, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4610, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4620, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4630, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4640, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4650, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4660, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4670, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4680, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4690, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4700, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4710, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4720, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4730, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4740, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4750, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4760, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4770, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4780, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4790, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4800, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4810, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4820, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4830, Loss= 0.7932, Training Accuracy= 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4840, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4850, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4860, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4870, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4880, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4890, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4900, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4910, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4920, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4930, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4940, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4950, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4960, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4970, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4980, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Epoch: 4990, Loss= 0.7932, Training Accuracy= 0.495\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4924\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 0.7127, Training Accuracy= 0.498\n",
      "Epoch: 10, Loss= 0.7052, Training Accuracy= 0.498\n",
      "Epoch: 20, Loss= 0.7043, Training Accuracy= 0.498\n",
      "Epoch: 30, Loss= 0.7040, Training Accuracy= 0.498\n",
      "Epoch: 40, Loss= 0.7038, Training Accuracy= 0.498\n",
      "Epoch: 50, Loss= 0.7037, Training Accuracy= 0.498\n",
      "Epoch: 60, Loss= 0.7036, Training Accuracy= 0.498\n",
      "Epoch: 70, Loss= 0.7036, Training Accuracy= 0.498\n",
      "Epoch: 80, Loss= 0.7036, Training Accuracy= 0.498\n",
      "Epoch: 90, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 100, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 110, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 120, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 130, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 140, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 150, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 160, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 170, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 180, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 190, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 200, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 210, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 220, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 230, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 240, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 250, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 260, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 270, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 280, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 290, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 300, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 310, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 320, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 330, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 340, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 350, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 360, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 370, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 380, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 390, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 400, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 410, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 420, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 430, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 440, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 450, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 460, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 470, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 480, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 490, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 500, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 510, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 520, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 530, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 540, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 550, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 560, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 570, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 580, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 590, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 600, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 610, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 620, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 630, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 640, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 650, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 660, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 670, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 680, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 690, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 700, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 710, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 720, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 730, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 740, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 750, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 760, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 770, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 780, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 790, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 800, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 810, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 820, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 830, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 840, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 850, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 860, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 870, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 880, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 890, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 900, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 910, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 920, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 930, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 940, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 950, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 960, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 970, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 980, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 990, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1000, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1010, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1020, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1030, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1040, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1050, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1060, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1070, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1080, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1090, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1100, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1110, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1120, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1130, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1140, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1150, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1160, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1170, Loss= 0.7034, Training Accuracy= 0.498\n",
      "Epoch: 1180, Loss= 0.7034, Training Accuracy= 0.498\n",
      "Epoch: 1190, Loss= 0.7034, Training Accuracy= 0.498\n",
      "Epoch: 1200, Loss= 0.7034, Training Accuracy= 0.498\n",
      "Epoch: 1210, Loss= 0.7033, Training Accuracy= 0.498\n",
      "Epoch: 1220, Loss= 0.7033, Training Accuracy= 0.498\n",
      "Epoch: 1230, Loss= 0.7033, Training Accuracy= 0.498\n",
      "Epoch: 1240, Loss= 0.7033, Training Accuracy= 0.498\n",
      "Epoch: 1250, Loss= 0.7032, Training Accuracy= 0.498\n",
      "Epoch: 1260, Loss= 0.7032, Training Accuracy= 0.498\n",
      "Epoch: 1270, Loss= 0.7032, Training Accuracy= 0.498\n",
      "Epoch: 1280, Loss= 0.7032, Training Accuracy= 0.498\n",
      "Epoch: 1290, Loss= 0.7032, Training Accuracy= 0.498\n",
      "Epoch: 1300, Loss= 0.7033, Training Accuracy= 0.498\n",
      "Epoch: 1310, Loss= 0.7033, Training Accuracy= 0.498\n",
      "Epoch: 1320, Loss= 0.7033, Training Accuracy= 0.498\n",
      "Epoch: 1330, Loss= 0.7033, Training Accuracy= 0.498\n",
      "Epoch: 1340, Loss= 0.7034, Training Accuracy= 0.498\n",
      "Epoch: 1350, Loss= 0.7034, Training Accuracy= 0.498\n",
      "Epoch: 1360, Loss= 0.7034, Training Accuracy= 0.498\n",
      "Epoch: 1370, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1380, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1390, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1400, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1410, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1420, Loss= 0.7035, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1430, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1440, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1450, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1460, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1470, Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 1480, Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 1490, Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 1500, Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 1510, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 1520, Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 1530, Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 1540, Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 1550, Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 1560, Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 1570, Loss= 0.7034, Training Accuracy= 0.499\n",
      "Epoch: 1580, Loss= 0.7034, Training Accuracy= 0.499\n",
      "Epoch: 1590, Loss= 0.7034, Training Accuracy= 0.499\n",
      "Epoch: 1600, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1610, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1620, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1630, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1640, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1650, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1660, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1670, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1680, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1690, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1700, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1710, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1720, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1730, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1740, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1750, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1760, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1770, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1780, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1790, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1800, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1810, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1820, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1830, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1840, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1850, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1860, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1870, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1880, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1890, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1900, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1910, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1920, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1930, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1940, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1950, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1960, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1970, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1980, Loss= 0.7034, Training Accuracy= 0.500\n",
      "Epoch: 1990, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2000, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2010, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2020, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2030, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2040, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2050, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2060, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2070, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2080, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2090, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2100, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2110, Loss= 0.7035, Training Accuracy= 0.500\n",
      "Epoch: 2120, Loss= 0.7036, Training Accuracy= 0.500\n",
      "Epoch: 2130, Loss= 0.7036, Training Accuracy= 0.500\n",
      "Epoch: 2140, Loss= 0.7036, Training Accuracy= 0.500\n",
      "Epoch: 2150, Loss= 0.7036, Training Accuracy= 0.500\n",
      "Epoch: 2160, Loss= 0.7036, Training Accuracy= 0.500\n",
      "Epoch: 2170, Loss= 0.7036, Training Accuracy= 0.500\n",
      "Epoch: 2180, Loss= 0.7036, Training Accuracy= 0.500\n",
      "Epoch: 2190, Loss= 0.7036, Training Accuracy= 0.500\n",
      "Epoch: 2200, Loss= 0.7036, Training Accuracy= 0.500\n",
      "Epoch: 2210, Loss= 0.7037, Training Accuracy= 0.500\n",
      "Epoch: 2220, Loss= 0.7037, Training Accuracy= 0.500\n",
      "Epoch: 2230, Loss= 0.7037, Training Accuracy= 0.500\n",
      "Epoch: 2240, Loss= 0.7037, Training Accuracy= 0.500\n",
      "Epoch: 2250, Loss= 0.7037, Training Accuracy= 0.500\n",
      "Epoch: 2260, Loss= 0.7037, Training Accuracy= 0.500\n",
      "Epoch: 2270, Loss= 0.7037, Training Accuracy= 0.500\n",
      "Epoch: 2280, Loss= 0.7037, Training Accuracy= 0.500\n",
      "Epoch: 2290, Loss= 0.7038, Training Accuracy= 0.500\n",
      "Epoch: 2300, Loss= 0.7038, Training Accuracy= 0.500\n",
      "Epoch: 2310, Loss= 0.7038, Training Accuracy= 0.500\n",
      "Epoch: 2320, Loss= 0.7038, Training Accuracy= 0.500\n",
      "Epoch: 2330, Loss= 0.7038, Training Accuracy= 0.500\n",
      "Epoch: 2340, Loss= 0.7038, Training Accuracy= 0.500\n",
      "Epoch: 2350, Loss= 0.7038, Training Accuracy= 0.500\n",
      "Epoch: 2360, Loss= 0.7038, Training Accuracy= 0.500\n",
      "Epoch: 2370, Loss= 0.7039, Training Accuracy= 0.500\n",
      "Epoch: 2380, Loss= 0.7039, Training Accuracy= 0.500\n",
      "Epoch: 2390, Loss= 0.7039, Training Accuracy= 0.500\n",
      "Epoch: 2400, Loss= 0.7039, Training Accuracy= 0.500\n",
      "Epoch: 2410, Loss= 0.7039, Training Accuracy= 0.500\n",
      "Epoch: 2420, Loss= 0.7040, Training Accuracy= 0.500\n",
      "Epoch: 2430, Loss= 0.7040, Training Accuracy= 0.500\n",
      "Epoch: 2440, Loss= 0.7040, Training Accuracy= 0.500\n",
      "Epoch: 2450, Loss= 0.7040, Training Accuracy= 0.500\n",
      "Epoch: 2460, Loss= 0.7041, Training Accuracy= 0.500\n",
      "Epoch: 2470, Loss= 0.7041, Training Accuracy= 0.500\n",
      "Epoch: 2480, Loss= 0.7042, Training Accuracy= 0.500\n",
      "Epoch: 2490, Loss= 0.7042, Training Accuracy= 0.500\n",
      "Epoch: 2500, Loss= 0.7043, Training Accuracy= 0.499\n",
      "Epoch: 2510, Loss= 0.7044, Training Accuracy= 0.500\n",
      "Epoch: 2520, Loss= 0.7045, Training Accuracy= 0.500\n",
      "Epoch: 2530, Loss= 0.7046, Training Accuracy= 0.500\n",
      "Epoch: 2540, Loss= 0.7046, Training Accuracy= 0.500\n",
      "Epoch: 2550, Loss= 0.7047, Training Accuracy= 0.500\n",
      "Epoch: 2560, Loss= 0.7048, Training Accuracy= 0.500\n",
      "Epoch: 2570, Loss= 0.7048, Training Accuracy= 0.500\n",
      "Epoch: 2580, Loss= 0.7049, Training Accuracy= 0.500\n",
      "Epoch: 2590, Loss= 0.7049, Training Accuracy= 0.500\n",
      "Epoch: 2600, Loss= 0.7050, Training Accuracy= 0.500\n",
      "Epoch: 2610, Loss= 0.7050, Training Accuracy= 0.501\n",
      "Epoch: 2620, Loss= 0.7050, Training Accuracy= 0.501\n",
      "Epoch: 2630, Loss= 0.7051, Training Accuracy= 0.501\n",
      "Epoch: 2640, Loss= 0.7051, Training Accuracy= 0.501\n",
      "Epoch: 2650, Loss= 0.7051, Training Accuracy= 0.501\n",
      "Epoch: 2660, Loss= 0.7051, Training Accuracy= 0.501\n",
      "Epoch: 2670, Loss= 0.7051, Training Accuracy= 0.501\n",
      "Epoch: 2680, Loss= 0.7050, Training Accuracy= 0.501\n",
      "Epoch: 2690, Loss= 0.7050, Training Accuracy= 0.501\n",
      "Epoch: 2700, Loss= 0.7049, Training Accuracy= 0.501\n",
      "Epoch: 2710, Loss= 0.7048, Training Accuracy= 0.501\n",
      "Epoch: 2720, Loss= 0.7047, Training Accuracy= 0.501\n",
      "Epoch: 2730, Loss= 0.7046, Training Accuracy= 0.501\n",
      "Epoch: 2740, Loss= 0.7045, Training Accuracy= 0.501\n",
      "Epoch: 2750, Loss= 0.7045, Training Accuracy= 0.501\n",
      "Epoch: 2760, Loss= 0.7046, Training Accuracy= 0.501\n",
      "Epoch: 2770, Loss= 0.7047, Training Accuracy= 0.501\n",
      "Epoch: 2780, Loss= 0.7048, Training Accuracy= 0.501\n",
      "Epoch: 2790, Loss= 0.7049, Training Accuracy= 0.501\n",
      "Epoch: 2800, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 2810, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 2820, Loss= 0.7055, Training Accuracy= 0.501\n",
      "Epoch: 2830, Loss= 0.7053, Training Accuracy= 0.501\n",
      "Epoch: 2840, Loss= 0.7056, Training Accuracy= 0.501\n",
      "Epoch: 2850, Loss= 0.7059, Training Accuracy= 0.501\n",
      "Epoch: 2860, Loss= 0.7059, Training Accuracy= 0.501\n",
      "Epoch: 2870, Loss= 0.7058, Training Accuracy= 0.501\n",
      "Epoch: 2880, Loss= 0.7056, Training Accuracy= 0.502\n",
      "Epoch: 2890, Loss= 0.7054, Training Accuracy= 0.502\n",
      "Epoch: 2900, Loss= 0.7050, Training Accuracy= 0.501\n",
      "Epoch: 2910, Loss= 0.7056, Training Accuracy= 0.502\n",
      "Epoch: 2920, Loss= 0.7053, Training Accuracy= 0.501\n",
      "Epoch: 2930, Loss= 0.7059, Training Accuracy= 0.502\n",
      "Epoch: 2940, Loss= 0.7054, Training Accuracy= 0.501\n",
      "Epoch: 2950, Loss= 0.7059, Training Accuracy= 0.501\n",
      "Epoch: 2960, Loss= 0.7050, Training Accuracy= 0.498\n",
      "Epoch: 2970, Loss= 0.7049, Training Accuracy= 0.498\n",
      "Epoch: 2980, Loss= 0.7048, Training Accuracy= 0.498\n",
      "Epoch: 2990, Loss= 0.7047, Training Accuracy= 0.498\n",
      "Epoch: 3000, Loss= 0.7047, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3010, Loss= 0.7046, Training Accuracy= 0.498\n",
      "Epoch: 3020, Loss= 0.7046, Training Accuracy= 0.498\n",
      "Epoch: 3030, Loss= 0.7046, Training Accuracy= 0.498\n",
      "Epoch: 3040, Loss= 0.7046, Training Accuracy= 0.498\n",
      "Epoch: 3050, Loss= 0.7054, Training Accuracy= 0.499\n",
      "Epoch: 3060, Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 3070, Loss= 0.7047, Training Accuracy= 0.500\n",
      "Epoch: 3080, Loss= 0.7051, Training Accuracy= 0.500\n",
      "Epoch: 3090, Loss= 0.7044, Training Accuracy= 0.501\n",
      "Epoch: 3100, Loss= 0.7042, Training Accuracy= 0.502\n",
      "Epoch: 3110, Loss= 0.7040, Training Accuracy= 0.502\n",
      "Epoch: 3120, Loss= 0.7038, Training Accuracy= 0.502\n",
      "Epoch: 3130, Loss= 0.7038, Training Accuracy= 0.502\n",
      "Epoch: 3140, Loss= 0.7038, Training Accuracy= 0.502\n",
      "Epoch: 3150, Loss= 0.7039, Training Accuracy= 0.502\n",
      "Epoch: 3160, Loss= 0.7035, Training Accuracy= 0.502\n",
      "Epoch: 3170, Loss= 0.7040, Training Accuracy= 0.502\n",
      "Epoch: 3180, Loss= 0.7047, Training Accuracy= 0.498\n",
      "Epoch: 3190, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 3200, Loss= 0.7042, Training Accuracy= 0.502\n",
      "Epoch: 3210, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 3220, Loss= 0.7035, Training Accuracy= 0.503\n",
      "Epoch: 3230, Loss= 0.7035, Training Accuracy= 0.501\n",
      "Epoch: 3240, Loss= 0.7046, Training Accuracy= 0.501\n",
      "Epoch: 3250, Loss= 0.7041, Training Accuracy= 0.503\n",
      "Epoch: 3260, Loss= 0.7038, Training Accuracy= 0.502\n",
      "Epoch: 3270, Loss= 0.7041, Training Accuracy= 0.503\n",
      "Epoch: 3280, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 3290, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 3300, Loss= 0.7038, Training Accuracy= 0.502\n",
      "Epoch: 3310, Loss= 0.7041, Training Accuracy= 0.503\n",
      "Epoch: 3320, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 3330, Loss= 0.7040, Training Accuracy= 0.505\n",
      "Epoch: 3340, Loss= 0.7045, Training Accuracy= 0.503\n",
      "Epoch: 3350, Loss= 0.7057, Training Accuracy= 0.498\n",
      "Epoch: 3360, Loss= 0.7058, Training Accuracy= 0.498\n",
      "Epoch: 3370, Loss= 0.7058, Training Accuracy= 0.500\n",
      "Epoch: 3380, Loss= 0.7027, Training Accuracy= 0.503\n",
      "Epoch: 3390, Loss= 0.7056, Training Accuracy= 0.504\n",
      "Epoch: 3400, Loss= 0.7050, Training Accuracy= 0.503\n",
      "Epoch: 3410, Loss= 0.7045, Training Accuracy= 0.505\n",
      "Epoch: 3420, Loss= 0.7045, Training Accuracy= 0.504\n",
      "Epoch: 3430, Loss= 0.7058, Training Accuracy= 0.499\n",
      "Epoch: 3440, Loss= 0.7063, Training Accuracy= 0.501\n",
      "Epoch: 3450, Loss= 0.7049, Training Accuracy= 0.498\n",
      "Epoch: 3460, Loss= 0.7041, Training Accuracy= 0.498\n",
      "Epoch: 3470, Loss= 0.7060, Training Accuracy= 0.501\n",
      "Epoch: 3480, Loss= 0.7055, Training Accuracy= 0.502\n",
      "Epoch: 3490, Loss= 0.7070, Training Accuracy= 0.503\n",
      "Epoch: 3500, Loss= 0.7055, Training Accuracy= 0.506\n",
      "Epoch: 3510, Loss= 0.7066, Training Accuracy= 0.504\n",
      "Epoch: 3520, Loss= 0.7037, Training Accuracy= 0.506\n",
      "Epoch: 3530, Loss= 0.7080, Training Accuracy= 0.500\n",
      "Epoch: 3540, Loss= 0.7035, Training Accuracy= 0.502\n",
      "Epoch: 3550, Loss= 0.7058, Training Accuracy= 0.502\n",
      "Epoch: 3560, Loss= 0.7090, Training Accuracy= 0.498\n",
      "Epoch: 3570, Loss= 0.7063, Training Accuracy= 0.498\n",
      "Epoch: 3580, Loss= 0.7072, Training Accuracy= 0.498\n",
      "Epoch: 3590, Loss= 0.7083, Training Accuracy= 0.498\n",
      "Epoch: 3600, Loss= 0.7085, Training Accuracy= 0.498\n",
      "Epoch: 3610, Loss= 0.7086, Training Accuracy= 0.498\n",
      "Epoch: 3620, Loss= 0.7088, Training Accuracy= 0.498\n",
      "Epoch: 3630, Loss= 0.7088, Training Accuracy= 0.498\n",
      "Epoch: 3640, Loss= 0.7074, Training Accuracy= 0.504\n",
      "Epoch: 3650, Loss= 0.7036, Training Accuracy= 0.498\n",
      "Epoch: 3660, Loss= 0.7036, Training Accuracy= 0.498\n",
      "Epoch: 3670, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 3680, Loss= 0.7031, Training Accuracy= 0.498\n",
      "Epoch: 3690, Loss= 0.7029, Training Accuracy= 0.498\n",
      "Epoch: 3700, Loss= 0.7028, Training Accuracy= 0.499\n",
      "Epoch: 3710, Loss= 0.7027, Training Accuracy= 0.499\n",
      "Epoch: 3720, Loss= 0.7027, Training Accuracy= 0.499\n",
      "Epoch: 3730, Loss= 0.7028, Training Accuracy= 0.500\n",
      "Epoch: 3740, Loss= 0.7028, Training Accuracy= 0.500\n",
      "Epoch: 3750, Loss= 0.7032, Training Accuracy= 0.500\n",
      "Epoch: 3760, Loss= 0.7030, Training Accuracy= 0.499\n",
      "Epoch: 3770, Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 3780, Loss= 0.7037, Training Accuracy= 0.498\n",
      "Epoch: 3790, Loss= 0.7047, Training Accuracy= 0.497\n",
      "Epoch: 3800, Loss= 0.7155, Training Accuracy= 0.542\n",
      "Epoch: 3810, Loss= 0.7089, Training Accuracy= 0.562\n",
      "Epoch: 3820, Loss= 0.7072, Training Accuracy= 0.576\n",
      "Epoch: 3830, Loss= 0.6599, Training Accuracy= 0.602\n",
      "Epoch: 3840, Loss= 0.6482, Training Accuracy= 0.600\n",
      "Epoch: 3850, Loss= 0.6355, Training Accuracy= 0.616\n",
      "Epoch: 3860, Loss= 0.6177, Training Accuracy= 0.616\n",
      "Epoch: 3870, Loss= 0.6110, Training Accuracy= 0.627\n",
      "Epoch: 3880, Loss= 0.6443, Training Accuracy= 0.620\n",
      "Epoch: 3890, Loss= 0.6228, Training Accuracy= 0.616\n",
      "Epoch: 3900, Loss= 0.6505, Training Accuracy= 0.587\n",
      "Epoch: 3910, Loss= 0.5917, Training Accuracy= 0.647\n",
      "Epoch: 3920, Loss= 0.5831, Training Accuracy= 0.661\n",
      "Epoch: 3930, Loss= 0.5807, Training Accuracy= 0.664\n",
      "Epoch: 3940, Loss= 0.5405, Training Accuracy= 0.682\n",
      "Epoch: 3950, Loss= 0.5207, Training Accuracy= 0.692\n",
      "Epoch: 3960, Loss= 0.5073, Training Accuracy= 0.694\n",
      "Epoch: 3970, Loss= 0.5002, Training Accuracy= 0.692\n",
      "Epoch: 3980, Loss= 0.4782, Training Accuracy= 0.698\n",
      "Epoch: 3990, Loss= 0.5066, Training Accuracy= 0.687\n",
      "Epoch: 4000, Loss= 0.4774, Training Accuracy= 0.704\n",
      "Epoch: 4010, Loss= 0.4941, Training Accuracy= 0.701\n",
      "Epoch: 4020, Loss= 0.5098, Training Accuracy= 0.696\n",
      "Epoch: 4030, Loss= 0.6267, Training Accuracy= 0.606\n",
      "Epoch: 4040, Loss= 0.6280, Training Accuracy= 0.595\n",
      "Epoch: 4050, Loss= 0.6298, Training Accuracy= 0.599\n",
      "Epoch: 4060, Loss= 0.5892, Training Accuracy= 0.603\n",
      "Epoch: 4070, Loss= 0.5722, Training Accuracy= 0.623\n",
      "Epoch: 4080, Loss= 0.5616, Training Accuracy= 0.628\n",
      "Epoch: 4090, Loss= 0.6552, Training Accuracy= 0.618\n",
      "Epoch: 4100, Loss= 0.6450, Training Accuracy= 0.619\n",
      "Epoch: 4110, Loss= 0.6302, Training Accuracy= 0.619\n",
      "Epoch: 4120, Loss= 0.6227, Training Accuracy= 0.627\n",
      "Epoch: 4130, Loss= 0.6200, Training Accuracy= 0.633\n",
      "Epoch: 4140, Loss= 0.6563, Training Accuracy= 0.625\n",
      "Epoch: 4150, Loss= 0.6531, Training Accuracy= 0.630\n",
      "Epoch: 4160, Loss= 0.6718, Training Accuracy= 0.627\n",
      "Epoch: 4170, Loss= 0.6100, Training Accuracy= 0.627\n",
      "Epoch: 4180, Loss= 0.6874, Training Accuracy= 0.636\n",
      "Epoch: 4190, Loss= 0.6061, Training Accuracy= 0.631\n",
      "Epoch: 4200, Loss= 0.6050, Training Accuracy= 0.625\n",
      "Epoch: 4210, Loss= 0.6062, Training Accuracy= 0.676\n",
      "Epoch: 4220, Loss= 0.6896, Training Accuracy= 0.678\n",
      "Epoch: 4230, Loss= 0.6601, Training Accuracy= 0.673\n",
      "Epoch: 4240, Loss= 0.6809, Training Accuracy= 0.654\n",
      "Epoch: 4250, Loss= 0.6701, Training Accuracy= 0.606\n",
      "Epoch: 4260, Loss= 0.6721, Training Accuracy= 0.654\n",
      "Epoch: 4270, Loss= 0.6336, Training Accuracy= 0.605\n",
      "Epoch: 4280, Loss= 1.0423, Training Accuracy= 0.502\n",
      "Epoch: 4290, Loss= 1.0416, Training Accuracy= 0.502\n",
      "Epoch: 4300, Loss= 1.0416, Training Accuracy= 0.502\n",
      "Epoch: 4310, Loss= 1.0421, Training Accuracy= 0.502\n",
      "Epoch: 4320, Loss= 1.0431, Training Accuracy= 0.502\n",
      "Epoch: 4330, Loss= 1.0433, Training Accuracy= 0.502\n",
      "Epoch: 4340, Loss= 1.0433, Training Accuracy= 0.502\n",
      "Epoch: 4350, Loss= 1.0433, Training Accuracy= 0.502\n",
      "Epoch: 4360, Loss= 1.0433, Training Accuracy= 0.502\n",
      "Epoch: 4370, Loss= 1.0433, Training Accuracy= 0.502\n",
      "Epoch: 4380, Loss= 1.0433, Training Accuracy= 0.502\n",
      "Epoch: 4390, Loss= 1.0433, Training Accuracy= 0.502\n",
      "Epoch: 4400, Loss= 1.0433, Training Accuracy= 0.502\n",
      "Epoch: 4410, Loss= 1.0433, Training Accuracy= 0.502\n",
      "Epoch: 4420, Loss= 1.0433, Training Accuracy= 0.502\n",
      "Epoch: 4430, Loss= 1.0434, Training Accuracy= 0.502\n",
      "Epoch: 4440, Loss= 1.0434, Training Accuracy= 0.502\n",
      "Epoch: 4450, Loss= 1.0434, Training Accuracy= 0.502\n",
      "Epoch: 4460, Loss= 1.0434, Training Accuracy= 0.502\n",
      "Epoch: 4470, Loss= 1.0434, Training Accuracy= 0.502\n",
      "Epoch: 4480, Loss= 1.0435, Training Accuracy= 0.502\n",
      "Epoch: 4490, Loss= 1.0435, Training Accuracy= 0.502\n",
      "Epoch: 4500, Loss= 1.0435, Training Accuracy= 0.502\n",
      "Epoch: 4510, Loss= 1.0436, Training Accuracy= 0.502\n",
      "Epoch: 4520, Loss= 1.0436, Training Accuracy= 0.502\n",
      "Epoch: 4530, Loss= 1.0436, Training Accuracy= 0.502\n",
      "Epoch: 4540, Loss= 1.0437, Training Accuracy= 0.502\n",
      "Epoch: 4550, Loss= 1.0437, Training Accuracy= 0.502\n",
      "Epoch: 4560, Loss= 1.0437, Training Accuracy= 0.502\n",
      "Epoch: 4570, Loss= 1.0438, Training Accuracy= 0.502\n",
      "Epoch: 4580, Loss= 1.0438, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4590, Loss= 1.0438, Training Accuracy= 0.502\n",
      "Epoch: 4600, Loss= 1.0438, Training Accuracy= 0.502\n",
      "Epoch: 4610, Loss= 1.0435, Training Accuracy= 0.502\n",
      "Epoch: 4620, Loss= 1.0425, Training Accuracy= 0.502\n",
      "Epoch: 4630, Loss= 0.8494, Training Accuracy= 0.502\n",
      "Epoch: 4640, Loss= 0.8148, Training Accuracy= 0.502\n",
      "Epoch: 4650, Loss= 0.8513, Training Accuracy= 0.498\n",
      "Epoch: 4660, Loss= 0.8500, Training Accuracy= 0.498\n",
      "Epoch: 4670, Loss= 0.8494, Training Accuracy= 0.498\n",
      "Epoch: 4680, Loss= 0.8489, Training Accuracy= 0.498\n",
      "Epoch: 4690, Loss= 0.8486, Training Accuracy= 0.498\n",
      "Epoch: 4700, Loss= 0.8484, Training Accuracy= 0.498\n",
      "Epoch: 4710, Loss= 0.8482, Training Accuracy= 0.498\n",
      "Epoch: 4720, Loss= 0.8480, Training Accuracy= 0.498\n",
      "Epoch: 4730, Loss= 0.8479, Training Accuracy= 0.498\n",
      "Epoch: 4740, Loss= 0.8477, Training Accuracy= 0.498\n",
      "Epoch: 4750, Loss= 0.8476, Training Accuracy= 0.498\n",
      "Epoch: 4760, Loss= 0.8475, Training Accuracy= 0.498\n",
      "Epoch: 4770, Loss= 0.8474, Training Accuracy= 0.498\n",
      "Epoch: 4780, Loss= 0.8473, Training Accuracy= 0.498\n",
      "Epoch: 4790, Loss= 0.8472, Training Accuracy= 0.498\n",
      "Epoch: 4800, Loss= 0.8471, Training Accuracy= 0.498\n",
      "Epoch: 4810, Loss= 0.8470, Training Accuracy= 0.498\n",
      "Epoch: 4820, Loss= 0.8469, Training Accuracy= 0.498\n",
      "Epoch: 4830, Loss= 0.8468, Training Accuracy= 0.498\n",
      "Epoch: 4840, Loss= 0.8467, Training Accuracy= 0.498\n",
      "Epoch: 4850, Loss= 0.8467, Training Accuracy= 0.498\n",
      "Epoch: 4860, Loss= 0.8466, Training Accuracy= 0.498\n",
      "Epoch: 4870, Loss= 0.8465, Training Accuracy= 0.498\n",
      "Epoch: 4880, Loss= 0.8465, Training Accuracy= 0.498\n",
      "Epoch: 4890, Loss= 0.8464, Training Accuracy= 0.498\n",
      "Epoch: 4900, Loss= 0.8463, Training Accuracy= 0.498\n",
      "Epoch: 4910, Loss= 0.8463, Training Accuracy= 0.498\n",
      "Epoch: 4920, Loss= 0.8462, Training Accuracy= 0.498\n",
      "Epoch: 4930, Loss= 0.8461, Training Accuracy= 0.498\n",
      "Epoch: 4940, Loss= 0.8461, Training Accuracy= 0.498\n",
      "Epoch: 4950, Loss= 0.8460, Training Accuracy= 0.498\n",
      "Epoch: 4960, Loss= 0.8460, Training Accuracy= 0.498\n",
      "Epoch: 4970, Loss= 0.8459, Training Accuracy= 0.498\n",
      "Epoch: 4980, Loss= 0.8459, Training Accuracy= 0.498\n",
      "Epoch: 4990, Loss= 0.8458, Training Accuracy= 0.498\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4954\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 0.7160, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.7054, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 40, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 50, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 60, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 70, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 80, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 90, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 100, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 120, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 130, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 150, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 160, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 170, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 180, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 190, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 200, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 230, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 240, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 250, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 260, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 270, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 280, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 290, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 310, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 320, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 330, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 340, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 350, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 360, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 370, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 380, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 390, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 400, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 410, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 420, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 430, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 440, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 450, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 460, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 470, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 480, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 490, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 500, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 510, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 520, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 530, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 540, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 550, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 560, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 570, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 580, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 590, Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 600, Loss= 0.7054, Training Accuracy= 0.502\n",
      "Epoch: 610, Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 620, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 630, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 640, Loss= 0.7056, Training Accuracy= 0.502\n",
      "Epoch: 650, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 660, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 670, Loss= 0.7054, Training Accuracy= 0.502\n",
      "Epoch: 680, Loss= 0.7057, Training Accuracy= 0.502\n",
      "Epoch: 690, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 700, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 710, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 720, Loss= 0.7058, Training Accuracy= 0.502\n",
      "Epoch: 730, Loss= 0.7062, Training Accuracy= 0.502\n",
      "Epoch: 740, Loss= 0.7060, Training Accuracy= 0.502\n",
      "Epoch: 750, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 760, Loss= 0.7057, Training Accuracy= 0.502\n",
      "Epoch: 770, Loss= 0.7054, Training Accuracy= 0.502\n",
      "Epoch: 780, Loss= 0.7053, Training Accuracy= 0.502\n",
      "Epoch: 790, Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 800, Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 810, Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 820, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 830, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 840, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 850, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 860, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 870, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 880, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 890, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 900, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 910, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 920, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 930, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 940, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 950, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 960, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 970, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 980, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 990, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 1000, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 1010, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 1020, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1030, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1040, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1050, Loss= 0.7044, Training Accuracy= 0.502\n",
      "Epoch: 1060, Loss= 0.7044, Training Accuracy= 0.502\n",
      "Epoch: 1070, Loss= 0.7043, Training Accuracy= 0.502\n",
      "Epoch: 1080, Loss= 0.7043, Training Accuracy= 0.502\n",
      "Epoch: 1090, Loss= 0.7042, Training Accuracy= 0.502\n",
      "Epoch: 1100, Loss= 0.7042, Training Accuracy= 0.502\n",
      "Epoch: 1110, Loss= 0.7042, Training Accuracy= 0.502\n",
      "Epoch: 1120, Loss= 0.7042, Training Accuracy= 0.502\n",
      "Epoch: 1130, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 1140, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 1150, Loss= 0.7040, Training Accuracy= 0.502\n",
      "Epoch: 1160, Loss= 0.7040, Training Accuracy= 0.502\n",
      "Epoch: 1170, Loss= 0.7041, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1180, Loss= 0.7042, Training Accuracy= 0.502\n",
      "Epoch: 1190, Loss= 0.7040, Training Accuracy= 0.502\n",
      "Epoch: 1200, Loss= 0.7039, Training Accuracy= 0.501\n",
      "Epoch: 1210, Loss= 0.7039, Training Accuracy= 0.501\n",
      "Epoch: 1220, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 1230, Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 1240, Loss= 0.7039, Training Accuracy= 0.501\n",
      "Epoch: 1250, Loss= 0.7038, Training Accuracy= 0.502\n",
      "Epoch: 1260, Loss= 0.7041, Training Accuracy= 0.501\n",
      "Epoch: 1270, Loss= 0.7040, Training Accuracy= 0.502\n",
      "Epoch: 1280, Loss= 0.7040, Training Accuracy= 0.502\n",
      "Epoch: 1290, Loss= 0.7041, Training Accuracy= 0.502\n",
      "Epoch: 1300, Loss= 0.7039, Training Accuracy= 0.502\n",
      "Epoch: 1310, Loss= 0.7039, Training Accuracy= 0.502\n",
      "Epoch: 1320, Loss= 0.7043, Training Accuracy= 0.502\n",
      "Epoch: 1330, Loss= 0.7040, Training Accuracy= 0.502\n",
      "Epoch: 1340, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1350, Loss= 0.7041, Training Accuracy= 0.503\n",
      "Epoch: 1360, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 1370, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1380, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1390, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 1400, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 1410, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 1420, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1430, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1440, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1450, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1460, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1470, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1480, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1490, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1500, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1510, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1520, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1530, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1540, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1550, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1560, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1570, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1580, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 1590, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 1600, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 1610, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1620, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 1630, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1640, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1650, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1660, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 1670, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 1680, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 1690, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1700, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 1710, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1720, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1730, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1740, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1750, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1760, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1770, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1780, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1790, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1800, Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 1810, Loss= 0.7044, Training Accuracy= 0.502\n",
      "Epoch: 1820, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1830, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 1840, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 1850, Loss= 0.7045, Training Accuracy= 0.501\n",
      "Epoch: 1860, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1870, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1880, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 1890, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1900, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 1910, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 1920, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 1930, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 1940, Loss= 0.7044, Training Accuracy= 0.502\n",
      "Epoch: 1950, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 1960, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 1970, Loss= 0.7048, Training Accuracy= 0.501\n",
      "Epoch: 1980, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1990, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 2000, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 2010, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 2020, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 2030, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 2040, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 2050, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 2060, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 2070, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 2080, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 2090, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 2100, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 2110, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 2120, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 2130, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 2140, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 2150, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 2160, Loss= 0.7056, Training Accuracy= 0.503\n",
      "Epoch: 2170, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 2180, Loss= 0.7046, Training Accuracy= 0.502\n",
      "Epoch: 2190, Loss= 0.7055, Training Accuracy= 0.502\n",
      "Epoch: 2200, Loss= 0.7048, Training Accuracy= 0.503\n",
      "Epoch: 2210, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 2220, Loss= 0.7054, Training Accuracy= 0.502\n",
      "Epoch: 2230, Loss= 0.7055, Training Accuracy= 0.502\n",
      "Epoch: 2240, Loss= 0.7056, Training Accuracy= 0.502\n",
      "Epoch: 2250, Loss= 0.7056, Training Accuracy= 0.502\n",
      "Epoch: 2260, Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 2270, Loss= 0.7055, Training Accuracy= 0.502\n",
      "Epoch: 2280, Loss= 0.7055, Training Accuracy= 0.502\n",
      "Epoch: 2290, Loss= 0.7055, Training Accuracy= 0.502\n",
      "Epoch: 2300, Loss= 0.7056, Training Accuracy= 0.502\n",
      "Epoch: 2310, Loss= 0.7058, Training Accuracy= 0.502\n",
      "Epoch: 2320, Loss= 0.7054, Training Accuracy= 0.502\n",
      "Epoch: 2330, Loss= 0.7050, Training Accuracy= 0.503\n",
      "Epoch: 2340, Loss= 0.7074, Training Accuracy= 0.503\n",
      "Epoch: 2350, Loss= 0.7066, Training Accuracy= 0.502\n",
      "Epoch: 2360, Loss= 0.7072, Training Accuracy= 0.502\n",
      "Epoch: 2370, Loss= 0.7078, Training Accuracy= 0.502\n",
      "Epoch: 2380, Loss= 0.7065, Training Accuracy= 0.503\n",
      "Epoch: 2390, Loss= 0.7067, Training Accuracy= 0.502\n",
      "Epoch: 2400, Loss= 0.7064, Training Accuracy= 0.503\n",
      "Epoch: 2410, Loss= 0.7065, Training Accuracy= 0.502\n",
      "Epoch: 2420, Loss= 0.7066, Training Accuracy= 0.502\n",
      "Epoch: 2430, Loss= 0.7056, Training Accuracy= 0.503\n",
      "Epoch: 2440, Loss= 0.7060, Training Accuracy= 0.502\n",
      "Epoch: 2450, Loss= 0.7065, Training Accuracy= 0.502\n",
      "Epoch: 2460, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 2470, Loss= 0.7068, Training Accuracy= 0.504\n",
      "Epoch: 2480, Loss= 0.7059, Training Accuracy= 0.503\n",
      "Epoch: 2490, Loss= 0.7057, Training Accuracy= 0.503\n",
      "Epoch: 2500, Loss= 0.7071, Training Accuracy= 0.503\n",
      "Epoch: 2510, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2520, Loss= 0.7067, Training Accuracy= 0.502\n",
      "Epoch: 2530, Loss= 0.7066, Training Accuracy= 0.502\n",
      "Epoch: 2540, Loss= 0.7066, Training Accuracy= 0.502\n",
      "Epoch: 2550, Loss= 0.7067, Training Accuracy= 0.502\n",
      "Epoch: 2560, Loss= 0.7067, Training Accuracy= 0.502\n",
      "Epoch: 2570, Loss= 0.7068, Training Accuracy= 0.502\n",
      "Epoch: 2580, Loss= 0.7068, Training Accuracy= 0.502\n",
      "Epoch: 2590, Loss= 0.7068, Training Accuracy= 0.502\n",
      "Epoch: 2600, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2610, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2620, Loss= 0.7069, Training Accuracy= 0.503\n",
      "Epoch: 2630, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2640, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2650, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2660, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2670, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2680, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2690, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2700, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2710, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2720, Loss= 0.7069, Training Accuracy= 0.502\n",
      "Epoch: 2730, Loss= 0.7080, Training Accuracy= 0.503\n",
      "Epoch: 2740, Loss= 0.7036, Training Accuracy= 0.506\n",
      "Epoch: 2750, Loss= 0.7058, Training Accuracy= 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2760, Loss= 0.7122, Training Accuracy= 0.502\n",
      "Epoch: 2770, Loss= 0.7068, Training Accuracy= 0.503\n",
      "Epoch: 2780, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 2790, Loss= 0.7050, Training Accuracy= 0.504\n",
      "Epoch: 2800, Loss= 0.7046, Training Accuracy= 0.504\n",
      "Epoch: 2810, Loss= 0.7058, Training Accuracy= 0.504\n",
      "Epoch: 2820, Loss= 0.7082, Training Accuracy= 0.502\n",
      "Epoch: 2830, Loss= 0.7078, Training Accuracy= 0.502\n",
      "Epoch: 2840, Loss= 0.7060, Training Accuracy= 0.501\n",
      "Epoch: 2850, Loss= 0.7031, Training Accuracy= 0.505\n",
      "Epoch: 2860, Loss= 0.7039, Training Accuracy= 0.506\n",
      "Epoch: 2870, Loss= 0.7084, Training Accuracy= 0.502\n",
      "Epoch: 2880, Loss= 0.7067, Training Accuracy= 0.502\n",
      "Epoch: 2890, Loss= 0.7083, Training Accuracy= 0.502\n",
      "Epoch: 2900, Loss= 0.7085, Training Accuracy= 0.502\n",
      "Epoch: 2910, Loss= 0.7081, Training Accuracy= 0.502\n",
      "Epoch: 2920, Loss= 0.7079, Training Accuracy= 0.502\n",
      "Epoch: 2930, Loss= 0.7078, Training Accuracy= 0.502\n",
      "Epoch: 2940, Loss= 0.7078, Training Accuracy= 0.503\n",
      "Epoch: 2950, Loss= 0.7102, Training Accuracy= 0.503\n",
      "Epoch: 2960, Loss= 0.7045, Training Accuracy= 0.506\n",
      "Epoch: 2970, Loss= 0.7039, Training Accuracy= 0.505\n",
      "Epoch: 2980, Loss= 0.7065, Training Accuracy= 0.502\n",
      "Epoch: 2990, Loss= 0.7070, Training Accuracy= 0.501\n",
      "Epoch: 3000, Loss= 0.7035, Training Accuracy= 0.505\n",
      "Epoch: 3010, Loss= 0.7032, Training Accuracy= 0.503\n",
      "Epoch: 3020, Loss= 0.7065, Training Accuracy= 0.503\n",
      "Epoch: 3030, Loss= 0.7134, Training Accuracy= 0.502\n",
      "Epoch: 3040, Loss= 0.7079, Training Accuracy= 0.502\n",
      "Epoch: 3050, Loss= 0.7053, Training Accuracy= 0.501\n",
      "Epoch: 3060, Loss= 0.7081, Training Accuracy= 0.502\n",
      "Epoch: 3070, Loss= 0.7103, Training Accuracy= 0.502\n",
      "Epoch: 3080, Loss= 0.7127, Training Accuracy= 0.502\n",
      "Epoch: 3090, Loss= 0.7132, Training Accuracy= 0.502\n",
      "Epoch: 3100, Loss= 0.7057, Training Accuracy= 0.502\n",
      "Epoch: 3110, Loss= 0.7056, Training Accuracy= 0.502\n",
      "Epoch: 3120, Loss= 0.7060, Training Accuracy= 0.502\n",
      "Epoch: 3130, Loss= 0.7064, Training Accuracy= 0.502\n",
      "Epoch: 3140, Loss= 0.7068, Training Accuracy= 0.502\n",
      "Epoch: 3150, Loss= 0.7072, Training Accuracy= 0.502\n",
      "Epoch: 3160, Loss= 0.7075, Training Accuracy= 0.502\n",
      "Epoch: 3170, Loss= 0.7077, Training Accuracy= 0.502\n",
      "Epoch: 3180, Loss= 0.7080, Training Accuracy= 0.502\n",
      "Epoch: 3190, Loss= 0.7082, Training Accuracy= 0.502\n",
      "Epoch: 3200, Loss= 0.7083, Training Accuracy= 0.502\n",
      "Epoch: 3210, Loss= 0.7083, Training Accuracy= 0.502\n",
      "Epoch: 3220, Loss= 0.7083, Training Accuracy= 0.502\n",
      "Epoch: 3230, Loss= 0.7083, Training Accuracy= 0.502\n",
      "Epoch: 3240, Loss= 0.7079, Training Accuracy= 0.502\n",
      "Epoch: 3250, Loss= 0.7074, Training Accuracy= 0.502\n",
      "Epoch: 3260, Loss= 0.7385, Training Accuracy= 0.502\n",
      "Epoch: 3270, Loss= 0.7395, Training Accuracy= 0.502\n",
      "Epoch: 3280, Loss= 0.7128, Training Accuracy= 0.502\n",
      "Epoch: 3290, Loss= 0.7077, Training Accuracy= 0.502\n",
      "Epoch: 3300, Loss= 0.7063, Training Accuracy= 0.502\n",
      "Epoch: 3310, Loss= 0.7057, Training Accuracy= 0.502\n",
      "Epoch: 3320, Loss= 0.7054, Training Accuracy= 0.502\n",
      "Epoch: 3330, Loss= 0.7053, Training Accuracy= 0.502\n",
      "Epoch: 3340, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 3350, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 3360, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 3370, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 3380, Loss= 0.7050, Training Accuracy= 0.502\n",
      "Epoch: 3390, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3400, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3410, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3420, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3430, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3440, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3450, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3460, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3470, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3480, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3490, Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 3500, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3510, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3520, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3530, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3540, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3550, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3560, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3570, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3580, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3590, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3600, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3610, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3620, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3630, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3640, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3650, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3660, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3670, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3680, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3690, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3700, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3710, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3720, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3730, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3740, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3750, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3760, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3770, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3780, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3790, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3800, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3810, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3820, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3830, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3840, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3850, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3860, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3870, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3880, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3890, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3900, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3910, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3920, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3930, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3940, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3950, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3960, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3970, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3980, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 3990, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4000, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4010, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4020, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4030, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4040, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4050, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4060, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4070, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4080, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4090, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4100, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4110, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4120, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4130, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4140, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4150, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4160, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4170, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4180, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4190, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4200, Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 4210, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4220, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4230, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4240, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4250, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4260, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4270, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4280, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4290, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4300, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4310, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4320, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4330, Loss= 0.7047, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4340, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4350, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4360, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4370, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4380, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4390, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4400, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4410, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4420, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4430, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4440, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4450, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4460, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4470, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4480, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4490, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4500, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4510, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4520, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4530, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4540, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4550, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4560, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4570, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4580, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4590, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4600, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4610, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4620, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4630, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4640, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4650, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4660, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4670, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4680, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4690, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4700, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4710, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4720, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4730, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4740, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4750, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4760, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4770, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4780, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4790, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4800, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4810, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4820, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4830, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4840, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4850, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4860, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4870, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4880, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4890, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4900, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4910, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4920, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4930, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4940, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4950, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4960, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4970, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4980, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 4990, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4992\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.7039, Training Accuracy= 0.501\n",
      "Epoch: 10, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 20, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 30, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 40, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 50, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 60, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 70, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 80, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 90, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 100, Loss= 0.7034, Training Accuracy= 0.501\n",
      "Epoch: 110, Loss= 0.7033, Training Accuracy= 0.501\n",
      "Epoch: 120, Loss= 0.7033, Training Accuracy= 0.501\n",
      "Epoch: 130, Loss= 0.7033, Training Accuracy= 0.501\n",
      "Epoch: 140, Loss= 0.7033, Training Accuracy= 0.501\n",
      "Epoch: 150, Loss= 0.7033, Training Accuracy= 0.501\n",
      "Epoch: 160, Loss= 0.7033, Training Accuracy= 0.501\n",
      "Epoch: 170, Loss= 0.7033, Training Accuracy= 0.501\n",
      "Epoch: 180, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 190, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 200, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 210, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 220, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 230, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 240, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 250, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 260, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 270, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 280, Loss= 0.7032, Training Accuracy= 0.501\n",
      "Epoch: 290, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 300, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 310, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 320, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 330, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 340, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 350, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 360, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 370, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 380, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 390, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 400, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 410, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 420, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 430, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 440, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 450, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 460, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 470, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 480, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 490, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 500, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 510, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 520, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 530, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 540, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 550, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 560, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 570, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 580, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 590, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 600, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 610, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 620, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 630, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 640, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 650, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 660, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 670, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 680, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 690, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 700, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 710, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 720, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 730, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 740, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 750, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 760, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 770, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 780, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 790, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 800, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 810, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 820, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 830, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 840, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 850, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 860, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 870, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 880, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 890, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 900, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 910, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 920, Loss= 0.7030, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 930, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 940, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 950, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 960, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 970, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 980, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 990, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1000, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1010, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1020, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1030, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1040, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1050, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1060, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1070, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1080, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1090, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1100, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1110, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1120, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1130, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1140, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1150, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1160, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1170, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1180, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1190, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1200, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1210, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1220, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1230, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1240, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1250, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1260, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1270, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1280, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1290, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1300, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1310, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1320, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1330, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1340, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1350, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1360, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1370, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1380, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1390, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1400, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1410, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1420, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1430, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1440, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1450, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1460, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1470, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1480, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1490, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1500, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1510, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1520, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1530, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1540, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1550, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1560, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1570, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1580, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1590, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1600, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1610, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1620, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1630, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1640, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1650, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1660, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1670, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1680, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1690, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1700, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1710, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1720, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1730, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1740, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1750, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1760, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1770, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1780, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1790, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1800, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1810, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1820, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1830, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1840, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1850, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1860, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1870, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1880, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1890, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1900, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1910, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1920, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1930, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1940, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1950, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1960, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1970, Loss= 0.7030, Training Accuracy= 0.501\n",
      "Epoch: 1980, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 1990, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2000, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2010, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2020, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2030, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2040, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2050, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2060, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2070, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2080, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2090, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2100, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2110, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2120, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2130, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2140, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2150, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2160, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2170, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2180, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2190, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2200, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2210, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2220, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2230, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2240, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2250, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2260, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2270, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2280, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2290, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2300, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2310, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2320, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2330, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2340, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2350, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2360, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2370, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2380, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2390, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2400, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2410, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2420, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2430, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2440, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2450, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2460, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2470, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2480, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2490, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2500, Loss= 0.7029, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2510, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2520, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2530, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2540, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2550, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2560, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2570, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2580, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2590, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2600, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2610, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2620, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2630, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2640, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2650, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2660, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2670, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2680, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2690, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2700, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2710, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2720, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2730, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2740, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2750, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2760, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2770, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2780, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2790, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2800, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2810, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2820, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2830, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2840, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2850, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2860, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2870, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2880, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2890, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2900, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2910, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2920, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2930, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2940, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2950, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2960, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2970, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2980, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 2990, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3000, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3010, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3020, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3030, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3040, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3050, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3060, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3070, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3080, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3090, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3100, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3110, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3120, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3130, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3140, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3150, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3160, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3170, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3180, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3190, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3200, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3210, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3220, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3230, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3240, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3250, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3260, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3270, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3280, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3290, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3300, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3310, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3320, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3330, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3340, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3350, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3360, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3370, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3380, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3390, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3400, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3410, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3420, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3430, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3440, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3450, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3460, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3470, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3480, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3490, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3500, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3510, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3520, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3530, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3540, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3550, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3560, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3570, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3580, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3590, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3600, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3610, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3620, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3630, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3640, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3650, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3660, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3670, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3680, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3690, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3700, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3710, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3720, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3730, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3740, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3750, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3760, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3770, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3780, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3790, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3800, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3810, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3820, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3830, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3840, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3850, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3860, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3870, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3880, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3890, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3900, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3910, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3920, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3930, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3940, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3950, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3960, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3970, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3980, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3990, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4000, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4010, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4020, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4030, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4040, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4050, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4060, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4070, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4080, Loss= 0.7029, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4090, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4100, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4110, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4120, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4130, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4140, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4150, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4160, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4170, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4180, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4190, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4200, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4210, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4220, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4230, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4240, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4250, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4260, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4270, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4280, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4290, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4300, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4310, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4320, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4330, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4340, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4350, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4360, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4370, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4380, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4390, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4400, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4410, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4420, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4430, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4440, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4450, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4460, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4470, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4480, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4490, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4500, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4510, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4520, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4530, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4540, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4550, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4560, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4570, Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 4580, Loss= 0.7028, Training Accuracy= 0.501\n",
      "Epoch: 4590, Loss= 0.7028, Training Accuracy= 0.501\n",
      "Epoch: 4600, Loss= 0.7028, Training Accuracy= 0.501\n",
      "Epoch: 4610, Loss= 0.7027, Training Accuracy= 0.501\n",
      "Epoch: 4620, Loss= 0.7027, Training Accuracy= 0.501\n",
      "Epoch: 4630, Loss= 0.7027, Training Accuracy= 0.501\n",
      "Epoch: 4640, Loss= 0.7027, Training Accuracy= 0.501\n",
      "Epoch: 4650, Loss= 0.7026, Training Accuracy= 0.501\n",
      "Epoch: 4660, Loss= 0.7026, Training Accuracy= 0.501\n",
      "Epoch: 4670, Loss= 0.7026, Training Accuracy= 0.501\n",
      "Epoch: 4680, Loss= 0.7026, Training Accuracy= 0.501\n",
      "Epoch: 4690, Loss= 0.7025, Training Accuracy= 0.501\n",
      "Epoch: 4700, Loss= 0.7025, Training Accuracy= 0.501\n",
      "Epoch: 4710, Loss= 0.7025, Training Accuracy= 0.501\n",
      "Epoch: 4720, Loss= 0.7025, Training Accuracy= 0.501\n",
      "Epoch: 4730, Loss= 0.7025, Training Accuracy= 0.501\n",
      "Epoch: 4740, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4750, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4760, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4770, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4780, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4790, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4800, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4810, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4820, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4830, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4840, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4850, Loss= 0.7024, Training Accuracy= 0.501\n",
      "Epoch: 4860, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4870, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4880, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4890, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4900, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4910, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4920, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4930, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4940, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4950, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4960, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4970, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4980, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Epoch: 4990, Loss= 0.7023, Training Accuracy= 0.501\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4986\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 2.3\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 5000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [0.49349999, 0.4928, 0.49590001, 0.49869999, 0.49329999, 0.49439999, 0.49239999, 0.49540001, 0.49919999, 0.49860001]\n",
      "mean of test_accuracies_10replications:  0.49542\n",
      "standard deviation of test_accuracies_10replications_std_mean:  2.46162619442e-05\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn3FiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97af52dd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
