{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 25\n",
    "N = 25\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.7273, Training Accuracy= 0.509\n",
      "Epoch: 10, Loss= 0.7154, Training Accuracy= 0.509\n",
      "Epoch: 20, Loss= 0.7101, Training Accuracy= 0.509\n",
      "Epoch: 30, Loss= 0.7074, Training Accuracy= 0.509\n",
      "Epoch: 40, Loss= 0.7057, Training Accuracy= 0.509\n",
      "Epoch: 50, Loss= 0.7046, Training Accuracy= 0.509\n",
      "Epoch: 60, Loss= 0.7038, Training Accuracy= 0.509\n",
      "Epoch: 70, Loss= 0.7032, Training Accuracy= 0.509\n",
      "Epoch: 80, Loss= 0.7027, Training Accuracy= 0.509\n",
      "Epoch: 90, Loss= 0.7023, Training Accuracy= 0.509\n",
      "Epoch: 100, Loss= 0.7020, Training Accuracy= 0.509\n",
      "Epoch: 110, Loss= 0.7017, Training Accuracy= 0.509\n",
      "Epoch: 120, Loss= 0.7015, Training Accuracy= 0.509\n",
      "Epoch: 130, Loss= 0.7013, Training Accuracy= 0.509\n",
      "Epoch: 140, Loss= 0.7012, Training Accuracy= 0.509\n",
      "Epoch: 150, Loss= 0.7010, Training Accuracy= 0.509\n",
      "Epoch: 160, Loss= 0.7009, Training Accuracy= 0.509\n",
      "Epoch: 170, Loss= 0.7008, Training Accuracy= 0.509\n",
      "Epoch: 180, Loss= 0.7008, Training Accuracy= 0.509\n",
      "Epoch: 190, Loss= 0.7007, Training Accuracy= 0.509\n",
      "Epoch: 200, Loss= 0.7006, Training Accuracy= 0.509\n",
      "Epoch: 210, Loss= 0.7006, Training Accuracy= 0.509\n",
      "Epoch: 220, Loss= 0.7005, Training Accuracy= 0.509\n",
      "Epoch: 230, Loss= 0.7005, Training Accuracy= 0.509\n",
      "Epoch: 240, Loss= 0.7005, Training Accuracy= 0.509\n",
      "Epoch: 250, Loss= 0.7004, Training Accuracy= 0.509\n",
      "Epoch: 260, Loss= 0.7004, Training Accuracy= 0.509\n",
      "Epoch: 270, Loss= 0.7004, Training Accuracy= 0.509\n",
      "Epoch: 280, Loss= 0.7004, Training Accuracy= 0.509\n",
      "Epoch: 290, Loss= 0.7003, Training Accuracy= 0.509\n",
      "Epoch: 300, Loss= 0.7003, Training Accuracy= 0.509\n",
      "Epoch: 310, Loss= 0.7003, Training Accuracy= 0.509\n",
      "Epoch: 320, Loss= 0.7003, Training Accuracy= 0.509\n",
      "Epoch: 330, Loss= 0.7003, Training Accuracy= 0.509\n",
      "Epoch: 340, Loss= 0.7003, Training Accuracy= 0.509\n",
      "Epoch: 350, Loss= 0.7002, Training Accuracy= 0.509\n",
      "Epoch: 360, Loss= 0.7002, Training Accuracy= 0.509\n",
      "Epoch: 370, Loss= 0.7002, Training Accuracy= 0.509\n",
      "Epoch: 380, Loss= 0.7002, Training Accuracy= 0.509\n",
      "Epoch: 390, Loss= 0.7002, Training Accuracy= 0.509\n",
      "Epoch: 400, Loss= 0.7002, Training Accuracy= 0.509\n",
      "Epoch: 410, Loss= 0.7002, Training Accuracy= 0.509\n",
      "Epoch: 420, Loss= 0.7002, Training Accuracy= 0.509\n",
      "Epoch: 430, Loss= 0.7002, Training Accuracy= 0.509\n",
      "Epoch: 440, Loss= 0.7002, Training Accuracy= 0.509\n",
      "Epoch: 450, Loss= 0.7003, Training Accuracy= 0.509\n",
      "Epoch: 460, Loss= 0.7003, Training Accuracy= 0.509\n",
      "Epoch: 470, Loss= 0.7004, Training Accuracy= 0.509\n",
      "Epoch: 480, Loss= 0.7006, Training Accuracy= 0.509\n",
      "Epoch: 490, Loss= 0.7008, Training Accuracy= 0.509\n",
      "Epoch: 500, Loss= 0.7010, Training Accuracy= 0.509\n",
      "Epoch: 510, Loss= 0.7012, Training Accuracy= 0.509\n",
      "Epoch: 520, Loss= 0.7014, Training Accuracy= 0.509\n",
      "Epoch: 530, Loss= 0.7015, Training Accuracy= 0.509\n",
      "Epoch: 540, Loss= 0.7018, Training Accuracy= 0.509\n",
      "Epoch: 550, Loss= 0.7023, Training Accuracy= 0.509\n",
      "Epoch: 560, Loss= 0.7012, Training Accuracy= 0.509\n",
      "Epoch: 570, Loss= 0.7011, Training Accuracy= 0.509\n",
      "Epoch: 580, Loss= 0.7017, Training Accuracy= 0.509\n",
      "Epoch: 590, Loss= 0.7034, Training Accuracy= 0.509\n",
      "Epoch: 600, Loss= 0.7000, Training Accuracy= 0.510\n",
      "Epoch: 610, Loss= 0.6269, Training Accuracy= 0.578\n",
      "Epoch: 620, Loss= 0.4818, Training Accuracy= 0.718\n",
      "Epoch: 630, Loss= 0.7038, Training Accuracy= 0.800\n",
      "Epoch: 640, Loss= 0.7405, Training Accuracy= 0.510\n",
      "Epoch: 650, Loss= 0.7515, Training Accuracy= 0.506\n",
      "Epoch: 660, Loss= 0.7420, Training Accuracy= 0.512\n",
      "Epoch: 670, Loss= 0.7476, Training Accuracy= 0.515\n",
      "Epoch: 680, Loss= 0.7677, Training Accuracy= 0.518\n",
      "Epoch: 690, Loss= 0.7116, Training Accuracy= 0.547\n",
      "Epoch: 700, Loss= 0.7252, Training Accuracy= 0.542\n",
      "Epoch: 710, Loss= 0.7342, Training Accuracy= 0.507\n",
      "Epoch: 720, Loss= 0.7237, Training Accuracy= 0.517\n",
      "Epoch: 730, Loss= 0.7220, Training Accuracy= 0.510\n",
      "Epoch: 740, Loss= 0.7168, Training Accuracy= 0.510\n",
      "Epoch: 750, Loss= 0.7135, Training Accuracy= 0.511\n",
      "Epoch: 760, Loss= 0.7106, Training Accuracy= 0.514\n",
      "Epoch: 770, Loss= 0.7083, Training Accuracy= 0.515\n",
      "Epoch: 780, Loss= 0.7068, Training Accuracy= 0.514\n",
      "Epoch: 790, Loss= 0.7094, Training Accuracy= 0.512\n",
      "Epoch: 800, Loss= 0.4255, Training Accuracy= 0.768\n",
      "Epoch: 810, Loss= 0.7238, Training Accuracy= 0.509\n",
      "Epoch: 820, Loss= 0.6191, Training Accuracy= 0.618\n",
      "Epoch: 830, Loss= 0.7144, Training Accuracy= 0.520\n",
      "Epoch: 840, Loss= 0.7113, Training Accuracy= 0.526\n",
      "Epoch: 850, Loss= 0.7139, Training Accuracy= 0.527\n",
      "Epoch: 860, Loss= 0.7184, Training Accuracy= 0.516\n",
      "Epoch: 870, Loss= 0.7126, Training Accuracy= 0.514\n",
      "Epoch: 880, Loss= 0.7104, Training Accuracy= 0.514\n",
      "Epoch: 890, Loss= 0.7090, Training Accuracy= 0.514\n",
      "Epoch: 900, Loss= 0.7081, Training Accuracy= 0.515\n",
      "Epoch: 910, Loss= 0.7074, Training Accuracy= 0.514\n",
      "Epoch: 920, Loss= 0.7068, Training Accuracy= 0.515\n",
      "Epoch: 930, Loss= 0.7064, Training Accuracy= 0.515\n",
      "Epoch: 940, Loss= 0.7060, Training Accuracy= 0.516\n",
      "Epoch: 950, Loss= 0.7049, Training Accuracy= 0.518\n",
      "Epoch: 960, Loss= 0.7042, Training Accuracy= 0.518\n",
      "Epoch: 970, Loss= 0.7085, Training Accuracy= 0.517\n",
      "Epoch: 980, Loss= 0.6965, Training Accuracy= 0.537\n",
      "Epoch: 990, Loss= 0.7131, Training Accuracy= 0.517\n",
      "Epoch: 1000, Loss= 0.7063, Training Accuracy= 0.511\n",
      "Epoch: 1010, Loss= 0.7048, Training Accuracy= 0.510\n",
      "Epoch: 1020, Loss= 0.7036, Training Accuracy= 0.513\n",
      "Epoch: 1030, Loss= 0.7026, Training Accuracy= 0.516\n",
      "Epoch: 1040, Loss= 0.7017, Training Accuracy= 0.516\n",
      "Epoch: 1050, Loss= 0.7010, Training Accuracy= 0.517\n",
      "Epoch: 1060, Loss= 0.6999, Training Accuracy= 0.517\n",
      "Epoch: 1070, Loss= 0.6992, Training Accuracy= 0.519\n",
      "Epoch: 1080, Loss= 0.6946, Training Accuracy= 0.528\n",
      "Epoch: 1090, Loss= 0.6563, Training Accuracy= 0.601\n",
      "Epoch: 1100, Loss= 0.1086, Training Accuracy= 0.950\n",
      "Epoch: 1110, Loss= 0.7582, Training Accuracy= 0.507\n",
      "Epoch: 1120, Loss= 0.7210, Training Accuracy= 0.511\n",
      "Epoch: 1130, Loss= 0.7167, Training Accuracy= 0.511\n",
      "Epoch: 1140, Loss= 0.7147, Training Accuracy= 0.512\n",
      "Epoch: 1150, Loss= 0.7138, Training Accuracy= 0.513\n",
      "Epoch: 1160, Loss= 0.7127, Training Accuracy= 0.514\n",
      "Epoch: 1170, Loss= 0.7116, Training Accuracy= 0.515\n",
      "Epoch: 1180, Loss= 0.7104, Training Accuracy= 0.516\n",
      "Epoch: 1190, Loss= 0.7092, Training Accuracy= 0.517\n",
      "Epoch: 1200, Loss= 0.7082, Training Accuracy= 0.517\n",
      "Epoch: 1210, Loss= 0.7059, Training Accuracy= 0.521\n",
      "Epoch: 1220, Loss= 0.7058, Training Accuracy= 0.517\n",
      "Epoch: 1230, Loss= 0.7048, Training Accuracy= 0.523\n",
      "Epoch: 1240, Loss= 0.7069, Training Accuracy= 0.521\n",
      "Epoch: 1250, Loss= 0.7072, Training Accuracy= 0.521\n",
      "Epoch: 1260, Loss= 0.7012, Training Accuracy= 0.526\n",
      "Epoch: 1270, Loss= 0.7091, Training Accuracy= 0.511\n",
      "Epoch: 1280, Loss= 0.7065, Training Accuracy= 0.510\n",
      "Epoch: 1290, Loss= 0.7055, Training Accuracy= 0.512\n",
      "Epoch: 1300, Loss= 0.7048, Training Accuracy= 0.513\n",
      "Epoch: 1310, Loss= 0.7034, Training Accuracy= 0.513\n",
      "Epoch: 1320, Loss= 0.7030, Training Accuracy= 0.513\n",
      "Epoch: 1330, Loss= 0.7022, Training Accuracy= 0.514\n",
      "Epoch: 1340, Loss= 0.6997, Training Accuracy= 0.517\n",
      "Epoch: 1350, Loss= 0.6995, Training Accuracy= 0.519\n",
      "Epoch: 1360, Loss= 0.6992, Training Accuracy= 0.521\n",
      "Epoch: 1370, Loss= 0.6998, Training Accuracy= 0.520\n",
      "Epoch: 1380, Loss= 0.6998, Training Accuracy= 0.518\n",
      "Epoch: 1390, Loss= 0.6989, Training Accuracy= 0.522\n",
      "Epoch: 1400, Loss= 0.6982, Training Accuracy= 0.521\n",
      "Epoch: 1410, Loss= 0.6973, Training Accuracy= 0.526\n",
      "Epoch: 1420, Loss= 0.6977, Training Accuracy= 0.522\n",
      "Epoch: 1430, Loss= 0.6965, Training Accuracy= 0.525\n",
      "Epoch: 1440, Loss= 0.7019, Training Accuracy= 0.521\n",
      "Epoch: 1450, Loss= 0.7007, Training Accuracy= 0.523\n",
      "Epoch: 1460, Loss= 0.6988, Training Accuracy= 0.524\n",
      "Epoch: 1470, Loss= 0.6960, Training Accuracy= 0.530\n",
      "Epoch: 1480, Loss= 0.7307, Training Accuracy= 0.512\n",
      "Epoch: 1490, Loss= 0.7290, Training Accuracy= 0.513\n",
      "Epoch: 1500, Loss= 0.7274, Training Accuracy= 0.513\n",
      "Epoch: 1510, Loss= 0.7260, Training Accuracy= 0.513\n",
      "Epoch: 1520, Loss= 0.7246, Training Accuracy= 0.513\n",
      "Epoch: 1530, Loss= 0.7231, Training Accuracy= 0.513\n",
      "Epoch: 1540, Loss= 0.7220, Training Accuracy= 0.513\n",
      "Epoch: 1550, Loss= 0.7210, Training Accuracy= 0.515\n",
      "Epoch: 1560, Loss= 0.7201, Training Accuracy= 0.515\n",
      "Epoch: 1570, Loss= 0.7191, Training Accuracy= 0.518\n",
      "Epoch: 1580, Loss= 0.7181, Training Accuracy= 0.519\n",
      "Epoch: 1590, Loss= 0.7172, Training Accuracy= 0.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss= 0.7156, Training Accuracy= 0.522\n",
      "Epoch: 1610, Loss= 0.7145, Training Accuracy= 0.523\n",
      "Epoch: 1620, Loss= 0.7136, Training Accuracy= 0.524\n",
      "Epoch: 1630, Loss= 0.7126, Training Accuracy= 0.524\n",
      "Epoch: 1640, Loss= 0.7119, Training Accuracy= 0.525\n",
      "Epoch: 1650, Loss= 0.7107, Training Accuracy= 0.526\n",
      "Epoch: 1660, Loss= 0.7105, Training Accuracy= 0.525\n",
      "Epoch: 1670, Loss= 0.7099, Training Accuracy= 0.526\n",
      "Epoch: 1680, Loss= 0.7099, Training Accuracy= 0.524\n",
      "Epoch: 1690, Loss= 0.7094, Training Accuracy= 0.527\n",
      "Epoch: 1700, Loss= 0.7075, Training Accuracy= 0.528\n",
      "Epoch: 1710, Loss= 0.7078, Training Accuracy= 0.529\n",
      "Epoch: 1720, Loss= 0.7065, Training Accuracy= 0.528\n",
      "Epoch: 1730, Loss= 0.7072, Training Accuracy= 0.531\n",
      "Epoch: 1740, Loss= 0.7059, Training Accuracy= 0.531\n",
      "Epoch: 1750, Loss= 0.7062, Training Accuracy= 0.532\n",
      "Epoch: 1760, Loss= 0.7044, Training Accuracy= 0.534\n",
      "Epoch: 1770, Loss= 0.7038, Training Accuracy= 0.530\n",
      "Epoch: 1780, Loss= 0.7030, Training Accuracy= 0.534\n",
      "Epoch: 1790, Loss= 0.7026, Training Accuracy= 0.536\n",
      "Epoch: 1800, Loss= 0.7019, Training Accuracy= 0.535\n",
      "Epoch: 1810, Loss= 0.7456, Training Accuracy= 0.510\n",
      "Epoch: 1820, Loss= 0.7239, Training Accuracy= 0.516\n",
      "Epoch: 1830, Loss= 0.7276, Training Accuracy= 0.515\n",
      "Epoch: 1840, Loss= 0.7241, Training Accuracy= 0.513\n",
      "Epoch: 1850, Loss= 0.7311, Training Accuracy= 0.516\n",
      "Epoch: 1860, Loss= 0.7132, Training Accuracy= 0.533\n",
      "Epoch: 1870, Loss= 0.6221, Training Accuracy= 0.630\n",
      "Epoch: 1880, Loss= 0.7530, Training Accuracy= 0.507\n",
      "Epoch: 1890, Loss= 0.7460, Training Accuracy= 0.512\n",
      "Epoch: 1900, Loss= 0.7427, Training Accuracy= 0.513\n",
      "Epoch: 1910, Loss= 0.7403, Training Accuracy= 0.512\n",
      "Epoch: 1920, Loss= 0.7385, Training Accuracy= 0.512\n",
      "Epoch: 1930, Loss= 0.7372, Training Accuracy= 0.513\n",
      "Epoch: 1940, Loss= 0.7361, Training Accuracy= 0.513\n",
      "Epoch: 1950, Loss= 0.7355, Training Accuracy= 0.512\n",
      "Epoch: 1960, Loss= 0.7351, Training Accuracy= 0.513\n",
      "Epoch: 1970, Loss= 0.7348, Training Accuracy= 0.514\n",
      "Epoch: 1980, Loss= 0.7347, Training Accuracy= 0.514\n",
      "Epoch: 1990, Loss= 0.7348, Training Accuracy= 0.512\n",
      "Epoch: 2000, Loss= 0.7348, Training Accuracy= 0.512\n",
      "Epoch: 2010, Loss= 0.7354, Training Accuracy= 0.511\n",
      "Epoch: 2020, Loss= 0.7359, Training Accuracy= 0.512\n",
      "Epoch: 2030, Loss= 0.7356, Training Accuracy= 0.510\n",
      "Epoch: 2040, Loss= 0.7355, Training Accuracy= 0.512\n",
      "Epoch: 2050, Loss= 0.7333, Training Accuracy= 0.518\n",
      "Epoch: 2060, Loss= 0.7346, Training Accuracy= 0.529\n",
      "Epoch: 2070, Loss= 0.6182, Training Accuracy= 0.613\n",
      "Epoch: 2080, Loss= 0.5100, Training Accuracy= 0.715\n",
      "Epoch: 2090, Loss= 0.3124, Training Accuracy= 0.831\n",
      "Epoch: 2100, Loss= 0.1881, Training Accuracy= 0.910\n",
      "Epoch: 2110, Loss= 0.1922, Training Accuracy= 0.905\n",
      "Epoch: 2120, Loss= 0.0632, Training Accuracy= 0.978\n",
      "Epoch: 2130, Loss= 0.0200, Training Accuracy= 0.995\n",
      "Epoch: 2140, Loss= 0.0131, Training Accuracy= 0.997\n",
      "Epoch: 2150, Loss= 0.0113, Training Accuracy= 0.998\n",
      "Epoch: 2160, Loss= 0.0096, Training Accuracy= 0.998\n",
      "Epoch: 2170, Loss= 0.0072, Training Accuracy= 0.998\n",
      "Epoch: 2180, Loss= 0.0055, Training Accuracy= 0.999\n",
      "Epoch: 2190, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2200, Loss= 0.0038, Training Accuracy= 1.000\n",
      "Epoch: 2210, Loss= 0.0036, Training Accuracy= 0.999\n",
      "Epoch: 2220, Loss= 0.0032, Training Accuracy= 0.999\n",
      "Epoch: 2230, Loss= 0.0029, Training Accuracy= 0.999\n",
      "Epoch: 2240, Loss= 0.0028, Training Accuracy= 0.999\n",
      "Epoch: 2250, Loss= 0.0026, Training Accuracy= 0.999\n",
      "Epoch: 2260, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 2280, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.9984\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.7449, Training Accuracy= 0.494\n",
      "Epoch: 10, Loss= 0.7119, Training Accuracy= 0.494\n",
      "Epoch: 20, Loss= 0.7060, Training Accuracy= 0.494\n",
      "Epoch: 30, Loss= 0.7035, Training Accuracy= 0.494\n",
      "Epoch: 40, Loss= 0.7020, Training Accuracy= 0.494\n",
      "Epoch: 50, Loss= 0.7011, Training Accuracy= 0.494\n",
      "Epoch: 60, Loss= 0.7004, Training Accuracy= 0.494\n",
      "Epoch: 70, Loss= 0.6999, Training Accuracy= 0.494\n",
      "Epoch: 80, Loss= 0.6995, Training Accuracy= 0.494\n",
      "Epoch: 90, Loss= 0.6992, Training Accuracy= 0.494\n",
      "Epoch: 100, Loss= 0.6990, Training Accuracy= 0.494\n",
      "Epoch: 110, Loss= 0.6988, Training Accuracy= 0.494\n",
      "Epoch: 120, Loss= 0.6987, Training Accuracy= 0.494\n",
      "Epoch: 130, Loss= 0.6985, Training Accuracy= 0.494\n",
      "Epoch: 140, Loss= 0.6984, Training Accuracy= 0.494\n",
      "Epoch: 150, Loss= 0.6983, Training Accuracy= 0.494\n",
      "Epoch: 160, Loss= 0.6982, Training Accuracy= 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170, Loss= 0.6982, Training Accuracy= 0.494\n",
      "Epoch: 180, Loss= 0.6981, Training Accuracy= 0.494\n",
      "Epoch: 190, Loss= 0.6981, Training Accuracy= 0.494\n",
      "Epoch: 200, Loss= 0.6980, Training Accuracy= 0.494\n",
      "Epoch: 210, Loss= 0.6980, Training Accuracy= 0.494\n",
      "Epoch: 220, Loss= 0.6979, Training Accuracy= 0.494\n",
      "Epoch: 230, Loss= 0.6979, Training Accuracy= 0.494\n",
      "Epoch: 240, Loss= 0.6979, Training Accuracy= 0.494\n",
      "Epoch: 250, Loss= 0.6979, Training Accuracy= 0.494\n",
      "Epoch: 260, Loss= 0.6978, Training Accuracy= 0.494\n",
      "Epoch: 270, Loss= 0.6978, Training Accuracy= 0.494\n",
      "Epoch: 280, Loss= 0.6978, Training Accuracy= 0.494\n",
      "Epoch: 290, Loss= 0.6978, Training Accuracy= 0.494\n",
      "Epoch: 300, Loss= 0.6978, Training Accuracy= 0.494\n",
      "Epoch: 310, Loss= 0.6978, Training Accuracy= 0.494\n",
      "Epoch: 320, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 330, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 340, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 350, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 360, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 370, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 380, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 390, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 400, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 410, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 420, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 430, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 440, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 450, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 460, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 470, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 480, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 490, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 500, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 510, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 520, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 530, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 540, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 550, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 560, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 570, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 580, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 590, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 600, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 610, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 620, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 630, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 640, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 650, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 660, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 670, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 680, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 690, Loss= 0.6975, Training Accuracy= 0.493\n",
      "Epoch: 700, Loss= 0.6974, Training Accuracy= 0.493\n",
      "Epoch: 710, Loss= 0.6974, Training Accuracy= 0.494\n",
      "Epoch: 720, Loss= 0.6974, Training Accuracy= 0.494\n",
      "Epoch: 730, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 740, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 750, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 760, Loss= 0.6977, Training Accuracy= 0.494\n",
      "Epoch: 770, Loss= 0.6979, Training Accuracy= 0.495\n",
      "Epoch: 780, Loss= 0.6980, Training Accuracy= 0.495\n",
      "Epoch: 790, Loss= 0.6982, Training Accuracy= 0.495\n",
      "Epoch: 800, Loss= 0.6984, Training Accuracy= 0.497\n",
      "Epoch: 810, Loss= 0.6986, Training Accuracy= 0.499\n",
      "Epoch: 820, Loss= 0.6988, Training Accuracy= 0.499\n",
      "Epoch: 830, Loss= 0.6993, Training Accuracy= 0.500\n",
      "Epoch: 840, Loss= 0.6997, Training Accuracy= 0.500\n",
      "Epoch: 850, Loss= 0.7003, Training Accuracy= 0.501\n",
      "Epoch: 860, Loss= 0.7008, Training Accuracy= 0.502\n",
      "Epoch: 870, Loss= 0.7008, Training Accuracy= 0.503\n",
      "Epoch: 880, Loss= 0.7009, Training Accuracy= 0.504\n",
      "Epoch: 890, Loss= 0.7008, Training Accuracy= 0.502\n",
      "Epoch: 900, Loss= 0.7041, Training Accuracy= 0.501\n",
      "Epoch: 910, Loss= 0.7017, Training Accuracy= 0.503\n",
      "Epoch: 920, Loss= 0.6997, Training Accuracy= 0.504\n",
      "Epoch: 930, Loss= 0.7016, Training Accuracy= 0.506\n",
      "Epoch: 940, Loss= 0.7012, Training Accuracy= 0.503\n",
      "Epoch: 950, Loss= 0.7004, Training Accuracy= 0.502\n",
      "Epoch: 960, Loss= 0.7013, Training Accuracy= 0.505\n",
      "Epoch: 970, Loss= 0.7012, Training Accuracy= 0.503\n",
      "Epoch: 980, Loss= 0.7019, Training Accuracy= 0.505\n",
      "Epoch: 990, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1000, Loss= 0.7023, Training Accuracy= 0.508\n",
      "Epoch: 1010, Loss= 0.6988, Training Accuracy= 0.511\n",
      "Epoch: 1020, Loss= 0.7024, Training Accuracy= 0.511\n",
      "Epoch: 1030, Loss= 0.7051, Training Accuracy= 0.517\n",
      "Epoch: 1040, Loss= 0.7003, Training Accuracy= 0.510\n",
      "Epoch: 1050, Loss= 0.7045, Training Accuracy= 0.515\n",
      "Epoch: 1060, Loss= 0.7032, Training Accuracy= 0.517\n",
      "Epoch: 1070, Loss= 0.7072, Training Accuracy= 0.521\n",
      "Epoch: 1080, Loss= 0.7088, Training Accuracy= 0.519\n",
      "Epoch: 1090, Loss= 0.7051, Training Accuracy= 0.526\n",
      "Epoch: 1100, Loss= 0.7042, Training Accuracy= 0.524\n",
      "Epoch: 1110, Loss= 0.7027, Training Accuracy= 0.516\n",
      "Epoch: 1120, Loss= 0.6993, Training Accuracy= 0.529\n",
      "Epoch: 1130, Loss= 0.7026, Training Accuracy= 0.525\n",
      "Epoch: 1140, Loss= 0.7006, Training Accuracy= 0.528\n",
      "Epoch: 1150, Loss= 0.7046, Training Accuracy= 0.527\n",
      "Epoch: 1160, Loss= 0.7005, Training Accuracy= 0.529\n",
      "Epoch: 1170, Loss= 0.7085, Training Accuracy= 0.522\n",
      "Epoch: 1180, Loss= 0.6983, Training Accuracy= 0.544\n",
      "Epoch: 1190, Loss= 0.6960, Training Accuracy= 0.541\n",
      "Epoch: 1200, Loss= 0.6801, Training Accuracy= 0.567\n",
      "Epoch: 1210, Loss= 0.6818, Training Accuracy= 0.562\n",
      "Epoch: 1220, Loss= 0.6942, Training Accuracy= 0.529\n",
      "Epoch: 1230, Loss= 0.7129, Training Accuracy= 0.527\n",
      "Epoch: 1240, Loss= 0.6770, Training Accuracy= 0.571\n",
      "Epoch: 1250, Loss= 0.6888, Training Accuracy= 0.557\n",
      "Epoch: 1260, Loss= 0.6960, Training Accuracy= 0.550\n",
      "Epoch: 1270, Loss= 0.7184, Training Accuracy= 0.503\n",
      "Epoch: 1280, Loss= 0.7007, Training Accuracy= 0.546\n",
      "Epoch: 1290, Loss= 0.6844, Training Accuracy= 0.563\n",
      "Epoch: 1300, Loss= 0.6727, Training Accuracy= 0.578\n",
      "Epoch: 1310, Loss= 0.6651, Training Accuracy= 0.591\n",
      "Epoch: 1320, Loss= 0.7192, Training Accuracy= 0.501\n",
      "Epoch: 1330, Loss= 0.7120, Training Accuracy= 0.502\n",
      "Epoch: 1340, Loss= 0.7125, Training Accuracy= 0.502\n",
      "Epoch: 1350, Loss= 0.7012, Training Accuracy= 0.509\n",
      "Epoch: 1360, Loss= 0.7121, Training Accuracy= 0.512\n",
      "Epoch: 1370, Loss= 0.7115, Training Accuracy= 0.513\n",
      "Epoch: 1380, Loss= 0.7236, Training Accuracy= 0.496\n",
      "Epoch: 1390, Loss= 0.7199, Training Accuracy= 0.503\n",
      "Epoch: 1400, Loss= 0.7173, Training Accuracy= 0.506\n",
      "Epoch: 1410, Loss= 0.7172, Training Accuracy= 0.500\n",
      "Epoch: 1420, Loss= 0.7157, Training Accuracy= 0.507\n",
      "Epoch: 1430, Loss= 0.7094, Training Accuracy= 0.520\n",
      "Epoch: 1440, Loss= 0.7094, Training Accuracy= 0.520\n",
      "Epoch: 1450, Loss= 0.7067, Training Accuracy= 0.523\n",
      "Epoch: 1460, Loss= 0.7125, Training Accuracy= 0.513\n",
      "Epoch: 1470, Loss= 0.7019, Training Accuracy= 0.521\n",
      "Epoch: 1480, Loss= 0.6894, Training Accuracy= 0.539\n",
      "Epoch: 1490, Loss= 0.6806, Training Accuracy= 0.543\n",
      "Epoch: 1500, Loss= 0.6753, Training Accuracy= 0.558\n",
      "Epoch: 1510, Loss= 0.6839, Training Accuracy= 0.554\n",
      "Epoch: 1520, Loss= 0.7579, Training Accuracy= 0.495\n",
      "Epoch: 1530, Loss= 0.7364, Training Accuracy= 0.498\n",
      "Epoch: 1540, Loss= 0.7376, Training Accuracy= 0.498\n",
      "Epoch: 1550, Loss= 0.7541, Training Accuracy= 0.496\n",
      "Epoch: 1560, Loss= 0.7341, Training Accuracy= 0.495\n",
      "Epoch: 1570, Loss= 0.7279, Training Accuracy= 0.498\n",
      "Epoch: 1580, Loss= 0.7222, Training Accuracy= 0.503\n",
      "Epoch: 1590, Loss= 0.7192, Training Accuracy= 0.500\n",
      "Epoch: 1600, Loss= 0.7049, Training Accuracy= 0.510\n",
      "Epoch: 1610, Loss= 0.7080, Training Accuracy= 0.515\n",
      "Epoch: 1620, Loss= 0.7042, Training Accuracy= 0.517\n",
      "Epoch: 1630, Loss= 0.7077, Training Accuracy= 0.518\n",
      "Epoch: 1640, Loss= 0.7283, Training Accuracy= 0.507\n",
      "Epoch: 1650, Loss= 0.7030, Training Accuracy= 0.522\n",
      "Epoch: 1660, Loss= 0.7066, Training Accuracy= 0.520\n",
      "Epoch: 1670, Loss= 0.6906, Training Accuracy= 0.535\n",
      "Epoch: 1680, Loss= 0.7042, Training Accuracy= 0.539\n",
      "Epoch: 1690, Loss= 0.7148, Training Accuracy= 0.525\n",
      "Epoch: 1700, Loss= 0.6875, Training Accuracy= 0.543\n",
      "Epoch: 1710, Loss= 0.6756, Training Accuracy= 0.560\n",
      "Epoch: 1720, Loss= 0.6862, Training Accuracy= 0.549\n",
      "Epoch: 1730, Loss= 0.6742, Training Accuracy= 0.563\n",
      "Epoch: 1740, Loss= 0.6659, Training Accuracy= 0.572\n",
      "Epoch: 1750, Loss= 0.6710, Training Accuracy= 0.567\n",
      "Epoch: 1760, Loss= 0.6783, Training Accuracy= 0.557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1770, Loss= 0.6891, Training Accuracy= 0.554\n",
      "Epoch: 1780, Loss= 0.6945, Training Accuracy= 0.556\n",
      "Epoch: 1790, Loss= 0.6734, Training Accuracy= 0.564\n",
      "Epoch: 1800, Loss= 0.6755, Training Accuracy= 0.566\n",
      "Epoch: 1810, Loss= 0.7148, Training Accuracy= 0.497\n",
      "Epoch: 1820, Loss= 0.7096, Training Accuracy= 0.499\n",
      "Epoch: 1830, Loss= 0.7118, Training Accuracy= 0.505\n",
      "Epoch: 1840, Loss= 0.6991, Training Accuracy= 0.513\n",
      "Epoch: 1850, Loss= 0.7065, Training Accuracy= 0.500\n",
      "Epoch: 1860, Loss= 0.7081, Training Accuracy= 0.504\n",
      "Epoch: 1870, Loss= 0.7049, Training Accuracy= 0.507\n",
      "Epoch: 1880, Loss= 0.6993, Training Accuracy= 0.514\n",
      "Epoch: 1890, Loss= 0.7047, Training Accuracy= 0.519\n",
      "Epoch: 1900, Loss= 0.6977, Training Accuracy= 0.525\n",
      "Epoch: 1910, Loss= 0.6947, Training Accuracy= 0.543\n",
      "Epoch: 1920, Loss= 0.6878, Training Accuracy= 0.537\n",
      "Epoch: 1930, Loss= 0.6887, Training Accuracy= 0.543\n",
      "Epoch: 1940, Loss= 0.7020, Training Accuracy= 0.530\n",
      "Epoch: 1950, Loss= 0.6986, Training Accuracy= 0.538\n",
      "Epoch: 1960, Loss= 0.6836, Training Accuracy= 0.556\n",
      "Epoch: 1970, Loss= 0.6825, Training Accuracy= 0.557\n",
      "Epoch: 1980, Loss= 0.6956, Training Accuracy= 0.530\n",
      "Epoch: 1990, Loss= 0.6882, Training Accuracy= 0.545\n",
      "Epoch: 2000, Loss= 0.6726, Training Accuracy= 0.578\n",
      "Epoch: 2010, Loss= 0.6829, Training Accuracy= 0.562\n",
      "Epoch: 2020, Loss= 0.6705, Training Accuracy= 0.576\n",
      "Epoch: 2030, Loss= 0.6840, Training Accuracy= 0.550\n",
      "Epoch: 2040, Loss= 0.6750, Training Accuracy= 0.572\n",
      "Epoch: 2050, Loss= 0.6672, Training Accuracy= 0.591\n",
      "Epoch: 2060, Loss= 0.6582, Training Accuracy= 0.602\n",
      "Epoch: 2070, Loss= 0.6730, Training Accuracy= 0.576\n",
      "Epoch: 2080, Loss= 0.6781, Training Accuracy= 0.567\n",
      "Epoch: 2090, Loss= 0.6604, Training Accuracy= 0.592\n",
      "Epoch: 2100, Loss= 0.6898, Training Accuracy= 0.539\n",
      "Epoch: 2110, Loss= 0.6663, Training Accuracy= 0.586\n",
      "Epoch: 2120, Loss= 0.6495, Training Accuracy= 0.606\n",
      "Epoch: 2130, Loss= 0.6728, Training Accuracy= 0.576\n",
      "Epoch: 2140, Loss= 0.6781, Training Accuracy= 0.564\n",
      "Epoch: 2150, Loss= 0.7304, Training Accuracy= 0.496\n",
      "Epoch: 2160, Loss= 0.7109, Training Accuracy= 0.507\n",
      "Epoch: 2170, Loss= 0.7078, Training Accuracy= 0.519\n",
      "Epoch: 2180, Loss= 0.6975, Training Accuracy= 0.525\n",
      "Epoch: 2190, Loss= 0.6917, Training Accuracy= 0.536\n",
      "Epoch: 2200, Loss= 0.7053, Training Accuracy= 0.520\n",
      "Epoch: 2210, Loss= 0.6884, Training Accuracy= 0.540\n",
      "Epoch: 2220, Loss= 0.6892, Training Accuracy= 0.547\n",
      "Epoch: 2230, Loss= 0.6882, Training Accuracy= 0.543\n",
      "Epoch: 2240, Loss= 0.6809, Training Accuracy= 0.564\n",
      "Epoch: 2250, Loss= 0.6706, Training Accuracy= 0.579\n",
      "Epoch: 2260, Loss= 0.6622, Training Accuracy= 0.591\n",
      "Epoch: 2270, Loss= 0.6614, Training Accuracy= 0.591\n",
      "Epoch: 2280, Loss= 0.6607, Training Accuracy= 0.593\n",
      "Epoch: 2290, Loss= 0.6508, Training Accuracy= 0.607\n",
      "Epoch: 2300, Loss= 0.6753, Training Accuracy= 0.584\n",
      "Epoch: 2310, Loss= 0.6498, Training Accuracy= 0.614\n",
      "Epoch: 2320, Loss= 0.6502, Training Accuracy= 0.611\n",
      "Epoch: 2330, Loss= 0.6543, Training Accuracy= 0.603\n",
      "Epoch: 2340, Loss= 0.6350, Training Accuracy= 0.628\n",
      "Epoch: 2350, Loss= 0.6349, Training Accuracy= 0.630\n",
      "Epoch: 2360, Loss= 0.6712, Training Accuracy= 0.587\n",
      "Epoch: 2370, Loss= 0.6554, Training Accuracy= 0.602\n",
      "Epoch: 2380, Loss= 0.6598, Training Accuracy= 0.602\n",
      "Epoch: 2390, Loss= 0.6387, Training Accuracy= 0.625\n",
      "Epoch: 2400, Loss= 0.6572, Training Accuracy= 0.608\n",
      "Epoch: 2410, Loss= 0.6415, Training Accuracy= 0.624\n",
      "Epoch: 2420, Loss= 0.6747, Training Accuracy= 0.583\n",
      "Epoch: 2430, Loss= 0.6365, Training Accuracy= 0.626\n",
      "Epoch: 2440, Loss= 0.6322, Training Accuracy= 0.634\n",
      "Epoch: 2450, Loss= 0.6639, Training Accuracy= 0.598\n",
      "Epoch: 2460, Loss= 0.6321, Training Accuracy= 0.636\n",
      "Epoch: 2470, Loss= 0.6368, Training Accuracy= 0.623\n",
      "Epoch: 2480, Loss= 0.6535, Training Accuracy= 0.611\n",
      "Epoch: 2490, Loss= 0.6388, Training Accuracy= 0.621\n",
      "Epoch: 2500, Loss= 0.6419, Training Accuracy= 0.623\n",
      "Epoch: 2510, Loss= 0.6273, Training Accuracy= 0.633\n",
      "Epoch: 2520, Loss= 0.6185, Training Accuracy= 0.651\n",
      "Epoch: 2530, Loss= 0.6317, Training Accuracy= 0.635\n",
      "Epoch: 2540, Loss= 0.6319, Training Accuracy= 0.636\n",
      "Epoch: 2550, Loss= 0.6312, Training Accuracy= 0.633\n",
      "Epoch: 2560, Loss= 0.6240, Training Accuracy= 0.642\n",
      "Epoch: 2570, Loss= 0.6261, Training Accuracy= 0.640\n",
      "Epoch: 2580, Loss= 0.6128, Training Accuracy= 0.660\n",
      "Epoch: 2590, Loss= 0.6393, Training Accuracy= 0.625\n",
      "Epoch: 2600, Loss= 0.6336, Training Accuracy= 0.639\n",
      "Epoch: 2610, Loss= 0.6209, Training Accuracy= 0.648\n",
      "Epoch: 2620, Loss= 0.6663, Training Accuracy= 0.589\n",
      "Epoch: 2630, Loss= 0.6259, Training Accuracy= 0.642\n",
      "Epoch: 2640, Loss= 0.6200, Training Accuracy= 0.649\n",
      "Epoch: 2650, Loss= 0.6123, Training Accuracy= 0.659\n",
      "Epoch: 2660, Loss= 0.6066, Training Accuracy= 0.660\n",
      "Epoch: 2670, Loss= 0.6153, Training Accuracy= 0.652\n",
      "Epoch: 2680, Loss= 0.6161, Training Accuracy= 0.650\n",
      "Epoch: 2690, Loss= 0.6140, Training Accuracy= 0.654\n",
      "Epoch: 2700, Loss= 0.6121, Training Accuracy= 0.654\n",
      "Epoch: 2710, Loss= 0.6384, Training Accuracy= 0.632\n",
      "Epoch: 2720, Loss= 0.6189, Training Accuracy= 0.653\n",
      "Epoch: 2730, Loss= 0.6202, Training Accuracy= 0.646\n",
      "Epoch: 2740, Loss= 0.6571, Training Accuracy= 0.615\n",
      "Epoch: 2750, Loss= 0.6404, Training Accuracy= 0.623\n",
      "Epoch: 2760, Loss= 0.6321, Training Accuracy= 0.641\n",
      "Epoch: 2770, Loss= 0.6100, Training Accuracy= 0.660\n",
      "Epoch: 2780, Loss= 0.6102, Training Accuracy= 0.660\n",
      "Epoch: 2790, Loss= 0.5952, Training Accuracy= 0.672\n",
      "Epoch: 2800, Loss= 0.6480, Training Accuracy= 0.616\n",
      "Epoch: 2810, Loss= 0.5927, Training Accuracy= 0.670\n",
      "Epoch: 2820, Loss= 0.6419, Training Accuracy= 0.629\n",
      "Epoch: 2830, Loss= 0.6050, Training Accuracy= 0.664\n",
      "Epoch: 2840, Loss= 0.6143, Training Accuracy= 0.655\n",
      "Epoch: 2850, Loss= 0.6236, Training Accuracy= 0.640\n",
      "Epoch: 2860, Loss= 0.6215, Training Accuracy= 0.652\n",
      "Epoch: 2870, Loss= 0.6158, Training Accuracy= 0.649\n",
      "Epoch: 2880, Loss= 0.5837, Training Accuracy= 0.684\n",
      "Epoch: 2890, Loss= 0.6556, Training Accuracy= 0.610\n",
      "Epoch: 2900, Loss= 0.5910, Training Accuracy= 0.673\n",
      "Epoch: 2910, Loss= 0.6024, Training Accuracy= 0.669\n",
      "Epoch: 2920, Loss= 0.6065, Training Accuracy= 0.668\n",
      "Epoch: 2930, Loss= 0.6054, Training Accuracy= 0.666\n",
      "Epoch: 2940, Loss= 0.6196, Training Accuracy= 0.647\n",
      "Epoch: 2950, Loss= 0.5911, Training Accuracy= 0.680\n",
      "Epoch: 2960, Loss= 0.6259, Training Accuracy= 0.643\n",
      "Epoch: 2970, Loss= 0.6125, Training Accuracy= 0.653\n",
      "Epoch: 2980, Loss= 0.5951, Training Accuracy= 0.675\n",
      "Epoch: 2990, Loss= 0.6509, Training Accuracy= 0.629\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4935\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.7409, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 0.7194, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.7135, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.7106, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.7088, Training Accuracy= 0.497\n",
      "Epoch: 50, Loss= 0.7076, Training Accuracy= 0.497\n",
      "Epoch: 60, Loss= 0.7067, Training Accuracy= 0.497\n",
      "Epoch: 70, Loss= 0.7060, Training Accuracy= 0.497\n",
      "Epoch: 80, Loss= 0.7054, Training Accuracy= 0.497\n",
      "Epoch: 90, Loss= 0.7050, Training Accuracy= 0.497\n",
      "Epoch: 100, Loss= 0.7046, Training Accuracy= 0.497\n",
      "Epoch: 110, Loss= 0.7043, Training Accuracy= 0.497\n",
      "Epoch: 120, Loss= 0.7040, Training Accuracy= 0.497\n",
      "Epoch: 130, Loss= 0.7038, Training Accuracy= 0.497\n",
      "Epoch: 140, Loss= 0.7036, Training Accuracy= 0.497\n",
      "Epoch: 150, Loss= 0.7034, Training Accuracy= 0.497\n",
      "Epoch: 160, Loss= 0.7033, Training Accuracy= 0.497\n",
      "Epoch: 170, Loss= 0.7031, Training Accuracy= 0.497\n",
      "Epoch: 180, Loss= 0.7030, Training Accuracy= 0.497\n",
      "Epoch: 190, Loss= 0.7029, Training Accuracy= 0.497\n",
      "Epoch: 200, Loss= 0.7028, Training Accuracy= 0.497\n",
      "Epoch: 210, Loss= 0.7027, Training Accuracy= 0.497\n",
      "Epoch: 220, Loss= 0.7026, Training Accuracy= 0.497\n",
      "Epoch: 230, Loss= 0.7026, Training Accuracy= 0.497\n",
      "Epoch: 240, Loss= 0.7025, Training Accuracy= 0.497\n",
      "Epoch: 250, Loss= 0.7024, Training Accuracy= 0.497\n",
      "Epoch: 260, Loss= 0.7024, Training Accuracy= 0.497\n",
      "Epoch: 270, Loss= 0.7023, Training Accuracy= 0.497\n",
      "Epoch: 280, Loss= 0.7022, Training Accuracy= 0.497\n",
      "Epoch: 290, Loss= 0.7022, Training Accuracy= 0.497\n",
      "Epoch: 300, Loss= 0.7021, Training Accuracy= 0.497\n",
      "Epoch: 310, Loss= 0.7021, Training Accuracy= 0.497\n",
      "Epoch: 320, Loss= 0.7021, Training Accuracy= 0.497\n",
      "Epoch: 330, Loss= 0.7020, Training Accuracy= 0.497\n",
      "Epoch: 340, Loss= 0.7020, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, Loss= 0.7019, Training Accuracy= 0.497\n",
      "Epoch: 360, Loss= 0.7019, Training Accuracy= 0.497\n",
      "Epoch: 370, Loss= 0.7019, Training Accuracy= 0.497\n",
      "Epoch: 380, Loss= 0.7018, Training Accuracy= 0.497\n",
      "Epoch: 390, Loss= 0.7018, Training Accuracy= 0.497\n",
      "Epoch: 400, Loss= 0.7018, Training Accuracy= 0.497\n",
      "Epoch: 410, Loss= 0.7017, Training Accuracy= 0.497\n",
      "Epoch: 420, Loss= 0.7017, Training Accuracy= 0.497\n",
      "Epoch: 430, Loss= 0.7017, Training Accuracy= 0.497\n",
      "Epoch: 440, Loss= 0.7016, Training Accuracy= 0.497\n",
      "Epoch: 450, Loss= 0.7016, Training Accuracy= 0.497\n",
      "Epoch: 460, Loss= 0.7016, Training Accuracy= 0.497\n",
      "Epoch: 470, Loss= 0.7016, Training Accuracy= 0.497\n",
      "Epoch: 480, Loss= 0.7015, Training Accuracy= 0.497\n",
      "Epoch: 490, Loss= 0.7015, Training Accuracy= 0.497\n",
      "Epoch: 500, Loss= 0.7015, Training Accuracy= 0.497\n",
      "Epoch: 510, Loss= 0.7015, Training Accuracy= 0.497\n",
      "Epoch: 520, Loss= 0.7015, Training Accuracy= 0.497\n",
      "Epoch: 530, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 540, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 550, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 560, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 570, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 580, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 590, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 600, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 610, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 620, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 630, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 640, Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 650, Loss= 0.7015, Training Accuracy= 0.497\n",
      "Epoch: 660, Loss= 0.7015, Training Accuracy= 0.497\n",
      "Epoch: 670, Loss= 0.7015, Training Accuracy= 0.497\n",
      "Epoch: 680, Loss= 0.7016, Training Accuracy= 0.497\n",
      "Epoch: 690, Loss= 0.7017, Training Accuracy= 0.497\n",
      "Epoch: 700, Loss= 0.7018, Training Accuracy= 0.497\n",
      "Epoch: 710, Loss= 0.7018, Training Accuracy= 0.497\n",
      "Epoch: 720, Loss= 0.7020, Training Accuracy= 0.497\n",
      "Epoch: 730, Loss= 0.7022, Training Accuracy= 0.497\n",
      "Epoch: 740, Loss= 0.7024, Training Accuracy= 0.497\n",
      "Epoch: 750, Loss= 0.7022, Training Accuracy= 0.497\n",
      "Epoch: 760, Loss= 0.7016, Training Accuracy= 0.498\n",
      "Epoch: 770, Loss= 0.7008, Training Accuracy= 0.501\n",
      "Epoch: 780, Loss= 0.7007, Training Accuracy= 0.500\n",
      "Epoch: 790, Loss= 0.7022, Training Accuracy= 0.502\n",
      "Epoch: 800, Loss= 0.7015, Training Accuracy= 0.505\n",
      "Epoch: 810, Loss= 0.7012, Training Accuracy= 0.505\n",
      "Epoch: 820, Loss= 0.6999, Training Accuracy= 0.508\n",
      "Epoch: 830, Loss= 0.6986, Training Accuracy= 0.511\n",
      "Epoch: 840, Loss= 0.6979, Training Accuracy= 0.513\n",
      "Epoch: 850, Loss= 0.6989, Training Accuracy= 0.504\n",
      "Epoch: 860, Loss= 0.6965, Training Accuracy= 0.517\n",
      "Epoch: 870, Loss= 0.7012, Training Accuracy= 0.503\n",
      "Epoch: 880, Loss= 0.6980, Training Accuracy= 0.509\n",
      "Epoch: 890, Loss= 0.7039, Training Accuracy= 0.505\n",
      "Epoch: 900, Loss= 0.6971, Training Accuracy= 0.507\n",
      "Epoch: 910, Loss= 0.7050, Training Accuracy= 0.512\n",
      "Epoch: 920, Loss= 0.7190, Training Accuracy= 0.507\n",
      "Epoch: 930, Loss= 0.7198, Training Accuracy= 0.510\n",
      "Epoch: 940, Loss= 0.7246, Training Accuracy= 0.509\n",
      "Epoch: 950, Loss= 0.7453, Training Accuracy= 0.491\n",
      "Epoch: 960, Loss= 0.7150, Training Accuracy= 0.498\n",
      "Epoch: 970, Loss= 0.7123, Training Accuracy= 0.498\n",
      "Epoch: 980, Loss= 0.7107, Training Accuracy= 0.499\n",
      "Epoch: 990, Loss= 0.7096, Training Accuracy= 0.499\n",
      "Epoch: 1000, Loss= 0.7087, Training Accuracy= 0.500\n",
      "Epoch: 1010, Loss= 0.7075, Training Accuracy= 0.501\n",
      "Epoch: 1020, Loss= 0.7057, Training Accuracy= 0.505\n",
      "Epoch: 1030, Loss= 0.7129, Training Accuracy= 0.502\n",
      "Epoch: 1040, Loss= 0.7130, Training Accuracy= 0.496\n",
      "Epoch: 1050, Loss= 0.7105, Training Accuracy= 0.497\n",
      "Epoch: 1060, Loss= 0.7091, Training Accuracy= 0.497\n",
      "Epoch: 1070, Loss= 0.7081, Training Accuracy= 0.497\n",
      "Epoch: 1080, Loss= 0.7073, Training Accuracy= 0.497\n",
      "Epoch: 1090, Loss= 0.7065, Training Accuracy= 0.497\n",
      "Epoch: 1100, Loss= 0.7060, Training Accuracy= 0.497\n",
      "Epoch: 1110, Loss= 0.7056, Training Accuracy= 0.497\n",
      "Epoch: 1120, Loss= 0.7050, Training Accuracy= 0.497\n",
      "Epoch: 1130, Loss= 0.7045, Training Accuracy= 0.497\n",
      "Epoch: 1140, Loss= 0.7042, Training Accuracy= 0.497\n",
      "Epoch: 1150, Loss= 0.7038, Training Accuracy= 0.499\n",
      "Epoch: 1160, Loss= 0.7033, Training Accuracy= 0.500\n",
      "Epoch: 1170, Loss= 0.6968, Training Accuracy= 0.508\n",
      "Epoch: 1180, Loss= 0.7065, Training Accuracy= 0.498\n",
      "Epoch: 1190, Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1200, Loss= 0.7072, Training Accuracy= 0.497\n",
      "Epoch: 1210, Loss= 0.7059, Training Accuracy= 0.497\n",
      "Epoch: 1220, Loss= 0.7053, Training Accuracy= 0.497\n",
      "Epoch: 1230, Loss= 0.7050, Training Accuracy= 0.497\n",
      "Epoch: 1240, Loss= 0.7047, Training Accuracy= 0.497\n",
      "Epoch: 1250, Loss= 0.7045, Training Accuracy= 0.497\n",
      "Epoch: 1260, Loss= 0.7044, Training Accuracy= 0.497\n",
      "Epoch: 1270, Loss= 0.7043, Training Accuracy= 0.497\n",
      "Epoch: 1280, Loss= 0.7041, Training Accuracy= 0.497\n",
      "Epoch: 1290, Loss= 0.7040, Training Accuracy= 0.497\n",
      "Epoch: 1300, Loss= 0.7044, Training Accuracy= 0.496\n",
      "Epoch: 1310, Loss= 0.7042, Training Accuracy= 0.497\n",
      "Epoch: 1320, Loss= 0.7041, Training Accuracy= 0.496\n",
      "Epoch: 1330, Loss= 0.7039, Training Accuracy= 0.497\n",
      "Epoch: 1340, Loss= 0.7038, Training Accuracy= 0.497\n",
      "Epoch: 1350, Loss= 0.7037, Training Accuracy= 0.496\n",
      "Epoch: 1360, Loss= 0.7035, Training Accuracy= 0.497\n",
      "Epoch: 1370, Loss= 0.7033, Training Accuracy= 0.498\n",
      "Epoch: 1380, Loss= 0.7027, Training Accuracy= 0.498\n",
      "Epoch: 1390, Loss= 0.7025, Training Accuracy= 0.498\n",
      "Epoch: 1400, Loss= 0.7023, Training Accuracy= 0.499\n",
      "Epoch: 1410, Loss= 0.7021, Training Accuracy= 0.499\n",
      "Epoch: 1420, Loss= 0.7019, Training Accuracy= 0.500\n",
      "Epoch: 1430, Loss= 0.7031, Training Accuracy= 0.500\n",
      "Epoch: 1440, Loss= 0.7009, Training Accuracy= 0.501\n",
      "Epoch: 1450, Loss= 0.7007, Training Accuracy= 0.502\n",
      "Epoch: 1460, Loss= 0.7002, Training Accuracy= 0.502\n",
      "Epoch: 1470, Loss= 0.6996, Training Accuracy= 0.503\n",
      "Epoch: 1480, Loss= 0.6991, Training Accuracy= 0.505\n",
      "Epoch: 1490, Loss= 0.7004, Training Accuracy= 0.505\n",
      "Epoch: 1500, Loss= 0.7047, Training Accuracy= 0.505\n",
      "Epoch: 1510, Loss= 0.6967, Training Accuracy= 0.512\n",
      "Epoch: 1520, Loss= 0.6955, Training Accuracy= 0.516\n",
      "Epoch: 1530, Loss= 0.6936, Training Accuracy= 0.516\n",
      "Epoch: 1540, Loss= 0.7017, Training Accuracy= 0.502\n",
      "Epoch: 1550, Loss= 0.7051, Training Accuracy= 0.499\n",
      "Epoch: 1560, Loss= 0.7029, Training Accuracy= 0.500\n",
      "Epoch: 1570, Loss= 0.7014, Training Accuracy= 0.504\n",
      "Epoch: 1580, Loss= 0.7008, Training Accuracy= 0.506\n",
      "Epoch: 1590, Loss= 0.6989, Training Accuracy= 0.510\n",
      "Epoch: 1600, Loss= 0.6980, Training Accuracy= 0.512\n",
      "Epoch: 1610, Loss= 0.6978, Training Accuracy= 0.512\n",
      "Epoch: 1620, Loss= 0.6971, Training Accuracy= 0.516\n",
      "Epoch: 1630, Loss= 0.6950, Training Accuracy= 0.520\n",
      "Epoch: 1640, Loss= 0.6953, Training Accuracy= 0.516\n",
      "Epoch: 1650, Loss= 0.6892, Training Accuracy= 0.532\n",
      "Epoch: 1660, Loss= 0.6929, Training Accuracy= 0.528\n",
      "Epoch: 1670, Loss= 0.6858, Training Accuracy= 0.539\n",
      "Epoch: 1680, Loss= 0.6855, Training Accuracy= 0.542\n",
      "Epoch: 1690, Loss= 0.6879, Training Accuracy= 0.537\n",
      "Epoch: 1700, Loss= 0.7083, Training Accuracy= 0.500\n",
      "Epoch: 1710, Loss= 0.6995, Training Accuracy= 0.511\n",
      "Epoch: 1720, Loss= 0.7008, Training Accuracy= 0.516\n",
      "Epoch: 1730, Loss= 0.7060, Training Accuracy= 0.510\n",
      "Epoch: 1740, Loss= 0.6963, Training Accuracy= 0.516\n",
      "Epoch: 1750, Loss= 0.6962, Training Accuracy= 0.521\n",
      "Epoch: 1760, Loss= 0.6978, Training Accuracy= 0.521\n",
      "Epoch: 1770, Loss= 0.6952, Training Accuracy= 0.525\n",
      "Epoch: 1780, Loss= 0.6923, Training Accuracy= 0.535\n",
      "Epoch: 1790, Loss= 0.6877, Training Accuracy= 0.540\n",
      "Epoch: 1800, Loss= 0.6870, Training Accuracy= 0.545\n",
      "Epoch: 1810, Loss= 0.6796, Training Accuracy= 0.564\n",
      "Epoch: 1820, Loss= 0.6807, Training Accuracy= 0.561\n",
      "Epoch: 1830, Loss= 0.7160, Training Accuracy= 0.497\n",
      "Epoch: 1840, Loss= 0.7093, Training Accuracy= 0.505\n",
      "Epoch: 1850, Loss= 0.7046, Training Accuracy= 0.521\n",
      "Epoch: 1860, Loss= 0.7050, Training Accuracy= 0.522\n",
      "Epoch: 1870, Loss= 0.7005, Training Accuracy= 0.524\n",
      "Epoch: 1880, Loss= 0.6977, Training Accuracy= 0.528\n",
      "Epoch: 1890, Loss= 0.6948, Training Accuracy= 0.537\n",
      "Epoch: 1900, Loss= 0.7021, Training Accuracy= 0.523\n",
      "Epoch: 1910, Loss= 0.6954, Training Accuracy= 0.541\n",
      "Epoch: 1920, Loss= 0.6923, Training Accuracy= 0.541\n",
      "Epoch: 1930, Loss= 0.6872, Training Accuracy= 0.553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1940, Loss= 0.6862, Training Accuracy= 0.559\n",
      "Epoch: 1950, Loss= 0.6772, Training Accuracy= 0.567\n",
      "Epoch: 1960, Loss= 0.6922, Training Accuracy= 0.551\n",
      "Epoch: 1970, Loss= 0.6969, Training Accuracy= 0.547\n",
      "Epoch: 1980, Loss= 0.6764, Training Accuracy= 0.570\n",
      "Epoch: 1990, Loss= 0.6696, Training Accuracy= 0.580\n",
      "Epoch: 2000, Loss= 0.6690, Training Accuracy= 0.585\n",
      "Epoch: 2010, Loss= 0.6669, Training Accuracy= 0.585\n",
      "Epoch: 2020, Loss= 0.6679, Training Accuracy= 0.588\n",
      "Epoch: 2030, Loss= 0.6701, Training Accuracy= 0.582\n",
      "Epoch: 2040, Loss= 0.6646, Training Accuracy= 0.591\n",
      "Epoch: 2050, Loss= 0.6830, Training Accuracy= 0.570\n",
      "Epoch: 2060, Loss= 0.6815, Training Accuracy= 0.565\n",
      "Epoch: 2070, Loss= 0.6648, Training Accuracy= 0.590\n",
      "Epoch: 2080, Loss= 0.6614, Training Accuracy= 0.593\n",
      "Epoch: 2090, Loss= 0.6915, Training Accuracy= 0.552\n",
      "Epoch: 2100, Loss= 0.6623, Training Accuracy= 0.598\n",
      "Epoch: 2110, Loss= 0.6754, Training Accuracy= 0.575\n",
      "Epoch: 2120, Loss= 0.6609, Training Accuracy= 0.594\n",
      "Epoch: 2130, Loss= 0.6599, Training Accuracy= 0.594\n",
      "Epoch: 2140, Loss= 0.6591, Training Accuracy= 0.600\n",
      "Epoch: 2150, Loss= 0.6720, Training Accuracy= 0.576\n",
      "Epoch: 2160, Loss= 0.6623, Training Accuracy= 0.594\n",
      "Epoch: 2170, Loss= 0.6896, Training Accuracy= 0.562\n",
      "Epoch: 2180, Loss= 0.6789, Training Accuracy= 0.584\n",
      "Epoch: 2190, Loss= 0.6601, Training Accuracy= 0.602\n",
      "Epoch: 2200, Loss= 0.6426, Training Accuracy= 0.620\n",
      "Epoch: 2210, Loss= 0.6676, Training Accuracy= 0.595\n",
      "Epoch: 2220, Loss= 0.6867, Training Accuracy= 0.578\n",
      "Epoch: 2230, Loss= 0.6508, Training Accuracy= 0.609\n",
      "Epoch: 2240, Loss= 0.6361, Training Accuracy= 0.626\n",
      "Epoch: 2250, Loss= 0.6513, Training Accuracy= 0.618\n",
      "Epoch: 2260, Loss= 0.6585, Training Accuracy= 0.600\n",
      "Epoch: 2270, Loss= 0.6444, Training Accuracy= 0.618\n",
      "Epoch: 2280, Loss= 0.6336, Training Accuracy= 0.632\n",
      "Epoch: 2290, Loss= 0.6798, Training Accuracy= 0.586\n",
      "Epoch: 2300, Loss= 0.6540, Training Accuracy= 0.606\n",
      "Epoch: 2310, Loss= 0.6286, Training Accuracy= 0.633\n",
      "Epoch: 2320, Loss= 0.6360, Training Accuracy= 0.631\n",
      "Epoch: 2330, Loss= 0.6300, Training Accuracy= 0.630\n",
      "Epoch: 2340, Loss= 0.7400, Training Accuracy= 0.510\n",
      "Epoch: 2350, Loss= 0.6960, Training Accuracy= 0.605\n",
      "Epoch: 2360, Loss= 0.5295, Training Accuracy= 0.689\n",
      "Epoch: 2370, Loss= 0.3973, Training Accuracy= 0.824\n",
      "Epoch: 2380, Loss= 0.4417, Training Accuracy= 0.849\n",
      "Epoch: 2390, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.6939, Training Accuracy= 0.503\n",
      "Epoch: 10, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 20, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 30, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 40, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 50, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 60, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 80, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 90, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 100, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 110, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 120, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 130, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 150, Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 160, Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 170, Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 180, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 190, Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 200, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 210, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 220, Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 230, Loss= 0.6924, Training Accuracy= 0.520\n",
      "Epoch: 240, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 250, Loss= 0.6923, Training Accuracy= 0.516\n",
      "Epoch: 260, Loss= 0.6923, Training Accuracy= 0.516\n",
      "Epoch: 270, Loss= 0.6922, Training Accuracy= 0.516\n",
      "Epoch: 280, Loss= 0.6921, Training Accuracy= 0.516\n",
      "Epoch: 290, Loss= 0.6921, Training Accuracy= 0.516\n",
      "Epoch: 300, Loss= 0.6920, Training Accuracy= 0.521\n",
      "Epoch: 310, Loss= 0.6918, Training Accuracy= 0.521\n",
      "Epoch: 320, Loss= 0.6917, Training Accuracy= 0.519\n",
      "Epoch: 330, Loss= 0.6916, Training Accuracy= 0.521\n",
      "Epoch: 340, Loss= 0.6914, Training Accuracy= 0.520\n",
      "Epoch: 350, Loss= 0.6912, Training Accuracy= 0.520\n",
      "Epoch: 360, Loss= 0.6911, Training Accuracy= 0.519\n",
      "Epoch: 370, Loss= 0.6911, Training Accuracy= 0.519\n",
      "Epoch: 380, Loss= 0.6910, Training Accuracy= 0.515\n",
      "Epoch: 390, Loss= 0.6914, Training Accuracy= 0.515\n",
      "Epoch: 400, Loss= 0.6919, Training Accuracy= 0.517\n",
      "Epoch: 410, Loss= 0.6910, Training Accuracy= 0.518\n",
      "Epoch: 420, Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 430, Loss= 0.6920, Training Accuracy= 0.520\n",
      "Epoch: 440, Loss= 0.6912, Training Accuracy= 0.520\n",
      "Epoch: 450, Loss= 0.6911, Training Accuracy= 0.524\n",
      "Epoch: 460, Loss= 0.6916, Training Accuracy= 0.523\n",
      "Epoch: 470, Loss= 0.6903, Training Accuracy= 0.528\n",
      "Epoch: 480, Loss= 0.6918, Training Accuracy= 0.518\n",
      "Epoch: 490, Loss= 0.6926, Training Accuracy= 0.520\n",
      "Epoch: 500, Loss= 0.6967, Training Accuracy= 0.516\n",
      "Epoch: 510, Loss= 0.7018, Training Accuracy= 0.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 520, Loss= 0.6965, Training Accuracy= 0.520\n",
      "Epoch: 530, Loss= 0.6956, Training Accuracy= 0.522\n",
      "Epoch: 540, Loss= 0.6899, Training Accuracy= 0.537\n",
      "Epoch: 550, Loss= 0.6965, Training Accuracy= 0.531\n",
      "Epoch: 560, Loss= 0.6950, Training Accuracy= 0.526\n",
      "Epoch: 570, Loss= 0.6993, Training Accuracy= 0.534\n",
      "Epoch: 580, Loss= 0.6968, Training Accuracy= 0.539\n",
      "Epoch: 590, Loss= 0.7043, Training Accuracy= 0.527\n",
      "Epoch: 600, Loss= 0.6794, Training Accuracy= 0.562\n",
      "Epoch: 610, Loss= 0.6862, Training Accuracy= 0.558\n",
      "Epoch: 620, Loss= 0.6828, Training Accuracy= 0.559\n",
      "Epoch: 630, Loss= 0.6787, Training Accuracy= 0.570\n",
      "Epoch: 640, Loss= 0.6799, Training Accuracy= 0.565\n",
      "Epoch: 650, Loss= 0.6876, Training Accuracy= 0.555\n",
      "Epoch: 660, Loss= 0.6938, Training Accuracy= 0.547\n",
      "Epoch: 670, Loss= 0.7036, Training Accuracy= 0.551\n",
      "Epoch: 680, Loss= 0.6910, Training Accuracy= 0.557\n",
      "Epoch: 690, Loss= 0.6605, Training Accuracy= 0.600\n",
      "Epoch: 700, Loss= 0.6723, Training Accuracy= 0.575\n",
      "Epoch: 710, Loss= 0.7090, Training Accuracy= 0.502\n",
      "Epoch: 720, Loss= 0.6966, Training Accuracy= 0.503\n",
      "Epoch: 730, Loss= 0.6947, Training Accuracy= 0.505\n",
      "Epoch: 740, Loss= 0.6940, Training Accuracy= 0.506\n",
      "Epoch: 750, Loss= 0.6937, Training Accuracy= 0.506\n",
      "Epoch: 760, Loss= 0.6935, Training Accuracy= 0.509\n",
      "Epoch: 770, Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 780, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 790, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 800, Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 810, Loss= 0.6927, Training Accuracy= 0.514\n",
      "Epoch: 820, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 830, Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 840, Loss= 0.6922, Training Accuracy= 0.519\n",
      "Epoch: 850, Loss= 0.6918, Training Accuracy= 0.521\n",
      "Epoch: 860, Loss= 0.6914, Training Accuracy= 0.525\n",
      "Epoch: 870, Loss= 0.6910, Training Accuracy= 0.528\n",
      "Epoch: 880, Loss= 0.6905, Training Accuracy= 0.535\n",
      "Epoch: 890, Loss= 0.6890, Training Accuracy= 0.537\n",
      "Epoch: 900, Loss= 0.6883, Training Accuracy= 0.544\n",
      "Epoch: 910, Loss= 0.6867, Training Accuracy= 0.547\n",
      "Epoch: 920, Loss= 0.6856, Training Accuracy= 0.549\n",
      "Epoch: 930, Loss= 0.6855, Training Accuracy= 0.547\n",
      "Epoch: 940, Loss= 0.6835, Training Accuracy= 0.556\n",
      "Epoch: 950, Loss= 0.6884, Training Accuracy= 0.548\n",
      "Epoch: 960, Loss= 0.6885, Training Accuracy= 0.556\n",
      "Epoch: 970, Loss= 0.6885, Training Accuracy= 0.563\n",
      "Epoch: 980, Loss= 0.6839, Training Accuracy= 0.559\n",
      "Epoch: 990, Loss= 0.6758, Training Accuracy= 0.582\n",
      "Epoch: 1000, Loss= 0.6835, Training Accuracy= 0.568\n",
      "Epoch: 1010, Loss= 0.6750, Training Accuracy= 0.577\n",
      "Epoch: 1020, Loss= 0.6716, Training Accuracy= 0.584\n",
      "Epoch: 1030, Loss= 0.6708, Training Accuracy= 0.588\n",
      "Epoch: 1040, Loss= 0.6742, Training Accuracy= 0.586\n",
      "Epoch: 1050, Loss= 0.6698, Training Accuracy= 0.587\n",
      "Epoch: 1060, Loss= 0.6642, Training Accuracy= 0.594\n",
      "Epoch: 1070, Loss= 0.6741, Training Accuracy= 0.581\n",
      "Epoch: 1080, Loss= 0.6834, Training Accuracy= 0.570\n",
      "Epoch: 1090, Loss= 0.6612, Training Accuracy= 0.606\n",
      "Epoch: 1100, Loss= 0.6543, Training Accuracy= 0.608\n",
      "Epoch: 1110, Loss= 0.7088, Training Accuracy= 0.551\n",
      "Epoch: 1120, Loss= 0.6615, Training Accuracy= 0.607\n",
      "Epoch: 1130, Loss= 0.6641, Training Accuracy= 0.599\n",
      "Epoch: 1140, Loss= 0.7294, Training Accuracy= 0.532\n",
      "Epoch: 1150, Loss= 0.6638, Training Accuracy= 0.597\n",
      "Epoch: 1160, Loss= 0.6352, Training Accuracy= 0.630\n",
      "Epoch: 1170, Loss= 0.6632, Training Accuracy= 0.598\n",
      "Epoch: 1180, Loss= 0.7181, Training Accuracy= 0.545\n",
      "Epoch: 1190, Loss= 0.6308, Training Accuracy= 0.642\n",
      "Epoch: 1200, Loss= 0.6292, Training Accuracy= 0.641\n",
      "Epoch: 1210, Loss= 0.6250, Training Accuracy= 0.641\n",
      "Epoch: 1220, Loss= 0.6310, Training Accuracy= 0.635\n",
      "Epoch: 1230, Loss= 0.6271, Training Accuracy= 0.642\n",
      "Epoch: 1240, Loss= 0.6431, Training Accuracy= 0.621\n",
      "Epoch: 1250, Loss= 0.6252, Training Accuracy= 0.644\n",
      "Epoch: 1260, Loss= 0.6229, Training Accuracy= 0.643\n",
      "Epoch: 1270, Loss= 0.6259, Training Accuracy= 0.646\n",
      "Epoch: 1280, Loss= 0.6165, Training Accuracy= 0.652\n",
      "Epoch: 1290, Loss= 0.8078, Training Accuracy= 0.508\n",
      "Epoch: 1300, Loss= 0.6869, Training Accuracy= 0.549\n",
      "Epoch: 1310, Loss= 0.6791, Training Accuracy= 0.567\n",
      "Epoch: 1320, Loss= 0.6713, Training Accuracy= 0.581\n",
      "Epoch: 1330, Loss= 0.6682, Training Accuracy= 0.584\n",
      "Epoch: 1340, Loss= 0.6638, Training Accuracy= 0.592\n",
      "Epoch: 1350, Loss= 0.6491, Training Accuracy= 0.610\n",
      "Epoch: 1360, Loss= 0.6648, Training Accuracy= 0.593\n",
      "Epoch: 1370, Loss= 0.6844, Training Accuracy= 0.552\n",
      "Epoch: 1380, Loss= 0.6672, Training Accuracy= 0.586\n",
      "Epoch: 1390, Loss= 0.6499, Training Accuracy= 0.607\n",
      "Epoch: 1400, Loss= 0.6452, Training Accuracy= 0.615\n",
      "Epoch: 1410, Loss= 0.6431, Training Accuracy= 0.619\n",
      "Epoch: 1420, Loss= 0.6468, Training Accuracy= 0.609\n",
      "Epoch: 1430, Loss= 0.7165, Training Accuracy= 0.511\n",
      "Epoch: 1440, Loss= 0.6917, Training Accuracy= 0.526\n",
      "Epoch: 1450, Loss= 0.6879, Training Accuracy= 0.538\n",
      "Epoch: 1460, Loss= 0.6875, Training Accuracy= 0.545\n",
      "Epoch: 1470, Loss= 0.6829, Training Accuracy= 0.554\n",
      "Epoch: 1480, Loss= 0.6798, Training Accuracy= 0.556\n",
      "Epoch: 1490, Loss= 0.6720, Training Accuracy= 0.572\n",
      "Epoch: 1500, Loss= 0.6790, Training Accuracy= 0.559\n",
      "Epoch: 1510, Loss= 0.6699, Training Accuracy= 0.576\n",
      "Epoch: 1520, Loss= 0.6607, Training Accuracy= 0.590\n",
      "Epoch: 1530, Loss= 0.6546, Training Accuracy= 0.599\n",
      "Epoch: 1540, Loss= 0.6506, Training Accuracy= 0.599\n",
      "Epoch: 1550, Loss= 0.6499, Training Accuracy= 0.600\n",
      "Epoch: 1560, Loss= 0.6922, Training Accuracy= 0.553\n",
      "Epoch: 1570, Loss= 0.6512, Training Accuracy= 0.604\n",
      "Epoch: 1580, Loss= 0.6471, Training Accuracy= 0.610\n",
      "Epoch: 1590, Loss= 0.6442, Training Accuracy= 0.611\n",
      "Epoch: 1600, Loss= 0.6322, Training Accuracy= 0.625\n",
      "Epoch: 1610, Loss= 0.6949, Training Accuracy= 0.518\n",
      "Epoch: 1620, Loss= 0.6950, Training Accuracy= 0.514\n",
      "Epoch: 1630, Loss= 0.6932, Training Accuracy= 0.519\n",
      "Epoch: 1640, Loss= 0.6917, Training Accuracy= 0.523\n",
      "Epoch: 1650, Loss= 0.7192, Training Accuracy= 0.501\n",
      "Epoch: 1660, Loss= 0.6954, Training Accuracy= 0.516\n",
      "Epoch: 1670, Loss= 0.6939, Training Accuracy= 0.521\n",
      "Epoch: 1680, Loss= 0.6926, Training Accuracy= 0.525\n",
      "Epoch: 1690, Loss= 0.6891, Training Accuracy= 0.528\n",
      "Epoch: 1700, Loss= 0.6919, Training Accuracy= 0.531\n",
      "Epoch: 1710, Loss= 0.6904, Training Accuracy= 0.533\n",
      "Epoch: 1720, Loss= 0.6877, Training Accuracy= 0.537\n",
      "Epoch: 1730, Loss= 0.6891, Training Accuracy= 0.539\n",
      "Epoch: 1740, Loss= 0.7066, Training Accuracy= 0.509\n",
      "Epoch: 1750, Loss= 0.6956, Training Accuracy= 0.513\n",
      "Epoch: 1760, Loss= 0.6951, Training Accuracy= 0.514\n",
      "Epoch: 1770, Loss= 0.6945, Training Accuracy= 0.520\n",
      "Epoch: 1780, Loss= 0.6940, Training Accuracy= 0.520\n",
      "Epoch: 1790, Loss= 0.7021, Training Accuracy= 0.502\n",
      "Epoch: 1800, Loss= 0.6960, Training Accuracy= 0.509\n",
      "Epoch: 1810, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 1820, Loss= 0.6947, Training Accuracy= 0.516\n",
      "Epoch: 1830, Loss= 0.6940, Training Accuracy= 0.521\n",
      "Epoch: 1840, Loss= 0.6932, Training Accuracy= 0.522\n",
      "Epoch: 1850, Loss= 0.6968, Training Accuracy= 0.517\n",
      "Epoch: 1860, Loss= 0.6963, Training Accuracy= 0.516\n",
      "Epoch: 1870, Loss= 0.6939, Training Accuracy= 0.526\n",
      "Epoch: 1880, Loss= 0.6922, Training Accuracy= 0.531\n",
      "Epoch: 1890, Loss= 0.6899, Training Accuracy= 0.537\n",
      "Epoch: 1900, Loss= 0.6893, Training Accuracy= 0.538\n",
      "Epoch: 1910, Loss= 0.6902, Training Accuracy= 0.537\n",
      "Epoch: 1920, Loss= 0.6900, Training Accuracy= 0.540\n",
      "Epoch: 1930, Loss= 0.6861, Training Accuracy= 0.546\n",
      "Epoch: 1940, Loss= 0.6835, Training Accuracy= 0.550\n",
      "Epoch: 1950, Loss= 0.6906, Training Accuracy= 0.536\n",
      "Epoch: 1960, Loss= 0.6812, Training Accuracy= 0.554\n",
      "Epoch: 1970, Loss= 0.6804, Training Accuracy= 0.554\n",
      "Epoch: 1980, Loss= 0.6814, Training Accuracy= 0.553\n",
      "Epoch: 1990, Loss= 0.6813, Training Accuracy= 0.560\n",
      "Epoch: 2000, Loss= 0.6862, Training Accuracy= 0.548\n",
      "Epoch: 2010, Loss= 0.6856, Training Accuracy= 0.546\n",
      "Epoch: 2020, Loss= 0.6960, Training Accuracy= 0.506\n",
      "Epoch: 2030, Loss= 0.6946, Training Accuracy= 0.510\n",
      "Epoch: 2040, Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 2050, Loss= 0.6921, Training Accuracy= 0.515\n",
      "Epoch: 2060, Loss= 0.6902, Training Accuracy= 0.529\n",
      "Epoch: 2070, Loss= 0.6910, Training Accuracy= 0.528\n",
      "Epoch: 2080, Loss= 0.6873, Training Accuracy= 0.538\n",
      "Epoch: 2090, Loss= 0.6893, Training Accuracy= 0.536\n",
      "Epoch: 2100, Loss= 0.7488, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2110, Loss= 0.6970, Training Accuracy= 0.506\n",
      "Epoch: 2120, Loss= 0.6963, Training Accuracy= 0.508\n",
      "Epoch: 2130, Loss= 0.6955, Training Accuracy= 0.514\n",
      "Epoch: 2140, Loss= 0.6946, Training Accuracy= 0.516\n",
      "Epoch: 2150, Loss= 0.6947, Training Accuracy= 0.511\n",
      "Epoch: 2160, Loss= 0.7035, Training Accuracy= 0.503\n",
      "Epoch: 2170, Loss= 0.7026, Training Accuracy= 0.503\n",
      "Epoch: 2180, Loss= 0.7018, Training Accuracy= 0.503\n",
      "Epoch: 2190, Loss= 0.7012, Training Accuracy= 0.503\n",
      "Epoch: 2200, Loss= 0.7006, Training Accuracy= 0.503\n",
      "Epoch: 2210, Loss= 0.6998, Training Accuracy= 0.503\n",
      "Epoch: 2220, Loss= 0.6992, Training Accuracy= 0.503\n",
      "Epoch: 2230, Loss= 0.6987, Training Accuracy= 0.502\n",
      "Epoch: 2240, Loss= 0.6982, Training Accuracy= 0.503\n",
      "Epoch: 2250, Loss= 0.6972, Training Accuracy= 0.504\n",
      "Epoch: 2260, Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 2270, Loss= 0.6961, Training Accuracy= 0.505\n",
      "Epoch: 2280, Loss= 0.6955, Training Accuracy= 0.508\n",
      "Epoch: 2290, Loss= 0.7020, Training Accuracy= 0.507\n",
      "Epoch: 2300, Loss= 0.6953, Training Accuracy= 0.501\n",
      "Epoch: 2310, Loss= 0.6948, Training Accuracy= 0.502\n",
      "Epoch: 2320, Loss= 0.6946, Training Accuracy= 0.505\n",
      "Epoch: 2330, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 2340, Loss= 0.6944, Training Accuracy= 0.508\n",
      "Epoch: 2350, Loss= 0.6944, Training Accuracy= 0.508\n",
      "Epoch: 2360, Loss= 0.6934, Training Accuracy= 0.508\n",
      "Epoch: 2370, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 2380, Loss= 0.6950, Training Accuracy= 0.505\n",
      "Epoch: 2390, Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 2400, Loss= 0.6939, Training Accuracy= 0.504\n",
      "Epoch: 2410, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 2420, Loss= 0.6969, Training Accuracy= 0.498\n",
      "Epoch: 2430, Loss= 0.6969, Training Accuracy= 0.498\n",
      "Epoch: 2440, Loss= 0.6969, Training Accuracy= 0.498\n",
      "Epoch: 2450, Loss= 0.6968, Training Accuracy= 0.498\n",
      "Epoch: 2460, Loss= 0.6968, Training Accuracy= 0.498\n",
      "Epoch: 2470, Loss= 0.6967, Training Accuracy= 0.498\n",
      "Epoch: 2480, Loss= 0.6967, Training Accuracy= 0.498\n",
      "Epoch: 2490, Loss= 0.6966, Training Accuracy= 0.499\n",
      "Epoch: 2500, Loss= 0.6966, Training Accuracy= 0.499\n",
      "Epoch: 2510, Loss= 0.6965, Training Accuracy= 0.499\n",
      "Epoch: 2520, Loss= 0.6965, Training Accuracy= 0.499\n",
      "Epoch: 2530, Loss= 0.6964, Training Accuracy= 0.498\n",
      "Epoch: 2540, Loss= 0.6964, Training Accuracy= 0.499\n",
      "Epoch: 2550, Loss= 0.6963, Training Accuracy= 0.499\n",
      "Epoch: 2560, Loss= 0.6963, Training Accuracy= 0.499\n",
      "Epoch: 2570, Loss= 0.6962, Training Accuracy= 0.499\n",
      "Epoch: 2580, Loss= 0.6962, Training Accuracy= 0.499\n",
      "Epoch: 2590, Loss= 0.6962, Training Accuracy= 0.499\n",
      "Epoch: 2600, Loss= 0.6961, Training Accuracy= 0.500\n",
      "Epoch: 2610, Loss= 0.6961, Training Accuracy= 0.499\n",
      "Epoch: 2620, Loss= 0.6960, Training Accuracy= 0.500\n",
      "Epoch: 2630, Loss= 0.6960, Training Accuracy= 0.500\n",
      "Epoch: 2640, Loss= 0.6959, Training Accuracy= 0.501\n",
      "Epoch: 2650, Loss= 0.6959, Training Accuracy= 0.501\n",
      "Epoch: 2660, Loss= 0.6958, Training Accuracy= 0.501\n",
      "Epoch: 2670, Loss= 0.6958, Training Accuracy= 0.501\n",
      "Epoch: 2680, Loss= 0.6957, Training Accuracy= 0.501\n",
      "Epoch: 2690, Loss= 0.6957, Training Accuracy= 0.501\n",
      "Epoch: 2700, Loss= 0.6956, Training Accuracy= 0.501\n",
      "Epoch: 2710, Loss= 0.6955, Training Accuracy= 0.500\n",
      "Epoch: 2720, Loss= 0.6954, Training Accuracy= 0.500\n",
      "Epoch: 2730, Loss= 0.6953, Training Accuracy= 0.500\n",
      "Epoch: 2740, Loss= 0.6952, Training Accuracy= 0.500\n",
      "Epoch: 2750, Loss= 0.6951, Training Accuracy= 0.500\n",
      "Epoch: 2760, Loss= 0.6950, Training Accuracy= 0.500\n",
      "Epoch: 2770, Loss= 0.6948, Training Accuracy= 0.499\n",
      "Epoch: 2780, Loss= 0.6947, Training Accuracy= 0.501\n",
      "Epoch: 2790, Loss= 0.6945, Training Accuracy= 0.501\n",
      "Epoch: 2800, Loss= 0.6944, Training Accuracy= 0.502\n",
      "Epoch: 2810, Loss= 0.6943, Training Accuracy= 0.502\n",
      "Epoch: 2820, Loss= 0.6941, Training Accuracy= 0.504\n",
      "Epoch: 2830, Loss= 0.6939, Training Accuracy= 0.506\n",
      "Epoch: 2840, Loss= 0.6937, Training Accuracy= 0.507\n",
      "Epoch: 2850, Loss= 0.6934, Training Accuracy= 0.510\n",
      "Epoch: 2860, Loss= 0.6930, Training Accuracy= 0.514\n",
      "Epoch: 2870, Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 2880, Loss= 0.6927, Training Accuracy= 0.518\n",
      "Epoch: 2890, Loss= 0.6927, Training Accuracy= 0.519\n",
      "Epoch: 2900, Loss= 0.6926, Training Accuracy= 0.519\n",
      "Epoch: 2910, Loss= 0.6926, Training Accuracy= 0.520\n",
      "Epoch: 2920, Loss= 0.6925, Training Accuracy= 0.520\n",
      "Epoch: 2930, Loss= 0.6924, Training Accuracy= 0.520\n",
      "Epoch: 2940, Loss= 0.6924, Training Accuracy= 0.521\n",
      "Epoch: 2950, Loss= 0.6923, Training Accuracy= 0.523\n",
      "Epoch: 2960, Loss= 0.6922, Training Accuracy= 0.524\n",
      "Epoch: 2970, Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 2980, Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 2990, Loss= 0.6920, Training Accuracy= 0.521\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4962\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.7064, Training Accuracy= 0.506\n",
      "Epoch: 10, Loss= 0.6965, Training Accuracy= 0.506\n",
      "Epoch: 20, Loss= 0.6956, Training Accuracy= 0.506\n",
      "Epoch: 30, Loss= 0.6952, Training Accuracy= 0.506\n",
      "Epoch: 40, Loss= 0.6951, Training Accuracy= 0.506\n",
      "Epoch: 50, Loss= 0.6949, Training Accuracy= 0.506\n",
      "Epoch: 60, Loss= 0.6948, Training Accuracy= 0.506\n",
      "Epoch: 70, Loss= 0.6948, Training Accuracy= 0.506\n",
      "Epoch: 80, Loss= 0.6947, Training Accuracy= 0.506\n",
      "Epoch: 90, Loss= 0.6947, Training Accuracy= 0.506\n",
      "Epoch: 100, Loss= 0.6947, Training Accuracy= 0.506\n",
      "Epoch: 110, Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 120, Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 130, Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 150, Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 160, Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 170, Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 180, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 190, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 200, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 210, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 220, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 230, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 240, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 250, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 260, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 270, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 280, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 290, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 300, Loss= 0.6945, Training Accuracy= 0.506\n",
      "Epoch: 310, Loss= 0.6944, Training Accuracy= 0.506\n",
      "Epoch: 320, Loss= 0.6944, Training Accuracy= 0.506\n",
      "Epoch: 330, Loss= 0.6944, Training Accuracy= 0.506\n",
      "Epoch: 340, Loss= 0.6944, Training Accuracy= 0.506\n",
      "Epoch: 350, Loss= 0.6944, Training Accuracy= 0.506\n",
      "Epoch: 360, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 370, Loss= 0.6944, Training Accuracy= 0.506\n",
      "Epoch: 380, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 390, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 400, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 410, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 420, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 430, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 440, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 450, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 460, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 470, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 480, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 490, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 500, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 510, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 520, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 530, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 540, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 550, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 560, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 570, Loss= 0.6943, Training Accuracy= 0.506\n",
      "Epoch: 580, Loss= 0.6943, Training Accuracy= 0.506\n",
      "Epoch: 590, Loss= 0.6943, Training Accuracy= 0.506\n",
      "Epoch: 600, Loss= 0.6942, Training Accuracy= 0.507\n",
      "Epoch: 610, Loss= 0.6942, Training Accuracy= 0.507\n",
      "Epoch: 620, Loss= 0.6942, Training Accuracy= 0.507\n",
      "Epoch: 630, Loss= 0.6942, Training Accuracy= 0.506\n",
      "Epoch: 640, Loss= 0.6942, Training Accuracy= 0.507\n",
      "Epoch: 650, Loss= 0.6941, Training Accuracy= 0.507\n",
      "Epoch: 660, Loss= 0.6941, Training Accuracy= 0.507\n",
      "Epoch: 670, Loss= 0.6940, Training Accuracy= 0.508\n",
      "Epoch: 680, Loss= 0.6940, Training Accuracy= 0.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 690, Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 700, Loss= 0.6939, Training Accuracy= 0.512\n",
      "Epoch: 710, Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 720, Loss= 0.6937, Training Accuracy= 0.511\n",
      "Epoch: 730, Loss= 0.6936, Training Accuracy= 0.513\n",
      "Epoch: 740, Loss= 0.6935, Training Accuracy= 0.512\n",
      "Epoch: 750, Loss= 0.6933, Training Accuracy= 0.514\n",
      "Epoch: 760, Loss= 0.6932, Training Accuracy= 0.516\n",
      "Epoch: 770, Loss= 0.6930, Training Accuracy= 0.518\n",
      "Epoch: 780, Loss= 0.6929, Training Accuracy= 0.520\n",
      "Epoch: 790, Loss= 0.6929, Training Accuracy= 0.520\n",
      "Epoch: 800, Loss= 0.6935, Training Accuracy= 0.518\n",
      "Epoch: 810, Loss= 0.6943, Training Accuracy= 0.518\n",
      "Epoch: 820, Loss= 0.6955, Training Accuracy= 0.522\n",
      "Epoch: 830, Loss= 0.6934, Training Accuracy= 0.528\n",
      "Epoch: 840, Loss= 0.6923, Training Accuracy= 0.530\n",
      "Epoch: 850, Loss= 0.6924, Training Accuracy= 0.530\n",
      "Epoch: 860, Loss= 0.6923, Training Accuracy= 0.535\n",
      "Epoch: 870, Loss= 0.6900, Training Accuracy= 0.544\n",
      "Epoch: 880, Loss= 0.6891, Training Accuracy= 0.549\n",
      "Epoch: 890, Loss= 0.6876, Training Accuracy= 0.555\n",
      "Epoch: 900, Loss= 0.6862, Training Accuracy= 0.563\n",
      "Epoch: 910, Loss= 0.6831, Training Accuracy= 0.565\n",
      "Epoch: 920, Loss= 0.6794, Training Accuracy= 0.568\n",
      "Epoch: 930, Loss= 0.6809, Training Accuracy= 0.566\n",
      "Epoch: 940, Loss= 0.7106, Training Accuracy= 0.532\n",
      "Epoch: 950, Loss= 0.6852, Training Accuracy= 0.566\n",
      "Epoch: 960, Loss= 0.6781, Training Accuracy= 0.575\n",
      "Epoch: 970, Loss= 0.6694, Training Accuracy= 0.589\n",
      "Epoch: 980, Loss= 0.6772, Training Accuracy= 0.579\n",
      "Epoch: 990, Loss= 0.6954, Training Accuracy= 0.545\n",
      "Epoch: 1000, Loss= 0.6817, Training Accuracy= 0.575\n",
      "Epoch: 1010, Loss= 0.6803, Training Accuracy= 0.578\n",
      "Epoch: 1020, Loss= 0.6751, Training Accuracy= 0.587\n",
      "Epoch: 1030, Loss= 0.6704, Training Accuracy= 0.596\n",
      "Epoch: 1040, Loss= 0.6711, Training Accuracy= 0.593\n",
      "Epoch: 1050, Loss= 0.6412, Training Accuracy= 0.625\n",
      "Epoch: 1060, Loss= 0.6517, Training Accuracy= 0.617\n",
      "Epoch: 1070, Loss= 0.6465, Training Accuracy= 0.619\n",
      "Epoch: 1080, Loss= 0.7039, Training Accuracy= 0.519\n",
      "Epoch: 1090, Loss= 0.6585, Training Accuracy= 0.605\n",
      "Epoch: 1100, Loss= 0.6734, Training Accuracy= 0.598\n",
      "Epoch: 1110, Loss= 0.6408, Training Accuracy= 0.628\n",
      "Epoch: 1120, Loss= 0.7216, Training Accuracy= 0.524\n",
      "Epoch: 1130, Loss= 0.6393, Training Accuracy= 0.630\n",
      "Epoch: 1140, Loss= 0.6417, Training Accuracy= 0.629\n",
      "Epoch: 1150, Loss= 0.6321, Training Accuracy= 0.641\n",
      "Epoch: 1160, Loss= 0.6634, Training Accuracy= 0.607\n",
      "Epoch: 1170, Loss= 0.6446, Training Accuracy= 0.628\n",
      "Epoch: 1180, Loss= 0.6168, Training Accuracy= 0.656\n",
      "Epoch: 1190, Loss= 0.6242, Training Accuracy= 0.650\n",
      "Epoch: 1200, Loss= 0.6205, Training Accuracy= 0.655\n",
      "Epoch: 1210, Loss= 0.6108, Training Accuracy= 0.660\n",
      "Epoch: 1220, Loss= 0.7294, Training Accuracy= 0.558\n",
      "Epoch: 1230, Loss= 0.5973, Training Accuracy= 0.677\n",
      "Epoch: 1240, Loss= 0.6035, Training Accuracy= 0.668\n",
      "Epoch: 1250, Loss= 0.6452, Training Accuracy= 0.627\n",
      "Epoch: 1260, Loss= 0.6383, Training Accuracy= 0.638\n",
      "Epoch: 1270, Loss= 0.6005, Training Accuracy= 0.668\n",
      "Epoch: 1280, Loss= 0.6468, Training Accuracy= 0.627\n",
      "Epoch: 1290, Loss= 0.6248, Training Accuracy= 0.653\n",
      "Epoch: 1300, Loss= 0.7189, Training Accuracy= 0.515\n",
      "Epoch: 1310, Loss= 0.6915, Training Accuracy= 0.535\n",
      "Epoch: 1320, Loss= 0.6823, Training Accuracy= 0.554\n",
      "Epoch: 1330, Loss= 0.6720, Training Accuracy= 0.574\n",
      "Epoch: 1340, Loss= 0.6845, Training Accuracy= 0.560\n",
      "Epoch: 1350, Loss= 0.7128, Training Accuracy= 0.518\n",
      "Epoch: 1360, Loss= 0.6862, Training Accuracy= 0.554\n",
      "Epoch: 1370, Loss= 0.6754, Training Accuracy= 0.572\n",
      "Epoch: 1380, Loss= 0.6767, Training Accuracy= 0.573\n",
      "Epoch: 1390, Loss= 0.6788, Training Accuracy= 0.572\n",
      "Epoch: 1400, Loss= 0.6655, Training Accuracy= 0.590\n",
      "Epoch: 1410, Loss= 0.6568, Training Accuracy= 0.596\n",
      "Epoch: 1420, Loss= 0.6510, Training Accuracy= 0.605\n",
      "Epoch: 1430, Loss= 0.6462, Training Accuracy= 0.614\n",
      "Epoch: 1440, Loss= 0.6442, Training Accuracy= 0.619\n",
      "Epoch: 1450, Loss= 0.6452, Training Accuracy= 0.613\n",
      "Epoch: 1460, Loss= 0.6355, Training Accuracy= 0.632\n",
      "Epoch: 1470, Loss= 0.6815, Training Accuracy= 0.565\n",
      "Epoch: 1480, Loss= 0.6604, Training Accuracy= 0.611\n",
      "Epoch: 1490, Loss= 0.6476, Training Accuracy= 0.612\n",
      "Epoch: 1500, Loss= 0.6302, Training Accuracy= 0.633\n",
      "Epoch: 1510, Loss= 0.6576, Training Accuracy= 0.609\n",
      "Epoch: 1520, Loss= 0.6301, Training Accuracy= 0.638\n",
      "Epoch: 1530, Loss= 0.6270, Training Accuracy= 0.644\n",
      "Epoch: 1540, Loss= 0.6542, Training Accuracy= 0.613\n",
      "Epoch: 1550, Loss= 0.6428, Training Accuracy= 0.624\n",
      "Epoch: 1560, Loss= 0.6641, Training Accuracy= 0.608\n",
      "Epoch: 1570, Loss= 0.6956, Training Accuracy= 0.520\n",
      "Epoch: 1580, Loss= 0.6878, Training Accuracy= 0.545\n",
      "Epoch: 1590, Loss= 0.6794, Training Accuracy= 0.563\n",
      "Epoch: 1600, Loss= 0.6783, Training Accuracy= 0.562\n",
      "Epoch: 1610, Loss= 0.6725, Training Accuracy= 0.577\n",
      "Epoch: 1620, Loss= 0.6748, Training Accuracy= 0.581\n",
      "Epoch: 1630, Loss= 0.6643, Training Accuracy= 0.591\n",
      "Epoch: 1640, Loss= 0.6592, Training Accuracy= 0.593\n",
      "Epoch: 1650, Loss= 0.6467, Training Accuracy= 0.615\n",
      "Epoch: 1660, Loss= 0.6572, Training Accuracy= 0.599\n",
      "Epoch: 1670, Loss= 0.6488, Training Accuracy= 0.610\n",
      "Epoch: 1680, Loss= 0.6435, Training Accuracy= 0.626\n",
      "Epoch: 1690, Loss= 0.6363, Training Accuracy= 0.628\n",
      "Epoch: 1700, Loss= 0.6269, Training Accuracy= 0.641\n",
      "Epoch: 1710, Loss= 0.6266, Training Accuracy= 0.635\n",
      "Epoch: 1720, Loss= 0.6434, Training Accuracy= 0.616\n",
      "Epoch: 1730, Loss= 0.6165, Training Accuracy= 0.652\n",
      "Epoch: 1740, Loss= 0.6208, Training Accuracy= 0.641\n",
      "Epoch: 1750, Loss= 0.6267, Training Accuracy= 0.644\n",
      "Epoch: 1760, Loss= 0.6075, Training Accuracy= 0.663\n",
      "Epoch: 1770, Loss= 0.6097, Training Accuracy= 0.658\n",
      "Epoch: 1780, Loss= 0.6052, Training Accuracy= 0.663\n",
      "Epoch: 1790, Loss= 0.6492, Training Accuracy= 0.627\n",
      "Epoch: 1800, Loss= 0.6064, Training Accuracy= 0.662\n",
      "Epoch: 1810, Loss= 0.5938, Training Accuracy= 0.671\n",
      "Epoch: 1820, Loss= 0.6101, Training Accuracy= 0.659\n",
      "Epoch: 1830, Loss= 0.5933, Training Accuracy= 0.675\n",
      "Epoch: 1840, Loss= 0.6004, Training Accuracy= 0.673\n",
      "Epoch: 1850, Loss= 0.5898, Training Accuracy= 0.679\n",
      "Epoch: 1860, Loss= 0.5825, Training Accuracy= 0.687\n",
      "Epoch: 1870, Loss= 0.6969, Training Accuracy= 0.510\n",
      "Epoch: 1880, Loss= 0.6934, Training Accuracy= 0.522\n",
      "Epoch: 1890, Loss= 0.6906, Training Accuracy= 0.537\n",
      "Epoch: 1900, Loss= 0.6939, Training Accuracy= 0.542\n",
      "Epoch: 1910, Loss= 0.6896, Training Accuracy= 0.547\n",
      "Epoch: 1920, Loss= 0.6759, Training Accuracy= 0.571\n",
      "Epoch: 1930, Loss= 0.6777, Training Accuracy= 0.570\n",
      "Epoch: 1940, Loss= 0.6749, Training Accuracy= 0.572\n",
      "Epoch: 1950, Loss= 0.6836, Training Accuracy= 0.571\n",
      "Epoch: 1960, Loss= 0.6836, Training Accuracy= 0.561\n",
      "Epoch: 1970, Loss= 0.6772, Training Accuracy= 0.574\n",
      "Epoch: 1980, Loss= 0.6731, Training Accuracy= 0.579\n",
      "Epoch: 1990, Loss= 0.6711, Training Accuracy= 0.583\n",
      "Epoch: 2000, Loss= 0.6600, Training Accuracy= 0.598\n",
      "Epoch: 2010, Loss= 0.6569, Training Accuracy= 0.606\n",
      "Epoch: 2020, Loss= 0.6604, Training Accuracy= 0.601\n",
      "Epoch: 2030, Loss= 0.6516, Training Accuracy= 0.613\n",
      "Epoch: 2040, Loss= 0.6548, Training Accuracy= 0.610\n",
      "Epoch: 2050, Loss= 0.6985, Training Accuracy= 0.550\n",
      "Epoch: 2060, Loss= 0.6701, Training Accuracy= 0.586\n",
      "Epoch: 2070, Loss= 0.6464, Training Accuracy= 0.623\n",
      "Epoch: 2080, Loss= 0.6485, Training Accuracy= 0.620\n",
      "Epoch: 2090, Loss= 0.6423, Training Accuracy= 0.623\n",
      "Epoch: 2100, Loss= 0.6473, Training Accuracy= 0.622\n",
      "Epoch: 2110, Loss= 0.6639, Training Accuracy= 0.602\n",
      "Epoch: 2120, Loss= 0.6631, Training Accuracy= 0.609\n",
      "Epoch: 2130, Loss= 0.6360, Training Accuracy= 0.635\n",
      "Epoch: 2140, Loss= 0.6194, Training Accuracy= 0.654\n",
      "Epoch: 2150, Loss= 0.6414, Training Accuracy= 0.629\n",
      "Epoch: 2160, Loss= 0.6438, Training Accuracy= 0.623\n",
      "Epoch: 2170, Loss= 0.6364, Training Accuracy= 0.631\n",
      "Epoch: 2180, Loss= 0.6216, Training Accuracy= 0.652\n",
      "Epoch: 2190, Loss= 0.6223, Training Accuracy= 0.649\n",
      "Epoch: 2200, Loss= 0.6450, Training Accuracy= 0.623\n",
      "Epoch: 2210, Loss= 0.6343, Training Accuracy= 0.634\n",
      "Epoch: 2220, Loss= 0.6338, Training Accuracy= 0.638\n",
      "Epoch: 2230, Loss= 0.6283, Training Accuracy= 0.642\n",
      "Epoch: 2240, Loss= 0.6132, Training Accuracy= 0.662\n",
      "Epoch: 2250, Loss= 0.6338, Training Accuracy= 0.636\n",
      "Epoch: 2260, Loss= 0.6289, Training Accuracy= 0.644\n",
      "Epoch: 2270, Loss= 0.6399, Training Accuracy= 0.631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2280, Loss= 0.6324, Training Accuracy= 0.635\n",
      "Epoch: 2290, Loss= 0.6023, Training Accuracy= 0.665\n",
      "Epoch: 2300, Loss= 0.6510, Training Accuracy= 0.618\n",
      "Epoch: 2310, Loss= 0.6199, Training Accuracy= 0.652\n",
      "Epoch: 2320, Loss= 0.6947, Training Accuracy= 0.526\n",
      "Epoch: 2330, Loss= 0.6921, Training Accuracy= 0.538\n",
      "Epoch: 2340, Loss= 0.6826, Training Accuracy= 0.554\n",
      "Epoch: 2350, Loss= 0.6811, Training Accuracy= 0.563\n",
      "Epoch: 2360, Loss= 0.6727, Training Accuracy= 0.582\n",
      "Epoch: 2370, Loss= 0.6615, Training Accuracy= 0.595\n",
      "Epoch: 2380, Loss= 0.6829, Training Accuracy= 0.565\n",
      "Epoch: 2390, Loss= 0.6711, Training Accuracy= 0.581\n",
      "Epoch: 2400, Loss= 0.6513, Training Accuracy= 0.612\n",
      "Epoch: 2410, Loss= 0.6786, Training Accuracy= 0.580\n",
      "Epoch: 2420, Loss= 0.6382, Training Accuracy= 0.629\n",
      "Epoch: 2430, Loss= 0.6333, Training Accuracy= 0.636\n",
      "Epoch: 2440, Loss= 0.6377, Training Accuracy= 0.631\n",
      "Epoch: 2450, Loss= 0.6374, Training Accuracy= 0.633\n",
      "Epoch: 2460, Loss= 0.6235, Training Accuracy= 0.648\n",
      "Epoch: 2470, Loss= 0.6461, Training Accuracy= 0.626\n",
      "Epoch: 2480, Loss= 0.6184, Training Accuracy= 0.652\n",
      "Epoch: 2490, Loss= 0.6300, Training Accuracy= 0.638\n",
      "Epoch: 2500, Loss= 0.7273, Training Accuracy= 0.510\n",
      "Epoch: 2510, Loss= 0.7198, Training Accuracy= 0.510\n",
      "Epoch: 2520, Loss= 0.7088, Training Accuracy= 0.506\n",
      "Epoch: 2530, Loss= 0.7042, Training Accuracy= 0.511\n",
      "Epoch: 2540, Loss= 0.7029, Training Accuracy= 0.513\n",
      "Epoch: 2550, Loss= 0.7026, Training Accuracy= 0.513\n",
      "Epoch: 2560, Loss= 0.7043, Training Accuracy= 0.517\n",
      "Epoch: 2570, Loss= 0.6993, Training Accuracy= 0.525\n",
      "Epoch: 2580, Loss= 0.7007, Training Accuracy= 0.520\n",
      "Epoch: 2590, Loss= 0.6973, Training Accuracy= 0.518\n",
      "Epoch: 2600, Loss= 0.6965, Training Accuracy= 0.525\n",
      "Epoch: 2610, Loss= 0.6988, Training Accuracy= 0.525\n",
      "Epoch: 2620, Loss= 0.6929, Training Accuracy= 0.536\n",
      "Epoch: 2630, Loss= 0.6976, Training Accuracy= 0.526\n",
      "Epoch: 2640, Loss= 0.6961, Training Accuracy= 0.535\n",
      "Epoch: 2650, Loss= 0.6937, Training Accuracy= 0.536\n",
      "Epoch: 2660, Loss= 0.6944, Training Accuracy= 0.518\n",
      "Epoch: 2670, Loss= 0.6971, Training Accuracy= 0.516\n",
      "Epoch: 2680, Loss= 0.6932, Training Accuracy= 0.533\n",
      "Epoch: 2690, Loss= 0.6885, Training Accuracy= 0.543\n",
      "Epoch: 2700, Loss= 0.6839, Training Accuracy= 0.555\n",
      "Epoch: 2710, Loss= 0.6832, Training Accuracy= 0.553\n",
      "Epoch: 2720, Loss= 0.6817, Training Accuracy= 0.555\n",
      "Epoch: 2730, Loss= 0.6836, Training Accuracy= 0.554\n",
      "Epoch: 2740, Loss= 0.6859, Training Accuracy= 0.549\n",
      "Epoch: 2750, Loss= 0.6783, Training Accuracy= 0.566\n",
      "Epoch: 2760, Loss= 0.6820, Training Accuracy= 0.556\n",
      "Epoch: 2770, Loss= 0.7083, Training Accuracy= 0.535\n",
      "Epoch: 2780, Loss= 0.6880, Training Accuracy= 0.546\n",
      "Epoch: 2790, Loss= 0.6831, Training Accuracy= 0.562\n",
      "Epoch: 2800, Loss= 0.6953, Training Accuracy= 0.542\n",
      "Epoch: 2810, Loss= 0.6816, Training Accuracy= 0.567\n",
      "Epoch: 2820, Loss= 0.6791, Training Accuracy= 0.566\n",
      "Epoch: 2830, Loss= 0.6921, Training Accuracy= 0.541\n",
      "Epoch: 2840, Loss= 0.7012, Training Accuracy= 0.514\n",
      "Epoch: 2850, Loss= 0.6836, Training Accuracy= 0.559\n",
      "Epoch: 2860, Loss= 1.2900, Training Accuracy= 0.494\n",
      "Epoch: 2870, Loss= 0.9991, Training Accuracy= 0.494\n",
      "Epoch: 2880, Loss= 0.8725, Training Accuracy= 0.506\n",
      "Epoch: 2890, Loss= 0.8027, Training Accuracy= 0.506\n",
      "Epoch: 2900, Loss= 0.7809, Training Accuracy= 0.506\n",
      "Epoch: 2910, Loss= 0.7986, Training Accuracy= 0.506\n",
      "Epoch: 2920, Loss= 0.7715, Training Accuracy= 0.506\n",
      "Epoch: 2930, Loss= 0.7478, Training Accuracy= 0.506\n",
      "Epoch: 2940, Loss= 0.7423, Training Accuracy= 0.506\n",
      "Epoch: 2950, Loss= 0.7391, Training Accuracy= 0.506\n",
      "Epoch: 2960, Loss= 0.7361, Training Accuracy= 0.506\n",
      "Epoch: 2970, Loss= 0.7317, Training Accuracy= 0.506\n",
      "Epoch: 2980, Loss= 0.7288, Training Accuracy= 0.506\n",
      "Epoch: 2990, Loss= 0.7253, Training Accuracy= 0.506\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 0.7054, Training Accuracy= 0.496\n",
      "Epoch: 10, Loss= 0.6994, Training Accuracy= 0.496\n",
      "Epoch: 20, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 30, Loss= 0.6975, Training Accuracy= 0.496\n",
      "Epoch: 40, Loss= 0.6970, Training Accuracy= 0.496\n",
      "Epoch: 50, Loss= 0.6967, Training Accuracy= 0.496\n",
      "Epoch: 60, Loss= 0.6964, Training Accuracy= 0.496\n",
      "Epoch: 70, Loss= 0.6962, Training Accuracy= 0.496\n",
      "Epoch: 80, Loss= 0.6961, Training Accuracy= 0.496\n",
      "Epoch: 90, Loss= 0.6960, Training Accuracy= 0.496\n",
      "Epoch: 100, Loss= 0.6959, Training Accuracy= 0.496\n",
      "Epoch: 110, Loss= 0.6959, Training Accuracy= 0.496\n",
      "Epoch: 120, Loss= 0.6958, Training Accuracy= 0.496\n",
      "Epoch: 130, Loss= 0.6958, Training Accuracy= 0.496\n",
      "Epoch: 140, Loss= 0.6955, Training Accuracy= 0.496\n",
      "Epoch: 150, Loss= 0.6957, Training Accuracy= 0.496\n",
      "Epoch: 160, Loss= 0.6981, Training Accuracy= 0.498\n",
      "Epoch: 170, Loss= 0.6971, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 0.6977, Training Accuracy= 0.501\n",
      "Epoch: 190, Loss= 0.6973, Training Accuracy= 0.502\n",
      "Epoch: 200, Loss= 0.6977, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.6969, Training Accuracy= 0.503\n",
      "Epoch: 220, Loss= 0.6971, Training Accuracy= 0.503\n",
      "Epoch: 230, Loss= 0.6970, Training Accuracy= 0.504\n",
      "Epoch: 240, Loss= 0.6969, Training Accuracy= 0.504\n",
      "Epoch: 250, Loss= 0.6967, Training Accuracy= 0.506\n",
      "Epoch: 260, Loss= 0.6966, Training Accuracy= 0.505\n",
      "Epoch: 270, Loss= 0.6967, Training Accuracy= 0.505\n",
      "Epoch: 280, Loss= 0.6968, Training Accuracy= 0.505\n",
      "Epoch: 290, Loss= 0.6972, Training Accuracy= 0.504\n",
      "Epoch: 300, Loss= 0.6963, Training Accuracy= 0.508\n",
      "Epoch: 310, Loss= 0.6960, Training Accuracy= 0.510\n",
      "Epoch: 320, Loss= 0.6961, Training Accuracy= 0.511\n",
      "Epoch: 330, Loss= 0.6960, Training Accuracy= 0.513\n",
      "Epoch: 340, Loss= 0.6957, Training Accuracy= 0.517\n",
      "Epoch: 350, Loss= 0.6953, Training Accuracy= 0.518\n",
      "Epoch: 360, Loss= 0.6952, Training Accuracy= 0.518\n",
      "Epoch: 370, Loss= 0.6948, Training Accuracy= 0.521\n",
      "Epoch: 380, Loss= 0.6977, Training Accuracy= 0.510\n",
      "Epoch: 390, Loss= 0.6957, Training Accuracy= 0.512\n",
      "Epoch: 400, Loss= 0.6958, Training Accuracy= 0.513\n",
      "Epoch: 410, Loss= 0.6959, Training Accuracy= 0.512\n",
      "Epoch: 420, Loss= 0.6956, Training Accuracy= 0.514\n",
      "Epoch: 430, Loss= 0.6951, Training Accuracy= 0.515\n",
      "Epoch: 440, Loss= 0.6943, Training Accuracy= 0.520\n",
      "Epoch: 450, Loss= 0.6936, Training Accuracy= 0.521\n",
      "Epoch: 460, Loss= 0.6959, Training Accuracy= 0.508\n",
      "Epoch: 470, Loss= 0.6940, Training Accuracy= 0.526\n",
      "Epoch: 480, Loss= 0.6949, Training Accuracy= 0.533\n",
      "Epoch: 490, Loss= 0.6941, Training Accuracy= 0.534\n",
      "Epoch: 500, Loss= 0.6890, Training Accuracy= 0.543\n",
      "Epoch: 510, Loss= 0.6824, Training Accuracy= 0.559\n",
      "Epoch: 520, Loss= 0.6834, Training Accuracy= 0.558\n",
      "Epoch: 530, Loss= 0.6490, Training Accuracy= 0.613\n",
      "Epoch: 540, Loss= 0.5305, Training Accuracy= 0.726\n",
      "Epoch: 550, Loss= 0.3306, Training Accuracy= 0.847\n",
      "Epoch: 560, Loss= 0.1873, Training Accuracy= 0.882\n",
      "Epoch: 570, Loss= 0.1714, Training Accuracy= 0.914\n",
      "Epoch: 580, Loss= 0.1433, Training Accuracy= 0.934\n",
      "Epoch: 590, Loss= 0.0457, Training Accuracy= 0.986\n",
      "Epoch: 600, Loss= 0.0726, Training Accuracy= 0.969\n",
      "Epoch: 610, Loss= 0.0350, Training Accuracy= 0.984\n",
      "Epoch: 620, Loss= 0.0242, Training Accuracy= 0.990\n",
      "Epoch: 630, Loss= 0.0343, Training Accuracy= 0.986\n",
      "Epoch: 640, Loss= 0.0427, Training Accuracy= 0.980\n",
      "Epoch: 650, Loss= 0.0221, Training Accuracy= 0.985\n",
      "Epoch: 660, Loss= 0.0180, Training Accuracy= 0.992\n",
      "Epoch: 670, Loss= 0.5027, Training Accuracy= 0.676\n",
      "Epoch: 680, Loss= 0.4578, Training Accuracy= 0.690\n",
      "Epoch: 690, Loss= 0.6297, Training Accuracy= 0.603\n",
      "Epoch: 700, Loss= 0.3770, Training Accuracy= 0.744\n",
      "Epoch: 710, Loss= 0.3492, Training Accuracy= 0.755\n",
      "Epoch: 720, Loss= 0.3484, Training Accuracy= 0.758\n",
      "Epoch: 730, Loss= 0.3480, Training Accuracy= 0.758\n",
      "Epoch: 740, Loss= 0.3479, Training Accuracy= 0.757\n",
      "Epoch: 750, Loss= 0.3475, Training Accuracy= 0.755\n",
      "Epoch: 760, Loss= 0.3473, Training Accuracy= 0.756\n",
      "Epoch: 770, Loss= 0.3472, Training Accuracy= 0.757\n",
      "Epoch: 780, Loss= 0.3470, Training Accuracy= 0.756\n",
      "Epoch: 790, Loss= 0.3468, Training Accuracy= 0.755\n",
      "Epoch: 800, Loss= 0.3466, Training Accuracy= 0.756\n",
      "Epoch: 810, Loss= 0.3459, Training Accuracy= 0.755\n",
      "Epoch: 820, Loss= 0.3452, Training Accuracy= 0.767\n",
      "Epoch: 830, Loss= 0.3432, Training Accuracy= 0.771\n",
      "Epoch: 840, Loss= 0.3148, Training Accuracy= 0.820\n",
      "Epoch: 850, Loss= 0.3844, Training Accuracy= 0.759\n",
      "Epoch: 860, Loss= 0.3976, Training Accuracy= 0.789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 870, Loss= 0.1861, Training Accuracy= 0.914\n",
      "Epoch: 880, Loss= 0.6145, Training Accuracy= 0.680\n",
      "Epoch: 890, Loss= 0.7496, Training Accuracy= 0.499\n",
      "Epoch: 900, Loss= 0.7326, Training Accuracy= 0.514\n",
      "Epoch: 910, Loss= 0.7250, Training Accuracy= 0.518\n",
      "Epoch: 920, Loss= 0.7197, Training Accuracy= 0.519\n",
      "Epoch: 930, Loss= 0.7157, Training Accuracy= 0.521\n",
      "Epoch: 940, Loss= 0.7122, Training Accuracy= 0.523\n",
      "Epoch: 950, Loss= 0.7079, Training Accuracy= 0.525\n",
      "Epoch: 960, Loss= 0.7028, Training Accuracy= 0.522\n",
      "Epoch: 970, Loss= 0.7015, Training Accuracy= 0.541\n",
      "Epoch: 980, Loss= 0.6904, Training Accuracy= 0.557\n",
      "Epoch: 990, Loss= 0.6885, Training Accuracy= 0.563\n",
      "Epoch: 1000, Loss= 0.6892, Training Accuracy= 0.576\n",
      "Epoch: 1010, Loss= 0.5760, Training Accuracy= 0.652\n",
      "Epoch: 1020, Loss= 0.5912, Training Accuracy= 0.667\n",
      "Epoch: 1030, Loss= 0.4443, Training Accuracy= 0.724\n",
      "Epoch: 1040, Loss= 0.5241, Training Accuracy= 0.665\n",
      "Epoch: 1050, Loss= 0.6367, Training Accuracy= 0.588\n",
      "Epoch: 1060, Loss= 0.6415, Training Accuracy= 0.593\n",
      "Epoch: 1070, Loss= 0.6367, Training Accuracy= 0.598\n",
      "Epoch: 1080, Loss= 0.7399, Training Accuracy= 0.608\n",
      "Epoch: 1090, Loss= 0.6198, Training Accuracy= 0.608\n",
      "Epoch: 1100, Loss= 0.5611, Training Accuracy= 0.636\n",
      "Epoch: 1110, Loss= 0.5478, Training Accuracy= 0.663\n",
      "Epoch: 1120, Loss= 0.5301, Training Accuracy= 0.664\n",
      "Epoch: 1130, Loss= 0.5263, Training Accuracy= 0.673\n",
      "Epoch: 1140, Loss= 0.5216, Training Accuracy= 0.683\n",
      "Epoch: 1150, Loss= 0.5187, Training Accuracy= 0.688\n",
      "Epoch: 1160, Loss= 0.5852, Training Accuracy= 0.630\n",
      "Epoch: 1170, Loss= 0.5382, Training Accuracy= 0.664\n",
      "Epoch: 1180, Loss= 0.5478, Training Accuracy= 0.671\n",
      "Epoch: 1190, Loss= 0.5884, Training Accuracy= 0.643\n",
      "Epoch: 1200, Loss= 0.3947, Training Accuracy= 0.746\n",
      "Epoch: 1210, Loss= 0.3874, Training Accuracy= 0.750\n",
      "Epoch: 1220, Loss= 0.3972, Training Accuracy= 0.746\n",
      "Epoch: 1230, Loss= 0.7393, Training Accuracy= 0.501\n",
      "Epoch: 1240, Loss= 0.7324, Training Accuracy= 0.500\n",
      "Epoch: 1250, Loss= 0.7250, Training Accuracy= 0.499\n",
      "Epoch: 1260, Loss= 0.7187, Training Accuracy= 0.499\n",
      "Epoch: 1270, Loss= 0.7164, Training Accuracy= 0.501\n",
      "Epoch: 1280, Loss= 0.7151, Training Accuracy= 0.501\n",
      "Epoch: 1290, Loss= 0.7141, Training Accuracy= 0.501\n",
      "Epoch: 1300, Loss= 0.7139, Training Accuracy= 0.501\n",
      "Epoch: 1310, Loss= 0.7135, Training Accuracy= 0.501\n",
      "Epoch: 1320, Loss= 0.7127, Training Accuracy= 0.502\n",
      "Epoch: 1330, Loss= 0.7103, Training Accuracy= 0.502\n",
      "Epoch: 1340, Loss= 0.7069, Training Accuracy= 0.506\n",
      "Epoch: 1350, Loss= 0.7055, Training Accuracy= 0.514\n",
      "Epoch: 1360, Loss= 0.7048, Training Accuracy= 0.520\n",
      "Epoch: 1370, Loss= 0.7045, Training Accuracy= 0.524\n",
      "Epoch: 1380, Loss= 0.7042, Training Accuracy= 0.524\n",
      "Epoch: 1390, Loss= 0.7040, Training Accuracy= 0.525\n",
      "Epoch: 1400, Loss= 0.7036, Training Accuracy= 0.525\n",
      "Epoch: 1410, Loss= 0.7034, Training Accuracy= 0.524\n",
      "Epoch: 1420, Loss= 0.7031, Training Accuracy= 0.525\n",
      "Epoch: 1430, Loss= 0.7027, Training Accuracy= 0.525\n",
      "Epoch: 1440, Loss= 0.7024, Training Accuracy= 0.524\n",
      "Epoch: 1450, Loss= 0.7022, Training Accuracy= 0.522\n",
      "Epoch: 1460, Loss= 0.7024, Training Accuracy= 0.524\n",
      "Epoch: 1470, Loss= 0.7025, Training Accuracy= 0.525\n",
      "Epoch: 1480, Loss= 0.7021, Training Accuracy= 0.522\n",
      "Epoch: 1490, Loss= 0.7014, Training Accuracy= 0.525\n",
      "Epoch: 1500, Loss= 0.7015, Training Accuracy= 0.525\n",
      "Epoch: 1510, Loss= 0.7004, Training Accuracy= 0.528\n",
      "Epoch: 1520, Loss= 0.7024, Training Accuracy= 0.525\n",
      "Epoch: 1530, Loss= 0.6990, Training Accuracy= 0.532\n",
      "Epoch: 1540, Loss= 0.7000, Training Accuracy= 0.532\n",
      "Epoch: 1550, Loss= 0.6974, Training Accuracy= 0.535\n",
      "Epoch: 1560, Loss= 0.6972, Training Accuracy= 0.533\n",
      "Epoch: 1570, Loss= 0.6971, Training Accuracy= 0.533\n",
      "Epoch: 1580, Loss= 0.6958, Training Accuracy= 0.537\n",
      "Epoch: 1590, Loss= 0.6940, Training Accuracy= 0.537\n",
      "Epoch: 1600, Loss= 0.6924, Training Accuracy= 0.540\n",
      "Epoch: 1610, Loss= 0.6949, Training Accuracy= 0.536\n",
      "Epoch: 1620, Loss= 0.6896, Training Accuracy= 0.546\n",
      "Epoch: 1630, Loss= 0.6882, Training Accuracy= 0.550\n",
      "Epoch: 1640, Loss= 0.6927, Training Accuracy= 0.529\n",
      "Epoch: 1650, Loss= 0.6892, Training Accuracy= 0.547\n",
      "Epoch: 1660, Loss= 0.6902, Training Accuracy= 0.544\n",
      "Epoch: 1670, Loss= 0.6868, Training Accuracy= 0.545\n",
      "Epoch: 1680, Loss= 0.6838, Training Accuracy= 0.552\n",
      "Epoch: 1690, Loss= 0.6848, Training Accuracy= 0.550\n",
      "Epoch: 1700, Loss= 0.6840, Training Accuracy= 0.552\n",
      "Epoch: 1710, Loss= 0.6840, Training Accuracy= 0.552\n",
      "Epoch: 1720, Loss= 0.6925, Training Accuracy= 0.548\n",
      "Epoch: 1730, Loss= 0.6856, Training Accuracy= 0.554\n",
      "Epoch: 1740, Loss= 0.6857, Training Accuracy= 0.549\n",
      "Epoch: 1750, Loss= 0.6895, Training Accuracy= 0.547\n",
      "Epoch: 1760, Loss= 0.6827, Training Accuracy= 0.560\n",
      "Epoch: 1770, Loss= 0.6832, Training Accuracy= 0.559\n",
      "Epoch: 1780, Loss= 0.6833, Training Accuracy= 0.558\n",
      "Epoch: 1790, Loss= 0.6862, Training Accuracy= 0.559\n",
      "Epoch: 1800, Loss= 0.6812, Training Accuracy= 0.562\n",
      "Epoch: 1810, Loss= 0.6800, Training Accuracy= 0.564\n",
      "Epoch: 1820, Loss= 0.6785, Training Accuracy= 0.566\n",
      "Epoch: 1830, Loss= 0.6939, Training Accuracy= 0.549\n",
      "Epoch: 1840, Loss= 0.6774, Training Accuracy= 0.560\n",
      "Epoch: 1850, Loss= 0.6774, Training Accuracy= 0.565\n",
      "Epoch: 1860, Loss= 0.6772, Training Accuracy= 0.561\n",
      "Epoch: 1870, Loss= 0.6898, Training Accuracy= 0.542\n",
      "Epoch: 1880, Loss= 0.6870, Training Accuracy= 0.548\n",
      "Epoch: 1890, Loss= 0.6759, Training Accuracy= 0.563\n",
      "Epoch: 1900, Loss= 0.6779, Training Accuracy= 0.555\n",
      "Epoch: 1910, Loss= 0.6737, Training Accuracy= 0.568\n",
      "Epoch: 1920, Loss= 0.6806, Training Accuracy= 0.568\n",
      "Epoch: 1930, Loss= 0.6828, Training Accuracy= 0.561\n",
      "Epoch: 1940, Loss= 0.6604, Training Accuracy= 0.591\n",
      "Epoch: 1950, Loss= 0.6993, Training Accuracy= 0.541\n",
      "Epoch: 1960, Loss= 0.7277, Training Accuracy= 0.497\n",
      "Epoch: 1970, Loss= 0.7224, Training Accuracy= 0.496\n",
      "Epoch: 1980, Loss= 0.7250, Training Accuracy= 0.496\n",
      "Epoch: 1990, Loss= 0.7199, Training Accuracy= 0.497\n",
      "Epoch: 2000, Loss= 0.7203, Training Accuracy= 0.496\n",
      "Epoch: 2010, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 2020, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 2030, Loss= 0.7198, Training Accuracy= 0.496\n",
      "Epoch: 2040, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 2050, Loss= 0.7153, Training Accuracy= 0.496\n",
      "Epoch: 2060, Loss= 0.7085, Training Accuracy= 0.496\n",
      "Epoch: 2070, Loss= 0.7064, Training Accuracy= 0.497\n",
      "Epoch: 2080, Loss= 0.7053, Training Accuracy= 0.499\n",
      "Epoch: 2090, Loss= 0.7093, Training Accuracy= 0.498\n",
      "Epoch: 2100, Loss= 0.7041, Training Accuracy= 0.499\n",
      "Epoch: 2110, Loss= 0.7047, Training Accuracy= 0.502\n",
      "Epoch: 2120, Loss= 0.7042, Training Accuracy= 0.503\n",
      "Epoch: 2130, Loss= 0.7063, Training Accuracy= 0.500\n",
      "Epoch: 2140, Loss= 0.7041, Training Accuracy= 0.503\n",
      "Epoch: 2150, Loss= 0.7024, Training Accuracy= 0.508\n",
      "Epoch: 2160, Loss= 0.7006, Training Accuracy= 0.514\n",
      "Epoch: 2170, Loss= 0.7032, Training Accuracy= 0.503\n",
      "Epoch: 2180, Loss= 0.7025, Training Accuracy= 0.503\n",
      "Epoch: 2190, Loss= 0.7215, Training Accuracy= 0.497\n",
      "Epoch: 2200, Loss= 0.7153, Training Accuracy= 0.498\n",
      "Epoch: 2210, Loss= 0.7178, Training Accuracy= 0.499\n",
      "Epoch: 2220, Loss= 0.7188, Training Accuracy= 0.500\n",
      "Epoch: 2230, Loss= 0.7157, Training Accuracy= 0.500\n",
      "Epoch: 2240, Loss= 0.7162, Training Accuracy= 0.501\n",
      "Epoch: 2250, Loss= 0.7149, Training Accuracy= 0.501\n",
      "Epoch: 2260, Loss= 0.7148, Training Accuracy= 0.501\n",
      "Epoch: 2270, Loss= 0.7065, Training Accuracy= 0.501\n",
      "Epoch: 2280, Loss= 0.7032, Training Accuracy= 0.497\n",
      "Epoch: 2290, Loss= 0.7033, Training Accuracy= 0.500\n",
      "Epoch: 2300, Loss= 0.7091, Training Accuracy= 0.503\n",
      "Epoch: 2310, Loss= 0.7094, Training Accuracy= 0.503\n",
      "Epoch: 2320, Loss= 0.7081, Training Accuracy= 0.505\n",
      "Epoch: 2330, Loss= 0.7162, Training Accuracy= 0.501\n",
      "Epoch: 2340, Loss= 0.7147, Training Accuracy= 0.500\n",
      "Epoch: 2350, Loss= 0.7104, Training Accuracy= 0.502\n",
      "Epoch: 2360, Loss= 0.7057, Training Accuracy= 0.506\n",
      "Epoch: 2370, Loss= 0.7058, Training Accuracy= 0.500\n",
      "Epoch: 2380, Loss= 0.7102, Training Accuracy= 0.503\n",
      "Epoch: 2390, Loss= 0.7129, Training Accuracy= 0.499\n",
      "Epoch: 2400, Loss= 0.7051, Training Accuracy= 0.501\n",
      "Epoch: 2410, Loss= 0.7051, Training Accuracy= 0.502\n",
      "Epoch: 2420, Loss= 0.7077, Training Accuracy= 0.501\n",
      "Epoch: 2430, Loss= 0.7058, Training Accuracy= 0.501\n",
      "Epoch: 2440, Loss= 0.7077, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2450, Loss= 0.7079, Training Accuracy= 0.507\n",
      "Epoch: 2460, Loss= 0.7062, Training Accuracy= 0.509\n",
      "Epoch: 2470, Loss= 0.7013, Training Accuracy= 0.514\n",
      "Epoch: 2480, Loss= 0.7055, Training Accuracy= 0.513\n",
      "Epoch: 2490, Loss= 0.7078, Training Accuracy= 0.510\n",
      "Epoch: 2500, Loss= 0.7038, Training Accuracy= 0.515\n",
      "Epoch: 2510, Loss= 0.7049, Training Accuracy= 0.518\n",
      "Epoch: 2520, Loss= 0.7026, Training Accuracy= 0.521\n",
      "Epoch: 2530, Loss= 0.7054, Training Accuracy= 0.522\n",
      "Epoch: 2540, Loss= 0.6987, Training Accuracy= 0.521\n",
      "Epoch: 2550, Loss= 0.7082, Training Accuracy= 0.512\n",
      "Epoch: 2560, Loss= 0.7042, Training Accuracy= 0.516\n",
      "Epoch: 2570, Loss= 0.7057, Training Accuracy= 0.510\n",
      "Epoch: 2580, Loss= 0.7029, Training Accuracy= 0.513\n",
      "Epoch: 2590, Loss= 0.6997, Training Accuracy= 0.519\n",
      "Epoch: 2600, Loss= 0.6988, Training Accuracy= 0.525\n",
      "Epoch: 2610, Loss= 0.7027, Training Accuracy= 0.517\n",
      "Epoch: 2620, Loss= 0.6992, Training Accuracy= 0.525\n",
      "Epoch: 2630, Loss= 0.6961, Training Accuracy= 0.506\n",
      "Epoch: 2640, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 2650, Loss= 0.6917, Training Accuracy= 0.519\n",
      "Epoch: 2660, Loss= 0.6911, Training Accuracy= 0.519\n",
      "Epoch: 2670, Loss= 0.6899, Training Accuracy= 0.523\n",
      "Epoch: 2680, Loss= 0.6899, Training Accuracy= 0.520\n",
      "Epoch: 2690, Loss= 0.6897, Training Accuracy= 0.526\n",
      "Epoch: 2700, Loss= 0.6897, Training Accuracy= 0.526\n",
      "Epoch: 2710, Loss= 0.6895, Training Accuracy= 0.526\n",
      "Epoch: 2720, Loss= 0.6897, Training Accuracy= 0.531\n",
      "Epoch: 2730, Loss= 0.6895, Training Accuracy= 0.534\n",
      "Epoch: 2740, Loss= 0.6865, Training Accuracy= 0.536\n",
      "Epoch: 2750, Loss= 0.6886, Training Accuracy= 0.535\n",
      "Epoch: 2760, Loss= 0.6867, Training Accuracy= 0.534\n",
      "Epoch: 2770, Loss= 0.6867, Training Accuracy= 0.544\n",
      "Epoch: 2780, Loss= 0.6869, Training Accuracy= 0.543\n",
      "Epoch: 2790, Loss= 0.7668, Training Accuracy= 0.496\n",
      "Epoch: 2800, Loss= 0.7340, Training Accuracy= 0.496\n",
      "Epoch: 2810, Loss= 0.7258, Training Accuracy= 0.496\n",
      "Epoch: 2820, Loss= 0.7198, Training Accuracy= 0.496\n",
      "Epoch: 2830, Loss= 0.7132, Training Accuracy= 0.496\n",
      "Epoch: 2840, Loss= 0.7100, Training Accuracy= 0.496\n",
      "Epoch: 2850, Loss= 0.7081, Training Accuracy= 0.496\n",
      "Epoch: 2860, Loss= 0.7075, Training Accuracy= 0.496\n",
      "Epoch: 2870, Loss= 0.7131, Training Accuracy= 0.496\n",
      "Epoch: 2880, Loss= 0.7078, Training Accuracy= 0.497\n",
      "Epoch: 2890, Loss= 0.7031, Training Accuracy= 0.497\n",
      "Epoch: 2900, Loss= 0.7007, Training Accuracy= 0.503\n",
      "Epoch: 2910, Loss= 0.6997, Training Accuracy= 0.504\n",
      "Epoch: 2920, Loss= 0.6992, Training Accuracy= 0.507\n",
      "Epoch: 2930, Loss= 0.6991, Training Accuracy= 0.509\n",
      "Epoch: 2940, Loss= 0.6983, Training Accuracy= 0.510\n",
      "Epoch: 2950, Loss= 0.6972, Training Accuracy= 0.513\n",
      "Epoch: 2960, Loss= 0.6958, Training Accuracy= 0.520\n",
      "Epoch: 2970, Loss= 0.6965, Training Accuracy= 0.519\n",
      "Epoch: 2980, Loss= 0.6966, Training Accuracy= 0.516\n",
      "Epoch: 2990, Loss= 0.7004, Training Accuracy= 0.502\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5059\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.7067, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 0.6985, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.6966, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.6957, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.6951, Training Accuracy= 0.497\n",
      "Epoch: 50, Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 60, Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 70, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.6942, Training Accuracy= 0.501\n",
      "Epoch: 90, Loss= 0.6941, Training Accuracy= 0.501\n",
      "Epoch: 100, Loss= 0.6941, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 120, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 130, Loss= 0.6939, Training Accuracy= 0.503\n",
      "Epoch: 140, Loss= 0.6938, Training Accuracy= 0.504\n",
      "Epoch: 150, Loss= 0.6938, Training Accuracy= 0.504\n",
      "Epoch: 160, Loss= 0.6937, Training Accuracy= 0.505\n",
      "Epoch: 170, Loss= 0.6937, Training Accuracy= 0.504\n",
      "Epoch: 180, Loss= 0.6936, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.6935, Training Accuracy= 0.507\n",
      "Epoch: 200, Loss= 0.6935, Training Accuracy= 0.511\n",
      "Epoch: 210, Loss= 0.6934, Training Accuracy= 0.510\n",
      "Epoch: 220, Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 230, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 240, Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 250, Loss= 0.6933, Training Accuracy= 0.507\n",
      "Epoch: 260, Loss= 0.6933, Training Accuracy= 0.507\n",
      "Epoch: 270, Loss= 0.6933, Training Accuracy= 0.507\n",
      "Epoch: 280, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 290, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 300, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 310, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 320, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 330, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 340, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 350, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 360, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 370, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 380, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 390, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 400, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 410, Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 420, Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 430, Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 440, Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 450, Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 460, Loss= 0.6930, Training Accuracy= 0.514\n",
      "Epoch: 470, Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 480, Loss= 0.6938, Training Accuracy= 0.509\n",
      "Epoch: 490, Loss= 0.6940, Training Accuracy= 0.508\n",
      "Epoch: 500, Loss= 0.6941, Training Accuracy= 0.508\n",
      "Epoch: 510, Loss= 0.6943, Training Accuracy= 0.510\n",
      "Epoch: 520, Loss= 0.6940, Training Accuracy= 0.513\n",
      "Epoch: 530, Loss= 0.6987, Training Accuracy= 0.508\n",
      "Epoch: 540, Loss= 0.6942, Training Accuracy= 0.513\n",
      "Epoch: 550, Loss= 0.6934, Training Accuracy= 0.516\n",
      "Epoch: 560, Loss= 0.6929, Training Accuracy= 0.518\n",
      "Epoch: 570, Loss= 0.6925, Training Accuracy= 0.521\n",
      "Epoch: 580, Loss= 0.6921, Training Accuracy= 0.523\n",
      "Epoch: 590, Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 600, Loss= 0.6936, Training Accuracy= 0.521\n",
      "Epoch: 610, Loss= 0.6946, Training Accuracy= 0.521\n",
      "Epoch: 620, Loss= 0.6963, Training Accuracy= 0.520\n",
      "Epoch: 630, Loss= 0.6969, Training Accuracy= 0.520\n",
      "Epoch: 640, Loss= 0.6964, Training Accuracy= 0.525\n",
      "Epoch: 650, Loss= 0.6936, Training Accuracy= 0.532\n",
      "Epoch: 660, Loss= 0.6920, Training Accuracy= 0.541\n",
      "Epoch: 670, Loss= 0.6884, Training Accuracy= 0.549\n",
      "Epoch: 680, Loss= 0.6958, Training Accuracy= 0.536\n",
      "Epoch: 690, Loss= 0.6954, Training Accuracy= 0.540\n",
      "Epoch: 700, Loss= 0.7255, Training Accuracy= 0.513\n",
      "Epoch: 710, Loss= 0.7067, Training Accuracy= 0.526\n",
      "Epoch: 720, Loss= 0.6879, Training Accuracy= 0.546\n",
      "Epoch: 730, Loss= 0.6889, Training Accuracy= 0.549\n",
      "Epoch: 740, Loss= 0.6941, Training Accuracy= 0.552\n",
      "Epoch: 750, Loss= 0.6901, Training Accuracy= 0.556\n",
      "Epoch: 760, Loss= 0.7022, Training Accuracy= 0.541\n",
      "Epoch: 770, Loss= 0.6750, Training Accuracy= 0.583\n",
      "Epoch: 780, Loss= 0.6825, Training Accuracy= 0.582\n",
      "Epoch: 790, Loss= 0.6742, Training Accuracy= 0.577\n",
      "Epoch: 800, Loss= 0.6806, Training Accuracy= 0.581\n",
      "Epoch: 810, Loss= 0.6572, Training Accuracy= 0.609\n",
      "Epoch: 820, Loss= 0.6703, Training Accuracy= 0.594\n",
      "Epoch: 830, Loss= 0.6481, Training Accuracy= 0.618\n",
      "Epoch: 840, Loss= 0.6547, Training Accuracy= 0.613\n",
      "Epoch: 850, Loss= 0.6676, Training Accuracy= 0.594\n",
      "Epoch: 860, Loss= 0.6613, Training Accuracy= 0.607\n",
      "Epoch: 870, Loss= 0.6451, Training Accuracy= 0.625\n",
      "Epoch: 880, Loss= 0.6582, Training Accuracy= 0.603\n",
      "Epoch: 890, Loss= 0.6764, Training Accuracy= 0.596\n",
      "Epoch: 900, Loss= 0.6405, Training Accuracy= 0.629\n",
      "Epoch: 910, Loss= 0.6276, Training Accuracy= 0.641\n",
      "Epoch: 920, Loss= 0.6269, Training Accuracy= 0.643\n",
      "Epoch: 930, Loss= 0.6611, Training Accuracy= 0.610\n",
      "Epoch: 940, Loss= 0.6351, Training Accuracy= 0.641\n",
      "Epoch: 950, Loss= 0.6272, Training Accuracy= 0.648\n",
      "Epoch: 960, Loss= 0.7018, Training Accuracy= 0.503\n",
      "Epoch: 970, Loss= 0.6904, Training Accuracy= 0.530\n",
      "Epoch: 980, Loss= 0.6863, Training Accuracy= 0.545\n",
      "Epoch: 990, Loss= 0.6843, Training Accuracy= 0.552\n",
      "Epoch: 1000, Loss= 0.6811, Training Accuracy= 0.563\n",
      "Epoch: 1010, Loss= 0.6783, Training Accuracy= 0.566\n",
      "Epoch: 1020, Loss= 0.6764, Training Accuracy= 0.572\n",
      "Epoch: 1030, Loss= 0.6714, Training Accuracy= 0.579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1040, Loss= 0.6648, Training Accuracy= 0.594\n",
      "Epoch: 1050, Loss= 0.6935, Training Accuracy= 0.538\n",
      "Epoch: 1060, Loss= 0.6601, Training Accuracy= 0.599\n",
      "Epoch: 1070, Loss= 0.6729, Training Accuracy= 0.580\n",
      "Epoch: 1080, Loss= 0.6547, Training Accuracy= 0.606\n",
      "Epoch: 1090, Loss= 0.6615, Training Accuracy= 0.597\n",
      "Epoch: 1100, Loss= 0.6452, Training Accuracy= 0.615\n",
      "Epoch: 1110, Loss= 0.6718, Training Accuracy= 0.578\n",
      "Epoch: 1120, Loss= 0.6905, Training Accuracy= 0.539\n",
      "Epoch: 1130, Loss= 0.6387, Training Accuracy= 0.625\n",
      "Epoch: 1140, Loss= 0.6732, Training Accuracy= 0.585\n",
      "Epoch: 1150, Loss= 0.6417, Training Accuracy= 0.623\n",
      "Epoch: 1160, Loss= 0.6405, Training Accuracy= 0.625\n",
      "Epoch: 1170, Loss= 0.6501, Training Accuracy= 0.622\n",
      "Epoch: 1180, Loss= 0.6368, Training Accuracy= 0.632\n",
      "Epoch: 1190, Loss= 0.6244, Training Accuracy= 0.650\n",
      "Epoch: 1200, Loss= 0.6345, Training Accuracy= 0.631\n",
      "Epoch: 1210, Loss= 0.6256, Training Accuracy= 0.645\n",
      "Epoch: 1220, Loss= 0.6290, Training Accuracy= 0.637\n",
      "Epoch: 1230, Loss= 0.6205, Training Accuracy= 0.652\n",
      "Epoch: 1240, Loss= 0.6363, Training Accuracy= 0.634\n",
      "Epoch: 1250, Loss= 0.6066, Training Accuracy= 0.663\n",
      "Epoch: 1260, Loss= 0.6221, Training Accuracy= 0.650\n",
      "Epoch: 1270, Loss= 0.6475, Training Accuracy= 0.623\n",
      "Epoch: 1280, Loss= 0.6595, Training Accuracy= 0.610\n",
      "Epoch: 1290, Loss= 0.6638, Training Accuracy= 0.605\n",
      "Epoch: 1300, Loss= 0.6928, Training Accuracy= 0.535\n",
      "Epoch: 1310, Loss= 0.6719, Training Accuracy= 0.576\n",
      "Epoch: 1320, Loss= 0.6559, Training Accuracy= 0.607\n",
      "Epoch: 1330, Loss= 0.6249, Training Accuracy= 0.646\n",
      "Epoch: 1340, Loss= 0.6256, Training Accuracy= 0.642\n",
      "Epoch: 1350, Loss= 0.6678, Training Accuracy= 0.591\n",
      "Epoch: 1360, Loss= 0.6093, Training Accuracy= 0.665\n",
      "Epoch: 1370, Loss= 0.6741, Training Accuracy= 0.607\n",
      "Epoch: 1380, Loss= 0.6218, Training Accuracy= 0.646\n",
      "Epoch: 1390, Loss= 0.5993, Training Accuracy= 0.669\n",
      "Epoch: 1400, Loss= 0.6209, Training Accuracy= 0.644\n",
      "Epoch: 1410, Loss= 0.6086, Training Accuracy= 0.657\n",
      "Epoch: 1420, Loss= 0.6001, Training Accuracy= 0.668\n",
      "Epoch: 1430, Loss= 0.6275, Training Accuracy= 0.644\n",
      "Epoch: 1440, Loss= 0.6192, Training Accuracy= 0.651\n",
      "Epoch: 1450, Loss= 0.5979, Training Accuracy= 0.666\n",
      "Epoch: 1460, Loss= 0.6940, Training Accuracy= 0.520\n",
      "Epoch: 1470, Loss= 0.6865, Training Accuracy= 0.541\n",
      "Epoch: 1480, Loss= 0.6836, Training Accuracy= 0.544\n",
      "Epoch: 1490, Loss= 0.6797, Training Accuracy= 0.561\n",
      "Epoch: 1500, Loss= 0.6754, Training Accuracy= 0.568\n",
      "Epoch: 1510, Loss= 0.6727, Training Accuracy= 0.573\n",
      "Epoch: 1520, Loss= 0.6704, Training Accuracy= 0.578\n",
      "Epoch: 1530, Loss= 0.6791, Training Accuracy= 0.559\n",
      "Epoch: 1540, Loss= 0.6758, Training Accuracy= 0.571\n",
      "Epoch: 1550, Loss= 0.6730, Training Accuracy= 0.576\n",
      "Epoch: 1560, Loss= 0.6761, Training Accuracy= 0.572\n",
      "Epoch: 1570, Loss= 0.6640, Training Accuracy= 0.591\n",
      "Epoch: 1580, Loss= 0.6723, Training Accuracy= 0.584\n",
      "Epoch: 1590, Loss= 0.6556, Training Accuracy= 0.601\n",
      "Epoch: 1600, Loss= 0.6544, Training Accuracy= 0.605\n",
      "Epoch: 1610, Loss= 0.6514, Training Accuracy= 0.607\n",
      "Epoch: 1620, Loss= 0.6439, Training Accuracy= 0.617\n",
      "Epoch: 1630, Loss= 0.6955, Training Accuracy= 0.515\n",
      "Epoch: 1640, Loss= 0.6877, Training Accuracy= 0.539\n",
      "Epoch: 1650, Loss= 0.6955, Training Accuracy= 0.508\n",
      "Epoch: 1660, Loss= 0.6959, Training Accuracy= 0.512\n",
      "Epoch: 1670, Loss= 0.6921, Training Accuracy= 0.523\n",
      "Epoch: 1680, Loss= 0.6911, Training Accuracy= 0.529\n",
      "Epoch: 1690, Loss= 0.6919, Training Accuracy= 0.529\n",
      "Epoch: 1700, Loss= 0.6904, Training Accuracy= 0.533\n",
      "Epoch: 1710, Loss= 0.6872, Training Accuracy= 0.544\n",
      "Epoch: 1720, Loss= 0.6844, Training Accuracy= 0.551\n",
      "Epoch: 1730, Loss= 0.6796, Training Accuracy= 0.557\n",
      "Epoch: 1740, Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 1750, Loss= 0.6936, Training Accuracy= 0.517\n",
      "Epoch: 1760, Loss= 0.6874, Training Accuracy= 0.540\n",
      "Epoch: 1770, Loss= 0.6827, Training Accuracy= 0.561\n",
      "Epoch: 1780, Loss= 0.6884, Training Accuracy= 0.543\n",
      "Epoch: 1790, Loss= 0.6778, Training Accuracy= 0.565\n",
      "Epoch: 1800, Loss= 0.6780, Training Accuracy= 0.562\n",
      "Epoch: 1810, Loss= 0.6709, Training Accuracy= 0.579\n",
      "Epoch: 1820, Loss= 0.6749, Training Accuracy= 0.574\n",
      "Epoch: 1830, Loss= 0.6660, Training Accuracy= 0.591\n",
      "Epoch: 1840, Loss= 0.6748, Training Accuracy= 0.573\n",
      "Epoch: 1850, Loss= 0.6721, Training Accuracy= 0.580\n",
      "Epoch: 1860, Loss= 0.6613, Training Accuracy= 0.590\n",
      "Epoch: 1870, Loss= 0.6708, Training Accuracy= 0.586\n",
      "Epoch: 1880, Loss= 0.6580, Training Accuracy= 0.603\n",
      "Epoch: 1890, Loss= 0.6553, Training Accuracy= 0.600\n",
      "Epoch: 1900, Loss= 0.6649, Training Accuracy= 0.596\n",
      "Epoch: 1910, Loss= 0.6557, Training Accuracy= 0.596\n",
      "Epoch: 1920, Loss= 0.6566, Training Accuracy= 0.602\n",
      "Epoch: 1930, Loss= 0.6906, Training Accuracy= 0.562\n",
      "Epoch: 1940, Loss= 0.6847, Training Accuracy= 0.553\n",
      "Epoch: 1950, Loss= 0.6711, Training Accuracy= 0.587\n",
      "Epoch: 1960, Loss= 0.6628, Training Accuracy= 0.586\n",
      "Epoch: 1970, Loss= 0.6676, Training Accuracy= 0.588\n",
      "Epoch: 1980, Loss= 0.6846, Training Accuracy= 0.545\n",
      "Epoch: 1990, Loss= 0.6641, Training Accuracy= 0.593\n",
      "Epoch: 2000, Loss= 0.6998, Training Accuracy= 0.560\n",
      "Epoch: 2010, Loss= 0.6457, Training Accuracy= 0.618\n",
      "Epoch: 2020, Loss= 0.6599, Training Accuracy= 0.603\n",
      "Epoch: 2030, Loss= 0.6613, Training Accuracy= 0.600\n",
      "Epoch: 2040, Loss= 0.6479, Training Accuracy= 0.616\n",
      "Epoch: 2050, Loss= 0.6992, Training Accuracy= 0.500\n",
      "Epoch: 2060, Loss= 0.6959, Training Accuracy= 0.507\n",
      "Epoch: 2070, Loss= 0.6943, Training Accuracy= 0.514\n",
      "Epoch: 2080, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 2090, Loss= 0.6883, Training Accuracy= 0.532\n",
      "Epoch: 2100, Loss= 0.6890, Training Accuracy= 0.535\n",
      "Epoch: 2110, Loss= 0.6842, Training Accuracy= 0.545\n",
      "Epoch: 2120, Loss= 0.6864, Training Accuracy= 0.540\n",
      "Epoch: 2130, Loss= 0.6910, Training Accuracy= 0.525\n",
      "Epoch: 2140, Loss= 0.6885, Training Accuracy= 0.528\n",
      "Epoch: 2150, Loss= 0.6868, Training Accuracy= 0.539\n",
      "Epoch: 2160, Loss= 0.6847, Training Accuracy= 0.544\n",
      "Epoch: 2170, Loss= 0.6846, Training Accuracy= 0.549\n",
      "Epoch: 2180, Loss= 0.6799, Training Accuracy= 0.556\n",
      "Epoch: 2190, Loss= 0.6745, Training Accuracy= 0.574\n",
      "Epoch: 2200, Loss= 0.6767, Training Accuracy= 0.563\n",
      "Epoch: 2210, Loss= 0.6734, Training Accuracy= 0.569\n",
      "Epoch: 2220, Loss= 0.6729, Training Accuracy= 0.568\n",
      "Epoch: 2230, Loss= 0.6716, Training Accuracy= 0.570\n",
      "Epoch: 2240, Loss= 0.6743, Training Accuracy= 0.574\n",
      "Epoch: 2250, Loss= 0.6665, Training Accuracy= 0.579\n",
      "Epoch: 2260, Loss= 0.6676, Training Accuracy= 0.580\n",
      "Epoch: 2270, Loss= 0.6700, Training Accuracy= 0.571\n",
      "Epoch: 2280, Loss= 0.6779, Training Accuracy= 0.571\n",
      "Epoch: 2290, Loss= 0.6628, Training Accuracy= 0.588\n",
      "Epoch: 2300, Loss= 0.7039, Training Accuracy= 0.550\n",
      "Epoch: 2310, Loss= 0.6685, Training Accuracy= 0.581\n",
      "Epoch: 2320, Loss= 0.6607, Training Accuracy= 0.591\n",
      "Epoch: 2330, Loss= 0.6619, Training Accuracy= 0.594\n",
      "Epoch: 2340, Loss= 0.6570, Training Accuracy= 0.590\n",
      "Epoch: 2350, Loss= 0.6689, Training Accuracy= 0.586\n",
      "Epoch: 2360, Loss= 0.6652, Training Accuracy= 0.590\n",
      "Epoch: 2370, Loss= 0.6599, Training Accuracy= 0.594\n",
      "Epoch: 2380, Loss= 0.6603, Training Accuracy= 0.594\n",
      "Epoch: 2390, Loss= 0.6626, Training Accuracy= 0.595\n",
      "Epoch: 2400, Loss= 0.6514, Training Accuracy= 0.607\n",
      "Epoch: 2410, Loss= 0.6501, Training Accuracy= 0.608\n",
      "Epoch: 2420, Loss= 0.6543, Training Accuracy= 0.604\n",
      "Epoch: 2430, Loss= 0.6750, Training Accuracy= 0.580\n",
      "Epoch: 2440, Loss= 0.6937, Training Accuracy= 0.556\n",
      "Epoch: 2450, Loss= 0.6627, Training Accuracy= 0.594\n",
      "Epoch: 2460, Loss= 0.6591, Training Accuracy= 0.600\n",
      "Epoch: 2470, Loss= 0.6443, Training Accuracy= 0.615\n",
      "Epoch: 2480, Loss= 0.6571, Training Accuracy= 0.600\n",
      "Epoch: 2490, Loss= 0.6454, Training Accuracy= 0.613\n",
      "Epoch: 2500, Loss= 0.6656, Training Accuracy= 0.592\n",
      "Epoch: 2510, Loss= 0.6851, Training Accuracy= 0.550\n",
      "Epoch: 2520, Loss= 0.6768, Training Accuracy= 0.567\n",
      "Epoch: 2530, Loss= 0.6722, Training Accuracy= 0.576\n",
      "Epoch: 2540, Loss= 0.6725, Training Accuracy= 0.583\n",
      "Epoch: 2550, Loss= 0.6641, Training Accuracy= 0.595\n",
      "Epoch: 2560, Loss= 0.6573, Training Accuracy= 0.604\n",
      "Epoch: 2570, Loss= 0.6571, Training Accuracy= 0.606\n",
      "Epoch: 2580, Loss= 0.6636, Training Accuracy= 0.592\n",
      "Epoch: 2590, Loss= 0.6555, Training Accuracy= 0.603\n",
      "Epoch: 2600, Loss= 0.6561, Training Accuracy= 0.597\n",
      "Epoch: 2610, Loss= 0.6441, Training Accuracy= 0.616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2620, Loss= 0.6452, Training Accuracy= 0.617\n",
      "Epoch: 2630, Loss= 0.6397, Training Accuracy= 0.629\n",
      "Epoch: 2640, Loss= 0.6580, Training Accuracy= 0.608\n",
      "Epoch: 2650, Loss= 0.6512, Training Accuracy= 0.612\n",
      "Epoch: 2660, Loss= 0.6494, Training Accuracy= 0.615\n",
      "Epoch: 2670, Loss= 0.6349, Training Accuracy= 0.632\n",
      "Epoch: 2680, Loss= 0.6542, Training Accuracy= 0.617\n",
      "Epoch: 2690, Loss= 0.6350, Training Accuracy= 0.629\n",
      "Epoch: 2700, Loss= 0.6374, Training Accuracy= 0.631\n",
      "Epoch: 2710, Loss= 0.6466, Training Accuracy= 0.614\n",
      "Epoch: 2720, Loss= 0.6324, Training Accuracy= 0.637\n",
      "Epoch: 2730, Loss= 0.6287, Training Accuracy= 0.638\n",
      "Epoch: 2740, Loss= 0.6279, Training Accuracy= 0.636\n",
      "Epoch: 2750, Loss= 0.6255, Training Accuracy= 0.641\n",
      "Epoch: 2760, Loss= 0.6633, Training Accuracy= 0.609\n",
      "Epoch: 2770, Loss= 0.6222, Training Accuracy= 0.641\n",
      "Epoch: 2780, Loss= 0.6766, Training Accuracy= 0.579\n",
      "Epoch: 2790, Loss= 0.6195, Training Accuracy= 0.653\n",
      "Epoch: 2800, Loss= 0.6303, Training Accuracy= 0.637\n",
      "Epoch: 2810, Loss= 0.6355, Training Accuracy= 0.632\n",
      "Epoch: 2820, Loss= 0.6521, Training Accuracy= 0.613\n",
      "Epoch: 2830, Loss= 0.6322, Training Accuracy= 0.639\n",
      "Epoch: 2840, Loss= 0.6915, Training Accuracy= 0.525\n",
      "Epoch: 2850, Loss= 0.6897, Training Accuracy= 0.538\n",
      "Epoch: 2860, Loss= 0.6845, Training Accuracy= 0.550\n",
      "Epoch: 2870, Loss= 0.6863, Training Accuracy= 0.549\n",
      "Epoch: 2880, Loss= 0.6782, Training Accuracy= 0.567\n",
      "Epoch: 2890, Loss= 0.6768, Training Accuracy= 0.570\n",
      "Epoch: 2900, Loss= 0.6901, Training Accuracy= 0.535\n",
      "Epoch: 2910, Loss= 0.6885, Training Accuracy= 0.541\n",
      "Epoch: 2920, Loss= 0.6866, Training Accuracy= 0.540\n",
      "Epoch: 2930, Loss= 0.6837, Training Accuracy= 0.550\n",
      "Epoch: 2940, Loss= 0.6782, Training Accuracy= 0.558\n",
      "Epoch: 2950, Loss= 0.6736, Training Accuracy= 0.575\n",
      "Epoch: 2960, Loss= 0.6885, Training Accuracy= 0.538\n",
      "Epoch: 2970, Loss= 0.6874, Training Accuracy= 0.546\n",
      "Epoch: 2980, Loss= 0.6833, Training Accuracy= 0.551\n",
      "Epoch: 2990, Loss= 0.6861, Training Accuracy= 0.549\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5048\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 0.6933, Training Accuracy= 0.496\n",
      "Epoch: 10, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 20, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 30, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 40, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 50, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 80, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 90, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.6928, Training Accuracy= 0.506\n",
      "Epoch: 110, Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 120, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 130, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 140, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 150, Loss= 0.6925, Training Accuracy= 0.511\n",
      "Epoch: 160, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 170, Loss= 0.6924, Training Accuracy= 0.512\n",
      "Epoch: 180, Loss= 0.6924, Training Accuracy= 0.513\n",
      "Epoch: 190, Loss= 0.6924, Training Accuracy= 0.517\n",
      "Epoch: 200, Loss= 0.6924, Training Accuracy= 0.517\n",
      "Epoch: 210, Loss= 0.6925, Training Accuracy= 0.516\n",
      "Epoch: 220, Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 230, Loss= 0.6926, Training Accuracy= 0.519\n",
      "Epoch: 240, Loss= 0.6927, Training Accuracy= 0.517\n",
      "Epoch: 250, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 260, Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 270, Loss= 0.6921, Training Accuracy= 0.518\n",
      "Epoch: 280, Loss= 0.6918, Training Accuracy= 0.520\n",
      "Epoch: 290, Loss= 0.6913, Training Accuracy= 0.523\n",
      "Epoch: 300, Loss= 0.6907, Training Accuracy= 0.526\n",
      "Epoch: 310, Loss= 0.6907, Training Accuracy= 0.530\n",
      "Epoch: 320, Loss= 0.6905, Training Accuracy= 0.529\n",
      "Epoch: 330, Loss= 0.6900, Training Accuracy= 0.530\n",
      "Epoch: 340, Loss= 0.6904, Training Accuracy= 0.529\n",
      "Epoch: 350, Loss= 0.6902, Training Accuracy= 0.533\n",
      "Epoch: 360, Loss= 0.6927, Training Accuracy= 0.526\n",
      "Epoch: 370, Loss= 0.6894, Training Accuracy= 0.537\n",
      "Epoch: 380, Loss= 0.6908, Training Accuracy= 0.526\n",
      "Epoch: 390, Loss= 0.6890, Training Accuracy= 0.535\n",
      "Epoch: 400, Loss= 0.6957, Training Accuracy= 0.517\n",
      "Epoch: 410, Loss= 0.6931, Training Accuracy= 0.524\n",
      "Epoch: 420, Loss= 0.6897, Training Accuracy= 0.537\n",
      "Epoch: 430, Loss= 0.6893, Training Accuracy= 0.538\n",
      "Epoch: 440, Loss= 0.6989, Training Accuracy= 0.518\n",
      "Epoch: 450, Loss= 0.6920, Training Accuracy= 0.537\n",
      "Epoch: 460, Loss= 0.6911, Training Accuracy= 0.542\n",
      "Epoch: 470, Loss= 0.7135, Training Accuracy= 0.505\n",
      "Epoch: 480, Loss= 0.6904, Training Accuracy= 0.528\n",
      "Epoch: 490, Loss= 0.6934, Training Accuracy= 0.533\n",
      "Epoch: 500, Loss= 0.6890, Training Accuracy= 0.547\n",
      "Epoch: 510, Loss= 0.6798, Training Accuracy= 0.562\n",
      "Epoch: 520, Loss= 0.7097, Training Accuracy= 0.518\n",
      "Epoch: 530, Loss= 0.6832, Training Accuracy= 0.562\n",
      "Epoch: 540, Loss= 0.6843, Training Accuracy= 0.561\n",
      "Epoch: 550, Loss= 0.6794, Training Accuracy= 0.569\n",
      "Epoch: 560, Loss= 0.6805, Training Accuracy= 0.571\n",
      "Epoch: 570, Loss= 0.6770, Training Accuracy= 0.579\n",
      "Epoch: 580, Loss= 0.6863, Training Accuracy= 0.544\n",
      "Epoch: 590, Loss= 0.6690, Training Accuracy= 0.590\n",
      "Epoch: 600, Loss= 0.7047, Training Accuracy= 0.557\n",
      "Epoch: 610, Loss= 0.6782, Training Accuracy= 0.580\n",
      "Epoch: 620, Loss= 0.6839, Training Accuracy= 0.581\n",
      "Epoch: 630, Loss= 0.6572, Training Accuracy= 0.606\n",
      "Epoch: 640, Loss= 0.7040, Training Accuracy= 0.506\n",
      "Epoch: 650, Loss= 0.6920, Training Accuracy= 0.529\n",
      "Epoch: 660, Loss= 0.6882, Training Accuracy= 0.539\n",
      "Epoch: 670, Loss= 0.6643, Training Accuracy= 0.593\n",
      "Epoch: 680, Loss= 0.6577, Training Accuracy= 0.615\n",
      "Epoch: 690, Loss= 0.6626, Training Accuracy= 0.603\n",
      "Epoch: 700, Loss= 0.6637, Training Accuracy= 0.599\n",
      "Epoch: 710, Loss= 0.6466, Training Accuracy= 0.619\n",
      "Epoch: 720, Loss= 0.6454, Training Accuracy= 0.617\n",
      "Epoch: 730, Loss= 0.6423, Training Accuracy= 0.627\n",
      "Epoch: 740, Loss= 0.6355, Training Accuracy= 0.638\n",
      "Epoch: 750, Loss= 0.6387, Training Accuracy= 0.633\n",
      "Epoch: 760, Loss= 0.6681, Training Accuracy= 0.595\n",
      "Epoch: 770, Loss= 0.6357, Training Accuracy= 0.636\n",
      "Epoch: 780, Loss= 0.6278, Training Accuracy= 0.644\n",
      "Epoch: 790, Loss= 0.6303, Training Accuracy= 0.640\n",
      "Epoch: 800, Loss= 0.6478, Training Accuracy= 0.626\n",
      "Epoch: 810, Loss= 0.6344, Training Accuracy= 0.638\n",
      "Epoch: 820, Loss= 0.6432, Training Accuracy= 0.625\n",
      "Epoch: 830, Loss= 0.6220, Training Accuracy= 0.645\n",
      "Epoch: 840, Loss= 0.6156, Training Accuracy= 0.657\n",
      "Epoch: 850, Loss= 0.6305, Training Accuracy= 0.642\n",
      "Epoch: 860, Loss= 0.7697, Training Accuracy= 0.510\n",
      "Epoch: 870, Loss= 0.6205, Training Accuracy= 0.651\n",
      "Epoch: 880, Loss= 0.6910, Training Accuracy= 0.529\n",
      "Epoch: 890, Loss= 0.6752, Training Accuracy= 0.571\n",
      "Epoch: 900, Loss= 0.6141, Training Accuracy= 0.662\n",
      "Epoch: 910, Loss= 0.7004, Training Accuracy= 0.520\n",
      "Epoch: 920, Loss= 0.6800, Training Accuracy= 0.562\n",
      "Epoch: 930, Loss= 0.6763, Training Accuracy= 0.568\n",
      "Epoch: 940, Loss= 0.6726, Training Accuracy= 0.574\n",
      "Epoch: 950, Loss= 0.6610, Training Accuracy= 0.600\n",
      "Epoch: 960, Loss= 0.6594, Training Accuracy= 0.601\n",
      "Epoch: 970, Loss= 0.6600, Training Accuracy= 0.595\n",
      "Epoch: 980, Loss= 0.6435, Training Accuracy= 0.624\n",
      "Epoch: 990, Loss= 0.6488, Training Accuracy= 0.618\n",
      "Epoch: 1000, Loss= 0.6239, Training Accuracy= 0.649\n",
      "Epoch: 1010, Loss= 0.6224, Training Accuracy= 0.647\n",
      "Epoch: 1020, Loss= 0.6318, Training Accuracy= 0.631\n",
      "Epoch: 1030, Loss= 0.6189, Training Accuracy= 0.649\n",
      "Epoch: 1040, Loss= 0.6530, Training Accuracy= 0.611\n",
      "Epoch: 1050, Loss= 0.6106, Training Accuracy= 0.658\n",
      "Epoch: 1060, Loss= 0.6170, Training Accuracy= 0.649\n",
      "Epoch: 1070, Loss= 0.6155, Training Accuracy= 0.655\n",
      "Epoch: 1080, Loss= 0.6272, Training Accuracy= 0.644\n",
      "Epoch: 1090, Loss= 0.5924, Training Accuracy= 0.675\n",
      "Epoch: 1100, Loss= 0.5983, Training Accuracy= 0.676\n",
      "Epoch: 1110, Loss= 0.6674, Training Accuracy= 0.595\n",
      "Epoch: 1120, Loss= 0.7113, Training Accuracy= 0.503\n",
      "Epoch: 1130, Loss= 0.6939, Training Accuracy= 0.514\n",
      "Epoch: 1140, Loss= 0.7005, Training Accuracy= 0.505\n",
      "Epoch: 1150, Loss= 0.6910, Training Accuracy= 0.531\n",
      "Epoch: 1160, Loss= 0.6865, Training Accuracy= 0.547\n",
      "Epoch: 1170, Loss= 0.6864, Training Accuracy= 0.546\n",
      "Epoch: 1180, Loss= 0.6794, Training Accuracy= 0.565\n",
      "Epoch: 1190, Loss= 0.6768, Training Accuracy= 0.570\n",
      "Epoch: 1200, Loss= 0.6763, Training Accuracy= 0.566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1210, Loss= 0.6742, Training Accuracy= 0.579\n",
      "Epoch: 1220, Loss= 0.6732, Training Accuracy= 0.581\n",
      "Epoch: 1230, Loss= 0.6590, Training Accuracy= 0.599\n",
      "Epoch: 1240, Loss= 0.6631, Training Accuracy= 0.589\n",
      "Epoch: 1250, Loss= 0.6482, Training Accuracy= 0.617\n",
      "Epoch: 1260, Loss= 0.6448, Training Accuracy= 0.621\n",
      "Epoch: 1270, Loss= 0.6542, Training Accuracy= 0.603\n",
      "Epoch: 1280, Loss= 0.6584, Training Accuracy= 0.609\n",
      "Epoch: 1290, Loss= 0.6776, Training Accuracy= 0.578\n",
      "Epoch: 1300, Loss= 0.6393, Training Accuracy= 0.628\n",
      "Epoch: 1310, Loss= 0.6769, Training Accuracy= 0.591\n",
      "Epoch: 1320, Loss= 0.6479, Training Accuracy= 0.620\n",
      "Epoch: 1330, Loss= 0.6464, Training Accuracy= 0.620\n",
      "Epoch: 1340, Loss= 0.6549, Training Accuracy= 0.613\n",
      "Epoch: 1350, Loss= 0.6355, Training Accuracy= 0.639\n",
      "Epoch: 1360, Loss= 0.6486, Training Accuracy= 0.615\n",
      "Epoch: 1370, Loss= 0.6383, Training Accuracy= 0.630\n",
      "Epoch: 1380, Loss= 0.6437, Training Accuracy= 0.622\n",
      "Epoch: 1390, Loss= 0.6332, Training Accuracy= 0.633\n",
      "Epoch: 1400, Loss= 0.6196, Training Accuracy= 0.652\n",
      "Epoch: 1410, Loss= 0.6405, Training Accuracy= 0.630\n",
      "Epoch: 1420, Loss= 0.6309, Training Accuracy= 0.638\n",
      "Epoch: 1430, Loss= 0.6265, Training Accuracy= 0.643\n",
      "Epoch: 1440, Loss= 0.6314, Training Accuracy= 0.635\n",
      "Epoch: 1450, Loss= 0.6225, Training Accuracy= 0.644\n",
      "Epoch: 1460, Loss= 0.6353, Training Accuracy= 0.634\n",
      "Epoch: 1470, Loss= 0.6197, Training Accuracy= 0.651\n",
      "Epoch: 1480, Loss= 0.6181, Training Accuracy= 0.653\n",
      "Epoch: 1490, Loss= 0.6257, Training Accuracy= 0.644\n",
      "Epoch: 1500, Loss= 0.6031, Training Accuracy= 0.667\n",
      "Epoch: 1510, Loss= 0.6510, Training Accuracy= 0.622\n",
      "Epoch: 1520, Loss= 0.6385, Training Accuracy= 0.627\n",
      "Epoch: 1530, Loss= 0.6158, Training Accuracy= 0.652\n",
      "Epoch: 1540, Loss= 0.6069, Training Accuracy= 0.660\n",
      "Epoch: 1550, Loss= 0.7270, Training Accuracy= 0.557\n",
      "Epoch: 1560, Loss= 0.6213, Training Accuracy= 0.649\n",
      "Epoch: 1570, Loss= 0.6134, Training Accuracy= 0.656\n",
      "Epoch: 1580, Loss= 0.6106, Training Accuracy= 0.660\n",
      "Epoch: 1590, Loss= 0.6161, Training Accuracy= 0.656\n",
      "Epoch: 1600, Loss= 0.6236, Training Accuracy= 0.650\n",
      "Epoch: 1610, Loss= 0.6087, Training Accuracy= 0.665\n",
      "Epoch: 1620, Loss= 0.6187, Training Accuracy= 0.654\n",
      "Epoch: 1630, Loss= 0.6080, Training Accuracy= 0.661\n",
      "Epoch: 1640, Loss= 0.5998, Training Accuracy= 0.672\n",
      "Epoch: 1650, Loss= 0.6322, Training Accuracy= 0.638\n",
      "Epoch: 1660, Loss= 0.6259, Training Accuracy= 0.647\n",
      "Epoch: 1670, Loss= 0.6084, Training Accuracy= 0.661\n",
      "Epoch: 1680, Loss= 0.6932, Training Accuracy= 0.529\n",
      "Epoch: 1690, Loss= 0.6781, Training Accuracy= 0.563\n",
      "Epoch: 1700, Loss= 0.6674, Training Accuracy= 0.582\n",
      "Epoch: 1710, Loss= 0.6651, Training Accuracy= 0.587\n",
      "Epoch: 1720, Loss= 0.6621, Training Accuracy= 0.590\n",
      "Epoch: 1730, Loss= 0.6504, Training Accuracy= 0.604\n",
      "Epoch: 1740, Loss= 0.6505, Training Accuracy= 0.603\n",
      "Epoch: 1750, Loss= 0.6453, Training Accuracy= 0.616\n",
      "Epoch: 1760, Loss= 0.6436, Training Accuracy= 0.618\n",
      "Epoch: 1770, Loss= 0.7171, Training Accuracy= 0.498\n",
      "Epoch: 1780, Loss= 0.6920, Training Accuracy= 0.516\n",
      "Epoch: 1790, Loss= 0.6891, Training Accuracy= 0.528\n",
      "Epoch: 1800, Loss= 0.6942, Training Accuracy= 0.513\n",
      "Epoch: 1810, Loss= 0.6873, Training Accuracy= 0.536\n",
      "Epoch: 1820, Loss= 0.6900, Training Accuracy= 0.534\n",
      "Epoch: 1830, Loss= 0.6843, Training Accuracy= 0.553\n",
      "Epoch: 1840, Loss= 0.6858, Training Accuracy= 0.548\n",
      "Epoch: 1850, Loss= 0.6801, Training Accuracy= 0.563\n",
      "Epoch: 1860, Loss= 0.6850, Training Accuracy= 0.555\n",
      "Epoch: 1870, Loss= 0.6767, Training Accuracy= 0.571\n",
      "Epoch: 1880, Loss= 0.6812, Training Accuracy= 0.566\n",
      "Epoch: 1890, Loss= 0.6831, Training Accuracy= 0.559\n",
      "Epoch: 1900, Loss= 0.6741, Training Accuracy= 0.578\n",
      "Epoch: 1910, Loss= 0.6733, Training Accuracy= 0.578\n",
      "Epoch: 1920, Loss= 0.6788, Training Accuracy= 0.572\n",
      "Epoch: 1930, Loss= 0.6744, Training Accuracy= 0.575\n",
      "Epoch: 1940, Loss= 0.6925, Training Accuracy= 0.556\n",
      "Epoch: 1950, Loss= 0.6744, Training Accuracy= 0.571\n",
      "Epoch: 1960, Loss= 0.6778, Training Accuracy= 0.562\n",
      "Epoch: 1970, Loss= 0.6796, Training Accuracy= 0.566\n",
      "Epoch: 1980, Loss= 0.6792, Training Accuracy= 0.570\n",
      "Epoch: 1990, Loss= 0.6704, Training Accuracy= 0.583\n",
      "Epoch: 2000, Loss= 0.6827, Training Accuracy= 0.568\n",
      "Epoch: 2010, Loss= 0.6744, Training Accuracy= 0.576\n",
      "Epoch: 2020, Loss= 0.6587, Training Accuracy= 0.593\n",
      "Epoch: 2030, Loss= 0.6633, Training Accuracy= 0.595\n",
      "Epoch: 2040, Loss= 0.6542, Training Accuracy= 0.602\n",
      "Epoch: 2050, Loss= 0.6791, Training Accuracy= 0.571\n",
      "Epoch: 2060, Loss= 0.6628, Training Accuracy= 0.590\n",
      "Epoch: 2070, Loss= 0.6499, Training Accuracy= 0.610\n",
      "Epoch: 2080, Loss= 0.6673, Training Accuracy= 0.581\n",
      "Epoch: 2090, Loss= 0.6863, Training Accuracy= 0.576\n",
      "Epoch: 2100, Loss= 0.6557, Training Accuracy= 0.607\n",
      "Epoch: 2110, Loss= 0.6906, Training Accuracy= 0.570\n",
      "Epoch: 2120, Loss= 0.6645, Training Accuracy= 0.591\n",
      "Epoch: 2130, Loss= 0.6610, Training Accuracy= 0.591\n",
      "Epoch: 2140, Loss= 0.6844, Training Accuracy= 0.562\n",
      "Epoch: 2150, Loss= 0.6447, Training Accuracy= 0.617\n",
      "Epoch: 2160, Loss= 0.6572, Training Accuracy= 0.602\n",
      "Epoch: 2170, Loss= 0.6489, Training Accuracy= 0.616\n",
      "Epoch: 2180, Loss= 0.6392, Training Accuracy= 0.625\n",
      "Epoch: 2190, Loss= 0.6605, Training Accuracy= 0.593\n",
      "Epoch: 2200, Loss= 0.6382, Training Accuracy= 0.629\n",
      "Epoch: 2210, Loss= 0.6361, Training Accuracy= 0.625\n",
      "Epoch: 2220, Loss= 0.6349, Training Accuracy= 0.633\n",
      "Epoch: 2230, Loss= 0.6430, Training Accuracy= 0.621\n",
      "Epoch: 2240, Loss= 0.6421, Training Accuracy= 0.618\n",
      "Epoch: 2250, Loss= 0.6229, Training Accuracy= 0.644\n",
      "Epoch: 2260, Loss= 0.6645, Training Accuracy= 0.593\n",
      "Epoch: 2270, Loss= 0.6248, Training Accuracy= 0.638\n",
      "Epoch: 2280, Loss= 0.6706, Training Accuracy= 0.582\n",
      "Epoch: 2290, Loss= 0.6352, Training Accuracy= 0.632\n",
      "Epoch: 2300, Loss= 0.6411, Training Accuracy= 0.620\n",
      "Epoch: 2310, Loss= 0.6371, Training Accuracy= 0.633\n",
      "Epoch: 2320, Loss= 0.6706, Training Accuracy= 0.581\n",
      "Epoch: 2330, Loss= 0.6989, Training Accuracy= 0.515\n",
      "Epoch: 2340, Loss= 0.6827, Training Accuracy= 0.548\n",
      "Epoch: 2350, Loss= 0.6812, Training Accuracy= 0.545\n",
      "Epoch: 2360, Loss= 0.6781, Training Accuracy= 0.558\n",
      "Epoch: 2370, Loss= 0.6952, Training Accuracy= 0.517\n",
      "Epoch: 2380, Loss= 0.6890, Training Accuracy= 0.528\n",
      "Epoch: 2390, Loss= 0.6881, Training Accuracy= 0.536\n",
      "Epoch: 2400, Loss= 0.6807, Training Accuracy= 0.548\n",
      "Epoch: 2410, Loss= 0.6787, Training Accuracy= 0.554\n",
      "Epoch: 2420, Loss= 0.6797, Training Accuracy= 0.548\n",
      "Epoch: 2430, Loss= 0.6754, Training Accuracy= 0.563\n",
      "Epoch: 2440, Loss= 0.6711, Training Accuracy= 0.571\n",
      "Epoch: 2450, Loss= 0.6735, Training Accuracy= 0.564\n",
      "Epoch: 2460, Loss= 0.6681, Training Accuracy= 0.570\n",
      "Epoch: 2470, Loss= 0.6752, Training Accuracy= 0.565\n",
      "Epoch: 2480, Loss= 0.6708, Training Accuracy= 0.566\n",
      "Epoch: 2490, Loss= 0.6754, Training Accuracy= 0.570\n",
      "Epoch: 2500, Loss= 0.6558, Training Accuracy= 0.593\n",
      "Epoch: 2510, Loss= 0.6718, Training Accuracy= 0.567\n",
      "Epoch: 2520, Loss= 0.6645, Training Accuracy= 0.577\n",
      "Epoch: 2530, Loss= 0.6995, Training Accuracy= 0.527\n",
      "Epoch: 2540, Loss= 0.6512, Training Accuracy= 0.600\n",
      "Epoch: 2550, Loss= 0.6721, Training Accuracy= 0.563\n",
      "Epoch: 2560, Loss= 0.6654, Training Accuracy= 0.572\n",
      "Epoch: 2570, Loss= 0.6559, Training Accuracy= 0.590\n",
      "Epoch: 2580, Loss= 0.6455, Training Accuracy= 0.601\n",
      "Epoch: 2590, Loss= 0.6525, Training Accuracy= 0.591\n",
      "Epoch: 2600, Loss= 0.6635, Training Accuracy= 0.580\n",
      "Epoch: 2610, Loss= 0.6552, Training Accuracy= 0.590\n",
      "Epoch: 2620, Loss= 0.6460, Training Accuracy= 0.605\n",
      "Epoch: 2630, Loss= 0.6493, Training Accuracy= 0.606\n",
      "Epoch: 2640, Loss= 0.6502, Training Accuracy= 0.603\n",
      "Epoch: 2650, Loss= 0.6524, Training Accuracy= 0.598\n",
      "Epoch: 2660, Loss= 0.6826, Training Accuracy= 0.546\n",
      "Epoch: 2670, Loss= 0.6521, Training Accuracy= 0.598\n",
      "Epoch: 2680, Loss= 0.6890, Training Accuracy= 0.526\n",
      "Epoch: 2690, Loss= 0.6811, Training Accuracy= 0.542\n",
      "Epoch: 2700, Loss= 0.6790, Training Accuracy= 0.550\n",
      "Epoch: 2710, Loss= 0.6512, Training Accuracy= 0.597\n",
      "Epoch: 2720, Loss= 0.6431, Training Accuracy= 0.599\n",
      "Epoch: 2730, Loss= 0.6420, Training Accuracy= 0.612\n",
      "Epoch: 2740, Loss= 0.6502, Training Accuracy= 0.602\n",
      "Epoch: 2750, Loss= 0.6309, Training Accuracy= 0.626\n",
      "Epoch: 2760, Loss= 0.6244, Training Accuracy= 0.632\n",
      "Epoch: 2770, Loss= 0.6273, Training Accuracy= 0.634\n",
      "Epoch: 2780, Loss= 0.6786, Training Accuracy= 0.586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2790, Loss= 0.6330, Training Accuracy= 0.621\n",
      "Epoch: 2800, Loss= 0.6205, Training Accuracy= 0.636\n",
      "Epoch: 2810, Loss= 0.6329, Training Accuracy= 0.622\n",
      "Epoch: 2820, Loss= 0.6283, Training Accuracy= 0.625\n",
      "Epoch: 2830, Loss= 0.6389, Training Accuracy= 0.615\n",
      "Epoch: 2840, Loss= 0.6293, Training Accuracy= 0.624\n",
      "Epoch: 2850, Loss= 0.6250, Training Accuracy= 0.632\n",
      "Epoch: 2860, Loss= 0.6500, Training Accuracy= 0.607\n",
      "Epoch: 2870, Loss= 0.6918, Training Accuracy= 0.544\n",
      "Epoch: 2880, Loss= 0.6708, Training Accuracy= 0.594\n",
      "Epoch: 2890, Loss= 0.6298, Training Accuracy= 0.621\n",
      "Epoch: 2900, Loss= 0.6441, Training Accuracy= 0.611\n",
      "Epoch: 2910, Loss= 0.6166, Training Accuracy= 0.638\n",
      "Epoch: 2920, Loss= 0.6751, Training Accuracy= 0.575\n",
      "Epoch: 2930, Loss= 0.6257, Training Accuracy= 0.630\n",
      "Epoch: 2940, Loss= 0.6599, Training Accuracy= 0.593\n",
      "Epoch: 2950, Loss= 0.6055, Training Accuracy= 0.647\n",
      "Epoch: 2960, Loss= 0.6900, Training Accuracy= 0.574\n",
      "Epoch: 2970, Loss= 0.6172, Training Accuracy= 0.644\n",
      "Epoch: 2980, Loss= 0.6191, Training Accuracy= 0.627\n",
      "Epoch: 2990, Loss= 0.6310, Training Accuracy= 0.628\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5059\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 10, Loss= 0.6983, Training Accuracy= 0.500\n",
      "Epoch: 20, Loss= 0.6975, Training Accuracy= 0.500\n",
      "Epoch: 30, Loss= 0.6971, Training Accuracy= 0.500\n",
      "Epoch: 40, Loss= 0.6969, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 0.6967, Training Accuracy= 0.500\n",
      "Epoch: 60, Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 100, Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 110, Loss= 0.6963, Training Accuracy= 0.500\n",
      "Epoch: 120, Loss= 0.6963, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 0.6963, Training Accuracy= 0.500\n",
      "Epoch: 140, Loss= 0.6963, Training Accuracy= 0.500\n",
      "Epoch: 150, Loss= 0.6963, Training Accuracy= 0.500\n",
      "Epoch: 160, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 190, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 200, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 210, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 220, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 230, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 250, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 260, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 270, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 280, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 290, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 300, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 310, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 320, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 330, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 340, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 350, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 360, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 370, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 380, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 390, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 400, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 410, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 420, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 430, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 440, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 450, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 460, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 470, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 480, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 490, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 500, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 510, Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 520, Loss= 0.6961, Training Accuracy= 0.500\n",
      "Epoch: 530, Loss= 0.6961, Training Accuracy= 0.500\n",
      "Epoch: 540, Loss= 0.6961, Training Accuracy= 0.500\n",
      "Epoch: 550, Loss= 0.6960, Training Accuracy= 0.500\n",
      "Epoch: 560, Loss= 0.6958, Training Accuracy= 0.500\n",
      "Epoch: 570, Loss= 0.6957, Training Accuracy= 0.500\n",
      "Epoch: 580, Loss= 0.6958, Training Accuracy= 0.503\n",
      "Epoch: 590, Loss= 0.6961, Training Accuracy= 0.503\n",
      "Epoch: 600, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 610, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 620, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 630, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 640, Loss= 0.6961, Training Accuracy= 0.507\n",
      "Epoch: 650, Loss= 0.6961, Training Accuracy= 0.509\n",
      "Epoch: 660, Loss= 0.6960, Training Accuracy= 0.509\n",
      "Epoch: 670, Loss= 0.6960, Training Accuracy= 0.509\n",
      "Epoch: 680, Loss= 0.6958, Training Accuracy= 0.512\n",
      "Epoch: 690, Loss= 0.6952, Training Accuracy= 0.513\n",
      "Epoch: 700, Loss= 0.6950, Training Accuracy= 0.518\n",
      "Epoch: 710, Loss= 0.6951, Training Accuracy= 0.516\n",
      "Epoch: 720, Loss= 0.6953, Training Accuracy= 0.518\n",
      "Epoch: 730, Loss= 0.6943, Training Accuracy= 0.521\n",
      "Epoch: 740, Loss= 0.6944, Training Accuracy= 0.524\n",
      "Epoch: 750, Loss= 0.6937, Training Accuracy= 0.526\n",
      "Epoch: 760, Loss= 0.6943, Training Accuracy= 0.524\n",
      "Epoch: 770, Loss= 0.6935, Training Accuracy= 0.529\n",
      "Epoch: 780, Loss= 0.6947, Training Accuracy= 0.528\n",
      "Epoch: 790, Loss= 0.6925, Training Accuracy= 0.531\n",
      "Epoch: 800, Loss= 0.6944, Training Accuracy= 0.532\n",
      "Epoch: 810, Loss= 0.6934, Training Accuracy= 0.533\n",
      "Epoch: 820, Loss= 0.6904, Training Accuracy= 0.539\n",
      "Epoch: 830, Loss= 0.6932, Training Accuracy= 0.536\n",
      "Epoch: 840, Loss= 0.6909, Training Accuracy= 0.541\n",
      "Epoch: 850, Loss= 0.6881, Training Accuracy= 0.551\n",
      "Epoch: 860, Loss= 0.6893, Training Accuracy= 0.546\n",
      "Epoch: 870, Loss= 0.6933, Training Accuracy= 0.540\n",
      "Epoch: 880, Loss= 0.6899, Training Accuracy= 0.545\n",
      "Epoch: 890, Loss= 0.6894, Training Accuracy= 0.555\n",
      "Epoch: 900, Loss= 0.6383, Training Accuracy= 0.600\n",
      "Epoch: 910, Loss= 0.6451, Training Accuracy= 0.649\n",
      "Epoch: 920, Loss= 0.2531, Training Accuracy= 0.842\n",
      "Epoch: 930, Loss= 0.1460, Training Accuracy= 0.921\n",
      "Epoch: 940, Loss= 0.4480, Training Accuracy= 0.736\n",
      "Epoch: 950, Loss= 0.2955, Training Accuracy= 0.841\n",
      "Epoch: 960, Loss= 0.2244, Training Accuracy= 0.887\n",
      "Epoch: 970, Loss= 0.0920, Training Accuracy= 0.962\n",
      "Epoch: 980, Loss= 0.8010, Training Accuracy= 0.500\n",
      "Epoch: 990, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 1000, Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 1010, Loss= 0.6997, Training Accuracy= 0.500\n",
      "Epoch: 1020, Loss= 0.7010, Training Accuracy= 0.500\n",
      "Epoch: 1030, Loss= 0.7016, Training Accuracy= 0.500\n",
      "Epoch: 1040, Loss= 0.7018, Training Accuracy= 0.500\n",
      "Epoch: 1050, Loss= 0.7020, Training Accuracy= 0.500\n",
      "Epoch: 1060, Loss= 0.7020, Training Accuracy= 0.500\n",
      "Epoch: 1070, Loss= 0.7020, Training Accuracy= 0.500\n",
      "Epoch: 1080, Loss= 0.7021, Training Accuracy= 0.500\n",
      "Epoch: 1090, Loss= 0.7021, Training Accuracy= 0.500\n",
      "Epoch: 1100, Loss= 0.7021, Training Accuracy= 0.500\n",
      "Epoch: 1110, Loss= 0.7022, Training Accuracy= 0.500\n",
      "Epoch: 1120, Loss= 0.7022, Training Accuracy= 0.500\n",
      "Epoch: 1130, Loss= 0.7022, Training Accuracy= 0.500\n",
      "Epoch: 1140, Loss= 0.7022, Training Accuracy= 0.500\n",
      "Epoch: 1150, Loss= 0.7021, Training Accuracy= 0.500\n",
      "Epoch: 1160, Loss= 0.7020, Training Accuracy= 0.500\n",
      "Epoch: 1170, Loss= 0.7018, Training Accuracy= 0.500\n",
      "Epoch: 1180, Loss= 0.7017, Training Accuracy= 0.500\n",
      "Epoch: 1190, Loss= 0.7016, Training Accuracy= 0.500\n",
      "Epoch: 1200, Loss= 0.7013, Training Accuracy= 0.500\n",
      "Epoch: 1210, Loss= 0.7016, Training Accuracy= 0.500\n",
      "Epoch: 1220, Loss= 0.7004, Training Accuracy= 0.503\n",
      "Epoch: 1230, Loss= 0.7013, Training Accuracy= 0.500\n",
      "Epoch: 1240, Loss= 0.7014, Training Accuracy= 0.502\n",
      "Epoch: 1250, Loss= 0.7001, Training Accuracy= 0.511\n",
      "Epoch: 1260, Loss= 0.6994, Training Accuracy= 0.502\n",
      "Epoch: 1270, Loss= 0.6985, Training Accuracy= 0.501\n",
      "Epoch: 1280, Loss= 0.6987, Training Accuracy= 0.502\n",
      "Epoch: 1290, Loss= 0.6985, Training Accuracy= 0.501\n",
      "Epoch: 1300, Loss= 0.6953, Training Accuracy= 0.503\n",
      "Epoch: 1310, Loss= 0.6987, Training Accuracy= 0.500\n",
      "Epoch: 1320, Loss= 0.6947, Training Accuracy= 0.506\n",
      "Epoch: 1330, Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 1340, Loss= 0.6943, Training Accuracy= 0.508\n",
      "Epoch: 1350, Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1360, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 1370, Loss= 0.6926, Training Accuracy= 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1380, Loss= 0.6936, Training Accuracy= 0.511\n",
      "Epoch: 1390, Loss= 0.6952, Training Accuracy= 0.510\n",
      "Epoch: 1400, Loss= 0.6959, Training Accuracy= 0.509\n",
      "Epoch: 1410, Loss= 0.6977, Training Accuracy= 0.508\n",
      "Epoch: 1420, Loss= 0.6912, Training Accuracy= 0.515\n",
      "Epoch: 1430, Loss= 0.6999, Training Accuracy= 0.509\n",
      "Epoch: 1440, Loss= 0.6882, Training Accuracy= 0.525\n",
      "Epoch: 1450, Loss= 0.6870, Training Accuracy= 0.527\n",
      "Epoch: 1460, Loss= 0.6850, Training Accuracy= 0.533\n",
      "Epoch: 1470, Loss= 0.6830, Training Accuracy= 0.536\n",
      "Epoch: 1480, Loss= 0.6834, Training Accuracy= 0.533\n",
      "Epoch: 1490, Loss= 0.6938, Training Accuracy= 0.515\n",
      "Epoch: 1500, Loss= 0.6930, Training Accuracy= 0.521\n",
      "Epoch: 1510, Loss= 0.6926, Training Accuracy= 0.520\n",
      "Epoch: 1520, Loss= 0.6922, Training Accuracy= 0.521\n",
      "Epoch: 1530, Loss= 0.6916, Training Accuracy= 0.522\n",
      "Epoch: 1540, Loss= 0.6904, Training Accuracy= 0.522\n",
      "Epoch: 1550, Loss= 0.6898, Training Accuracy= 0.526\n",
      "Epoch: 1560, Loss= 0.6899, Training Accuracy= 0.527\n",
      "Epoch: 1570, Loss= 0.6897, Training Accuracy= 0.530\n",
      "Epoch: 1580, Loss= 0.6888, Training Accuracy= 0.537\n",
      "Epoch: 1590, Loss= 0.6877, Training Accuracy= 0.543\n",
      "Epoch: 1600, Loss= 0.6869, Training Accuracy= 0.545\n",
      "Epoch: 1610, Loss= 0.6862, Training Accuracy= 0.544\n",
      "Epoch: 1620, Loss= 0.6854, Training Accuracy= 0.545\n",
      "Epoch: 1630, Loss= 0.6831, Training Accuracy= 0.555\n",
      "Epoch: 1640, Loss= 0.6816, Training Accuracy= 0.558\n",
      "Epoch: 1650, Loss= 0.6811, Training Accuracy= 0.555\n",
      "Epoch: 1660, Loss= 0.6796, Training Accuracy= 0.558\n",
      "Epoch: 1670, Loss= 0.6804, Training Accuracy= 0.553\n",
      "Epoch: 1680, Loss= 0.6803, Training Accuracy= 0.556\n",
      "Epoch: 1690, Loss= 0.6807, Training Accuracy= 0.557\n",
      "Epoch: 1700, Loss= 0.6760, Training Accuracy= 0.569\n",
      "Epoch: 1710, Loss= 0.6788, Training Accuracy= 0.566\n",
      "Epoch: 1720, Loss= 0.6722, Training Accuracy= 0.578\n",
      "Epoch: 1730, Loss= 0.6689, Training Accuracy= 0.584\n",
      "Epoch: 1740, Loss= 0.6260, Training Accuracy= 0.633\n",
      "Epoch: 1750, Loss= 0.6995, Training Accuracy= 0.500\n",
      "Epoch: 1760, Loss= 0.7030, Training Accuracy= 0.505\n",
      "Epoch: 1770, Loss= 0.7019, Training Accuracy= 0.514\n",
      "Epoch: 1780, Loss= 0.6836, Training Accuracy= 0.549\n",
      "Epoch: 1790, Loss= 0.5599, Training Accuracy= 0.682\n",
      "Epoch: 1800, Loss= 0.4879, Training Accuracy= 0.744\n",
      "Epoch: 1810, Loss= 0.4995, Training Accuracy= 0.694\n",
      "Epoch: 1820, Loss= 0.3012, Training Accuracy= 0.834\n",
      "Epoch: 1830, Loss= 0.6893, Training Accuracy= 0.522\n",
      "Epoch: 1840, Loss= 0.6717, Training Accuracy= 0.562\n",
      "Epoch: 1850, Loss= 0.3202, Training Accuracy= 0.819\n",
      "Epoch: 1860, Loss= 0.1804, Training Accuracy= 0.895\n",
      "Epoch: 1870, Loss= 0.1499, Training Accuracy= 0.919\n",
      "Epoch: 1880, Loss= 0.1073, Training Accuracy= 0.941\n",
      "Epoch: 1890, Loss= 0.0778, Training Accuracy= 0.957\n",
      "Epoch: 1900, Loss= 0.0650, Training Accuracy= 0.966\n",
      "Epoch: 1910, Loss= 0.0550, Training Accuracy= 0.971\n",
      "Epoch: 1920, Loss= 0.0185, Training Accuracy= 0.997\n",
      "Epoch: 1930, Loss= 0.1366, Training Accuracy= 0.939\n",
      "Epoch: 1940, Loss= 0.2951, Training Accuracy= 0.823\n",
      "Epoch: 1950, Loss= 0.2628, Training Accuracy= 0.849\n",
      "Epoch: 1960, Loss= 0.2289, Training Accuracy= 0.869\n",
      "Epoch: 1970, Loss= 0.5212, Training Accuracy= 0.791\n",
      "Epoch: 1980, Loss= 0.1087, Training Accuracy= 0.943\n",
      "Epoch: 1990, Loss= 0.0528, Training Accuracy= 0.980\n",
      "Epoch: 2000, Loss= 0.0040, Training Accuracy= 1.000\n",
      "Epoch: 2010, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2020, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2030, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2040, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2050, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2060, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2070, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2080, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2090, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2100, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2110, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2120, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2130, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2140, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2150, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2160, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2170, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2180, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2190, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2200, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2210, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2220, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2230, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2240, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2250, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2260, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2280, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.7035, Training Accuracy= 0.498\n",
      "Epoch: 10, Loss= 0.7004, Training Accuracy= 0.498\n",
      "Epoch: 20, Loss= 0.6986, Training Accuracy= 0.498\n",
      "Epoch: 30, Loss= 0.6978, Training Accuracy= 0.498\n",
      "Epoch: 40, Loss= 0.6974, Training Accuracy= 0.498\n",
      "Epoch: 50, Loss= 0.6971, Training Accuracy= 0.498\n",
      "Epoch: 60, Loss= 0.6968, Training Accuracy= 0.498\n",
      "Epoch: 70, Loss= 0.6967, Training Accuracy= 0.498\n",
      "Epoch: 80, Loss= 0.6965, Training Accuracy= 0.498\n",
      "Epoch: 90, Loss= 0.6964, Training Accuracy= 0.498\n",
      "Epoch: 100, Loss= 0.6963, Training Accuracy= 0.498\n",
      "Epoch: 110, Loss= 0.6963, Training Accuracy= 0.498\n",
      "Epoch: 120, Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 130, Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 140, Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 150, Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 160, Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 170, Loss= 0.6959, Training Accuracy= 0.498\n",
      "Epoch: 180, Loss= 0.6959, Training Accuracy= 0.498\n",
      "Epoch: 190, Loss= 0.6958, Training Accuracy= 0.498\n",
      "Epoch: 200, Loss= 0.6958, Training Accuracy= 0.498\n",
      "Epoch: 210, Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 220, Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 230, Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 240, Loss= 0.6956, Training Accuracy= 0.498\n",
      "Epoch: 250, Loss= 0.6956, Training Accuracy= 0.498\n",
      "Epoch: 260, Loss= 0.6955, Training Accuracy= 0.498\n",
      "Epoch: 270, Loss= 0.6955, Training Accuracy= 0.498\n",
      "Epoch: 280, Loss= 0.6955, Training Accuracy= 0.498\n",
      "Epoch: 290, Loss= 0.6954, Training Accuracy= 0.498\n",
      "Epoch: 300, Loss= 0.6954, Training Accuracy= 0.498\n",
      "Epoch: 310, Loss= 0.6953, Training Accuracy= 0.498\n",
      "Epoch: 320, Loss= 0.6953, Training Accuracy= 0.498\n",
      "Epoch: 330, Loss= 0.6953, Training Accuracy= 0.498\n",
      "Epoch: 340, Loss= 0.6952, Training Accuracy= 0.498\n",
      "Epoch: 350, Loss= 0.6952, Training Accuracy= 0.498\n",
      "Epoch: 360, Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 370, Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 380, Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 390, Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 400, Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 410, Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 420, Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 430, Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 440, Loss= 0.6950, Training Accuracy= 0.499\n",
      "Epoch: 450, Loss= 0.6950, Training Accuracy= 0.500\n",
      "Epoch: 460, Loss= 0.6950, Training Accuracy= 0.501\n",
      "Epoch: 470, Loss= 0.6950, Training Accuracy= 0.502\n",
      "Epoch: 480, Loss= 0.6950, Training Accuracy= 0.502\n",
      "Epoch: 490, Loss= 0.6950, Training Accuracy= 0.503\n",
      "Epoch: 500, Loss= 0.6951, Training Accuracy= 0.502\n",
      "Epoch: 510, Loss= 0.6951, Training Accuracy= 0.503\n",
      "Epoch: 520, Loss= 0.6951, Training Accuracy= 0.503\n",
      "Epoch: 530, Loss= 0.6951, Training Accuracy= 0.503\n",
      "Epoch: 540, Loss= 0.6951, Training Accuracy= 0.503\n",
      "Epoch: 550, Loss= 0.6952, Training Accuracy= 0.504\n",
      "Epoch: 560, Loss= 0.6952, Training Accuracy= 0.505\n",
      "Epoch: 570, Loss= 0.6952, Training Accuracy= 0.506\n",
      "Epoch: 580, Loss= 0.6952, Training Accuracy= 0.507\n",
      "Epoch: 590, Loss= 0.6952, Training Accuracy= 0.507\n",
      "Epoch: 600, Loss= 0.6952, Training Accuracy= 0.507\n",
      "Epoch: 610, Loss= 0.6952, Training Accuracy= 0.507\n",
      "Epoch: 620, Loss= 0.6951, Training Accuracy= 0.508\n",
      "Epoch: 630, Loss= 0.6951, Training Accuracy= 0.510\n",
      "Epoch: 640, Loss= 0.6950, Training Accuracy= 0.511\n",
      "Epoch: 650, Loss= 0.6949, Training Accuracy= 0.510\n",
      "Epoch: 660, Loss= 0.6946, Training Accuracy= 0.510\n",
      "Epoch: 670, Loss= 0.6944, Training Accuracy= 0.510\n",
      "Epoch: 680, Loss= 0.6941, Training Accuracy= 0.513\n",
      "Epoch: 690, Loss= 0.6939, Training Accuracy= 0.513\n",
      "Epoch: 700, Loss= 0.6938, Training Accuracy= 0.513\n",
      "Epoch: 710, Loss= 0.6936, Training Accuracy= 0.514\n",
      "Epoch: 720, Loss= 0.6935, Training Accuracy= 0.518\n",
      "Epoch: 730, Loss= 0.6934, Training Accuracy= 0.518\n",
      "Epoch: 740, Loss= 0.6933, Training Accuracy= 0.517\n",
      "Epoch: 750, Loss= 0.6931, Training Accuracy= 0.517\n",
      "Epoch: 760, Loss= 0.6930, Training Accuracy= 0.516\n",
      "Epoch: 770, Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 780, Loss= 0.6927, Training Accuracy= 0.518\n",
      "Epoch: 790, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 800, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 810, Loss= 0.6926, Training Accuracy= 0.520\n",
      "Epoch: 820, Loss= 0.6930, Training Accuracy= 0.521\n",
      "Epoch: 830, Loss= 0.6928, Training Accuracy= 0.521\n",
      "Epoch: 840, Loss= 0.6925, Training Accuracy= 0.524\n",
      "Epoch: 850, Loss= 0.6922, Training Accuracy= 0.527\n",
      "Epoch: 860, Loss= 0.6918, Training Accuracy= 0.528\n",
      "Epoch: 870, Loss= 0.6914, Training Accuracy= 0.530\n",
      "Epoch: 880, Loss= 0.6909, Training Accuracy= 0.530\n",
      "Epoch: 890, Loss= 0.6903, Training Accuracy= 0.531\n",
      "Epoch: 900, Loss= 0.6897, Training Accuracy= 0.535\n",
      "Epoch: 910, Loss= 0.6894, Training Accuracy= 0.534\n",
      "Epoch: 920, Loss= 0.6894, Training Accuracy= 0.535\n",
      "Epoch: 930, Loss= 0.6903, Training Accuracy= 0.531\n",
      "Epoch: 940, Loss= 0.6885, Training Accuracy= 0.536\n",
      "Epoch: 950, Loss= 0.6883, Training Accuracy= 0.536\n",
      "Epoch: 960, Loss= 0.6874, Training Accuracy= 0.540\n",
      "Epoch: 970, Loss= 0.6871, Training Accuracy= 0.544\n",
      "Epoch: 980, Loss= 0.6862, Training Accuracy= 0.549\n",
      "Epoch: 990, Loss= 0.6861, Training Accuracy= 0.550\n",
      "Epoch: 1000, Loss= 0.6851, Training Accuracy= 0.551\n",
      "Epoch: 1010, Loss= 0.6989, Training Accuracy= 0.511\n",
      "Epoch: 1020, Loss= 0.6955, Training Accuracy= 0.511\n",
      "Epoch: 1030, Loss= 0.6872, Training Accuracy= 0.545\n",
      "Epoch: 1040, Loss= 0.6838, Training Accuracy= 0.552\n",
      "Epoch: 1050, Loss= 0.6828, Training Accuracy= 0.558\n",
      "Epoch: 1060, Loss= 0.6822, Training Accuracy= 0.558\n",
      "Epoch: 1070, Loss= 0.6813, Training Accuracy= 0.559\n",
      "Epoch: 1080, Loss= 0.6801, Training Accuracy= 0.564\n",
      "Epoch: 1090, Loss= 0.6867, Training Accuracy= 0.552\n",
      "Epoch: 1100, Loss= 0.6832, Training Accuracy= 0.561\n",
      "Epoch: 1110, Loss= 0.6961, Training Accuracy= 0.512\n",
      "Epoch: 1120, Loss= 0.6949, Training Accuracy= 0.515\n",
      "Epoch: 1130, Loss= 0.6935, Training Accuracy= 0.523\n",
      "Epoch: 1140, Loss= 0.6916, Training Accuracy= 0.530\n",
      "Epoch: 1150, Loss= 0.6900, Training Accuracy= 0.536\n",
      "Epoch: 1160, Loss= 0.6904, Training Accuracy= 0.534\n",
      "Epoch: 1170, Loss= 0.6857, Training Accuracy= 0.548\n",
      "Epoch: 1180, Loss= 0.6981, Training Accuracy= 0.530\n",
      "Epoch: 1190, Loss= 0.6839, Training Accuracy= 0.554\n",
      "Epoch: 1200, Loss= 0.6844, Training Accuracy= 0.545\n",
      "Epoch: 1210, Loss= 0.6786, Training Accuracy= 0.567\n",
      "Epoch: 1220, Loss= 0.6838, Training Accuracy= 0.559\n",
      "Epoch: 1230, Loss= 0.6819, Training Accuracy= 0.566\n",
      "Epoch: 1240, Loss= 0.6784, Training Accuracy= 0.569\n",
      "Epoch: 1250, Loss= 0.6855, Training Accuracy= 0.556\n",
      "Epoch: 1260, Loss= 0.6800, Training Accuracy= 0.562\n",
      "Epoch: 1270, Loss= 0.6762, Training Accuracy= 0.569\n",
      "Epoch: 1280, Loss= 0.6784, Training Accuracy= 0.568\n",
      "Epoch: 1290, Loss= 0.6691, Training Accuracy= 0.585\n",
      "Epoch: 1300, Loss= 0.6675, Training Accuracy= 0.588\n",
      "Epoch: 1310, Loss= 0.6752, Training Accuracy= 0.575\n",
      "Epoch: 1320, Loss= 0.6830, Training Accuracy= 0.567\n",
      "Epoch: 1330, Loss= 0.6686, Training Accuracy= 0.591\n",
      "Epoch: 1340, Loss= 0.7008, Training Accuracy= 0.530\n",
      "Epoch: 1350, Loss= 0.7354, Training Accuracy= 0.508\n",
      "Epoch: 1360, Loss= 0.7061, Training Accuracy= 0.521\n",
      "Epoch: 1370, Loss= 0.6962, Training Accuracy= 0.537\n",
      "Epoch: 1380, Loss= 0.6985, Training Accuracy= 0.544\n",
      "Epoch: 1390, Loss= 0.6916, Training Accuracy= 0.550\n",
      "Epoch: 1400, Loss= 0.6913, Training Accuracy= 0.546\n",
      "Epoch: 1410, Loss= 0.6867, Training Accuracy= 0.562\n",
      "Epoch: 1420, Loss= 0.6790, Training Accuracy= 0.563\n",
      "Epoch: 1430, Loss= 0.6882, Training Accuracy= 0.554\n",
      "Epoch: 1440, Loss= 0.6860, Training Accuracy= 0.555\n",
      "Epoch: 1450, Loss= 0.7002, Training Accuracy= 0.526\n",
      "Epoch: 1460, Loss= 0.6836, Training Accuracy= 0.554\n",
      "Epoch: 1470, Loss= 0.6705, Training Accuracy= 0.578\n",
      "Epoch: 1480, Loss= 0.6690, Training Accuracy= 0.584\n",
      "Epoch: 1490, Loss= 0.6660, Training Accuracy= 0.584\n",
      "Epoch: 1500, Loss= 0.6653, Training Accuracy= 0.585\n",
      "Epoch: 1510, Loss= 0.6656, Training Accuracy= 0.583\n",
      "Epoch: 1520, Loss= 0.6771, Training Accuracy= 0.574\n",
      "Epoch: 1530, Loss= 0.6666, Training Accuracy= 0.591\n",
      "Epoch: 1540, Loss= 0.6535, Training Accuracy= 0.600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1550, Loss= 0.6792, Training Accuracy= 0.564\n",
      "Epoch: 1560, Loss= 0.6633, Training Accuracy= 0.588\n",
      "Epoch: 1570, Loss= 0.7318, Training Accuracy= 0.520\n",
      "Epoch: 1580, Loss= 0.7271, Training Accuracy= 0.530\n",
      "Epoch: 1590, Loss= 0.7184, Training Accuracy= 0.547\n",
      "Epoch: 1600, Loss= 0.6295, Training Accuracy= 0.645\n",
      "Epoch: 1610, Loss= 0.6963, Training Accuracy= 0.503\n",
      "Epoch: 1620, Loss= 0.6960, Training Accuracy= 0.507\n",
      "Epoch: 1630, Loss= 0.6949, Training Accuracy= 0.510\n",
      "Epoch: 1640, Loss= 0.7001, Training Accuracy= 0.499\n",
      "Epoch: 1650, Loss= 0.6975, Training Accuracy= 0.504\n",
      "Epoch: 1660, Loss= 0.6961, Training Accuracy= 0.506\n",
      "Epoch: 1670, Loss= 0.6952, Training Accuracy= 0.502\n",
      "Epoch: 1680, Loss= 0.6945, Training Accuracy= 0.508\n",
      "Epoch: 1690, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 1700, Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 1710, Loss= 0.6920, Training Accuracy= 0.523\n",
      "Epoch: 1720, Loss= 0.6921, Training Accuracy= 0.524\n",
      "Epoch: 1730, Loss= 0.6887, Training Accuracy= 0.535\n",
      "Epoch: 1740, Loss= 0.6921, Training Accuracy= 0.533\n",
      "Epoch: 1750, Loss= 0.6866, Training Accuracy= 0.545\n",
      "Epoch: 1760, Loss= 0.6896, Training Accuracy= 0.530\n",
      "Epoch: 1770, Loss= 0.6981, Training Accuracy= 0.533\n",
      "Epoch: 1780, Loss= 0.6837, Training Accuracy= 0.552\n",
      "Epoch: 1790, Loss= 0.6850, Training Accuracy= 0.553\n",
      "Epoch: 1800, Loss= 0.6909, Training Accuracy= 0.547\n",
      "Epoch: 1810, Loss= 0.6981, Training Accuracy= 0.541\n",
      "Epoch: 1820, Loss= 0.6964, Training Accuracy= 0.519\n",
      "Epoch: 1830, Loss= 0.6935, Training Accuracy= 0.517\n",
      "Epoch: 1840, Loss= 0.6911, Training Accuracy= 0.532\n",
      "Epoch: 1850, Loss= 0.6918, Training Accuracy= 0.531\n",
      "Epoch: 1860, Loss= 0.6946, Training Accuracy= 0.518\n",
      "Epoch: 1870, Loss= 0.6922, Training Accuracy= 0.530\n",
      "Epoch: 1880, Loss= 0.6960, Training Accuracy= 0.517\n",
      "Epoch: 1890, Loss= 0.6911, Training Accuracy= 0.532\n",
      "Epoch: 1900, Loss= 0.6893, Training Accuracy= 0.538\n",
      "Epoch: 1910, Loss= 0.6917, Training Accuracy= 0.530\n",
      "Epoch: 1920, Loss= 0.6873, Training Accuracy= 0.543\n",
      "Epoch: 1930, Loss= 0.6896, Training Accuracy= 0.540\n",
      "Epoch: 1940, Loss= 0.6896, Training Accuracy= 0.533\n",
      "Epoch: 1950, Loss= 0.6836, Training Accuracy= 0.555\n",
      "Epoch: 1960, Loss= 0.6943, Training Accuracy= 0.523\n",
      "Epoch: 1970, Loss= 0.6873, Training Accuracy= 0.544\n",
      "Epoch: 1980, Loss= 0.6849, Training Accuracy= 0.548\n",
      "Epoch: 1990, Loss= 0.6881, Training Accuracy= 0.548\n",
      "Epoch: 2000, Loss= 0.6878, Training Accuracy= 0.549\n",
      "Epoch: 2010, Loss= 0.6834, Training Accuracy= 0.554\n",
      "Epoch: 2020, Loss= 0.6946, Training Accuracy= 0.524\n",
      "Epoch: 2030, Loss= 0.6859, Training Accuracy= 0.546\n",
      "Epoch: 2040, Loss= 0.6866, Training Accuracy= 0.546\n",
      "Epoch: 2050, Loss= 0.6797, Training Accuracy= 0.564\n",
      "Epoch: 2060, Loss= 0.6790, Training Accuracy= 0.566\n",
      "Epoch: 2070, Loss= 0.6822, Training Accuracy= 0.563\n",
      "Epoch: 2080, Loss= 0.6755, Training Accuracy= 0.571\n",
      "Epoch: 2090, Loss= 0.6748, Training Accuracy= 0.572\n",
      "Epoch: 2100, Loss= 0.6796, Training Accuracy= 0.562\n",
      "Epoch: 2110, Loss= 0.6742, Training Accuracy= 0.569\n",
      "Epoch: 2120, Loss= 0.6750, Training Accuracy= 0.576\n",
      "Epoch: 2130, Loss= 0.6848, Training Accuracy= 0.544\n",
      "Epoch: 2140, Loss= 0.7576, Training Accuracy= 0.519\n",
      "Epoch: 2150, Loss= 0.7075, Training Accuracy= 0.500\n",
      "Epoch: 2160, Loss= 0.7064, Training Accuracy= 0.510\n",
      "Epoch: 2170, Loss= 0.7070, Training Accuracy= 0.525\n",
      "Epoch: 2180, Loss= 0.5602, Training Accuracy= 0.706\n",
      "Epoch: 2190, Loss= 0.4591, Training Accuracy= 0.746\n",
      "Epoch: 2200, Loss= 0.3009, Training Accuracy= 0.837\n",
      "Epoch: 2210, Loss= 0.2165, Training Accuracy= 0.886\n",
      "Epoch: 2220, Loss= 0.1768, Training Accuracy= 0.916\n",
      "Epoch: 2230, Loss= 0.1745, Training Accuracy= 0.922\n",
      "Epoch: 2240, Loss= 0.2606, Training Accuracy= 0.877\n",
      "Epoch: 2250, Loss= 0.0825, Training Accuracy= 0.967\n",
      "Epoch: 2260, Loss= 0.0087, Training Accuracy= 0.999\n",
      "Epoch: 2270, Loss= 0.2763, Training Accuracy= 0.828\n",
      "Epoch: 2280, Loss= 0.5693, Training Accuracy= 0.744\n",
      "Epoch: 2290, Loss= 0.6195, Training Accuracy= 0.748\n",
      "Epoch: 2300, Loss= 0.2379, Training Accuracy= 0.888\n",
      "Epoch: 2310, Loss= 0.3380, Training Accuracy= 0.806\n",
      "Epoch: 2320, Loss= 0.2848, Training Accuracy= 0.868\n",
      "Epoch: 2330, Loss= 0.2412, Training Accuracy= 0.884\n",
      "Epoch: 2340, Loss= 0.3934, Training Accuracy= 0.848\n",
      "Epoch: 2350, Loss= 0.2858, Training Accuracy= 0.899\n",
      "Epoch: 2360, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.85\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 3000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [0.99839997, 0.49349999, 1.0, 0.4962, 0.5, 0.50590003, 0.50480002, 0.50590003, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  0.70047\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.00244268238544\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlOcjrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f3b5c8510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
