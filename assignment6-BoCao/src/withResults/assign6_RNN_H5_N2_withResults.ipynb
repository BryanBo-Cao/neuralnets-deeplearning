{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 2\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.8956, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 0.8094, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.7650, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.7369, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.7197, Training Accuracy= 0.497\n",
      "Epoch: 50, Loss= 0.7096, Training Accuracy= 0.497\n",
      "Epoch: 60, Loss= 0.7036, Training Accuracy= 0.497\n",
      "Epoch: 70, Loss= 0.7000, Training Accuracy= 0.497\n",
      "Epoch: 80, Loss= 0.6977, Training Accuracy= 0.497\n",
      "Epoch: 90, Loss= 0.6962, Training Accuracy= 0.251\n",
      "Epoch: 100, Loss= 0.6951, Training Accuracy= 0.251\n",
      "Epoch: 110, Loss= 0.6943, Training Accuracy= 0.502\n",
      "Epoch: 120, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 130, Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 0.6925, Training Accuracy= 0.502\n",
      "Epoch: 150, Loss= 0.6919, Training Accuracy= 0.502\n",
      "Epoch: 160, Loss= 0.6914, Training Accuracy= 0.502\n",
      "Epoch: 170, Loss= 0.6909, Training Accuracy= 0.502\n",
      "Epoch: 180, Loss= 0.6904, Training Accuracy= 0.502\n",
      "Epoch: 190, Loss= 0.6899, Training Accuracy= 0.502\n",
      "Epoch: 200, Loss= 0.6894, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.6889, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.6883, Training Accuracy= 0.502\n",
      "Epoch: 230, Loss= 0.6878, Training Accuracy= 0.502\n",
      "Epoch: 240, Loss= 0.6872, Training Accuracy= 0.502\n",
      "Epoch: 250, Loss= 0.6866, Training Accuracy= 0.502\n",
      "Epoch: 260, Loss= 0.6860, Training Accuracy= 0.502\n",
      "Epoch: 270, Loss= 0.6853, Training Accuracy= 0.502\n",
      "Epoch: 280, Loss= 0.6846, Training Accuracy= 0.502\n",
      "Epoch: 290, Loss= 0.6839, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 0.6832, Training Accuracy= 0.502\n",
      "Epoch: 310, Loss= 0.6823, Training Accuracy= 0.502\n",
      "Epoch: 320, Loss= 0.6815, Training Accuracy= 0.502\n",
      "Epoch: 330, Loss= 0.6805, Training Accuracy= 0.502\n",
      "Epoch: 340, Loss= 0.6795, Training Accuracy= 0.502\n",
      "Epoch: 350, Loss= 0.6784, Training Accuracy= 0.502\n",
      "Epoch: 360, Loss= 0.6772, Training Accuracy= 0.502\n",
      "Epoch: 370, Loss= 0.6759, Training Accuracy= 0.502\n",
      "Epoch: 380, Loss= 0.6744, Training Accuracy= 0.502\n",
      "Epoch: 390, Loss= 0.6729, Training Accuracy= 0.502\n",
      "Epoch: 400, Loss= 0.6711, Training Accuracy= 0.502\n",
      "Epoch: 410, Loss= 0.6692, Training Accuracy= 0.502\n",
      "Epoch: 420, Loss= 0.6671, Training Accuracy= 0.502\n",
      "Epoch: 430, Loss= 0.6647, Training Accuracy= 0.502\n",
      "Epoch: 440, Loss= 0.6621, Training Accuracy= 0.502\n",
      "Epoch: 450, Loss= 0.6593, Training Accuracy= 0.502\n",
      "Epoch: 460, Loss= 0.6561, Training Accuracy= 0.502\n",
      "Epoch: 470, Loss= 0.6526, Training Accuracy= 0.502\n",
      "Epoch: 480, Loss= 0.6487, Training Accuracy= 0.502\n",
      "Epoch: 490, Loss= 0.6445, Training Accuracy= 0.502\n",
      "Epoch: 500, Loss= 0.6399, Training Accuracy= 0.502\n",
      "Epoch: 510, Loss= 0.6349, Training Accuracy= 0.502\n",
      "Epoch: 520, Loss= 0.6296, Training Accuracy= 0.502\n",
      "Epoch: 530, Loss= 0.6239, Training Accuracy= 0.502\n",
      "Epoch: 540, Loss= 0.6178, Training Accuracy= 0.502\n",
      "Epoch: 550, Loss= 0.6114, Training Accuracy= 0.502\n",
      "Epoch: 560, Loss= 0.6048, Training Accuracy= 0.502\n",
      "Epoch: 570, Loss= 0.5978, Training Accuracy= 0.502\n",
      "Epoch: 580, Loss= 0.5906, Training Accuracy= 0.749\n",
      "Epoch: 590, Loss= 0.5831, Training Accuracy= 0.749\n",
      "Epoch: 600, Loss= 0.5754, Training Accuracy= 0.749\n",
      "Epoch: 610, Loss= 0.5675, Training Accuracy= 0.749\n",
      "Epoch: 620, Loss= 0.5593, Training Accuracy= 0.749\n",
      "Epoch: 630, Loss= 0.5508, Training Accuracy= 0.749\n",
      "Epoch: 640, Loss= 0.5421, Training Accuracy= 0.749\n",
      "Epoch: 650, Loss= 0.5331, Training Accuracy= 0.749\n",
      "Epoch: 660, Loss= 0.5239, Training Accuracy= 0.749\n",
      "Epoch: 670, Loss= 0.5144, Training Accuracy= 0.749\n",
      "Epoch: 680, Loss= 0.5046, Training Accuracy= 0.749\n",
      "Epoch: 690, Loss= 0.4945, Training Accuracy= 0.749\n",
      "Epoch: 700, Loss= 0.4842, Training Accuracy= 0.749\n",
      "Epoch: 710, Loss= 0.4736, Training Accuracy= 0.749\n",
      "Epoch: 720, Loss= 0.4628, Training Accuracy= 0.749\n",
      "Epoch: 730, Loss= 0.4518, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.4406, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.4293, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.4180, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.4066, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.3952, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.3838, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.3725, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.3614, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.3504, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.3396, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.3290, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.3187, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.3086, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.2988, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.2893, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.2800, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.2711, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.2625, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.2542, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.2462, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.2385, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.2311, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.2240, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.2172, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.2107, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.2045, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1985, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1929, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1874, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1823, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1773, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1726, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1681, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1637, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1596, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1557, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1519, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1483, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1448, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1415, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1384, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.1353, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.1324, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.1296, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.1269, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.1243, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.1218, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1194, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1171, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1149, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1128, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1107, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1087, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1068, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1049, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1031, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.1014, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0997, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0981, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0965, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0950, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0935, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0921, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0907, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0893, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0880, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0867, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0855, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0843, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0831, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0820, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0809, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0798, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0787, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0777, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0767, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.9821, Training Accuracy= 0.498\n",
      "Epoch: 10, Loss= 0.9026, Training Accuracy= 0.498\n",
      "Epoch: 20, Loss= 0.8542, Training Accuracy= 0.498\n",
      "Epoch: 30, Loss= 0.8205, Training Accuracy= 0.498\n",
      "Epoch: 40, Loss= 0.7951, Training Accuracy= 0.498\n",
      "Epoch: 50, Loss= 0.7751, Training Accuracy= 0.498\n",
      "Epoch: 60, Loss= 0.7592, Training Accuracy= 0.498\n",
      "Epoch: 70, Loss= 0.7464, Training Accuracy= 0.498\n",
      "Epoch: 80, Loss= 0.7361, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Loss= 0.7278, Training Accuracy= 0.498\n",
      "Epoch: 100, Loss= 0.7210, Training Accuracy= 0.498\n",
      "Epoch: 110, Loss= 0.7155, Training Accuracy= 0.498\n",
      "Epoch: 120, Loss= 0.7109, Training Accuracy= 0.498\n",
      "Epoch: 130, Loss= 0.7070, Training Accuracy= 0.498\n",
      "Epoch: 140, Loss= 0.7037, Training Accuracy= 0.498\n",
      "Epoch: 150, Loss= 0.7009, Training Accuracy= 0.498\n",
      "Epoch: 160, Loss= 0.6985, Training Accuracy= 0.498\n",
      "Epoch: 170, Loss= 0.6964, Training Accuracy= 0.498\n",
      "Epoch: 180, Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 190, Loss= 0.6929, Training Accuracy= 0.498\n",
      "Epoch: 200, Loss= 0.6914, Training Accuracy= 0.498\n",
      "Epoch: 210, Loss= 0.6900, Training Accuracy= 0.498\n",
      "Epoch: 220, Loss= 0.6887, Training Accuracy= 0.498\n",
      "Epoch: 230, Loss= 0.6875, Training Accuracy= 0.498\n",
      "Epoch: 240, Loss= 0.6864, Training Accuracy= 0.498\n",
      "Epoch: 250, Loss= 0.6853, Training Accuracy= 0.498\n",
      "Epoch: 260, Loss= 0.6843, Training Accuracy= 0.498\n",
      "Epoch: 270, Loss= 0.6833, Training Accuracy= 0.498\n",
      "Epoch: 280, Loss= 0.6823, Training Accuracy= 0.498\n",
      "Epoch: 290, Loss= 0.6814, Training Accuracy= 0.498\n",
      "Epoch: 300, Loss= 0.6804, Training Accuracy= 0.498\n",
      "Epoch: 310, Loss= 0.6795, Training Accuracy= 0.498\n",
      "Epoch: 320, Loss= 0.6785, Training Accuracy= 0.498\n",
      "Epoch: 330, Loss= 0.6775, Training Accuracy= 0.498\n",
      "Epoch: 340, Loss= 0.6765, Training Accuracy= 0.498\n",
      "Epoch: 350, Loss= 0.6755, Training Accuracy= 0.498\n",
      "Epoch: 360, Loss= 0.6745, Training Accuracy= 0.498\n",
      "Epoch: 370, Loss= 0.6734, Training Accuracy= 0.498\n",
      "Epoch: 380, Loss= 0.6722, Training Accuracy= 0.498\n",
      "Epoch: 390, Loss= 0.6710, Training Accuracy= 0.498\n",
      "Epoch: 400, Loss= 0.6698, Training Accuracy= 0.498\n",
      "Epoch: 410, Loss= 0.6685, Training Accuracy= 0.498\n",
      "Epoch: 420, Loss= 0.6671, Training Accuracy= 0.498\n",
      "Epoch: 430, Loss= 0.6657, Training Accuracy= 0.498\n",
      "Epoch: 440, Loss= 0.6642, Training Accuracy= 0.498\n",
      "Epoch: 450, Loss= 0.6626, Training Accuracy= 0.498\n",
      "Epoch: 460, Loss= 0.6609, Training Accuracy= 0.498\n",
      "Epoch: 470, Loss= 0.6591, Training Accuracy= 0.498\n",
      "Epoch: 480, Loss= 0.6572, Training Accuracy= 0.498\n",
      "Epoch: 490, Loss= 0.6553, Training Accuracy= 0.498\n",
      "Epoch: 500, Loss= 0.6531, Training Accuracy= 0.498\n",
      "Epoch: 510, Loss= 0.6509, Training Accuracy= 0.498\n",
      "Epoch: 520, Loss= 0.6485, Training Accuracy= 0.498\n",
      "Epoch: 530, Loss= 0.6460, Training Accuracy= 0.498\n",
      "Epoch: 540, Loss= 0.6433, Training Accuracy= 0.498\n",
      "Epoch: 550, Loss= 0.6404, Training Accuracy= 0.498\n",
      "Epoch: 560, Loss= 0.6374, Training Accuracy= 0.498\n",
      "Epoch: 570, Loss= 0.6342, Training Accuracy= 0.498\n",
      "Epoch: 580, Loss= 0.6307, Training Accuracy= 0.498\n",
      "Epoch: 590, Loss= 0.6271, Training Accuracy= 0.498\n",
      "Epoch: 600, Loss= 0.6232, Training Accuracy= 0.498\n",
      "Epoch: 610, Loss= 0.6191, Training Accuracy= 0.498\n",
      "Epoch: 620, Loss= 0.6148, Training Accuracy= 0.498\n",
      "Epoch: 630, Loss= 0.6102, Training Accuracy= 0.749\n",
      "Epoch: 640, Loss= 0.6054, Training Accuracy= 0.749\n",
      "Epoch: 650, Loss= 0.6002, Training Accuracy= 0.749\n",
      "Epoch: 660, Loss= 0.5948, Training Accuracy= 0.749\n",
      "Epoch: 670, Loss= 0.5891, Training Accuracy= 0.749\n",
      "Epoch: 680, Loss= 0.5831, Training Accuracy= 0.749\n",
      "Epoch: 690, Loss= 0.5769, Training Accuracy= 0.749\n",
      "Epoch: 700, Loss= 0.5703, Training Accuracy= 0.749\n",
      "Epoch: 710, Loss= 0.5634, Training Accuracy= 0.749\n",
      "Epoch: 720, Loss= 0.5562, Training Accuracy= 0.749\n",
      "Epoch: 730, Loss= 0.5487, Training Accuracy= 0.749\n",
      "Epoch: 740, Loss= 0.5410, Training Accuracy= 0.749\n",
      "Epoch: 750, Loss= 0.5329, Training Accuracy= 0.749\n",
      "Epoch: 760, Loss= 0.5246, Training Accuracy= 0.749\n",
      "Epoch: 770, Loss= 0.5161, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.5073, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.4983, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.4891, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.4798, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.4703, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.4607, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.4510, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.4412, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.4314, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.4216, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.4118, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.4021, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.3925, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.3829, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.3734, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.3641, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.3550, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.3460, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.3372, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.3286, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.3201, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.3119, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.3039, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.2961, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.2886, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.2812, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.2741, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.2671, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.2604, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.2539, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.2476, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.2415, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.2357, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.2300, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.2244, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.2191, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.2139, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.2090, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.2041, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.1995, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.1950, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.1906, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.1864, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1823, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1784, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1746, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1709, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1673, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1638, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1605, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1572, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1541, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.1511, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.1481, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.1453, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.1425, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.1398, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.1372, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.1347, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.1322, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.1298, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.1275, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.1253, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.1231, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.1210, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.1189, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.1169, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.1150, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.1131, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.1112, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.1094, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.1077, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.7333, Training Accuracy= 0.504\n",
      "Epoch: 10, Loss= 0.7124, Training Accuracy= 0.504\n",
      "Epoch: 20, Loss= 0.7030, Training Accuracy= 0.504\n",
      "Epoch: 30, Loss= 0.6985, Training Accuracy= 0.504\n",
      "Epoch: 40, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 50, Loss= 0.6947, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6936, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6928, Training Accuracy= 0.504\n",
      "Epoch: 80, Loss= 0.6920, Training Accuracy= 0.504\n",
      "Epoch: 90, Loss= 0.6913, Training Accuracy= 0.504\n",
      "Epoch: 100, Loss= 0.6907, Training Accuracy= 0.504\n",
      "Epoch: 110, Loss= 0.6900, Training Accuracy= 0.504\n",
      "Epoch: 120, Loss= 0.6894, Training Accuracy= 0.504\n",
      "Epoch: 130, Loss= 0.6887, Training Accuracy= 0.504\n",
      "Epoch: 140, Loss= 0.6881, Training Accuracy= 0.504\n",
      "Epoch: 150, Loss= 0.6874, Training Accuracy= 0.504\n",
      "Epoch: 160, Loss= 0.6867, Training Accuracy= 0.504\n",
      "Epoch: 170, Loss= 0.6859, Training Accuracy= 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, Loss= 0.6852, Training Accuracy= 0.504\n",
      "Epoch: 190, Loss= 0.6843, Training Accuracy= 0.504\n",
      "Epoch: 200, Loss= 0.6835, Training Accuracy= 0.504\n",
      "Epoch: 210, Loss= 0.6825, Training Accuracy= 0.504\n",
      "Epoch: 220, Loss= 0.6815, Training Accuracy= 0.504\n",
      "Epoch: 230, Loss= 0.6805, Training Accuracy= 0.504\n",
      "Epoch: 240, Loss= 0.6793, Training Accuracy= 0.504\n",
      "Epoch: 250, Loss= 0.6780, Training Accuracy= 0.504\n",
      "Epoch: 260, Loss= 0.6767, Training Accuracy= 0.504\n",
      "Epoch: 270, Loss= 0.6752, Training Accuracy= 0.504\n",
      "Epoch: 280, Loss= 0.6735, Training Accuracy= 0.504\n",
      "Epoch: 290, Loss= 0.6716, Training Accuracy= 0.504\n",
      "Epoch: 300, Loss= 0.6696, Training Accuracy= 0.504\n",
      "Epoch: 310, Loss= 0.6673, Training Accuracy= 0.504\n",
      "Epoch: 320, Loss= 0.6647, Training Accuracy= 0.504\n",
      "Epoch: 330, Loss= 0.6619, Training Accuracy= 0.504\n",
      "Epoch: 340, Loss= 0.6586, Training Accuracy= 0.504\n",
      "Epoch: 350, Loss= 0.6550, Training Accuracy= 0.752\n",
      "Epoch: 360, Loss= 0.6508, Training Accuracy= 0.752\n",
      "Epoch: 370, Loss= 0.6461, Training Accuracy= 0.752\n",
      "Epoch: 380, Loss= 0.6407, Training Accuracy= 0.752\n",
      "Epoch: 390, Loss= 0.6347, Training Accuracy= 0.752\n",
      "Epoch: 400, Loss= 0.6277, Training Accuracy= 0.752\n",
      "Epoch: 410, Loss= 0.6199, Training Accuracy= 0.752\n",
      "Epoch: 420, Loss= 0.6111, Training Accuracy= 0.752\n",
      "Epoch: 430, Loss= 0.6012, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5903, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5782, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5651, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5508, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5355, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5193, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.5021, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.4842, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.4656, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.4465, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.4269, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.4072, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.3875, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.3680, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.3488, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.3302, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.3122, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.2950, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.2786, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.2632, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.2486, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.2350, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.2223, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.2105, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.1996, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.1894, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.1800, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.1712, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.1631, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.1556, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.1486, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.1422, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.1362, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.1306, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.1253, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.1205, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.1159, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.1117, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.1077, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.1040, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.1005, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0972, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0941, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0911, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0884, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0858, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0833, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0809, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0787, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0766, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0746, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0727, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0709, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0691, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0675, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0659, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0644, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0629, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0615, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0602, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0589, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0577, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0565, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0554, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0543, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0533, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0523, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0513, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0504, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0494, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0486, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0477, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0469, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0461, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0454, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0446, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0439, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0432, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0425, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0419, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0412, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0406, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0400, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0394, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0389, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0383, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0378, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0373, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0368, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0363, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0358, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0353, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0349, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0344, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0340, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0336, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0332, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0328, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0324, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0320, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0316, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0312, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0309, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0305, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0302, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0298, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.6881, Training Accuracy= 0.749\n",
      "Epoch: 10, Loss= 0.6692, Training Accuracy= 0.749\n",
      "Epoch: 20, Loss= 0.6563, Training Accuracy= 0.749\n",
      "Epoch: 30, Loss= 0.6467, Training Accuracy= 0.499\n",
      "Epoch: 40, Loss= 0.6389, Training Accuracy= 0.499\n",
      "Epoch: 50, Loss= 0.6324, Training Accuracy= 0.499\n",
      "Epoch: 60, Loss= 0.6266, Training Accuracy= 0.499\n",
      "Epoch: 70, Loss= 0.6215, Training Accuracy= 0.499\n",
      "Epoch: 80, Loss= 0.6167, Training Accuracy= 0.499\n",
      "Epoch: 90, Loss= 0.6122, Training Accuracy= 0.499\n",
      "Epoch: 100, Loss= 0.6079, Training Accuracy= 0.499\n",
      "Epoch: 110, Loss= 0.6037, Training Accuracy= 0.499\n",
      "Epoch: 120, Loss= 0.5996, Training Accuracy= 0.499\n",
      "Epoch: 130, Loss= 0.5955, Training Accuracy= 0.499\n",
      "Epoch: 140, Loss= 0.5914, Training Accuracy= 0.499\n",
      "Epoch: 150, Loss= 0.5873, Training Accuracy= 0.499\n",
      "Epoch: 160, Loss= 0.5832, Training Accuracy= 0.499\n",
      "Epoch: 170, Loss= 0.5790, Training Accuracy= 0.499\n",
      "Epoch: 180, Loss= 0.5748, Training Accuracy= 0.499\n",
      "Epoch: 190, Loss= 0.5705, Training Accuracy= 0.749\n",
      "Epoch: 200, Loss= 0.5661, Training Accuracy= 0.749\n",
      "Epoch: 210, Loss= 0.5617, Training Accuracy= 0.749\n",
      "Epoch: 220, Loss= 0.5571, Training Accuracy= 0.749\n",
      "Epoch: 230, Loss= 0.5525, Training Accuracy= 0.749\n",
      "Epoch: 240, Loss= 0.5479, Training Accuracy= 0.749\n",
      "Epoch: 250, Loss= 0.5431, Training Accuracy= 0.749\n",
      "Epoch: 260, Loss= 0.5383, Training Accuracy= 0.749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270, Loss= 0.5334, Training Accuracy= 0.749\n",
      "Epoch: 280, Loss= 0.5284, Training Accuracy= 0.749\n",
      "Epoch: 290, Loss= 0.5234, Training Accuracy= 0.749\n",
      "Epoch: 300, Loss= 0.5182, Training Accuracy= 0.749\n",
      "Epoch: 310, Loss= 0.5130, Training Accuracy= 0.749\n",
      "Epoch: 320, Loss= 0.5077, Training Accuracy= 0.749\n",
      "Epoch: 330, Loss= 0.5023, Training Accuracy= 0.749\n",
      "Epoch: 340, Loss= 0.4969, Training Accuracy= 0.749\n",
      "Epoch: 350, Loss= 0.4914, Training Accuracy= 0.749\n",
      "Epoch: 360, Loss= 0.4858, Training Accuracy= 0.749\n",
      "Epoch: 370, Loss= 0.4802, Training Accuracy= 0.749\n",
      "Epoch: 380, Loss= 0.4745, Training Accuracy= 0.749\n",
      "Epoch: 390, Loss= 0.4688, Training Accuracy= 0.749\n",
      "Epoch: 400, Loss= 0.4630, Training Accuracy= 0.749\n",
      "Epoch: 410, Loss= 0.4571, Training Accuracy= 0.749\n",
      "Epoch: 420, Loss= 0.4512, Training Accuracy= 0.749\n",
      "Epoch: 430, Loss= 0.4453, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.4393, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.4333, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.4273, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.4212, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.4152, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.4091, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.4030, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.3970, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.3909, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.3849, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.3789, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.3729, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.3670, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.3611, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.3553, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.3495, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.3437, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.3380, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.3324, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.3268, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.3213, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.3159, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.3105, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.3053, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.3000, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.2949, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.2898, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.2849, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.2800, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.2751, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.2704, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.2658, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.2612, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.2567, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.2523, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.2479, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.2437, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.2395, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.2354, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.2314, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.2275, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.2236, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.2198, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.2161, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.2125, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.2089, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.2054, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.2020, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.1987, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.1954, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.1922, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.1891, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.1860, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.1830, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.1801, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.1772, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1744, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1717, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1690, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1664, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1638, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1613, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1588, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1564, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1540, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1517, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1495, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1473, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1451, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1430, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1409, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.1389, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.1369, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.1350, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.1331, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.1313, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.1294, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1277, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1259, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1242, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1225, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1209, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1193, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1177, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1162, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1147, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.1132, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.1118, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.1104, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.1090, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.1076, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.1063, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.1050, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.1037, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.1025, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.1012, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.1000, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0989, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0977, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0966, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0954, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0943, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0933, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0922, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0912, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0902, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.8070, Training Accuracy= 0.255\n",
      "Epoch: 10, Loss= 0.7684, Training Accuracy= 0.496\n",
      "Epoch: 20, Loss= 0.7470, Training Accuracy= 0.496\n",
      "Epoch: 30, Loss= 0.7343, Training Accuracy= 0.496\n",
      "Epoch: 40, Loss= 0.7257, Training Accuracy= 0.496\n",
      "Epoch: 50, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 60, Loss= 0.7141, Training Accuracy= 0.496\n",
      "Epoch: 70, Loss= 0.7097, Training Accuracy= 0.496\n",
      "Epoch: 80, Loss= 0.7058, Training Accuracy= 0.496\n",
      "Epoch: 90, Loss= 0.7025, Training Accuracy= 0.496\n",
      "Epoch: 100, Loss= 0.6995, Training Accuracy= 0.496\n",
      "Epoch: 110, Loss= 0.6969, Training Accuracy= 0.496\n",
      "Epoch: 120, Loss= 0.6945, Training Accuracy= 0.496\n",
      "Epoch: 130, Loss= 0.6924, Training Accuracy= 0.496\n",
      "Epoch: 140, Loss= 0.6904, Training Accuracy= 0.496\n",
      "Epoch: 150, Loss= 0.6885, Training Accuracy= 0.496\n",
      "Epoch: 160, Loss= 0.6867, Training Accuracy= 0.496\n",
      "Epoch: 170, Loss= 0.6851, Training Accuracy= 0.496\n",
      "Epoch: 180, Loss= 0.6835, Training Accuracy= 0.496\n",
      "Epoch: 190, Loss= 0.6820, Training Accuracy= 0.496\n",
      "Epoch: 200, Loss= 0.6805, Training Accuracy= 0.496\n",
      "Epoch: 210, Loss= 0.6790, Training Accuracy= 0.496\n",
      "Epoch: 220, Loss= 0.6775, Training Accuracy= 0.496\n",
      "Epoch: 230, Loss= 0.6761, Training Accuracy= 0.496\n",
      "Epoch: 240, Loss= 0.6746, Training Accuracy= 0.496\n",
      "Epoch: 250, Loss= 0.6731, Training Accuracy= 0.496\n",
      "Epoch: 260, Loss= 0.6716, Training Accuracy= 0.496\n",
      "Epoch: 270, Loss= 0.6700, Training Accuracy= 0.496\n",
      "Epoch: 280, Loss= 0.6684, Training Accuracy= 0.746\n",
      "Epoch: 290, Loss= 0.6668, Training Accuracy= 0.746\n",
      "Epoch: 300, Loss= 0.6651, Training Accuracy= 0.746\n",
      "Epoch: 310, Loss= 0.6634, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.6616, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.6598, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.6578, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.6558, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, Loss= 0.6538, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.6516, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.6494, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.6470, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.6446, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.6421, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.6394, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.6367, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.6338, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.6308, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.6277, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.6244, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.6211, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.6175, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.6139, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.6100, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.6060, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.6019, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.5976, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.5931, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.5885, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.5837, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.5788, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.5736, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.5683, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.5629, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.5572, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.5514, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.5455, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.5394, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.5331, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.5267, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.5201, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.5134, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.5065, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.4995, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.4924, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.4851, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.4777, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.4702, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.4626, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.4549, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.4470, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.4391, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.4311, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.4230, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.4148, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.4066, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.3983, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.3899, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.3816, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.3732, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.3649, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.3566, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.3483, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.3400, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.3318, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.3237, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.3157, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.3078, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.3000, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.2923, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.2847, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.2773, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.2701, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.2630, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.2561, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.2494, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.2429, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.2365, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.2303, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.2243, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.2184, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.2128, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.2073, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.2020, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1968, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1919, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1871, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.1824, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.1779, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.1736, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.1694, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.1654, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.1614, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1577, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1540, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1505, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1471, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1438, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1406, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1375, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1345, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1317, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.1289, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.1262, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.1236, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.1211, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.1186, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.1163, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.1140, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.1118, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.1096, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.1075, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.1055, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.1036, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.1017, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0998, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0980, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0963, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0946, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0930, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0914, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0898, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 1.0558, Training Accuracy= 0.755\n",
      "Epoch: 10, Loss= 0.9281, Training Accuracy= 0.500\n",
      "Epoch: 20, Loss= 0.8500, Training Accuracy= 0.500\n",
      "Epoch: 30, Loss= 0.7940, Training Accuracy= 0.500\n",
      "Epoch: 40, Loss= 0.7549, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 0.7283, Training Accuracy= 0.500\n",
      "Epoch: 60, Loss= 0.7104, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.6984, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.6902, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.6845, Training Accuracy= 0.500\n",
      "Epoch: 100, Loss= 0.6803, Training Accuracy= 0.500\n",
      "Epoch: 110, Loss= 0.6771, Training Accuracy= 0.500\n",
      "Epoch: 120, Loss= 0.6745, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 0.6723, Training Accuracy= 0.500\n",
      "Epoch: 140, Loss= 0.6704, Training Accuracy= 0.500\n",
      "Epoch: 150, Loss= 0.6685, Training Accuracy= 0.500\n",
      "Epoch: 160, Loss= 0.6667, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 0.6649, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 0.6631, Training Accuracy= 0.500\n",
      "Epoch: 190, Loss= 0.6611, Training Accuracy= 0.755\n",
      "Epoch: 200, Loss= 0.6591, Training Accuracy= 0.755\n",
      "Epoch: 210, Loss= 0.6570, Training Accuracy= 0.755\n",
      "Epoch: 220, Loss= 0.6548, Training Accuracy= 0.755\n",
      "Epoch: 230, Loss= 0.6525, Training Accuracy= 0.755\n",
      "Epoch: 240, Loss= 0.6500, Training Accuracy= 0.755\n",
      "Epoch: 250, Loss= 0.6474, Training Accuracy= 0.755\n",
      "Epoch: 260, Loss= 0.6446, Training Accuracy= 0.755\n",
      "Epoch: 270, Loss= 0.6417, Training Accuracy= 0.755\n",
      "Epoch: 280, Loss= 0.6386, Training Accuracy= 0.755\n",
      "Epoch: 290, Loss= 0.6353, Training Accuracy= 0.755\n",
      "Epoch: 300, Loss= 0.6318, Training Accuracy= 0.755\n",
      "Epoch: 310, Loss= 0.6282, Training Accuracy= 0.755\n",
      "Epoch: 320, Loss= 0.6243, Training Accuracy= 0.755\n",
      "Epoch: 330, Loss= 0.6203, Training Accuracy= 0.755\n",
      "Epoch: 340, Loss= 0.6160, Training Accuracy= 0.755\n",
      "Epoch: 350, Loss= 0.6115, Training Accuracy= 0.755\n",
      "Epoch: 360, Loss= 0.6068, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.6018, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.5967, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.5913, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.5856, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.5797, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5735, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5672, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5605, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 450, Loss= 0.5537, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5466, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5393, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5318, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5241, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.5161, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.5080, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.4997, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.4913, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.4827, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.4740, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.4651, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.4561, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.4470, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4379, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.4287, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.4194, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.4101, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.4008, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.3914, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.3821, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.3729, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.3636, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.3545, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.3454, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.3364, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.3275, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.3187, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.3101, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.3016, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.2932, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.2850, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.2770, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.2692, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.2616, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.2542, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.2470, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.2400, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.2331, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.2265, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.2201, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.2139, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.2080, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.2022, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.1966, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.1912, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.1860, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.1810, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.1761, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.1715, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.1670, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.1627, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.1586, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.1546, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.1507, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1470, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1435, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1400, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1368, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1336, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1305, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1276, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1247, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1220, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1194, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1169, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1144, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1121, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1098, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1076, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.1055, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.1034, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.1014, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0995, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0977, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0959, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0942, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0925, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0909, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0893, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0878, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0863, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0849, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0835, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0822, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0809, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0796, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0784, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0772, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0760, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0749, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0738, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0727, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0717, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0707, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0697, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0688, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0678, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0669, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0660, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0652, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0643, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0635, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0627, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0619, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.7715, Training Accuracy= 0.503\n",
      "Epoch: 10, Loss= 0.7308, Training Accuracy= 0.503\n",
      "Epoch: 20, Loss= 0.7128, Training Accuracy= 0.493\n",
      "Epoch: 30, Loss= 0.7030, Training Accuracy= 0.493\n",
      "Epoch: 40, Loss= 0.6961, Training Accuracy= 0.493\n",
      "Epoch: 50, Loss= 0.6904, Training Accuracy= 0.493\n",
      "Epoch: 60, Loss= 0.6851, Training Accuracy= 0.493\n",
      "Epoch: 70, Loss= 0.6801, Training Accuracy= 0.493\n",
      "Epoch: 80, Loss= 0.6754, Training Accuracy= 0.493\n",
      "Epoch: 90, Loss= 0.6710, Training Accuracy= 0.493\n",
      "Epoch: 100, Loss= 0.6666, Training Accuracy= 0.493\n",
      "Epoch: 110, Loss= 0.6625, Training Accuracy= 0.493\n",
      "Epoch: 120, Loss= 0.6584, Training Accuracy= 0.493\n",
      "Epoch: 130, Loss= 0.6544, Training Accuracy= 0.751\n",
      "Epoch: 140, Loss= 0.6504, Training Accuracy= 1.000\n",
      "Epoch: 150, Loss= 0.6465, Training Accuracy= 1.000\n",
      "Epoch: 160, Loss= 0.6426, Training Accuracy= 1.000\n",
      "Epoch: 170, Loss= 0.6385, Training Accuracy= 1.000\n",
      "Epoch: 180, Loss= 0.6344, Training Accuracy= 1.000\n",
      "Epoch: 190, Loss= 0.6303, Training Accuracy= 1.000\n",
      "Epoch: 200, Loss= 0.6260, Training Accuracy= 1.000\n",
      "Epoch: 210, Loss= 0.6215, Training Accuracy= 1.000\n",
      "Epoch: 220, Loss= 0.6169, Training Accuracy= 1.000\n",
      "Epoch: 230, Loss= 0.6121, Training Accuracy= 1.000\n",
      "Epoch: 240, Loss= 0.6071, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.6019, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.5965, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.5908, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.5849, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.5788, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.5723, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.5656, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.5586, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.5514, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.5438, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.5360, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.5280, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.5197, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.5111, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.5023, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.4933, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.4842, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.4748, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.4653, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.4557, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.4460, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.4363, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.4265, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.4167, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.4069, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.3971, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.3874, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.3778, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.3683, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 540, Loss= 0.3589, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.3497, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.3406, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.3317, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.3230, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.3145, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.3062, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.2981, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.2902, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.2825, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.2751, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.2678, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.2608, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.2540, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.2473, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.2409, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.2347, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.2287, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.2229, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.2173, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.2119, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.2066, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.2015, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.1966, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.1918, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.1872, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.1828, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.1785, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.1743, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.1703, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.1664, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.1626, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.1590, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.1555, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.1520, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.1487, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.1455, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.1424, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.1394, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.1365, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.1337, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.1309, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.1283, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.1257, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.1232, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.1208, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1185, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1162, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1140, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1118, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1097, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1077, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1057, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1038, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1019, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1001, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0984, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0967, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0950, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0934, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0918, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0903, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0888, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0873, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0859, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0845, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0832, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0818, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0806, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0793, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0781, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0769, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0757, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0746, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0735, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0724, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0714, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0704, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0693, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0684, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0674, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0665, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0655, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0647, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0638, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0629, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0621, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0613, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0605, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0597, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0589, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0582, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0574, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0567, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0560, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0553, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 0.7358, Training Accuracy= 0.245\n",
      "Epoch: 10, Loss= 0.7214, Training Accuracy= 0.245\n",
      "Epoch: 20, Loss= 0.7133, Training Accuracy= 0.245\n",
      "Epoch: 30, Loss= 0.7082, Training Accuracy= 0.245\n",
      "Epoch: 40, Loss= 0.7045, Training Accuracy= 0.245\n",
      "Epoch: 50, Loss= 0.7016, Training Accuracy= 0.245\n",
      "Epoch: 60, Loss= 0.6992, Training Accuracy= 0.245\n",
      "Epoch: 70, Loss= 0.6970, Training Accuracy= 0.245\n",
      "Epoch: 80, Loss= 0.6950, Training Accuracy= 0.245\n",
      "Epoch: 90, Loss= 0.6932, Training Accuracy= 0.245\n",
      "Epoch: 100, Loss= 0.6915, Training Accuracy= 0.245\n",
      "Epoch: 110, Loss= 0.6899, Training Accuracy= 0.245\n",
      "Epoch: 120, Loss= 0.6883, Training Accuracy= 0.245\n",
      "Epoch: 130, Loss= 0.6868, Training Accuracy= 0.245\n",
      "Epoch: 140, Loss= 0.6854, Training Accuracy= 0.500\n",
      "Epoch: 150, Loss= 0.6839, Training Accuracy= 0.500\n",
      "Epoch: 160, Loss= 0.6825, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 0.6811, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 0.6796, Training Accuracy= 0.500\n",
      "Epoch: 190, Loss= 0.6782, Training Accuracy= 0.500\n",
      "Epoch: 200, Loss= 0.6768, Training Accuracy= 0.500\n",
      "Epoch: 210, Loss= 0.6753, Training Accuracy= 0.500\n",
      "Epoch: 220, Loss= 0.6738, Training Accuracy= 0.500\n",
      "Epoch: 230, Loss= 0.6723, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 0.6707, Training Accuracy= 0.500\n",
      "Epoch: 250, Loss= 0.6691, Training Accuracy= 0.500\n",
      "Epoch: 260, Loss= 0.6675, Training Accuracy= 0.500\n",
      "Epoch: 270, Loss= 0.6658, Training Accuracy= 0.500\n",
      "Epoch: 280, Loss= 0.6641, Training Accuracy= 0.500\n",
      "Epoch: 290, Loss= 0.6623, Training Accuracy= 0.500\n",
      "Epoch: 300, Loss= 0.6605, Training Accuracy= 0.500\n",
      "Epoch: 310, Loss= 0.6587, Training Accuracy= 0.500\n",
      "Epoch: 320, Loss= 0.6568, Training Accuracy= 0.500\n",
      "Epoch: 330, Loss= 0.6549, Training Accuracy= 0.500\n",
      "Epoch: 340, Loss= 0.6530, Training Accuracy= 0.500\n",
      "Epoch: 350, Loss= 0.6510, Training Accuracy= 0.500\n",
      "Epoch: 360, Loss= 0.6489, Training Accuracy= 0.500\n",
      "Epoch: 370, Loss= 0.6469, Training Accuracy= 0.500\n",
      "Epoch: 380, Loss= 0.6448, Training Accuracy= 0.500\n",
      "Epoch: 390, Loss= 0.6426, Training Accuracy= 0.500\n",
      "Epoch: 400, Loss= 0.6405, Training Accuracy= 0.500\n",
      "Epoch: 410, Loss= 0.6383, Training Accuracy= 0.500\n",
      "Epoch: 420, Loss= 0.6360, Training Accuracy= 0.500\n",
      "Epoch: 430, Loss= 0.6337, Training Accuracy= 0.500\n",
      "Epoch: 440, Loss= 0.6315, Training Accuracy= 0.500\n",
      "Epoch: 450, Loss= 0.6291, Training Accuracy= 0.500\n",
      "Epoch: 460, Loss= 0.6267, Training Accuracy= 0.500\n",
      "Epoch: 470, Loss= 0.6243, Training Accuracy= 0.500\n",
      "Epoch: 480, Loss= 0.6219, Training Accuracy= 0.500\n",
      "Epoch: 490, Loss= 0.6195, Training Accuracy= 0.500\n",
      "Epoch: 500, Loss= 0.6170, Training Accuracy= 0.500\n",
      "Epoch: 510, Loss= 0.6145, Training Accuracy= 0.500\n",
      "Epoch: 520, Loss= 0.6120, Training Accuracy= 0.500\n",
      "Epoch: 530, Loss= 0.6094, Training Accuracy= 0.500\n",
      "Epoch: 540, Loss= 0.6069, Training Accuracy= 0.500\n",
      "Epoch: 550, Loss= 0.6043, Training Accuracy= 0.500\n",
      "Epoch: 560, Loss= 0.6017, Training Accuracy= 0.500\n",
      "Epoch: 570, Loss= 0.5991, Training Accuracy= 0.500\n",
      "Epoch: 580, Loss= 0.5965, Training Accuracy= 0.500\n",
      "Epoch: 590, Loss= 0.5939, Training Accuracy= 0.500\n",
      "Epoch: 600, Loss= 0.5912, Training Accuracy= 0.500\n",
      "Epoch: 610, Loss= 0.5886, Training Accuracy= 0.500\n",
      "Epoch: 620, Loss= 0.5860, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 630, Loss= 0.5833, Training Accuracy= 0.500\n",
      "Epoch: 640, Loss= 0.5807, Training Accuracy= 0.500\n",
      "Epoch: 650, Loss= 0.5780, Training Accuracy= 0.500\n",
      "Epoch: 660, Loss= 0.5754, Training Accuracy= 0.500\n",
      "Epoch: 670, Loss= 0.5728, Training Accuracy= 0.500\n",
      "Epoch: 680, Loss= 0.5702, Training Accuracy= 0.500\n",
      "Epoch: 690, Loss= 0.5676, Training Accuracy= 0.500\n",
      "Epoch: 700, Loss= 0.5650, Training Accuracy= 0.500\n",
      "Epoch: 710, Loss= 0.5624, Training Accuracy= 0.500\n",
      "Epoch: 720, Loss= 0.5598, Training Accuracy= 0.500\n",
      "Epoch: 730, Loss= 0.5573, Training Accuracy= 0.500\n",
      "Epoch: 740, Loss= 0.5547, Training Accuracy= 0.500\n",
      "Epoch: 750, Loss= 0.5522, Training Accuracy= 0.758\n",
      "Epoch: 760, Loss= 0.5497, Training Accuracy= 0.758\n",
      "Epoch: 770, Loss= 0.5472, Training Accuracy= 0.758\n",
      "Epoch: 780, Loss= 0.5447, Training Accuracy= 0.758\n",
      "Epoch: 790, Loss= 0.5422, Training Accuracy= 0.758\n",
      "Epoch: 800, Loss= 0.5398, Training Accuracy= 0.758\n",
      "Epoch: 810, Loss= 0.5374, Training Accuracy= 0.758\n",
      "Epoch: 820, Loss= 0.5350, Training Accuracy= 0.758\n",
      "Epoch: 830, Loss= 0.5326, Training Accuracy= 0.758\n",
      "Epoch: 840, Loss= 0.5302, Training Accuracy= 0.758\n",
      "Epoch: 850, Loss= 0.5278, Training Accuracy= 0.758\n",
      "Epoch: 860, Loss= 0.5255, Training Accuracy= 0.758\n",
      "Epoch: 870, Loss= 0.5231, Training Accuracy= 0.758\n",
      "Epoch: 880, Loss= 0.5208, Training Accuracy= 0.758\n",
      "Epoch: 890, Loss= 0.5185, Training Accuracy= 0.758\n",
      "Epoch: 900, Loss= 0.5162, Training Accuracy= 0.758\n",
      "Epoch: 910, Loss= 0.5139, Training Accuracy= 0.758\n",
      "Epoch: 920, Loss= 0.5116, Training Accuracy= 0.758\n",
      "Epoch: 930, Loss= 0.5093, Training Accuracy= 0.758\n",
      "Epoch: 940, Loss= 0.5070, Training Accuracy= 0.758\n",
      "Epoch: 950, Loss= 0.5048, Training Accuracy= 0.758\n",
      "Epoch: 960, Loss= 0.5025, Training Accuracy= 0.758\n",
      "Epoch: 970, Loss= 0.5002, Training Accuracy= 0.758\n",
      "Epoch: 980, Loss= 0.4980, Training Accuracy= 0.758\n",
      "Epoch: 990, Loss= 0.4957, Training Accuracy= 0.758\n",
      "Epoch: 1000, Loss= 0.4934, Training Accuracy= 0.758\n",
      "Epoch: 1010, Loss= 0.4911, Training Accuracy= 0.758\n",
      "Epoch: 1020, Loss= 0.4888, Training Accuracy= 0.758\n",
      "Epoch: 1030, Loss= 0.4865, Training Accuracy= 0.758\n",
      "Epoch: 1040, Loss= 0.4842, Training Accuracy= 0.758\n",
      "Epoch: 1050, Loss= 0.4818, Training Accuracy= 0.758\n",
      "Epoch: 1060, Loss= 0.4794, Training Accuracy= 0.758\n",
      "Epoch: 1070, Loss= 0.4770, Training Accuracy= 0.758\n",
      "Epoch: 1080, Loss= 0.4746, Training Accuracy= 0.758\n",
      "Epoch: 1090, Loss= 0.4721, Training Accuracy= 0.758\n",
      "Epoch: 1100, Loss= 0.4696, Training Accuracy= 0.758\n",
      "Epoch: 1110, Loss= 0.4670, Training Accuracy= 0.758\n",
      "Epoch: 1120, Loss= 0.4644, Training Accuracy= 0.758\n",
      "Epoch: 1130, Loss= 0.4617, Training Accuracy= 0.758\n",
      "Epoch: 1140, Loss= 0.4590, Training Accuracy= 0.758\n",
      "Epoch: 1150, Loss= 0.4562, Training Accuracy= 0.758\n",
      "Epoch: 1160, Loss= 0.4533, Training Accuracy= 0.758\n",
      "Epoch: 1170, Loss= 0.4504, Training Accuracy= 0.758\n",
      "Epoch: 1180, Loss= 0.4473, Training Accuracy= 0.758\n",
      "Epoch: 1190, Loss= 0.4441, Training Accuracy= 0.758\n",
      "Epoch: 1200, Loss= 0.4409, Training Accuracy= 0.758\n",
      "Epoch: 1210, Loss= 0.4375, Training Accuracy= 0.758\n",
      "Epoch: 1220, Loss= 0.4341, Training Accuracy= 0.758\n",
      "Epoch: 1230, Loss= 0.4305, Training Accuracy= 0.758\n",
      "Epoch: 1240, Loss= 0.4268, Training Accuracy= 0.758\n",
      "Epoch: 1250, Loss= 0.4229, Training Accuracy= 0.758\n",
      "Epoch: 1260, Loss= 0.4189, Training Accuracy= 0.758\n",
      "Epoch: 1270, Loss= 0.4148, Training Accuracy= 0.758\n",
      "Epoch: 1280, Loss= 0.4106, Training Accuracy= 0.758\n",
      "Epoch: 1290, Loss= 0.4063, Training Accuracy= 0.758\n",
      "Epoch: 1300, Loss= 0.4018, Training Accuracy= 0.758\n",
      "Epoch: 1310, Loss= 0.3972, Training Accuracy= 0.758\n",
      "Epoch: 1320, Loss= 0.3925, Training Accuracy= 0.758\n",
      "Epoch: 1330, Loss= 0.3878, Training Accuracy= 0.758\n",
      "Epoch: 1340, Loss= 0.3830, Training Accuracy= 0.758\n",
      "Epoch: 1350, Loss= 0.3781, Training Accuracy= 0.758\n",
      "Epoch: 1360, Loss= 0.3732, Training Accuracy= 0.758\n",
      "Epoch: 1370, Loss= 0.3683, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.3634, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.3585, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.3536, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.3488, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.3440, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.3392, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.3345, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.3298, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.3252, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.3206, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.3161, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.3117, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 1.0630, Training Accuracy= 0.495\n",
      "Epoch: 10, Loss= 0.8487, Training Accuracy= 0.495\n",
      "Epoch: 20, Loss= 0.7662, Training Accuracy= 0.755\n",
      "Epoch: 30, Loss= 0.7349, Training Accuracy= 0.755\n",
      "Epoch: 40, Loss= 0.7208, Training Accuracy= 0.755\n",
      "Epoch: 50, Loss= 0.7126, Training Accuracy= 0.500\n",
      "Epoch: 60, Loss= 0.7067, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.7020, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.6979, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.6943, Training Accuracy= 0.500\n",
      "Epoch: 100, Loss= 0.6912, Training Accuracy= 0.500\n",
      "Epoch: 110, Loss= 0.6882, Training Accuracy= 0.500\n",
      "Epoch: 120, Loss= 0.6855, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 0.6830, Training Accuracy= 0.500\n",
      "Epoch: 140, Loss= 0.6806, Training Accuracy= 0.500\n",
      "Epoch: 150, Loss= 0.6783, Training Accuracy= 0.500\n",
      "Epoch: 160, Loss= 0.6760, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 0.6738, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 0.6716, Training Accuracy= 0.500\n",
      "Epoch: 190, Loss= 0.6694, Training Accuracy= 0.500\n",
      "Epoch: 200, Loss= 0.6672, Training Accuracy= 0.500\n",
      "Epoch: 210, Loss= 0.6650, Training Accuracy= 0.500\n",
      "Epoch: 220, Loss= 0.6627, Training Accuracy= 0.500\n",
      "Epoch: 230, Loss= 0.6604, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 0.6579, Training Accuracy= 0.755\n",
      "Epoch: 250, Loss= 0.6554, Training Accuracy= 0.755\n",
      "Epoch: 260, Loss= 0.6528, Training Accuracy= 0.755\n",
      "Epoch: 270, Loss= 0.6501, Training Accuracy= 0.755\n",
      "Epoch: 280, Loss= 0.6473, Training Accuracy= 0.755\n",
      "Epoch: 290, Loss= 0.6443, Training Accuracy= 0.755\n",
      "Epoch: 300, Loss= 0.6413, Training Accuracy= 0.755\n",
      "Epoch: 310, Loss= 0.6380, Training Accuracy= 0.755\n",
      "Epoch: 320, Loss= 0.6346, Training Accuracy= 0.755\n",
      "Epoch: 330, Loss= 0.6311, Training Accuracy= 0.755\n",
      "Epoch: 340, Loss= 0.6274, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.6235, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.6195, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.6152, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.6108, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.6061, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.6012, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.5962, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5908, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5853, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5796, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5737, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5675, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5611, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5545, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5477, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.5407, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.5335, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.5261, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.5186, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.5109, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.5030, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.4950, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.4869, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.4787, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4704, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.4620, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.4536, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.4451, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.4365, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.4280, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.4194, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.4108, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.4023, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.3937, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.3853, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.3768, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.3684, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 720, Loss= 0.3601, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.3519, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.3438, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.3357, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.3278, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.3199, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.3122, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.3047, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.2972, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.2899, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.2827, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.2757, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.2688, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.2621, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.2555, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.2491, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.2429, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.2368, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.2309, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.2251, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.2195, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.2141, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.2088, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.2037, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.1987, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.1939, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.1892, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.1847, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1803, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1761, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1720, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1680, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1642, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1605, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1569, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1534, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1501, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1468, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1437, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1407, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1377, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1349, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1322, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.1295, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.1270, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.1245, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.1221, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.1198, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.1175, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.1153, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.1132, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.1112, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.1092, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.1073, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.1054, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.1036, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.1018, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.1001, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0985, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0969, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0953, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0938, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0923, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0909, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0895, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0882, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0868, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0856, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0843, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0831, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0819, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0807, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0796, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0785, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0774, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0764, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0754, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0744, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.7686, Training Accuracy= 0.492\n",
      "Epoch: 10, Loss= 0.7466, Training Accuracy= 0.492\n",
      "Epoch: 20, Loss= 0.7337, Training Accuracy= 0.492\n",
      "Epoch: 30, Loss= 0.7239, Training Accuracy= 0.492\n",
      "Epoch: 40, Loss= 0.7162, Training Accuracy= 0.492\n",
      "Epoch: 50, Loss= 0.7101, Training Accuracy= 0.492\n",
      "Epoch: 60, Loss= 0.7052, Training Accuracy= 0.749\n",
      "Epoch: 70, Loss= 0.7011, Training Accuracy= 0.749\n",
      "Epoch: 80, Loss= 0.6977, Training Accuracy= 0.749\n",
      "Epoch: 90, Loss= 0.6947, Training Accuracy= 0.749\n",
      "Epoch: 100, Loss= 0.6920, Training Accuracy= 0.749\n",
      "Epoch: 110, Loss= 0.6896, Training Accuracy= 0.749\n",
      "Epoch: 120, Loss= 0.6874, Training Accuracy= 0.749\n",
      "Epoch: 130, Loss= 0.6854, Training Accuracy= 0.749\n",
      "Epoch: 140, Loss= 0.6834, Training Accuracy= 0.749\n",
      "Epoch: 150, Loss= 0.6814, Training Accuracy= 0.749\n",
      "Epoch: 160, Loss= 0.6795, Training Accuracy= 0.749\n",
      "Epoch: 170, Loss= 0.6775, Training Accuracy= 0.749\n",
      "Epoch: 180, Loss= 0.6755, Training Accuracy= 0.749\n",
      "Epoch: 190, Loss= 0.6734, Training Accuracy= 0.749\n",
      "Epoch: 200, Loss= 0.6712, Training Accuracy= 0.749\n",
      "Epoch: 210, Loss= 0.6689, Training Accuracy= 0.749\n",
      "Epoch: 220, Loss= 0.6665, Training Accuracy= 0.749\n",
      "Epoch: 230, Loss= 0.6640, Training Accuracy= 0.749\n",
      "Epoch: 240, Loss= 0.6613, Training Accuracy= 0.749\n",
      "Epoch: 250, Loss= 0.6584, Training Accuracy= 0.749\n",
      "Epoch: 260, Loss= 0.6553, Training Accuracy= 0.749\n",
      "Epoch: 270, Loss= 0.6520, Training Accuracy= 0.749\n",
      "Epoch: 280, Loss= 0.6485, Training Accuracy= 0.749\n",
      "Epoch: 290, Loss= 0.6448, Training Accuracy= 0.749\n",
      "Epoch: 300, Loss= 0.6407, Training Accuracy= 0.749\n",
      "Epoch: 310, Loss= 0.6365, Training Accuracy= 0.749\n",
      "Epoch: 320, Loss= 0.6319, Training Accuracy= 0.749\n",
      "Epoch: 330, Loss= 0.6271, Training Accuracy= 0.749\n",
      "Epoch: 340, Loss= 0.6219, Training Accuracy= 0.749\n",
      "Epoch: 350, Loss= 0.6165, Training Accuracy= 0.749\n",
      "Epoch: 360, Loss= 0.6107, Training Accuracy= 0.749\n",
      "Epoch: 370, Loss= 0.6045, Training Accuracy= 0.749\n",
      "Epoch: 380, Loss= 0.5980, Training Accuracy= 0.749\n",
      "Epoch: 390, Loss= 0.5912, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.5840, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.5765, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.5686, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.5604, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.5518, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.5430, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.5338, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.5244, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.5147, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.5048, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.4948, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.4845, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.4741, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.4637, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.4532, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.4426, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.4321, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.4216, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.4111, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.4008, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.3905, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.3804, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.3704, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.3607, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.3511, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.3417, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.3325, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.3235, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.3147, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.3062, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.2978, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.2898, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.2819, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.2743, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.2669, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.2597, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.2527, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.2460, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.2394, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.2331, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.2270, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 810, Loss= 0.2210, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.2153, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.2097, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.2043, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.1992, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.1941, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.1893, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.1846, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.1800, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.1756, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.1714, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.1673, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.1633, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.1595, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.1557, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.1521, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.1487, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.1453, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.1420, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.1389, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.1359, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.1329, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.1301, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.1273, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.1246, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.1220, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.1195, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.1171, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.1148, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.1125, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.1103, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.1081, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.1061, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.1041, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.1021, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.1002, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0984, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0966, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0949, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0932, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0916, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0900, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0885, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0870, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0856, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0841, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0828, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0814, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0802, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0789, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0777, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0765, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0753, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0742, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0731, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0720, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0710, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0700, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0690, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0680, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0671, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0662, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0653, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0644, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0635, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0627, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0619, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0611, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0603, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.000275\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 1500\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a RNN cell with tensorflow\n",
    "    rnn_cell = rnn.BasicRNNCell(num_hidden)\n",
    "\n",
    "    # Get RNN cell output\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  1.0\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.0\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmHyWFIwxxuSzpGCMMSbf/wOpzfhc8pk2oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcfd0fad7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
