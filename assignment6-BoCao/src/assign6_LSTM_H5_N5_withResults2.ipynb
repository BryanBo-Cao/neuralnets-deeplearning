{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 5\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.6958, Training Accuracy= 0.496\n",
      "Epoch: 10, Loss= 0.6932, Training Accuracy= 0.535\n",
      "Epoch: 20, Loss= 0.6930, Training Accuracy= 0.538\n",
      "Epoch: 30, Loss= 0.6930, Training Accuracy= 0.479\n",
      "Epoch: 40, Loss= 0.6930, Training Accuracy= 0.478\n",
      "Epoch: 50, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 60, Loss= 0.6929, Training Accuracy= 0.537\n",
      "Epoch: 70, Loss= 0.6929, Training Accuracy= 0.537\n",
      "Epoch: 80, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 90, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 100, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 110, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 120, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 130, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 140, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 150, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 160, Loss= 0.6928, Training Accuracy= 0.475\n",
      "Epoch: 170, Loss= 0.6928, Training Accuracy= 0.475\n",
      "Epoch: 180, Loss= 0.6927, Training Accuracy= 0.445\n",
      "Epoch: 190, Loss= 0.6906, Training Accuracy= 0.319\n",
      "Epoch: 200, Loss= 0.1555, Training Accuracy= 0.938\n",
      "Epoch: 210, Loss= 0.0071, Training Accuracy= 1.000\n",
      "Epoch: 220, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 230, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 240, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.6930, Training Accuracy= 0.472\n",
      "Epoch: 10, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 40, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 50, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 60, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 70, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 80, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 90, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 100, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 120, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 130, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 150, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 160, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 170, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 180, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 190, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 200, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 230, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 240, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 250, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 260, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 270, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 280, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 290, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 310, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 320, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 330, Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 340, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 350, Loss= 0.6861, Training Accuracy= 0.472\n",
      "Epoch: 360, Loss= 0.0441, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.0066, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0002, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.6979, Training Accuracy= 0.501\n",
      "Epoch: 10, Loss= 0.6953, Training Accuracy= 0.501\n",
      "Epoch: 20, Loss= 0.6950, Training Accuracy= 0.501\n",
      "Epoch: 30, Loss= 0.6949, Training Accuracy= 0.501\n",
      "Epoch: 40, Loss= 0.6948, Training Accuracy= 0.501\n",
      "Epoch: 50, Loss= 0.6948, Training Accuracy= 0.501\n",
      "Epoch: 60, Loss= 0.6948, Training Accuracy= 0.501\n",
      "Epoch: 70, Loss= 0.6947, Training Accuracy= 0.501\n",
      "Epoch: 80, Loss= 0.6947, Training Accuracy= 0.501\n",
      "Epoch: 90, Loss= 0.6947, Training Accuracy= 0.501\n",
      "Epoch: 100, Loss= 0.6947, Training Accuracy= 0.501\n",
      "Epoch: 110, Loss= 0.6945, Training Accuracy= 0.501\n",
      "Epoch: 120, Loss= 0.0787, Training Accuracy= 0.966\n",
      "Epoch: 130, Loss= 0.0060, Training Accuracy= 1.000\n",
      "Epoch: 140, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 150, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 160, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 170, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 180, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 190, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 200, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 210, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 220, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 230, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 240, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.6965, Training Accuracy= 0.509\n",
      "Epoch: 10, Loss= 0.6939, Training Accuracy= 0.509\n",
      "Epoch: 20, Loss= 0.6936, Training Accuracy= 0.509\n",
      "Epoch: 30, Loss= 0.6935, Training Accuracy= 0.509\n",
      "Epoch: 40, Loss= 0.6935, Training Accuracy= 0.509\n",
      "Epoch: 50, Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 60, Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 70, Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 80, Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 90, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 100, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 110, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 120, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 130, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 140, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 150, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 160, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 170, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 180, Loss= 0.6933, Training Accuracy= 0.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 200, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 210, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 220, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 230, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 240, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 250, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 260, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 270, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 280, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 290, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 300, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 310, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 320, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 330, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 340, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 350, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 360, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 370, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 380, Loss= 0.6880, Training Accuracy= 0.542\n",
      "Epoch: 390, Loss= 0.1088, Training Accuracy= 0.968\n",
      "Epoch: 400, Loss= 0.0868, Training Accuracy= 0.968\n",
      "Epoch: 410, Loss= 0.0247, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0069, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0038, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.6929, Training Accuracy= 0.450\n",
      "Epoch: 10, Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 20, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 30, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 40, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 50, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 60, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 70, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 80, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 90, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 100, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 110, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 120, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 130, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 140, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 150, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 160, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 170, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 180, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 190, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 200, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 210, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 220, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 230, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 240, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 250, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 260, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 270, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 280, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 290, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 300, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 310, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 320, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 330, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 340, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 350, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 360, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 370, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 380, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 390, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 400, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 410, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 420, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 430, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 440, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 450, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 460, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 470, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 480, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 490, Loss= 0.6928, Training Accuracy= 0.476\n",
      "Epoch: 500, Loss= 0.4786, Training Accuracy= 0.805\n",
      "Epoch: 510, Loss= 0.0188, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0039, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0002, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 0.6978, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.6941, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.6939, Training Accuracy= 0.466\n",
      "Epoch: 40, Loss= 0.6937, Training Accuracy= 0.466\n",
      "Epoch: 50, Loss= 0.6936, Training Accuracy= 0.466\n",
      "Epoch: 60, Loss= 0.6935, Training Accuracy= 0.466\n",
      "Epoch: 70, Loss= 0.6935, Training Accuracy= 0.466\n",
      "Epoch: 80, Loss= 0.6935, Training Accuracy= 0.466\n",
      "Epoch: 90, Loss= 0.6934, Training Accuracy= 0.466\n",
      "Epoch: 100, Loss= 0.6934, Training Accuracy= 0.466\n",
      "Epoch: 110, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 120, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 130, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 140, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 150, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 160, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 170, Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 180, Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 190, Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 200, Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 210, Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 220, Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 230, Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 240, Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 250, Loss= 0.6933, Training Accuracy= 0.529\n",
      "Epoch: 260, Loss= 0.6932, Training Accuracy= 0.529\n",
      "Epoch: 270, Loss= 0.6914, Training Accuracy= 0.410\n",
      "Epoch: 280, Loss= 0.0614, Training Accuracy= 0.970\n",
      "Epoch: 290, Loss= 0.0093, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.7025, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.6993, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.6986, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.6983, Training Accuracy= 0.502\n",
      "Epoch: 40, Loss= 0.6981, Training Accuracy= 0.502\n",
      "Epoch: 50, Loss= 0.6980, Training Accuracy= 0.502\n",
      "Epoch: 60, Loss= 0.6978, Training Accuracy= 0.502\n",
      "Epoch: 70, Loss= 0.6978, Training Accuracy= 0.502\n",
      "Epoch: 80, Loss= 0.6977, Training Accuracy= 0.502\n",
      "Epoch: 90, Loss= 0.6977, Training Accuracy= 0.502\n",
      "Epoch: 100, Loss= 0.6977, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.6976, Training Accuracy= 0.502\n",
      "Epoch: 120, Loss= 0.6976, Training Accuracy= 0.502\n",
      "Epoch: 130, Loss= 0.6976, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 0.6976, Training Accuracy= 0.502\n",
      "Epoch: 150, Loss= 0.6976, Training Accuracy= 0.502\n",
      "Epoch: 160, Loss= 0.6976, Training Accuracy= 0.502\n",
      "Epoch: 170, Loss= 0.6975, Training Accuracy= 0.502\n",
      "Epoch: 180, Loss= 0.6975, Training Accuracy= 0.502\n",
      "Epoch: 190, Loss= 0.6975, Training Accuracy= 0.502\n",
      "Epoch: 200, Loss= 0.6975, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.6973, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.1139, Training Accuracy= 0.969\n",
      "Epoch: 230, Loss= 0.0067, Training Accuracy= 1.000\n",
      "Epoch: 240, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.0003, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 0.6956, Training Accuracy= 0.500\n",
      "Epoch: 10, Loss= 0.6950, Training Accuracy= 0.500\n",
      "Epoch: 20, Loss= 0.6948, Training Accuracy= 0.500\n",
      "Epoch: 30, Loss= 0.6946, Training Accuracy= 0.500\n",
      "Epoch: 40, Loss= 0.6946, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 0.6945, Training Accuracy= 0.500\n",
      "Epoch: 60, Loss= 0.6945, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.6945, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.6945, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 100, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 110, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 120, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 140, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 150, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 160, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 190, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 200, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 210, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 220, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 230, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 250, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 260, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 270, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 280, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 290, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 300, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 310, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 320, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 330, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 340, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 350, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 360, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 370, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 380, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 390, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 400, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 410, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 420, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 430, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 440, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 450, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 460, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 470, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 480, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 490, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 500, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 510, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 520, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 530, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 540, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 550, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 560, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 570, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 580, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 590, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 600, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 610, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 620, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 630, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 640, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 650, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 660, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 670, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 680, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 690, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 700, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 710, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 720, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 730, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 740, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 750, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 760, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 770, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 780, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 790, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 800, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 810, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 820, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 830, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 840, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 850, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 860, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 870, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 880, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 890, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 900, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 910, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 920, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 930, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 940, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 950, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 960, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 970, Loss= 0.6944, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 980, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 990, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4976\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 0.6977, Training Accuracy= 0.504\n",
      "Epoch: 10, Loss= 0.6969, Training Accuracy= 0.504\n",
      "Epoch: 20, Loss= 0.6966, Training Accuracy= 0.504\n",
      "Epoch: 30, Loss= 0.6965, Training Accuracy= 0.504\n",
      "Epoch: 40, Loss= 0.6964, Training Accuracy= 0.504\n",
      "Epoch: 50, Loss= 0.6963, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6963, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 80, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 90, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 100, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 110, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 120, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 130, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 140, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 150, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 160, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 170, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 180, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 190, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 200, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 210, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 220, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 230, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 240, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 250, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 260, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 270, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 280, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 290, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 300, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 310, Loss= 0.6962, Training Accuracy= 0.504\n",
      "Epoch: 320, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 330, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 340, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 350, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 360, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 370, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 380, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 390, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 400, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 410, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 420, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 430, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 440, Loss= 0.6961, Training Accuracy= 0.504\n",
      "Epoch: 450, Loss= 0.6960, Training Accuracy= 0.504\n",
      "Epoch: 460, Loss= 0.6957, Training Accuracy= 0.504\n",
      "Epoch: 470, Loss= 0.2559, Training Accuracy= 0.936\n",
      "Epoch: 480, Loss= 0.2612, Training Accuracy= 0.873\n",
      "Epoch: 490, Loss= 0.0321, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0111, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0064, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0044, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.7000, Training Accuracy= 0.499\n",
      "Epoch: 10, Loss= 0.6971, Training Accuracy= 0.499\n",
      "Epoch: 20, Loss= 0.6962, Training Accuracy= 0.499\n",
      "Epoch: 30, Loss= 0.6958, Training Accuracy= 0.499\n",
      "Epoch: 40, Loss= 0.6955, Training Accuracy= 0.499\n",
      "Epoch: 50, Loss= 0.6953, Training Accuracy= 0.499\n",
      "Epoch: 60, Loss= 0.6952, Training Accuracy= 0.499\n",
      "Epoch: 70, Loss= 0.6951, Training Accuracy= 0.499\n",
      "Epoch: 80, Loss= 0.6951, Training Accuracy= 0.499\n",
      "Epoch: 90, Loss= 0.6950, Training Accuracy= 0.499\n",
      "Epoch: 100, Loss= 0.6950, Training Accuracy= 0.499\n",
      "Epoch: 110, Loss= 0.6949, Training Accuracy= 0.499\n",
      "Epoch: 120, Loss= 0.6949, Training Accuracy= 0.499\n",
      "Epoch: 130, Loss= 0.6948, Training Accuracy= 0.499\n",
      "Epoch: 140, Loss= 0.6948, Training Accuracy= 0.499\n",
      "Epoch: 150, Loss= 0.6948, Training Accuracy= 0.532\n",
      "Epoch: 160, Loss= 0.6947, Training Accuracy= 0.532\n",
      "Epoch: 170, Loss= 0.6947, Training Accuracy= 0.532\n",
      "Epoch: 180, Loss= 0.6947, Training Accuracy= 0.532\n",
      "Epoch: 190, Loss= 0.6947, Training Accuracy= 0.532\n",
      "Epoch: 200, Loss= 0.6946, Training Accuracy= 0.532\n",
      "Epoch: 210, Loss= 0.6946, Training Accuracy= 0.532\n",
      "Epoch: 220, Loss= 0.6946, Training Accuracy= 0.532\n",
      "Epoch: 230, Loss= 0.6946, Training Accuracy= 0.532\n",
      "Epoch: 240, Loss= 0.6945, Training Accuracy= 0.532\n",
      "Epoch: 250, Loss= 0.6945, Training Accuracy= 0.532\n",
      "Epoch: 260, Loss= 0.6943, Training Accuracy= 0.532\n",
      "Epoch: 270, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 280, Loss= 0.1614, Training Accuracy= 0.936\n",
      "Epoch: 290, Loss= 0.0098, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.75\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 1000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49759999, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  0.94976\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.00150720000267\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb678e32890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
