{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 25\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.7081, Training Accuracy= 0.505\n",
      "Epoch: 10, Loss= 0.6994, Training Accuracy= 0.505\n",
      "Epoch: 20, Loss= 0.6983, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 40, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 50, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 60, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 70, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 80, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 90, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 110, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 120, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 130, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 140, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 150, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 160, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 170, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 180, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 200, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 210, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 220, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 230, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 240, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 250, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 260, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 270, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 280, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 290, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 300, Loss= 0.6974, Training Accuracy= 0.505\n",
      "Epoch: 310, Loss= 0.6974, Training Accuracy= 0.505\n",
      "Epoch: 320, Loss= 0.6974, Training Accuracy= 0.505\n",
      "Epoch: 330, Loss= 0.6973, Training Accuracy= 0.505\n",
      "Epoch: 340, Loss= 0.6973, Training Accuracy= 0.505\n",
      "Epoch: 350, Loss= 0.6972, Training Accuracy= 0.505\n",
      "Epoch: 360, Loss= 0.6971, Training Accuracy= 0.505\n",
      "Epoch: 370, Loss= 0.6971, Training Accuracy= 0.505\n",
      "Epoch: 380, Loss= 0.6970, Training Accuracy= 0.505\n",
      "Epoch: 390, Loss= 0.6969, Training Accuracy= 0.505\n",
      "Epoch: 400, Loss= 0.6969, Training Accuracy= 0.505\n",
      "Epoch: 410, Loss= 0.6968, Training Accuracy= 0.506\n",
      "Epoch: 420, Loss= 0.6968, Training Accuracy= 0.506\n",
      "Epoch: 430, Loss= 0.6968, Training Accuracy= 0.506\n",
      "Epoch: 440, Loss= 0.6967, Training Accuracy= 0.507\n",
      "Epoch: 450, Loss= 0.6967, Training Accuracy= 0.506\n",
      "Epoch: 460, Loss= 0.6968, Training Accuracy= 0.507\n",
      "Epoch: 470, Loss= 0.6968, Training Accuracy= 0.507\n",
      "Epoch: 480, Loss= 0.6968, Training Accuracy= 0.506\n",
      "Epoch: 490, Loss= 0.6971, Training Accuracy= 0.506\n",
      "Epoch: 500, Loss= 0.6971, Training Accuracy= 0.507\n",
      "Epoch: 510, Loss= 0.6971, Training Accuracy= 0.507\n",
      "Epoch: 520, Loss= 0.6971, Training Accuracy= 0.508\n",
      "Epoch: 530, Loss= 0.6970, Training Accuracy= 0.508\n",
      "Epoch: 540, Loss= 0.6969, Training Accuracy= 0.510\n",
      "Epoch: 550, Loss= 0.6968, Training Accuracy= 0.510\n",
      "Epoch: 560, Loss= 0.6966, Training Accuracy= 0.512\n",
      "Epoch: 570, Loss= 0.6965, Training Accuracy= 0.513\n",
      "Epoch: 580, Loss= 0.6961, Training Accuracy= 0.515\n",
      "Epoch: 590, Loss= 0.6960, Training Accuracy= 0.516\n",
      "Epoch: 600, Loss= 0.6961, Training Accuracy= 0.517\n",
      "Epoch: 610, Loss= 0.6952, Training Accuracy= 0.519\n",
      "Epoch: 620, Loss= 0.6951, Training Accuracy= 0.519\n",
      "Epoch: 630, Loss= 0.6950, Training Accuracy= 0.521\n",
      "Epoch: 640, Loss= 0.6950, Training Accuracy= 0.522\n",
      "Epoch: 650, Loss= 0.6944, Training Accuracy= 0.523\n",
      "Epoch: 660, Loss= 0.6945, Training Accuracy= 0.522\n",
      "Epoch: 670, Loss= 0.6945, Training Accuracy= 0.524\n",
      "Epoch: 680, Loss= 0.6940, Training Accuracy= 0.525\n",
      "Epoch: 690, Loss= 0.6946, Training Accuracy= 0.525\n",
      "Epoch: 700, Loss= 0.6936, Training Accuracy= 0.525\n",
      "Epoch: 710, Loss= 0.6938, Training Accuracy= 0.523\n",
      "Epoch: 720, Loss= 0.6947, Training Accuracy= 0.529\n",
      "Epoch: 730, Loss= 0.6972, Training Accuracy= 0.508\n",
      "Epoch: 740, Loss= 0.6965, Training Accuracy= 0.511\n",
      "Epoch: 750, Loss= 0.6950, Training Accuracy= 0.517\n",
      "Epoch: 760, Loss= 0.6944, Training Accuracy= 0.522\n",
      "Epoch: 770, Loss= 0.6938, Training Accuracy= 0.523\n",
      "Epoch: 780, Loss= 0.6976, Training Accuracy= 0.518\n",
      "Epoch: 790, Loss= 0.6923, Training Accuracy= 0.531\n",
      "Epoch: 800, Loss= 0.6923, Training Accuracy= 0.532\n",
      "Epoch: 810, Loss= 0.6924, Training Accuracy= 0.530\n",
      "Epoch: 820, Loss= 0.6946, Training Accuracy= 0.529\n",
      "Epoch: 830, Loss= 0.6964, Training Accuracy= 0.505\n",
      "Epoch: 840, Loss= 0.6959, Training Accuracy= 0.506\n",
      "Epoch: 850, Loss= 0.6956, Training Accuracy= 0.507\n",
      "Epoch: 860, Loss= 0.6961, Training Accuracy= 0.511\n",
      "Epoch: 870, Loss= 0.6960, Training Accuracy= 0.511\n",
      "Epoch: 880, Loss= 0.6950, Training Accuracy= 0.512\n",
      "Epoch: 890, Loss= 0.6942, Training Accuracy= 0.514\n",
      "Epoch: 900, Loss= 0.6932, Training Accuracy= 0.521\n",
      "Epoch: 910, Loss= 0.6924, Training Accuracy= 0.527\n",
      "Epoch: 920, Loss= 0.6919, Training Accuracy= 0.531\n",
      "Epoch: 930, Loss= 0.6913, Training Accuracy= 0.533\n",
      "Epoch: 940, Loss= 0.6907, Training Accuracy= 0.534\n",
      "Epoch: 950, Loss= 0.6904, Training Accuracy= 0.535\n",
      "Epoch: 960, Loss= 0.6900, Training Accuracy= 0.533\n",
      "Epoch: 970, Loss= 0.6898, Training Accuracy= 0.534\n",
      "Epoch: 980, Loss= 0.6896, Training Accuracy= 0.533\n",
      "Epoch: 990, Loss= 0.6895, Training Accuracy= 0.535\n",
      "Epoch: 1000, Loss= 0.6894, Training Accuracy= 0.532\n",
      "Epoch: 1010, Loss= 0.6894, Training Accuracy= 0.531\n",
      "Epoch: 1020, Loss= 0.6889, Training Accuracy= 0.534\n",
      "Epoch: 1030, Loss= 0.6894, Training Accuracy= 0.531\n",
      "Epoch: 1040, Loss= 0.6893, Training Accuracy= 0.532\n",
      "Epoch: 1050, Loss= 0.6884, Training Accuracy= 0.533\n",
      "Epoch: 1060, Loss= 0.6892, Training Accuracy= 0.534\n",
      "Epoch: 1070, Loss= 0.6897, Training Accuracy= 0.533\n",
      "Epoch: 1080, Loss= 0.6899, Training Accuracy= 0.532\n",
      "Epoch: 1090, Loss= 0.6887, Training Accuracy= 0.535\n",
      "Epoch: 1100, Loss= 0.6963, Training Accuracy= 0.525\n",
      "Epoch: 1110, Loss= 0.6910, Training Accuracy= 0.532\n",
      "Epoch: 1120, Loss= 0.6943, Training Accuracy= 0.529\n",
      "Epoch: 1130, Loss= 0.6890, Training Accuracy= 0.538\n",
      "Epoch: 1140, Loss= 0.6932, Training Accuracy= 0.531\n",
      "Epoch: 1150, Loss= 0.6894, Training Accuracy= 0.536\n",
      "Epoch: 1160, Loss= 0.6893, Training Accuracy= 0.540\n",
      "Epoch: 1170, Loss= 0.6937, Training Accuracy= 0.533\n",
      "Epoch: 1180, Loss= 0.6879, Training Accuracy= 0.539\n",
      "Epoch: 1190, Loss= 0.6890, Training Accuracy= 0.539\n",
      "Epoch: 1200, Loss= 0.6909, Training Accuracy= 0.537\n",
      "Epoch: 1210, Loss= 0.6875, Training Accuracy= 0.547\n",
      "Epoch: 1220, Loss= 0.6972, Training Accuracy= 0.524\n",
      "Epoch: 1230, Loss= 0.6904, Training Accuracy= 0.536\n",
      "Epoch: 1240, Loss= 0.7014, Training Accuracy= 0.504\n",
      "Epoch: 1250, Loss= 0.7045, Training Accuracy= 0.506\n",
      "Epoch: 1260, Loss= 0.6995, Training Accuracy= 0.505\n",
      "Epoch: 1270, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 1280, Loss= 0.6997, Training Accuracy= 0.505\n",
      "Epoch: 1290, Loss= 0.7016, Training Accuracy= 0.505\n",
      "Epoch: 1300, Loss= 0.7001, Training Accuracy= 0.505\n",
      "Epoch: 1310, Loss= 0.6992, Training Accuracy= 0.506\n",
      "Epoch: 1320, Loss= 0.6994, Training Accuracy= 0.505\n",
      "Epoch: 1330, Loss= 0.7042, Training Accuracy= 0.505\n",
      "Epoch: 1340, Loss= 0.7013, Training Accuracy= 0.505\n",
      "Epoch: 1350, Loss= 0.6995, Training Accuracy= 0.505\n",
      "Epoch: 1360, Loss= 0.6995, Training Accuracy= 0.505\n",
      "Epoch: 1370, Loss= 0.6984, Training Accuracy= 0.505\n",
      "Epoch: 1380, Loss= 0.6973, Training Accuracy= 0.507\n",
      "Epoch: 1390, Loss= 0.6972, Training Accuracy= 0.508\n",
      "Epoch: 1400, Loss= 0.6972, Training Accuracy= 0.508\n",
      "Epoch: 1410, Loss= 0.6968, Training Accuracy= 0.508\n",
      "Epoch: 1420, Loss= 0.6970, Training Accuracy= 0.509\n",
      "Epoch: 1430, Loss= 0.6970, Training Accuracy= 0.508\n",
      "Epoch: 1440, Loss= 0.6974, Training Accuracy= 0.507\n",
      "Epoch: 1450, Loss= 0.6979, Training Accuracy= 0.508\n",
      "Epoch: 1460, Loss= 0.6989, Training Accuracy= 0.509\n",
      "Epoch: 1470, Loss= 0.6978, Training Accuracy= 0.508\n",
      "Epoch: 1480, Loss= 0.6980, Training Accuracy= 0.508\n",
      "Epoch: 1490, Loss= 0.6982, Training Accuracy= 0.509\n",
      "Epoch: 1500, Loss= 0.6968, Training Accuracy= 0.507\n",
      "Epoch: 1510, Loss= 0.6965, Training Accuracy= 0.511\n",
      "Epoch: 1520, Loss= 0.7008, Training Accuracy= 0.507\n",
      "Epoch: 1530, Loss= 0.6990, Training Accuracy= 0.508\n",
      "Epoch: 1540, Loss= 0.7020, Training Accuracy= 0.507\n",
      "Epoch: 1550, Loss= 0.7070, Training Accuracy= 0.505\n",
      "Epoch: 1560, Loss= 0.7052, Training Accuracy= 0.505\n",
      "Epoch: 1570, Loss= 0.7042, Training Accuracy= 0.505\n",
      "Epoch: 1580, Loss= 0.7031, Training Accuracy= 0.505\n",
      "Epoch: 1590, Loss= 0.7020, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss= 0.7011, Training Accuracy= 0.505\n",
      "Epoch: 1610, Loss= 0.7006, Training Accuracy= 0.505\n",
      "Epoch: 1620, Loss= 0.7001, Training Accuracy= 0.505\n",
      "Epoch: 1630, Loss= 0.6997, Training Accuracy= 0.505\n",
      "Epoch: 1640, Loss= 0.6994, Training Accuracy= 0.505\n",
      "Epoch: 1650, Loss= 0.6989, Training Accuracy= 0.505\n",
      "Epoch: 1660, Loss= 0.6991, Training Accuracy= 0.505\n",
      "Epoch: 1670, Loss= 0.6989, Training Accuracy= 0.505\n",
      "Epoch: 1680, Loss= 0.6985, Training Accuracy= 0.505\n",
      "Epoch: 1690, Loss= 0.6983, Training Accuracy= 0.505\n",
      "Epoch: 1700, Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 1710, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 1720, Loss= 0.7005, Training Accuracy= 0.505\n",
      "Epoch: 1730, Loss= 0.7001, Training Accuracy= 0.505\n",
      "Epoch: 1740, Loss= 0.6998, Training Accuracy= 0.505\n",
      "Epoch: 1750, Loss= 0.6995, Training Accuracy= 0.505\n",
      "Epoch: 1760, Loss= 0.6993, Training Accuracy= 0.505\n",
      "Epoch: 1770, Loss= 0.6992, Training Accuracy= 0.505\n",
      "Epoch: 1780, Loss= 0.6990, Training Accuracy= 0.505\n",
      "Epoch: 1790, Loss= 0.6989, Training Accuracy= 0.505\n",
      "Epoch: 1800, Loss= 0.6988, Training Accuracy= 0.505\n",
      "Epoch: 1810, Loss= 0.6986, Training Accuracy= 0.505\n",
      "Epoch: 1820, Loss= 0.6985, Training Accuracy= 0.505\n",
      "Epoch: 1830, Loss= 0.6984, Training Accuracy= 0.505\n",
      "Epoch: 1840, Loss= 0.6983, Training Accuracy= 0.505\n",
      "Epoch: 1850, Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 1860, Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 1870, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 1880, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 1890, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 1900, Loss= 0.6974, Training Accuracy= 0.505\n",
      "Epoch: 1910, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 1920, Loss= 0.6974, Training Accuracy= 0.505\n",
      "Epoch: 1930, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 1940, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 1950, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 1960, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 1970, Loss= 0.6974, Training Accuracy= 0.505\n",
      "Epoch: 1980, Loss= 0.6974, Training Accuracy= 0.505\n",
      "Epoch: 1990, Loss= 0.6973, Training Accuracy= 0.505\n",
      "Epoch: 2000, Loss= 0.6973, Training Accuracy= 0.505\n",
      "Epoch: 2010, Loss= 0.6972, Training Accuracy= 0.505\n",
      "Epoch: 2020, Loss= 0.6972, Training Accuracy= 0.505\n",
      "Epoch: 2030, Loss= 0.6972, Training Accuracy= 0.505\n",
      "Epoch: 2040, Loss= 0.6971, Training Accuracy= 0.505\n",
      "Epoch: 2050, Loss= 0.6971, Training Accuracy= 0.505\n",
      "Epoch: 2060, Loss= 0.6970, Training Accuracy= 0.505\n",
      "Epoch: 2070, Loss= 0.6969, Training Accuracy= 0.505\n",
      "Epoch: 2080, Loss= 0.6969, Training Accuracy= 0.505\n",
      "Epoch: 2090, Loss= 0.6968, Training Accuracy= 0.505\n",
      "Epoch: 2100, Loss= 0.6967, Training Accuracy= 0.505\n",
      "Epoch: 2110, Loss= 0.6966, Training Accuracy= 0.505\n",
      "Epoch: 2120, Loss= 0.6964, Training Accuracy= 0.505\n",
      "Epoch: 2130, Loss= 0.6963, Training Accuracy= 0.505\n",
      "Epoch: 2140, Loss= 0.6962, Training Accuracy= 0.505\n",
      "Epoch: 2150, Loss= 0.6961, Training Accuracy= 0.505\n",
      "Epoch: 2160, Loss= 0.6960, Training Accuracy= 0.506\n",
      "Epoch: 2170, Loss= 0.6960, Training Accuracy= 0.506\n",
      "Epoch: 2180, Loss= 0.6959, Training Accuracy= 0.506\n",
      "Epoch: 2190, Loss= 0.6959, Training Accuracy= 0.506\n",
      "Epoch: 2200, Loss= 0.6958, Training Accuracy= 0.506\n",
      "Epoch: 2210, Loss= 0.6958, Training Accuracy= 0.506\n",
      "Epoch: 2220, Loss= 0.6958, Training Accuracy= 0.507\n",
      "Epoch: 2230, Loss= 0.6958, Training Accuracy= 0.507\n",
      "Epoch: 2240, Loss= 0.6957, Training Accuracy= 0.507\n",
      "Epoch: 2250, Loss= 0.6957, Training Accuracy= 0.507\n",
      "Epoch: 2260, Loss= 0.6956, Training Accuracy= 0.507\n",
      "Epoch: 2270, Loss= 0.6955, Training Accuracy= 0.508\n",
      "Epoch: 2280, Loss= 0.6955, Training Accuracy= 0.509\n",
      "Epoch: 2290, Loss= 0.6954, Training Accuracy= 0.510\n",
      "Epoch: 2300, Loss= 0.6952, Training Accuracy= 0.509\n",
      "Epoch: 2310, Loss= 0.6984, Training Accuracy= 0.505\n",
      "Epoch: 2320, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 2330, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 2340, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 2350, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 2360, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 2370, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 2380, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 2390, Loss= 0.6976, Training Accuracy= 0.505\n",
      "Epoch: 2400, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 2410, Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 2420, Loss= 0.6974, Training Accuracy= 0.505\n",
      "Epoch: 2430, Loss= 0.6974, Training Accuracy= 0.505\n",
      "Epoch: 2440, Loss= 0.6974, Training Accuracy= 0.505\n",
      "Epoch: 2450, Loss= 0.6973, Training Accuracy= 0.505\n",
      "Epoch: 2460, Loss= 0.6973, Training Accuracy= 0.505\n",
      "Epoch: 2470, Loss= 0.6973, Training Accuracy= 0.506\n",
      "Epoch: 2480, Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 2490, Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 2500, Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 2510, Loss= 0.6972, Training Accuracy= 0.507\n",
      "Epoch: 2520, Loss= 0.6971, Training Accuracy= 0.507\n",
      "Epoch: 2530, Loss= 0.6971, Training Accuracy= 0.506\n",
      "Epoch: 2540, Loss= 0.6971, Training Accuracy= 0.506\n",
      "Epoch: 2550, Loss= 0.6971, Training Accuracy= 0.506\n",
      "Epoch: 2560, Loss= 0.6971, Training Accuracy= 0.507\n",
      "Epoch: 2570, Loss= 0.6971, Training Accuracy= 0.507\n",
      "Epoch: 2580, Loss= 0.6971, Training Accuracy= 0.507\n",
      "Epoch: 2590, Loss= 0.6971, Training Accuracy= 0.507\n",
      "Epoch: 2600, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2610, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2620, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2630, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2640, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2650, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2660, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2670, Loss= 0.6970, Training Accuracy= 0.508\n",
      "Epoch: 2680, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2690, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2700, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2710, Loss= 0.6970, Training Accuracy= 0.507\n",
      "Epoch: 2720, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2730, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2740, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2750, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2760, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2770, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2780, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2790, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2800, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2810, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2820, Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 2830, Loss= 0.6968, Training Accuracy= 0.507\n",
      "Epoch: 2840, Loss= 0.6968, Training Accuracy= 0.507\n",
      "Epoch: 2850, Loss= 0.6968, Training Accuracy= 0.507\n",
      "Epoch: 2860, Loss= 0.6968, Training Accuracy= 0.507\n",
      "Epoch: 2870, Loss= 0.6968, Training Accuracy= 0.507\n",
      "Epoch: 2880, Loss= 0.6968, Training Accuracy= 0.508\n",
      "Epoch: 2890, Loss= 0.6968, Training Accuracy= 0.508\n",
      "Epoch: 2900, Loss= 0.6968, Training Accuracy= 0.508\n",
      "Epoch: 2910, Loss= 0.6968, Training Accuracy= 0.507\n",
      "Epoch: 2920, Loss= 0.6968, Training Accuracy= 0.508\n",
      "Epoch: 2930, Loss= 0.6968, Training Accuracy= 0.508\n",
      "Epoch: 2940, Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 2950, Loss= 0.6967, Training Accuracy= 0.507\n",
      "Epoch: 2960, Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 2970, Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 2980, Loss= 0.6967, Training Accuracy= 0.507\n",
      "Epoch: 2990, Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 3000, Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 3010, Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 3020, Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 3030, Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 3040, Loss= 0.6966, Training Accuracy= 0.508\n",
      "Epoch: 3050, Loss= 0.6966, Training Accuracy= 0.508\n",
      "Epoch: 3060, Loss= 0.6966, Training Accuracy= 0.507\n",
      "Epoch: 3070, Loss= 0.6966, Training Accuracy= 0.507\n",
      "Epoch: 3080, Loss= 0.6966, Training Accuracy= 0.507\n",
      "Epoch: 3090, Loss= 0.6966, Training Accuracy= 0.507\n",
      "Epoch: 3100, Loss= 0.6966, Training Accuracy= 0.507\n",
      "Epoch: 3110, Loss= 0.6966, Training Accuracy= 0.507\n",
      "Epoch: 3120, Loss= 0.6966, Training Accuracy= 0.507\n",
      "Epoch: 3130, Loss= 0.6966, Training Accuracy= 0.507\n",
      "Epoch: 3140, Loss= 0.6966, Training Accuracy= 0.507\n",
      "Epoch: 3150, Loss= 0.6966, Training Accuracy= 0.507\n",
      "Epoch: 3160, Loss= 0.6965, Training Accuracy= 0.507\n",
      "Epoch: 3170, Loss= 0.6965, Training Accuracy= 0.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3180, Loss= 0.6965, Training Accuracy= 0.507\n",
      "Epoch: 3190, Loss= 0.6965, Training Accuracy= 0.507\n",
      "Epoch: 3200, Loss= 0.6965, Training Accuracy= 0.507\n",
      "Epoch: 3210, Loss= 0.6965, Training Accuracy= 0.507\n",
      "Epoch: 3220, Loss= 0.6965, Training Accuracy= 0.507\n",
      "Epoch: 3230, Loss= 0.6965, Training Accuracy= 0.507\n",
      "Epoch: 3240, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3250, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3260, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3270, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3280, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3290, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3300, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3310, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3320, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3330, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3340, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3350, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3360, Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3370, Loss= 0.6965, Training Accuracy= 0.509\n",
      "Epoch: 3380, Loss= 0.6965, Training Accuracy= 0.509\n",
      "Epoch: 3390, Loss= 0.6966, Training Accuracy= 0.509\n",
      "Epoch: 3400, Loss= 0.6966, Training Accuracy= 0.509\n",
      "Epoch: 3410, Loss= 0.6966, Training Accuracy= 0.509\n",
      "Epoch: 3420, Loss= 0.6966, Training Accuracy= 0.510\n",
      "Epoch: 3430, Loss= 0.6966, Training Accuracy= 0.510\n",
      "Epoch: 3440, Loss= 0.6966, Training Accuracy= 0.510\n",
      "Epoch: 3450, Loss= 0.6966, Training Accuracy= 0.511\n",
      "Epoch: 3460, Loss= 0.6966, Training Accuracy= 0.510\n",
      "Epoch: 3470, Loss= 0.6966, Training Accuracy= 0.510\n",
      "Epoch: 3480, Loss= 0.6966, Training Accuracy= 0.510\n",
      "Epoch: 3490, Loss= 0.6966, Training Accuracy= 0.510\n",
      "Epoch: 3500, Loss= 0.6966, Training Accuracy= 0.511\n",
      "Epoch: 3510, Loss= 0.6966, Training Accuracy= 0.511\n",
      "Epoch: 3520, Loss= 0.6965, Training Accuracy= 0.510\n",
      "Epoch: 3530, Loss= 0.6965, Training Accuracy= 0.510\n",
      "Epoch: 3540, Loss= 0.6965, Training Accuracy= 0.511\n",
      "Epoch: 3550, Loss= 0.6965, Training Accuracy= 0.510\n",
      "Epoch: 3560, Loss= 0.6965, Training Accuracy= 0.510\n",
      "Epoch: 3570, Loss= 0.6964, Training Accuracy= 0.510\n",
      "Epoch: 3580, Loss= 0.6964, Training Accuracy= 0.512\n",
      "Epoch: 3590, Loss= 0.6965, Training Accuracy= 0.513\n",
      "Epoch: 3600, Loss= 0.6965, Training Accuracy= 0.514\n",
      "Epoch: 3610, Loss= 0.6965, Training Accuracy= 0.513\n",
      "Epoch: 3620, Loss= 0.6965, Training Accuracy= 0.513\n",
      "Epoch: 3630, Loss= 0.6965, Training Accuracy= 0.513\n",
      "Epoch: 3640, Loss= 0.6964, Training Accuracy= 0.515\n",
      "Epoch: 3650, Loss= 0.6964, Training Accuracy= 0.515\n",
      "Epoch: 3660, Loss= 0.6965, Training Accuracy= 0.517\n",
      "Epoch: 3670, Loss= 0.6965, Training Accuracy= 0.516\n",
      "Epoch: 3680, Loss= 0.6966, Training Accuracy= 0.516\n",
      "Epoch: 3690, Loss= 0.6967, Training Accuracy= 0.518\n",
      "Epoch: 3700, Loss= 0.6968, Training Accuracy= 0.518\n",
      "Epoch: 3710, Loss= 0.6969, Training Accuracy= 0.517\n",
      "Epoch: 3720, Loss= 0.6978, Training Accuracy= 0.519\n",
      "Epoch: 3730, Loss= 0.6966, Training Accuracy= 0.517\n",
      "Epoch: 3740, Loss= 0.6982, Training Accuracy= 0.517\n",
      "Epoch: 3750, Loss= 0.6974, Training Accuracy= 0.518\n",
      "Epoch: 3760, Loss= 0.6968, Training Accuracy= 0.515\n",
      "Epoch: 3770, Loss= 0.6968, Training Accuracy= 0.517\n",
      "Epoch: 3780, Loss= 0.6978, Training Accuracy= 0.513\n",
      "Epoch: 3790, Loss= 0.6990, Training Accuracy= 0.509\n",
      "Epoch: 3800, Loss= 0.6965, Training Accuracy= 0.516\n",
      "Epoch: 3810, Loss= 0.6973, Training Accuracy= 0.518\n",
      "Epoch: 3820, Loss= 0.6971, Training Accuracy= 0.517\n",
      "Epoch: 3830, Loss= 0.6956, Training Accuracy= 0.519\n",
      "Epoch: 3840, Loss= 0.6969, Training Accuracy= 0.518\n",
      "Epoch: 3850, Loss= 0.6967, Training Accuracy= 0.519\n",
      "Epoch: 3860, Loss= 0.6966, Training Accuracy= 0.518\n",
      "Epoch: 3870, Loss= 0.6958, Training Accuracy= 0.518\n",
      "Epoch: 3880, Loss= 0.6949, Training Accuracy= 0.518\n",
      "Epoch: 3890, Loss= 0.6957, Training Accuracy= 0.518\n",
      "Epoch: 3900, Loss= 0.6956, Training Accuracy= 0.519\n",
      "Epoch: 3910, Loss= 0.6949, Training Accuracy= 0.519\n",
      "Epoch: 3920, Loss= 0.6963, Training Accuracy= 0.518\n",
      "Epoch: 3930, Loss= 0.6962, Training Accuracy= 0.517\n",
      "Epoch: 3940, Loss= 0.6961, Training Accuracy= 0.520\n",
      "Epoch: 3950, Loss= 0.6972, Training Accuracy= 0.520\n",
      "Epoch: 3960, Loss= 0.6977, Training Accuracy= 0.517\n",
      "Epoch: 3970, Loss= 0.6977, Training Accuracy= 0.519\n",
      "Epoch: 3980, Loss= 0.6981, Training Accuracy= 0.509\n",
      "Epoch: 3990, Loss= 0.6949, Training Accuracy= 0.521\n",
      "Epoch: 4000, Loss= 0.6959, Training Accuracy= 0.521\n",
      "Epoch: 4010, Loss= 0.6958, Training Accuracy= 0.519\n",
      "Epoch: 4020, Loss= 0.6969, Training Accuracy= 0.512\n",
      "Epoch: 4030, Loss= 0.6953, Training Accuracy= 0.521\n",
      "Epoch: 4040, Loss= 0.6953, Training Accuracy= 0.522\n",
      "Epoch: 4050, Loss= 0.6954, Training Accuracy= 0.521\n",
      "Epoch: 4060, Loss= 0.6971, Training Accuracy= 0.520\n",
      "Epoch: 4070, Loss= 0.6976, Training Accuracy= 0.519\n",
      "Epoch: 4080, Loss= 0.6963, Training Accuracy= 0.521\n",
      "Epoch: 4090, Loss= 0.6995, Training Accuracy= 0.507\n",
      "Epoch: 4100, Loss= 0.6990, Training Accuracy= 0.510\n",
      "Epoch: 4110, Loss= 0.6960, Training Accuracy= 0.509\n",
      "Epoch: 4120, Loss= 0.6956, Training Accuracy= 0.510\n",
      "Epoch: 4130, Loss= 0.6956, Training Accuracy= 0.511\n",
      "Epoch: 4140, Loss= 0.6957, Training Accuracy= 0.513\n",
      "Epoch: 4150, Loss= 0.6961, Training Accuracy= 0.512\n",
      "Epoch: 4160, Loss= 0.6964, Training Accuracy= 0.512\n",
      "Epoch: 4170, Loss= 0.6974, Training Accuracy= 0.511\n",
      "Epoch: 4180, Loss= 0.6978, Training Accuracy= 0.511\n",
      "Epoch: 4190, Loss= 0.6962, Training Accuracy= 0.514\n",
      "Epoch: 4200, Loss= 0.6960, Training Accuracy= 0.515\n",
      "Epoch: 4210, Loss= 0.6963, Training Accuracy= 0.515\n",
      "Epoch: 4220, Loss= 0.6992, Training Accuracy= 0.510\n",
      "Epoch: 4230, Loss= 0.6958, Training Accuracy= 0.516\n",
      "Epoch: 4240, Loss= 0.6973, Training Accuracy= 0.513\n",
      "Epoch: 4250, Loss= 0.6973, Training Accuracy= 0.511\n",
      "Epoch: 4260, Loss= 0.6979, Training Accuracy= 0.512\n",
      "Epoch: 4270, Loss= 0.6978, Training Accuracy= 0.512\n",
      "Epoch: 4280, Loss= 0.6982, Training Accuracy= 0.511\n",
      "Epoch: 4290, Loss= 0.6986, Training Accuracy= 0.511\n",
      "Epoch: 4300, Loss= 0.6984, Training Accuracy= 0.509\n",
      "Epoch: 4310, Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 4320, Loss= 0.6982, Training Accuracy= 0.508\n",
      "Epoch: 4330, Loss= 0.6984, Training Accuracy= 0.512\n",
      "Epoch: 4340, Loss= 0.6976, Training Accuracy= 0.513\n",
      "Epoch: 4350, Loss= 0.6989, Training Accuracy= 0.511\n",
      "Epoch: 4360, Loss= 0.6983, Training Accuracy= 0.512\n",
      "Epoch: 4370, Loss= 0.6956, Training Accuracy= 0.515\n",
      "Epoch: 4380, Loss= 0.6981, Training Accuracy= 0.510\n",
      "Epoch: 4390, Loss= 0.6975, Training Accuracy= 0.511\n",
      "Epoch: 4400, Loss= 0.6978, Training Accuracy= 0.511\n",
      "Epoch: 4410, Loss= 0.6987, Training Accuracy= 0.511\n",
      "Epoch: 4420, Loss= 0.6958, Training Accuracy= 0.516\n",
      "Epoch: 4430, Loss= 0.6966, Training Accuracy= 0.515\n",
      "Epoch: 4440, Loss= 0.6970, Training Accuracy= 0.514\n",
      "Epoch: 4450, Loss= 0.6969, Training Accuracy= 0.513\n",
      "Epoch: 4460, Loss= 0.6966, Training Accuracy= 0.515\n",
      "Epoch: 4470, Loss= 0.6966, Training Accuracy= 0.516\n",
      "Epoch: 4480, Loss= 0.6948, Training Accuracy= 0.518\n",
      "Epoch: 4490, Loss= 0.6986, Training Accuracy= 0.514\n",
      "Epoch: 4500, Loss= 0.6953, Training Accuracy= 0.517\n",
      "Epoch: 4510, Loss= 0.6985, Training Accuracy= 0.511\n",
      "Epoch: 4520, Loss= 0.6970, Training Accuracy= 0.515\n",
      "Epoch: 4530, Loss= 0.6975, Training Accuracy= 0.513\n",
      "Epoch: 4540, Loss= 0.6966, Training Accuracy= 0.515\n",
      "Epoch: 4550, Loss= 0.6968, Training Accuracy= 0.517\n",
      "Epoch: 4560, Loss= 0.6960, Training Accuracy= 0.519\n",
      "Epoch: 4570, Loss= 0.7053, Training Accuracy= 0.510\n",
      "Epoch: 4580, Loss= 0.7089, Training Accuracy= 0.506\n",
      "Epoch: 4590, Loss= 0.7105, Training Accuracy= 0.506\n",
      "Epoch: 4600, Loss= 0.7078, Training Accuracy= 0.508\n",
      "Epoch: 4610, Loss= 0.7054, Training Accuracy= 0.513\n",
      "Epoch: 4620, Loss= 0.7077, Training Accuracy= 0.509\n",
      "Epoch: 4630, Loss= 0.7078, Training Accuracy= 0.507\n",
      "Epoch: 4640, Loss= 0.7058, Training Accuracy= 0.507\n",
      "Epoch: 4650, Loss= 0.7088, Training Accuracy= 0.505\n",
      "Epoch: 4660, Loss= 0.7094, Training Accuracy= 0.505\n",
      "Epoch: 4670, Loss= 0.7078, Training Accuracy= 0.505\n",
      "Epoch: 4680, Loss= 0.7072, Training Accuracy= 0.505\n",
      "Epoch: 4690, Loss= 0.7070, Training Accuracy= 0.505\n",
      "Epoch: 4700, Loss= 0.7061, Training Accuracy= 0.505\n",
      "Epoch: 4710, Loss= 0.7038, Training Accuracy= 0.505\n",
      "Epoch: 4720, Loss= 0.7064, Training Accuracy= 0.505\n",
      "Epoch: 4730, Loss= 0.7088, Training Accuracy= 0.505\n",
      "Epoch: 4740, Loss= 0.7122, Training Accuracy= 0.505\n",
      "Epoch: 4750, Loss= 0.7090, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4760, Loss= 0.7126, Training Accuracy= 0.505\n",
      "Epoch: 4770, Loss= 0.7268, Training Accuracy= 0.505\n",
      "Epoch: 4780, Loss= 0.6944, Training Accuracy= 0.507\n",
      "Epoch: 4790, Loss= 0.6639, Training Accuracy= 0.566\n",
      "Epoch: 4800, Loss= 0.6365, Training Accuracy= 0.572\n",
      "Epoch: 4810, Loss= 0.6303, Training Accuracy= 0.573\n",
      "Epoch: 4820, Loss= 0.6201, Training Accuracy= 0.586\n",
      "Epoch: 4830, Loss= 0.6132, Training Accuracy= 0.599\n",
      "Epoch: 4840, Loss= 0.6110, Training Accuracy= 0.601\n",
      "Epoch: 4850, Loss= 0.5832, Training Accuracy= 0.625\n",
      "Epoch: 4860, Loss= 0.4791, Training Accuracy= 0.728\n",
      "Epoch: 4870, Loss= 0.4893, Training Accuracy= 0.715\n",
      "Epoch: 4880, Loss= 0.6052, Training Accuracy= 0.688\n",
      "Epoch: 4890, Loss= 0.6066, Training Accuracy= 0.690\n",
      "Epoch: 4900, Loss= 0.6208, Training Accuracy= 0.693\n",
      "Epoch: 4910, Loss= 0.6262, Training Accuracy= 0.697\n",
      "Epoch: 4920, Loss= 0.6196, Training Accuracy= 0.697\n",
      "Epoch: 4930, Loss= 0.6160, Training Accuracy= 0.695\n",
      "Epoch: 4940, Loss= 0.6399, Training Accuracy= 0.693\n",
      "Epoch: 4950, Loss= 0.6535, Training Accuracy= 0.688\n",
      "Epoch: 4960, Loss= 0.6533, Training Accuracy= 0.700\n",
      "Epoch: 4970, Loss= 0.6451, Training Accuracy= 0.709\n",
      "Epoch: 4980, Loss= 0.6289, Training Accuracy= 0.714\n",
      "Epoch: 4990, Loss= 0.6020, Training Accuracy= 0.714\n",
      "Epoch: 5000, Loss= 0.5744, Training Accuracy= 0.718\n",
      "Epoch: 5010, Loss= 0.5623, Training Accuracy= 0.723\n",
      "Epoch: 5020, Loss= 0.5526, Training Accuracy= 0.729\n",
      "Epoch: 5030, Loss= 0.5469, Training Accuracy= 0.730\n",
      "Epoch: 5040, Loss= 0.5320, Training Accuracy= 0.736\n",
      "Epoch: 5050, Loss= 0.8157, Training Accuracy= 0.602\n",
      "Epoch: 5060, Loss= 0.5109, Training Accuracy= 0.702\n",
      "Epoch: 5070, Loss= 0.5128, Training Accuracy= 0.707\n",
      "Epoch: 5080, Loss= 0.5422, Training Accuracy= 0.710\n",
      "Epoch: 5090, Loss= 0.5079, Training Accuracy= 0.704\n",
      "Epoch: 5100, Loss= 0.4748, Training Accuracy= 0.747\n",
      "Epoch: 5110, Loss= 0.4824, Training Accuracy= 0.743\n",
      "Epoch: 5120, Loss= 0.5208, Training Accuracy= 0.714\n",
      "Epoch: 5130, Loss= 0.4849, Training Accuracy= 0.718\n",
      "Epoch: 5140, Loss= 0.4664, Training Accuracy= 0.750\n",
      "Epoch: 5150, Loss= 0.4881, Training Accuracy= 0.715\n",
      "Epoch: 5160, Loss= 0.4804, Training Accuracy= 0.713\n",
      "Epoch: 5170, Loss= 0.4677, Training Accuracy= 0.752\n",
      "Epoch: 5180, Loss= 0.4758, Training Accuracy= 0.753\n",
      "Epoch: 5190, Loss= 0.4838, Training Accuracy= 0.750\n",
      "Epoch: 5200, Loss= 0.4897, Training Accuracy= 0.749\n",
      "Epoch: 5210, Loss= 0.4928, Training Accuracy= 0.751\n",
      "Epoch: 5220, Loss= 0.4908, Training Accuracy= 0.753\n",
      "Epoch: 5230, Loss= 0.4884, Training Accuracy= 0.754\n",
      "Epoch: 5240, Loss= 0.5217, Training Accuracy= 0.707\n",
      "Epoch: 5250, Loss= 0.4976, Training Accuracy= 0.718\n",
      "Epoch: 5260, Loss= 0.4761, Training Accuracy= 0.725\n",
      "Epoch: 5270, Loss= 0.5581, Training Accuracy= 0.701\n",
      "Epoch: 5280, Loss= 0.5726, Training Accuracy= 0.700\n",
      "Epoch: 5290, Loss= 0.5816, Training Accuracy= 0.698\n",
      "Epoch: 5300, Loss= 0.4807, Training Accuracy= 0.738\n",
      "Epoch: 5310, Loss= 0.4605, Training Accuracy= 0.747\n",
      "Epoch: 5320, Loss= 0.4638, Training Accuracy= 0.744\n",
      "Epoch: 5330, Loss= 0.4613, Training Accuracy= 0.745\n",
      "Epoch: 5340, Loss= 0.4505, Training Accuracy= 0.753\n",
      "Epoch: 5350, Loss= 0.4430, Training Accuracy= 0.758\n",
      "Epoch: 5360, Loss= 0.4398, Training Accuracy= 0.760\n",
      "Epoch: 5370, Loss= 0.4385, Training Accuracy= 0.760\n",
      "Epoch: 5380, Loss= 0.4385, Training Accuracy= 0.759\n",
      "Epoch: 5390, Loss= 0.4406, Training Accuracy= 0.760\n",
      "Epoch: 5400, Loss= 0.4432, Training Accuracy= 0.761\n",
      "Epoch: 5410, Loss= 0.4470, Training Accuracy= 0.758\n",
      "Epoch: 5420, Loss= 0.4512, Training Accuracy= 0.756\n",
      "Epoch: 5430, Loss= 0.4581, Training Accuracy= 0.757\n",
      "Epoch: 5440, Loss= 0.4669, Training Accuracy= 0.755\n",
      "Epoch: 5450, Loss= 0.4797, Training Accuracy= 0.761\n",
      "Epoch: 5460, Loss= 0.4896, Training Accuracy= 0.757\n",
      "Epoch: 5470, Loss= 0.5009, Training Accuracy= 0.757\n",
      "Epoch: 5480, Loss= 0.5095, Training Accuracy= 0.753\n",
      "Epoch: 5490, Loss= 0.5121, Training Accuracy= 0.752\n",
      "Epoch: 5500, Loss= 0.5157, Training Accuracy= 0.752\n",
      "Epoch: 5510, Loss= 0.5146, Training Accuracy= 0.752\n",
      "Epoch: 5520, Loss= 0.5144, Training Accuracy= 0.752\n",
      "Epoch: 5530, Loss= 0.5061, Training Accuracy= 0.757\n",
      "Epoch: 5540, Loss= 0.4875, Training Accuracy= 0.754\n",
      "Epoch: 5550, Loss= 0.4959, Training Accuracy= 0.761\n",
      "Epoch: 5560, Loss= 0.4876, Training Accuracy= 0.759\n",
      "Epoch: 5570, Loss= 0.4942, Training Accuracy= 0.760\n",
      "Epoch: 5580, Loss= 0.4771, Training Accuracy= 0.761\n",
      "Epoch: 5590, Loss= 0.4672, Training Accuracy= 0.760\n",
      "Epoch: 5600, Loss= 0.4864, Training Accuracy= 0.762\n",
      "Epoch: 5610, Loss= 0.4598, Training Accuracy= 0.760\n",
      "Epoch: 5620, Loss= 0.4619, Training Accuracy= 0.759\n",
      "Epoch: 5630, Loss= 0.4920, Training Accuracy= 0.758\n",
      "Epoch: 5640, Loss= 0.4827, Training Accuracy= 0.748\n",
      "Epoch: 5650, Loss= 0.5542, Training Accuracy= 0.627\n",
      "Epoch: 5660, Loss= 0.4691, Training Accuracy= 0.689\n",
      "Epoch: 5670, Loss= 0.4553, Training Accuracy= 0.693\n",
      "Epoch: 5680, Loss= 0.4459, Training Accuracy= 0.704\n",
      "Epoch: 5690, Loss= 0.4201, Training Accuracy= 0.715\n",
      "Epoch: 5700, Loss= 0.4089, Training Accuracy= 0.733\n",
      "Epoch: 5710, Loss= 0.5226, Training Accuracy= 0.659\n",
      "Epoch: 5720, Loss= 0.4011, Training Accuracy= 0.732\n",
      "Epoch: 5730, Loss= 0.3972, Training Accuracy= 0.738\n",
      "Epoch: 5740, Loss= 0.3954, Training Accuracy= 0.742\n",
      "Epoch: 5750, Loss= 0.3942, Training Accuracy= 0.743\n",
      "Epoch: 5760, Loss= 0.3926, Training Accuracy= 0.741\n",
      "Epoch: 5770, Loss= 0.3911, Training Accuracy= 0.741\n",
      "Epoch: 5780, Loss= 0.3897, Training Accuracy= 0.740\n",
      "Epoch: 5790, Loss= 0.3893, Training Accuracy= 0.739\n",
      "Epoch: 5800, Loss= 0.3864, Training Accuracy= 0.746\n",
      "Epoch: 5810, Loss= 0.3828, Training Accuracy= 0.740\n",
      "Epoch: 5820, Loss= 0.3830, Training Accuracy= 0.732\n",
      "Epoch: 5830, Loss= 0.3772, Training Accuracy= 0.743\n",
      "Epoch: 5840, Loss= 0.3729, Training Accuracy= 0.758\n",
      "Epoch: 5850, Loss= 0.3740, Training Accuracy= 0.753\n",
      "Epoch: 5860, Loss= 0.3815, Training Accuracy= 0.745\n",
      "Epoch: 5870, Loss= 0.3714, Training Accuracy= 0.758\n",
      "Epoch: 5880, Loss= 0.3704, Training Accuracy= 0.763\n",
      "Epoch: 5890, Loss= 0.3788, Training Accuracy= 0.764\n",
      "Epoch: 5900, Loss= 0.3796, Training Accuracy= 0.766\n",
      "Epoch: 5910, Loss= 0.3784, Training Accuracy= 0.764\n",
      "Epoch: 5920, Loss= 0.3822, Training Accuracy= 0.763\n",
      "Epoch: 5930, Loss= 0.3791, Training Accuracy= 0.765\n",
      "Epoch: 5940, Loss= 0.3820, Training Accuracy= 0.765\n",
      "Epoch: 5950, Loss= 0.3785, Training Accuracy= 0.770\n",
      "Epoch: 5960, Loss= 0.3782, Training Accuracy= 0.772\n",
      "Epoch: 5970, Loss= 0.3770, Training Accuracy= 0.775\n",
      "Epoch: 5980, Loss= 0.3821, Training Accuracy= 0.775\n",
      "Epoch: 5990, Loss= 0.3807, Training Accuracy= 0.776\n",
      "Epoch: 6000, Loss= 0.3778, Training Accuracy= 0.775\n",
      "Epoch: 6010, Loss= 0.3764, Training Accuracy= 0.777\n",
      "Epoch: 6020, Loss= 0.5737, Training Accuracy= 0.729\n",
      "Epoch: 6030, Loss= 0.3647, Training Accuracy= 0.780\n",
      "Epoch: 6040, Loss= 0.4492, Training Accuracy= 0.749\n",
      "Epoch: 6050, Loss= 0.3571, Training Accuracy= 0.783\n",
      "Epoch: 6060, Loss= 0.3580, Training Accuracy= 0.784\n",
      "Epoch: 6070, Loss= 0.3585, Training Accuracy= 0.781\n",
      "Epoch: 6080, Loss= 0.3495, Training Accuracy= 0.783\n",
      "Epoch: 6090, Loss= 0.3550, Training Accuracy= 0.785\n",
      "Epoch: 6100, Loss= 0.3482, Training Accuracy= 0.775\n",
      "Epoch: 6110, Loss= 0.3470, Training Accuracy= 0.791\n",
      "Epoch: 6120, Loss= 0.3446, Training Accuracy= 0.788\n",
      "Epoch: 6130, Loss= 0.3506, Training Accuracy= 0.789\n",
      "Epoch: 6140, Loss= 0.5452, Training Accuracy= 0.706\n",
      "Epoch: 6150, Loss= 0.3441, Training Accuracy= 0.789\n",
      "Epoch: 6160, Loss= 0.3442, Training Accuracy= 0.796\n",
      "Epoch: 6170, Loss= 0.3437, Training Accuracy= 0.787\n",
      "Epoch: 6180, Loss= 0.3448, Training Accuracy= 0.796\n",
      "Epoch: 6190, Loss= 0.3470, Training Accuracy= 0.786\n",
      "Epoch: 6200, Loss= 0.3492, Training Accuracy= 0.786\n",
      "Epoch: 6210, Loss= 0.3447, Training Accuracy= 0.794\n",
      "Epoch: 6220, Loss= 0.3471, Training Accuracy= 0.784\n",
      "Epoch: 6230, Loss= 0.3406, Training Accuracy= 0.793\n",
      "Epoch: 6240, Loss= 0.3574, Training Accuracy= 0.783\n",
      "Epoch: 6250, Loss= 0.3496, Training Accuracy= 0.786\n",
      "Epoch: 6260, Loss= 0.3382, Training Accuracy= 0.791\n",
      "Epoch: 6270, Loss= 0.3476, Training Accuracy= 0.791\n",
      "Epoch: 6280, Loss= 0.3415, Training Accuracy= 0.792\n",
      "Epoch: 6290, Loss= 0.3412, Training Accuracy= 0.791\n",
      "Epoch: 6300, Loss= 0.3511, Training Accuracy= 0.774\n",
      "Epoch: 6310, Loss= 0.3386, Training Accuracy= 0.796\n",
      "Epoch: 6320, Loss= 0.3389, Training Accuracy= 0.796\n",
      "Epoch: 6330, Loss= 0.3355, Training Accuracy= 0.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6340, Loss= 0.3354, Training Accuracy= 0.788\n",
      "Epoch: 6350, Loss= 0.3361, Training Accuracy= 0.797\n",
      "Epoch: 6360, Loss= 0.3346, Training Accuracy= 0.797\n",
      "Epoch: 6370, Loss= 0.3488, Training Accuracy= 0.778\n",
      "Epoch: 6380, Loss= 0.3611, Training Accuracy= 0.780\n",
      "Epoch: 6390, Loss= 0.3329, Training Accuracy= 0.801\n",
      "Epoch: 6400, Loss= 0.3355, Training Accuracy= 0.793\n",
      "Epoch: 6410, Loss= 0.4131, Training Accuracy= 0.773\n",
      "Epoch: 6420, Loss= 0.5356, Training Accuracy= 0.644\n",
      "Epoch: 6430, Loss= 0.5086, Training Accuracy= 0.663\n",
      "Epoch: 6440, Loss= 0.4938, Training Accuracy= 0.689\n",
      "Epoch: 6450, Loss= 0.4985, Training Accuracy= 0.710\n",
      "Epoch: 6460, Loss= 0.5010, Training Accuracy= 0.709\n",
      "Epoch: 6470, Loss= 0.5036, Training Accuracy= 0.709\n",
      "Epoch: 6480, Loss= 0.5008, Training Accuracy= 0.701\n",
      "Epoch: 6490, Loss= 0.5080, Training Accuracy= 0.707\n",
      "Epoch: 6500, Loss= 0.5082, Training Accuracy= 0.710\n",
      "Epoch: 6510, Loss= 0.5046, Training Accuracy= 0.710\n",
      "Epoch: 6520, Loss= 0.5000, Training Accuracy= 0.713\n",
      "Epoch: 6530, Loss= 0.4962, Training Accuracy= 0.715\n",
      "Epoch: 6540, Loss= 0.4880, Training Accuracy= 0.717\n",
      "Epoch: 6550, Loss= 0.4782, Training Accuracy= 0.718\n",
      "Epoch: 6560, Loss= 0.4779, Training Accuracy= 0.719\n",
      "Epoch: 6570, Loss= 0.4802, Training Accuracy= 0.720\n",
      "Epoch: 6580, Loss= 0.4817, Training Accuracy= 0.719\n",
      "Epoch: 6590, Loss= 0.4830, Training Accuracy= 0.720\n",
      "Epoch: 6600, Loss= 0.4839, Training Accuracy= 0.720\n",
      "Epoch: 6610, Loss= 0.4846, Training Accuracy= 0.721\n",
      "Epoch: 6620, Loss= 0.4851, Training Accuracy= 0.721\n",
      "Epoch: 6630, Loss= 0.4856, Training Accuracy= 0.721\n",
      "Epoch: 6640, Loss= 0.4859, Training Accuracy= 0.721\n",
      "Epoch: 6650, Loss= 0.4862, Training Accuracy= 0.721\n",
      "Epoch: 6660, Loss= 0.4865, Training Accuracy= 0.721\n",
      "Epoch: 6670, Loss= 0.4868, Training Accuracy= 0.721\n",
      "Epoch: 6680, Loss= 0.4870, Training Accuracy= 0.720\n",
      "Epoch: 6690, Loss= 0.4872, Training Accuracy= 0.720\n",
      "Epoch: 6700, Loss= 0.4873, Training Accuracy= 0.720\n",
      "Epoch: 6710, Loss= 0.4874, Training Accuracy= 0.720\n",
      "Epoch: 6720, Loss= 0.4874, Training Accuracy= 0.720\n",
      "Epoch: 6730, Loss= 0.4872, Training Accuracy= 0.720\n",
      "Epoch: 6740, Loss= 0.4868, Training Accuracy= 0.721\n",
      "Epoch: 6750, Loss= 0.4857, Training Accuracy= 0.721\n",
      "Epoch: 6760, Loss= 0.4833, Training Accuracy= 0.721\n",
      "Epoch: 6770, Loss= 0.4760, Training Accuracy= 0.721\n",
      "Epoch: 6780, Loss= 0.4720, Training Accuracy= 0.719\n",
      "Epoch: 6790, Loss= 0.4805, Training Accuracy= 0.711\n",
      "Epoch: 6800, Loss= 0.4858, Training Accuracy= 0.708\n",
      "Epoch: 6810, Loss= 0.4868, Training Accuracy= 0.708\n",
      "Epoch: 6820, Loss= 0.4828, Training Accuracy= 0.708\n",
      "Epoch: 6830, Loss= 0.4778, Training Accuracy= 0.711\n",
      "Epoch: 6840, Loss= 0.4755, Training Accuracy= 0.712\n",
      "Epoch: 6850, Loss= 0.4736, Training Accuracy= 0.713\n",
      "Epoch: 6860, Loss= 0.4673, Training Accuracy= 0.716\n",
      "Epoch: 6870, Loss= 0.4601, Training Accuracy= 0.721\n",
      "Epoch: 6880, Loss= 0.4519, Training Accuracy= 0.723\n",
      "Epoch: 6890, Loss= 0.4448, Training Accuracy= 0.724\n",
      "Epoch: 6900, Loss= 0.4420, Training Accuracy= 0.726\n",
      "Epoch: 6910, Loss= 0.4373, Training Accuracy= 0.727\n",
      "Epoch: 6920, Loss= 0.4347, Training Accuracy= 0.727\n",
      "Epoch: 6930, Loss= 0.4335, Training Accuracy= 0.727\n",
      "Epoch: 6940, Loss= 0.4325, Training Accuracy= 0.727\n",
      "Epoch: 6950, Loss= 0.4312, Training Accuracy= 0.729\n",
      "Epoch: 6960, Loss= 0.4300, Training Accuracy= 0.730\n",
      "Epoch: 6970, Loss= 0.4291, Training Accuracy= 0.732\n",
      "Epoch: 6980, Loss= 0.4286, Training Accuracy= 0.735\n",
      "Epoch: 6990, Loss= 0.4263, Training Accuracy= 0.741\n",
      "Epoch: 7000, Loss= 0.4291, Training Accuracy= 0.747\n",
      "Epoch: 7010, Loss= 0.4265, Training Accuracy= 0.748\n",
      "Epoch: 7020, Loss= 0.4206, Training Accuracy= 0.746\n",
      "Epoch: 7030, Loss= 0.4222, Training Accuracy= 0.744\n",
      "Epoch: 7040, Loss= 0.4332, Training Accuracy= 0.741\n",
      "Epoch: 7050, Loss= 0.4449, Training Accuracy= 0.738\n",
      "Epoch: 7060, Loss= 0.4512, Training Accuracy= 0.737\n",
      "Epoch: 7070, Loss= 0.4549, Training Accuracy= 0.737\n",
      "Epoch: 7080, Loss= 0.4578, Training Accuracy= 0.736\n",
      "Epoch: 7090, Loss= 0.4608, Training Accuracy= 0.734\n",
      "Epoch: 7100, Loss= 0.4648, Training Accuracy= 0.731\n",
      "Epoch: 7110, Loss= 0.4688, Training Accuracy= 0.729\n",
      "Epoch: 7120, Loss= 0.4701, Training Accuracy= 0.727\n",
      "Epoch: 7130, Loss= 0.4581, Training Accuracy= 0.732\n",
      "Epoch: 7140, Loss= 0.4525, Training Accuracy= 0.734\n",
      "Epoch: 7150, Loss= 0.4485, Training Accuracy= 0.736\n",
      "Epoch: 7160, Loss= 0.4458, Training Accuracy= 0.737\n",
      "Epoch: 7170, Loss= 0.4398, Training Accuracy= 0.738\n",
      "Epoch: 7180, Loss= 0.4389, Training Accuracy= 0.738\n",
      "Epoch: 7190, Loss= 0.4350, Training Accuracy= 0.739\n",
      "Epoch: 7200, Loss= 0.4350, Training Accuracy= 0.740\n",
      "Epoch: 7210, Loss= 0.4329, Training Accuracy= 0.742\n",
      "Epoch: 7220, Loss= 0.4346, Training Accuracy= 0.742\n",
      "Epoch: 7230, Loss= 0.4338, Training Accuracy= 0.743\n",
      "Epoch: 7240, Loss= 0.4326, Training Accuracy= 0.743\n",
      "Epoch: 7250, Loss= 0.4321, Training Accuracy= 0.743\n",
      "Epoch: 7260, Loss= 0.4307, Training Accuracy= 0.743\n",
      "Epoch: 7270, Loss= 0.4284, Training Accuracy= 0.744\n",
      "Epoch: 7280, Loss= 0.4282, Training Accuracy= 0.744\n",
      "Epoch: 7290, Loss= 0.4271, Training Accuracy= 0.745\n",
      "Epoch: 7300, Loss= 0.4259, Training Accuracy= 0.744\n",
      "Epoch: 7310, Loss= 0.4248, Training Accuracy= 0.744\n",
      "Epoch: 7320, Loss= 0.4239, Training Accuracy= 0.745\n",
      "Epoch: 7330, Loss= 0.4232, Training Accuracy= 0.744\n",
      "Epoch: 7340, Loss= 0.4228, Training Accuracy= 0.746\n",
      "Epoch: 7350, Loss= 0.4226, Training Accuracy= 0.746\n",
      "Epoch: 7360, Loss= 0.4228, Training Accuracy= 0.746\n",
      "Epoch: 7370, Loss= 0.4229, Training Accuracy= 0.747\n",
      "Epoch: 7380, Loss= 0.4231, Training Accuracy= 0.746\n",
      "Epoch: 7390, Loss= 0.4232, Training Accuracy= 0.747\n",
      "Epoch: 7400, Loss= 0.4234, Training Accuracy= 0.747\n",
      "Epoch: 7410, Loss= 0.4239, Training Accuracy= 0.747\n",
      "Epoch: 7420, Loss= 0.4246, Training Accuracy= 0.747\n",
      "Epoch: 7430, Loss= 0.4256, Training Accuracy= 0.748\n",
      "Epoch: 7440, Loss= 0.4265, Training Accuracy= 0.746\n",
      "Epoch: 7450, Loss= 0.4273, Training Accuracy= 0.745\n",
      "Epoch: 7460, Loss= 0.4284, Training Accuracy= 0.745\n",
      "Epoch: 7470, Loss= 0.4304, Training Accuracy= 0.743\n",
      "Epoch: 7480, Loss= 0.4346, Training Accuracy= 0.741\n",
      "Epoch: 7490, Loss= 0.4440, Training Accuracy= 0.736\n",
      "Epoch: 7500, Loss= 0.4443, Training Accuracy= 0.737\n",
      "Epoch: 7510, Loss= 0.4398, Training Accuracy= 0.741\n",
      "Epoch: 7520, Loss= 0.4323, Training Accuracy= 0.742\n",
      "Epoch: 7530, Loss= 0.4291, Training Accuracy= 0.743\n",
      "Epoch: 7540, Loss= 0.4233, Training Accuracy= 0.750\n",
      "Epoch: 7550, Loss= 0.4073, Training Accuracy= 0.768\n",
      "Epoch: 7560, Loss= 0.4026, Training Accuracy= 0.774\n",
      "Epoch: 7570, Loss= 0.7110, Training Accuracy= 0.504\n",
      "Epoch: 7580, Loss= 0.6986, Training Accuracy= 0.506\n",
      "Epoch: 7590, Loss= 0.6956, Training Accuracy= 0.509\n",
      "Epoch: 7600, Loss= 0.6917, Training Accuracy= 0.535\n",
      "Epoch: 7610, Loss= 0.6865, Training Accuracy= 0.537\n",
      "Epoch: 7620, Loss= 0.6849, Training Accuracy= 0.563\n",
      "Epoch: 7630, Loss= 0.6838, Training Accuracy= 0.566\n",
      "Epoch: 7640, Loss= 0.6961, Training Accuracy= 0.509\n",
      "Epoch: 7650, Loss= 0.6814, Training Accuracy= 0.553\n",
      "Epoch: 7660, Loss= 0.6790, Training Accuracy= 0.553\n",
      "Epoch: 7670, Loss= 0.6772, Training Accuracy= 0.547\n",
      "Epoch: 7680, Loss= 0.6766, Training Accuracy= 0.551\n",
      "Epoch: 7690, Loss= 0.6763, Training Accuracy= 0.566\n",
      "Epoch: 7700, Loss= 0.6998, Training Accuracy= 0.505\n",
      "Epoch: 7710, Loss= 0.6991, Training Accuracy= 0.505\n",
      "Epoch: 7720, Loss= 0.6988, Training Accuracy= 0.505\n",
      "Epoch: 7730, Loss= 0.6986, Training Accuracy= 0.505\n",
      "Epoch: 7740, Loss= 0.6985, Training Accuracy= 0.505\n",
      "Epoch: 7750, Loss= 0.6984, Training Accuracy= 0.505\n",
      "Epoch: 7760, Loss= 0.6983, Training Accuracy= 0.505\n",
      "Epoch: 7770, Loss= 0.6983, Training Accuracy= 0.505\n",
      "Epoch: 7780, Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 7790, Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 7800, Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 7810, Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 7820, Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 7830, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7840, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7850, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7860, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7870, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7880, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7890, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7900, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7910, Loss= 0.6981, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7920, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7930, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7940, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7950, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7960, Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 7970, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 7980, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 7990, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8000, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8010, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8020, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8030, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8040, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8050, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8060, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8070, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8080, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8090, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8100, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8110, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8120, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8130, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 8140, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 8150, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 8160, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 8170, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 8180, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 8190, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 8200, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 8210, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 8220, Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 8230, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8240, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8250, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8260, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8270, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8280, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8290, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8300, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8310, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8320, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8330, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8340, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8350, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8360, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8370, Loss= 0.6978, Training Accuracy= 0.504\n",
      "Epoch: 8380, Loss= 0.6978, Training Accuracy= 0.504\n",
      "Epoch: 8390, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8400, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8410, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8420, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8430, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8440, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8450, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8460, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8470, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8480, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8490, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8500, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8510, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8520, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8530, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8540, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8550, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8560, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8570, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8580, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8590, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8600, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8610, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8620, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8630, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8640, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8650, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8660, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8670, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8680, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8690, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8700, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8710, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8720, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8730, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8740, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8750, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8760, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8770, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8780, Loss= 0.6978, Training Accuracy= 0.505\n",
      "Epoch: 8790, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8800, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8810, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8820, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8830, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8840, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8850, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8860, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8870, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8880, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8890, Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 8900, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 8910, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 8920, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 8930, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 8940, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 8950, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 8960, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 8970, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 8980, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 8990, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9000, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9010, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9020, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9030, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9040, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9050, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9060, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9070, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9080, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9090, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9100, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9110, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9120, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9130, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9140, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9150, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9160, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9170, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9180, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9190, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9200, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9210, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9220, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9230, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9240, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9250, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9260, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9270, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9280, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9290, Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 9300, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9310, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9320, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9330, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9340, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9350, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9360, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9370, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9380, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9390, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9400, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9410, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9420, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9430, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9440, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9450, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9460, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9470, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9480, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9490, Loss= 0.6977, Training Accuracy= 0.506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9500, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9510, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9520, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9530, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9540, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9550, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9560, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9570, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9580, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9590, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9600, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9610, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9620, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9630, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9640, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9650, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9660, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9670, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9680, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9690, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9700, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9710, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9720, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9730, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9740, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9750, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9760, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9770, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9780, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9790, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9800, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9810, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9820, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9830, Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 9840, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 9850, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 9860, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 9870, Loss= 0.6976, Training Accuracy= 0.507\n",
      "Epoch: 9880, Loss= 0.6976, Training Accuracy= 0.507\n",
      "Epoch: 9890, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 9900, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 9910, Loss= 0.6976, Training Accuracy= 0.507\n",
      "Epoch: 9920, Loss= 0.6976, Training Accuracy= 0.507\n",
      "Epoch: 9930, Loss= 0.6976, Training Accuracy= 0.507\n",
      "Epoch: 9940, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 9950, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 9960, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 9970, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 9980, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 9990, Loss= 0.6976, Training Accuracy= 0.506\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4923\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.7220, Training Accuracy= 0.506\n",
      "Epoch: 10, Loss= 0.7184, Training Accuracy= 0.506\n",
      "Epoch: 20, Loss= 0.7158, Training Accuracy= 0.506\n",
      "Epoch: 30, Loss= 0.7139, Training Accuracy= 0.506\n",
      "Epoch: 40, Loss= 0.7125, Training Accuracy= 0.506\n",
      "Epoch: 50, Loss= 0.7113, Training Accuracy= 0.506\n",
      "Epoch: 60, Loss= 0.7104, Training Accuracy= 0.506\n",
      "Epoch: 70, Loss= 0.7097, Training Accuracy= 0.506\n",
      "Epoch: 80, Loss= 0.7090, Training Accuracy= 0.506\n",
      "Epoch: 90, Loss= 0.7085, Training Accuracy= 0.506\n",
      "Epoch: 100, Loss= 0.7080, Training Accuracy= 0.506\n",
      "Epoch: 110, Loss= 0.7076, Training Accuracy= 0.506\n",
      "Epoch: 120, Loss= 0.7073, Training Accuracy= 0.506\n",
      "Epoch: 130, Loss= 0.7069, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.7067, Training Accuracy= 0.506\n",
      "Epoch: 150, Loss= 0.7064, Training Accuracy= 0.506\n",
      "Epoch: 160, Loss= 0.7062, Training Accuracy= 0.506\n",
      "Epoch: 170, Loss= 0.7060, Training Accuracy= 0.506\n",
      "Epoch: 180, Loss= 0.7058, Training Accuracy= 0.506\n",
      "Epoch: 190, Loss= 0.7056, Training Accuracy= 0.506\n",
      "Epoch: 200, Loss= 0.7055, Training Accuracy= 0.506\n",
      "Epoch: 210, Loss= 0.7053, Training Accuracy= 0.506\n",
      "Epoch: 220, Loss= 0.7052, Training Accuracy= 0.506\n",
      "Epoch: 230, Loss= 0.7051, Training Accuracy= 0.506\n",
      "Epoch: 240, Loss= 0.7050, Training Accuracy= 0.506\n",
      "Epoch: 250, Loss= 0.7048, Training Accuracy= 0.506\n",
      "Epoch: 260, Loss= 0.7047, Training Accuracy= 0.506\n",
      "Epoch: 270, Loss= 0.7047, Training Accuracy= 0.506\n",
      "Epoch: 280, Loss= 0.7046, Training Accuracy= 0.506\n",
      "Epoch: 290, Loss= 0.7045, Training Accuracy= 0.506\n",
      "Epoch: 300, Loss= 0.7044, Training Accuracy= 0.506\n",
      "Epoch: 310, Loss= 0.7043, Training Accuracy= 0.506\n",
      "Epoch: 320, Loss= 0.7043, Training Accuracy= 0.506\n",
      "Epoch: 330, Loss= 0.7042, Training Accuracy= 0.506\n",
      "Epoch: 340, Loss= 0.7041, Training Accuracy= 0.506\n",
      "Epoch: 350, Loss= 0.7041, Training Accuracy= 0.506\n",
      "Epoch: 360, Loss= 0.7040, Training Accuracy= 0.506\n",
      "Epoch: 370, Loss= 0.7040, Training Accuracy= 0.506\n",
      "Epoch: 380, Loss= 0.7039, Training Accuracy= 0.506\n",
      "Epoch: 390, Loss= 0.7039, Training Accuracy= 0.506\n",
      "Epoch: 400, Loss= 0.7038, Training Accuracy= 0.506\n",
      "Epoch: 410, Loss= 0.7038, Training Accuracy= 0.506\n",
      "Epoch: 420, Loss= 0.7037, Training Accuracy= 0.506\n",
      "Epoch: 430, Loss= 0.7037, Training Accuracy= 0.506\n",
      "Epoch: 440, Loss= 0.7037, Training Accuracy= 0.506\n",
      "Epoch: 450, Loss= 0.7036, Training Accuracy= 0.506\n",
      "Epoch: 460, Loss= 0.7036, Training Accuracy= 0.506\n",
      "Epoch: 470, Loss= 0.7036, Training Accuracy= 0.506\n",
      "Epoch: 480, Loss= 0.7035, Training Accuracy= 0.506\n",
      "Epoch: 490, Loss= 0.7035, Training Accuracy= 0.506\n",
      "Epoch: 500, Loss= 0.7035, Training Accuracy= 0.506\n",
      "Epoch: 510, Loss= 0.7034, Training Accuracy= 0.506\n",
      "Epoch: 520, Loss= 0.7034, Training Accuracy= 0.506\n",
      "Epoch: 530, Loss= 0.7034, Training Accuracy= 0.506\n",
      "Epoch: 540, Loss= 0.7033, Training Accuracy= 0.506\n",
      "Epoch: 550, Loss= 0.7033, Training Accuracy= 0.506\n",
      "Epoch: 560, Loss= 0.7033, Training Accuracy= 0.506\n",
      "Epoch: 570, Loss= 0.7033, Training Accuracy= 0.506\n",
      "Epoch: 580, Loss= 0.7032, Training Accuracy= 0.506\n",
      "Epoch: 590, Loss= 0.7032, Training Accuracy= 0.506\n",
      "Epoch: 600, Loss= 0.7032, Training Accuracy= 0.506\n",
      "Epoch: 610, Loss= 0.7032, Training Accuracy= 0.506\n",
      "Epoch: 620, Loss= 0.7031, Training Accuracy= 0.506\n",
      "Epoch: 630, Loss= 0.7031, Training Accuracy= 0.506\n",
      "Epoch: 640, Loss= 0.7031, Training Accuracy= 0.506\n",
      "Epoch: 650, Loss= 0.7031, Training Accuracy= 0.506\n",
      "Epoch: 660, Loss= 0.7031, Training Accuracy= 0.506\n",
      "Epoch: 670, Loss= 0.7031, Training Accuracy= 0.506\n",
      "Epoch: 680, Loss= 0.7030, Training Accuracy= 0.506\n",
      "Epoch: 690, Loss= 0.7030, Training Accuracy= 0.506\n",
      "Epoch: 700, Loss= 0.7030, Training Accuracy= 0.506\n",
      "Epoch: 710, Loss= 0.7030, Training Accuracy= 0.506\n",
      "Epoch: 720, Loss= 0.7030, Training Accuracy= 0.506\n",
      "Epoch: 730, Loss= 0.7030, Training Accuracy= 0.506\n",
      "Epoch: 740, Loss= 0.7029, Training Accuracy= 0.506\n",
      "Epoch: 750, Loss= 0.7029, Training Accuracy= 0.506\n",
      "Epoch: 760, Loss= 0.7029, Training Accuracy= 0.506\n",
      "Epoch: 770, Loss= 0.7029, Training Accuracy= 0.506\n",
      "Epoch: 780, Loss= 0.7029, Training Accuracy= 0.506\n",
      "Epoch: 790, Loss= 0.7029, Training Accuracy= 0.506\n",
      "Epoch: 800, Loss= 0.7029, Training Accuracy= 0.506\n",
      "Epoch: 810, Loss= 0.7028, Training Accuracy= 0.506\n",
      "Epoch: 820, Loss= 0.7028, Training Accuracy= 0.506\n",
      "Epoch: 830, Loss= 0.7028, Training Accuracy= 0.506\n",
      "Epoch: 840, Loss= 0.7028, Training Accuracy= 0.506\n",
      "Epoch: 850, Loss= 0.7028, Training Accuracy= 0.506\n",
      "Epoch: 860, Loss= 0.7028, Training Accuracy= 0.506\n",
      "Epoch: 870, Loss= 0.7028, Training Accuracy= 0.506\n",
      "Epoch: 880, Loss= 0.7028, Training Accuracy= 0.506\n",
      "Epoch: 890, Loss= 0.7028, Training Accuracy= 0.506\n",
      "Epoch: 900, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 910, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 920, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 930, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 940, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 950, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 960, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 970, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 980, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 990, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 1000, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 1010, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 1020, Loss= 0.7027, Training Accuracy= 0.506\n",
      "Epoch: 1030, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1040, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1050, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1060, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1070, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1080, Loss= 0.7026, Training Accuracy= 0.506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1090, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1100, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1110, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1120, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1130, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1140, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1150, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1160, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1170, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1180, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1190, Loss= 0.7026, Training Accuracy= 0.506\n",
      "Epoch: 1200, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1210, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1220, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1230, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1240, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1250, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1260, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1270, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1280, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1290, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1300, Loss= 0.7025, Training Accuracy= 0.506\n",
      "Epoch: 1310, Loss= 0.7025, Training Accuracy= 0.506\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.8\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 10000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
