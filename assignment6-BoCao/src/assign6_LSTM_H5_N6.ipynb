{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 6\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Minibatch Loss= 0.7154, Training Accuracy= 0.502\n",
      "Epoch: 10, Minibatch Loss= 0.7025, Training Accuracy= 0.502\n",
      "Epoch: 20, Minibatch Loss= 0.7013, Training Accuracy= 0.502\n",
      "Epoch: 30, Minibatch Loss= 0.7007, Training Accuracy= 0.502\n",
      "Epoch: 40, Minibatch Loss= 0.7003, Training Accuracy= 0.502\n",
      "Epoch: 50, Minibatch Loss= 0.7000, Training Accuracy= 0.502\n",
      "Epoch: 60, Minibatch Loss= 0.6998, Training Accuracy= 0.502\n",
      "Epoch: 70, Minibatch Loss= 0.6996, Training Accuracy= 0.502\n",
      "Epoch: 80, Minibatch Loss= 0.6994, Training Accuracy= 0.502\n",
      "Epoch: 90, Minibatch Loss= 0.6993, Training Accuracy= 0.502\n",
      "Epoch: 100, Minibatch Loss= 0.6992, Training Accuracy= 0.502\n",
      "Epoch: 110, Minibatch Loss= 0.6991, Training Accuracy= 0.502\n",
      "Epoch: 120, Minibatch Loss= 0.6990, Training Accuracy= 0.502\n",
      "Epoch: 130, Minibatch Loss= 0.6989, Training Accuracy= 0.502\n",
      "Epoch: 140, Minibatch Loss= 0.6989, Training Accuracy= 0.502\n",
      "Epoch: 150, Minibatch Loss= 0.6988, Training Accuracy= 0.502\n",
      "Epoch: 160, Minibatch Loss= 0.6987, Training Accuracy= 0.502\n",
      "Epoch: 170, Minibatch Loss= 0.6987, Training Accuracy= 0.502\n",
      "Epoch: 180, Minibatch Loss= 0.6986, Training Accuracy= 0.502\n",
      "Epoch: 190, Minibatch Loss= 0.6986, Training Accuracy= 0.502\n",
      "Epoch: 200, Minibatch Loss= 0.6985, Training Accuracy= 0.502\n",
      "Epoch: 210, Minibatch Loss= 0.6985, Training Accuracy= 0.502\n",
      "Epoch: 220, Minibatch Loss= 0.6984, Training Accuracy= 0.502\n",
      "Epoch: 230, Minibatch Loss= 0.6984, Training Accuracy= 0.502\n",
      "Epoch: 240, Minibatch Loss= 0.6983, Training Accuracy= 0.502\n",
      "Epoch: 250, Minibatch Loss= 0.6983, Training Accuracy= 0.502\n",
      "Epoch: 260, Minibatch Loss= 0.6982, Training Accuracy= 0.502\n",
      "Epoch: 270, Minibatch Loss= 0.3540, Training Accuracy= 0.898\n",
      "Epoch: 280, Minibatch Loss= 0.0588, Training Accuracy= 0.984\n",
      "Epoch: 290, Minibatch Loss= 0.0036, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Minibatch Loss= 0.6932, Training Accuracy= 0.436\n",
      "Epoch: 10, Minibatch Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 20, Minibatch Loss= 0.6930, Training Accuracy= 0.500\n",
      "Epoch: 30, Minibatch Loss= 0.6931, Training Accuracy= 0.500\n",
      "Epoch: 40, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 50, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 60, Minibatch Loss= 0.6931, Training Accuracy= 0.486\n",
      "Epoch: 70, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 80, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 90, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 100, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 110, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 120, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 130, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 140, Minibatch Loss= 0.6930, Training Accuracy= 0.487\n",
      "Epoch: 150, Minibatch Loss= 0.6930, Training Accuracy= 0.487\n",
      "Epoch: 160, Minibatch Loss= 0.6930, Training Accuracy= 0.487\n",
      "Epoch: 170, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 180, Minibatch Loss= 0.6930, Training Accuracy= 0.489\n",
      "Epoch: 190, Minibatch Loss= 0.6930, Training Accuracy= 0.489\n",
      "Epoch: 200, Minibatch Loss= 0.6930, Training Accuracy= 0.522\n",
      "Epoch: 210, Minibatch Loss= 0.6930, Training Accuracy= 0.538\n",
      "Epoch: 220, Minibatch Loss= 0.6930, Training Accuracy= 0.538\n",
      "Epoch: 230, Minibatch Loss= 0.6930, Training Accuracy= 0.541\n",
      "Epoch: 240, Minibatch Loss= 0.6930, Training Accuracy= 0.541\n",
      "Epoch: 250, Minibatch Loss= 0.6930, Training Accuracy= 0.573\n",
      "Epoch: 260, Minibatch Loss= 0.6929, Training Accuracy= 0.573\n",
      "Epoch: 270, Minibatch Loss= 0.6929, Training Accuracy= 0.556\n",
      "Epoch: 280, Minibatch Loss= 0.6929, Training Accuracy= 0.556\n",
      "Epoch: 290, Minibatch Loss= 0.6929, Training Accuracy= 0.542\n",
      "Epoch: 300, Minibatch Loss= 0.6929, Training Accuracy= 0.542\n",
      "Epoch: 310, Minibatch Loss= 0.6929, Training Accuracy= 0.542\n",
      "Epoch: 320, Minibatch Loss= 0.6929, Training Accuracy= 0.558\n",
      "Epoch: 330, Minibatch Loss= 0.6929, Training Accuracy= 0.558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340, Minibatch Loss= 0.6929, Training Accuracy= 0.573\n",
      "Epoch: 350, Minibatch Loss= 0.6929, Training Accuracy= 0.573\n",
      "Epoch: 360, Minibatch Loss= 0.6929, Training Accuracy= 0.590\n",
      "Epoch: 370, Minibatch Loss= 0.6929, Training Accuracy= 0.590\n",
      "Epoch: 380, Minibatch Loss= 0.6929, Training Accuracy= 0.590\n",
      "Epoch: 390, Minibatch Loss= 0.6929, Training Accuracy= 0.590\n",
      "Epoch: 400, Minibatch Loss= 0.6929, Training Accuracy= 0.590\n",
      "Epoch: 410, Minibatch Loss= 0.6929, Training Accuracy= 0.575\n",
      "Epoch: 420, Minibatch Loss= 0.6929, Training Accuracy= 0.575\n",
      "Epoch: 430, Minibatch Loss= 0.6929, Training Accuracy= 0.575\n",
      "Epoch: 440, Minibatch Loss= 0.6928, Training Accuracy= 0.575\n",
      "Epoch: 450, Minibatch Loss= 0.6928, Training Accuracy= 0.575\n",
      "Epoch: 460, Minibatch Loss= 0.6928, Training Accuracy= 0.575\n",
      "Epoch: 470, Minibatch Loss= 0.6928, Training Accuracy= 0.575\n",
      "Epoch: 480, Minibatch Loss= 0.6928, Training Accuracy= 0.575\n",
      "Epoch: 490, Minibatch Loss= 0.6927, Training Accuracy= 0.575\n",
      "Epoch: 500, Minibatch Loss= 0.6917, Training Accuracy= 0.462\n",
      "Epoch: 510, Minibatch Loss= 0.0883, Training Accuracy= 0.984\n",
      "Epoch: 520, Minibatch Loss= 0.0044, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 2: \n",
      "Epoch: 0, Minibatch Loss= 0.7081, Training Accuracy= 0.507\n",
      "Epoch: 10, Minibatch Loss= 0.6991, Training Accuracy= 0.507\n",
      "Epoch: 20, Minibatch Loss= 0.6975, Training Accuracy= 0.507\n",
      "Epoch: 30, Minibatch Loss= 0.6968, Training Accuracy= 0.507\n",
      "Epoch: 40, Minibatch Loss= 0.6963, Training Accuracy= 0.507\n",
      "Epoch: 50, Minibatch Loss= 0.6960, Training Accuracy= 0.507\n",
      "Epoch: 60, Minibatch Loss= 0.6958, Training Accuracy= 0.507\n",
      "Epoch: 70, Minibatch Loss= 0.6956, Training Accuracy= 0.507\n",
      "Epoch: 80, Minibatch Loss= 0.6954, Training Accuracy= 0.507\n",
      "Epoch: 90, Minibatch Loss= 0.6953, Training Accuracy= 0.507\n",
      "Epoch: 100, Minibatch Loss= 0.6952, Training Accuracy= 0.507\n",
      "Epoch: 110, Minibatch Loss= 0.6951, Training Accuracy= 0.507\n",
      "Epoch: 120, Minibatch Loss= 0.6949, Training Accuracy= 0.507\n",
      "Epoch: 130, Minibatch Loss= 0.6089, Training Accuracy= 0.733\n",
      "Epoch: 140, Minibatch Loss= 0.1125, Training Accuracy= 0.968\n",
      "Epoch: 150, Minibatch Loss= 0.0873, Training Accuracy= 0.968\n",
      "Epoch: 160, Minibatch Loss= 0.0226, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0093, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0054, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0036, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Minibatch Loss= 0.7270, Training Accuracy= 0.495\n",
      "Epoch: 10, Minibatch Loss= 0.7009, Training Accuracy= 0.495\n",
      "Epoch: 20, Minibatch Loss= 0.6982, Training Accuracy= 0.495\n",
      "Epoch: 30, Minibatch Loss= 0.6970, Training Accuracy= 0.495\n",
      "Epoch: 40, Minibatch Loss= 0.6963, Training Accuracy= 0.495\n",
      "Epoch: 50, Minibatch Loss= 0.6959, Training Accuracy= 0.495\n",
      "Epoch: 60, Minibatch Loss= 0.6957, Training Accuracy= 0.495\n",
      "Epoch: 70, Minibatch Loss= 0.6955, Training Accuracy= 0.495\n",
      "Epoch: 80, Minibatch Loss= 0.6954, Training Accuracy= 0.495\n",
      "Epoch: 90, Minibatch Loss= 0.6953, Training Accuracy= 0.512\n",
      "Epoch: 100, Minibatch Loss= 0.6952, Training Accuracy= 0.497\n",
      "Epoch: 110, Minibatch Loss= 0.6952, Training Accuracy= 0.482\n",
      "Epoch: 120, Minibatch Loss= 0.6950, Training Accuracy= 0.500\n",
      "Epoch: 130, Minibatch Loss= 0.1054, Training Accuracy= 0.969\n",
      "Epoch: 140, Minibatch Loss= 0.0075, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Minibatch Loss= 0.6935, Training Accuracy= 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Minibatch Loss= 0.6937, Training Accuracy= 0.499\n",
      "Epoch: 20, Minibatch Loss= 0.6938, Training Accuracy= 0.499\n",
      "Epoch: 30, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 40, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 50, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 60, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 70, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 80, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 90, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 100, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 110, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 120, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 130, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 140, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 150, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 160, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 170, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 180, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 190, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 200, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 210, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 220, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 230, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 240, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 250, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 260, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 270, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 280, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 290, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 300, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 310, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 320, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 330, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 340, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 350, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 360, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 370, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 380, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 390, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 400, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 410, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 420, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 430, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 440, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 450, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 460, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 470, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 480, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 490, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 500, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 510, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 520, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 530, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 540, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 550, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 560, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 570, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 580, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 590, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 600, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 610, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 620, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 630, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 640, Minibatch Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 650, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 660, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 670, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 680, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 690, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 700, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 710, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 720, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 730, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 740, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 750, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 760, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 770, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 780, Minibatch Loss= 0.6939, Training Accuracy= 0.484\n",
      "Epoch: 790, Minibatch Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 800, Minibatch Loss= 0.6938, Training Accuracy= 0.517\n",
      "Epoch: 810, Minibatch Loss= 0.6929, Training Accuracy= 0.565\n",
      "Epoch: 820, Minibatch Loss= 0.6364, Training Accuracy= 0.583\n",
      "Epoch: 830, Minibatch Loss= 0.2600, Training Accuracy= 0.856\n",
      "Epoch: 840, Minibatch Loss= 0.0066, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Minibatch Loss= 0.7073, Training Accuracy= 0.506\n",
      "Epoch: 10, Minibatch Loss= 0.6991, Training Accuracy= 0.506\n",
      "Epoch: 20, Minibatch Loss= 0.6984, Training Accuracy= 0.506\n",
      "Epoch: 30, Minibatch Loss= 0.6980, Training Accuracy= 0.506\n",
      "Epoch: 40, Minibatch Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 50, Minibatch Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 60, Minibatch Loss= 0.6975, Training Accuracy= 0.506\n",
      "Epoch: 70, Minibatch Loss= 0.6974, Training Accuracy= 0.506\n",
      "Epoch: 80, Minibatch Loss= 0.6974, Training Accuracy= 0.506\n",
      "Epoch: 90, Minibatch Loss= 0.6973, Training Accuracy= 0.506\n",
      "Epoch: 100, Minibatch Loss= 0.6973, Training Accuracy= 0.506\n",
      "Epoch: 110, Minibatch Loss= 0.6973, Training Accuracy= 0.506\n",
      "Epoch: 120, Minibatch Loss= 0.6973, Training Accuracy= 0.506\n",
      "Epoch: 130, Minibatch Loss= 0.6973, Training Accuracy= 0.506\n",
      "Epoch: 140, Minibatch Loss= 0.6973, Training Accuracy= 0.506\n",
      "Epoch: 150, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 160, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 170, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 180, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 190, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 200, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 210, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 220, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 230, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 240, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 250, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 260, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 270, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 280, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 290, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 300, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 310, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 320, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 330, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 340, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 360, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 370, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 380, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 390, Minibatch Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 400, Minibatch Loss= 0.6962, Training Accuracy= 0.490\n",
      "Epoch: 410, Minibatch Loss= 0.1495, Training Accuracy= 0.952\n",
      "Epoch: 420, Minibatch Loss= 0.8481, Training Accuracy= 0.506\n",
      "Epoch: 430, Minibatch Loss= 0.8188, Training Accuracy= 0.506\n",
      "Epoch: 440, Minibatch Loss= 0.8109, Training Accuracy= 0.506\n",
      "Epoch: 450, Minibatch Loss= 0.8064, Training Accuracy= 0.506\n",
      "Epoch: 460, Minibatch Loss= 0.8007, Training Accuracy= 0.506\n",
      "Epoch: 470, Minibatch Loss= 0.7887, Training Accuracy= 0.506\n",
      "Epoch: 480, Minibatch Loss= 0.7674, Training Accuracy= 0.506\n",
      "Epoch: 490, Minibatch Loss= 0.7534, Training Accuracy= 0.506\n",
      "Epoch: 500, Minibatch Loss= 0.7488, Training Accuracy= 0.506\n",
      "Epoch: 510, Minibatch Loss= 0.7445, Training Accuracy= 0.506\n",
      "Epoch: 520, Minibatch Loss= 0.3618, Training Accuracy= 0.877\n",
      "Epoch: 530, Minibatch Loss= 0.8350, Training Accuracy= 0.506\n",
      "Epoch: 540, Minibatch Loss= 0.8266, Training Accuracy= 0.506\n",
      "Epoch: 550, Minibatch Loss= 0.8244, Training Accuracy= 0.506\n",
      "Epoch: 560, Minibatch Loss= 0.8233, Training Accuracy= 0.506\n",
      "Epoch: 570, Minibatch Loss= 0.8227, Training Accuracy= 0.506\n",
      "Epoch: 580, Minibatch Loss= 0.8223, Training Accuracy= 0.506\n",
      "Epoch: 590, Minibatch Loss= 0.8220, Training Accuracy= 0.506\n",
      "Epoch: 600, Minibatch Loss= 0.8218, Training Accuracy= 0.506\n",
      "Epoch: 610, Minibatch Loss= 0.8216, Training Accuracy= 0.506\n",
      "Epoch: 620, Minibatch Loss= 0.8215, Training Accuracy= 0.506\n",
      "Epoch: 630, Minibatch Loss= 0.8214, Training Accuracy= 0.506\n",
      "Epoch: 640, Minibatch Loss= 0.8213, Training Accuracy= 0.506\n",
      "Epoch: 650, Minibatch Loss= 0.8212, Training Accuracy= 0.506\n",
      "Epoch: 660, Minibatch Loss= 0.8211, Training Accuracy= 0.506\n",
      "Epoch: 670, Minibatch Loss= 0.8211, Training Accuracy= 0.506\n",
      "Epoch: 680, Minibatch Loss= 0.8210, Training Accuracy= 0.506\n",
      "Epoch: 690, Minibatch Loss= 0.8210, Training Accuracy= 0.506\n",
      "Epoch: 700, Minibatch Loss= 0.8209, Training Accuracy= 0.506\n",
      "Epoch: 710, Minibatch Loss= 0.8209, Training Accuracy= 0.506\n",
      "Epoch: 720, Minibatch Loss= 0.8208, Training Accuracy= 0.506\n",
      "Epoch: 730, Minibatch Loss= 0.8208, Training Accuracy= 0.506\n",
      "Epoch: 740, Minibatch Loss= 0.8208, Training Accuracy= 0.506\n",
      "Epoch: 750, Minibatch Loss= 0.8207, Training Accuracy= 0.506\n",
      "Epoch: 760, Minibatch Loss= 0.8207, Training Accuracy= 0.506\n",
      "Epoch: 770, Minibatch Loss= 0.8207, Training Accuracy= 0.506\n",
      "Epoch: 780, Minibatch Loss= 0.8207, Training Accuracy= 0.506\n",
      "Epoch: 790, Minibatch Loss= 0.8206, Training Accuracy= 0.506\n",
      "Epoch: 800, Minibatch Loss= 0.8206, Training Accuracy= 0.506\n",
      "Epoch: 810, Minibatch Loss= 0.8206, Training Accuracy= 0.506\n",
      "Epoch: 820, Minibatch Loss= 0.8205, Training Accuracy= 0.506\n",
      "Epoch: 830, Minibatch Loss= 0.8205, Training Accuracy= 0.506\n",
      "Epoch: 840, Minibatch Loss= 0.8205, Training Accuracy= 0.506\n",
      "Epoch: 850, Minibatch Loss= 0.8205, Training Accuracy= 0.506\n",
      "Epoch: 860, Minibatch Loss= 0.8204, Training Accuracy= 0.506\n",
      "Epoch: 870, Minibatch Loss= 0.8204, Training Accuracy= 0.506\n",
      "Epoch: 880, Minibatch Loss= 0.8204, Training Accuracy= 0.506\n",
      "Epoch: 890, Minibatch Loss= 0.8203, Training Accuracy= 0.506\n",
      "Epoch: 900, Minibatch Loss= 0.8203, Training Accuracy= 0.506\n",
      "Epoch: 910, Minibatch Loss= 0.8203, Training Accuracy= 0.506\n",
      "Epoch: 920, Minibatch Loss= 0.8203, Training Accuracy= 0.506\n",
      "Epoch: 930, Minibatch Loss= 0.8202, Training Accuracy= 0.506\n",
      "Epoch: 940, Minibatch Loss= 0.8202, Training Accuracy= 0.506\n",
      "Epoch: 950, Minibatch Loss= 0.8202, Training Accuracy= 0.506\n",
      "Epoch: 960, Minibatch Loss= 0.8202, Training Accuracy= 0.506\n",
      "Epoch: 970, Minibatch Loss= 0.8201, Training Accuracy= 0.506\n",
      "Epoch: 980, Minibatch Loss= 0.8201, Training Accuracy= 0.506\n",
      "Epoch: 990, Minibatch Loss= 0.8201, Training Accuracy= 0.506\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4926\n",
      "Replication: 6: \n",
      "Epoch: 0, Minibatch Loss= 0.7024, Training Accuracy= 0.497\n",
      "Epoch: 10, Minibatch Loss= 0.7005, Training Accuracy= 0.497\n",
      "Epoch: 20, Minibatch Loss= 0.6997, Training Accuracy= 0.497\n",
      "Epoch: 30, Minibatch Loss= 0.6990, Training Accuracy= 0.497\n",
      "Epoch: 40, Minibatch Loss= 0.6985, Training Accuracy= 0.497\n",
      "Epoch: 50, Minibatch Loss= 0.6981, Training Accuracy= 0.497\n",
      "Epoch: 60, Minibatch Loss= 0.6978, Training Accuracy= 0.497\n",
      "Epoch: 70, Minibatch Loss= 0.6976, Training Accuracy= 0.497\n",
      "Epoch: 80, Minibatch Loss= 0.6974, Training Accuracy= 0.497\n",
      "Epoch: 90, Minibatch Loss= 0.6972, Training Accuracy= 0.497\n",
      "Epoch: 100, Minibatch Loss= 0.6970, Training Accuracy= 0.497\n",
      "Epoch: 110, Minibatch Loss= 0.6969, Training Accuracy= 0.497\n",
      "Epoch: 120, Minibatch Loss= 0.6968, Training Accuracy= 0.497\n",
      "Epoch: 130, Minibatch Loss= 0.6967, Training Accuracy= 0.497\n",
      "Epoch: 140, Minibatch Loss= 0.6966, Training Accuracy= 0.497\n",
      "Epoch: 150, Minibatch Loss= 0.6966, Training Accuracy= 0.497\n",
      "Epoch: 160, Minibatch Loss= 0.6965, Training Accuracy= 0.497\n",
      "Epoch: 170, Minibatch Loss= 0.6964, Training Accuracy= 0.497\n",
      "Epoch: 180, Minibatch Loss= 0.6964, Training Accuracy= 0.497\n",
      "Epoch: 190, Minibatch Loss= 0.6964, Training Accuracy= 0.497\n",
      "Epoch: 200, Minibatch Loss= 0.6963, Training Accuracy= 0.497\n",
      "Epoch: 210, Minibatch Loss= 0.6963, Training Accuracy= 0.497\n",
      "Epoch: 220, Minibatch Loss= 0.6962, Training Accuracy= 0.497\n",
      "Epoch: 230, Minibatch Loss= 0.6962, Training Accuracy= 0.497\n",
      "Epoch: 240, Minibatch Loss= 0.6962, Training Accuracy= 0.497\n",
      "Epoch: 250, Minibatch Loss= 0.6962, Training Accuracy= 0.497\n",
      "Epoch: 260, Minibatch Loss= 0.6961, Training Accuracy= 0.497\n",
      "Epoch: 270, Minibatch Loss= 0.6961, Training Accuracy= 0.497\n",
      "Epoch: 280, Minibatch Loss= 0.6961, Training Accuracy= 0.497\n",
      "Epoch: 290, Minibatch Loss= 0.6961, Training Accuracy= 0.497\n",
      "Epoch: 300, Minibatch Loss= 0.6961, Training Accuracy= 0.497\n",
      "Epoch: 310, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 320, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 330, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 340, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 350, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 360, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 370, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 380, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 390, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 400, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 410, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 420, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 430, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 440, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 450, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 460, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 470, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 480, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 490, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 500, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 510, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 520, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 530, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 540, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 550, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 560, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 570, Minibatch Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 580, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 590, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 600, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 610, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 620, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 630, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 640, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 650, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 660, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 670, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 680, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 690, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 700, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 710, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 720, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 730, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 740, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 750, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 760, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 770, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 780, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 790, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 800, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 810, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 820, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 830, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 840, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 850, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 860, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 870, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 880, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 890, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 900, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 910, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 920, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 930, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 940, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 950, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 960, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 970, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 980, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 990, Minibatch Loss= 0.6958, Training Accuracy= 0.497\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5002\n",
      "Replication: 7: \n",
      "Epoch: 0, Minibatch Loss= 0.7552, Training Accuracy= 0.509\n",
      "Epoch: 10, Minibatch Loss= 0.7224, Training Accuracy= 0.509\n",
      "Epoch: 20, Minibatch Loss= 0.7186, Training Accuracy= 0.509\n",
      "Epoch: 30, Minibatch Loss= 0.7169, Training Accuracy= 0.509\n",
      "Epoch: 40, Minibatch Loss= 0.7159, Training Accuracy= 0.509\n",
      "Epoch: 50, Minibatch Loss= 0.7152, Training Accuracy= 0.509\n",
      "Epoch: 60, Minibatch Loss= 0.7148, Training Accuracy= 0.509\n",
      "Epoch: 70, Minibatch Loss= 0.7144, Training Accuracy= 0.509\n",
      "Epoch: 80, Minibatch Loss= 0.7141, Training Accuracy= 0.509\n",
      "Epoch: 90, Minibatch Loss= 0.7139, Training Accuracy= 0.509\n",
      "Epoch: 100, Minibatch Loss= 0.7137, Training Accuracy= 0.509\n",
      "Epoch: 110, Minibatch Loss= 0.7136, Training Accuracy= 0.509\n",
      "Epoch: 120, Minibatch Loss= 0.7135, Training Accuracy= 0.509\n",
      "Epoch: 130, Minibatch Loss= 0.7134, Training Accuracy= 0.509\n",
      "Epoch: 140, Minibatch Loss= 0.7133, Training Accuracy= 0.509\n",
      "Epoch: 150, Minibatch Loss= 0.7132, Training Accuracy= 0.509\n",
      "Epoch: 160, Minibatch Loss= 0.7132, Training Accuracy= 0.509\n",
      "Epoch: 170, Minibatch Loss= 0.7131, Training Accuracy= 0.509\n",
      "Epoch: 180, Minibatch Loss= 0.7131, Training Accuracy= 0.509\n",
      "Epoch: 190, Minibatch Loss= 0.7130, Training Accuracy= 0.509\n",
      "Epoch: 200, Minibatch Loss= 0.7130, Training Accuracy= 0.509\n",
      "Epoch: 210, Minibatch Loss= 0.7130, Training Accuracy= 0.509\n",
      "Epoch: 220, Minibatch Loss= 0.7129, Training Accuracy= 0.509\n",
      "Epoch: 230, Minibatch Loss= 0.7129, Training Accuracy= 0.509\n",
      "Epoch: 240, Minibatch Loss= 0.7129, Training Accuracy= 0.509\n",
      "Epoch: 250, Minibatch Loss= 0.7129, Training Accuracy= 0.509\n",
      "Epoch: 260, Minibatch Loss= 0.7129, Training Accuracy= 0.509\n",
      "Epoch: 270, Minibatch Loss= 0.7129, Training Accuracy= 0.509\n",
      "Epoch: 280, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 290, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 300, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 310, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 320, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 330, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 340, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 350, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 360, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 370, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 380, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 390, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 400, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 410, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 420, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 430, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 440, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 450, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 460, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 470, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 480, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 490, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 500, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 510, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 520, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 530, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 540, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 550, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 560, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 570, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 580, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 590, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 600, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 610, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 620, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 630, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 640, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 650, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 660, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 670, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 680, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 690, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 700, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 710, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 720, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 730, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 740, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 750, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 760, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 770, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 780, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 790, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 800, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 810, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 820, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 830, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 840, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 850, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 860, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 870, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 880, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 890, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 900, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 910, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 920, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 930, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 940, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 950, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 960, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 970, Minibatch Loss= 0.7127, Training Accuracy= 0.509\n",
      "Epoch: 980, Minibatch Loss= 0.7128, Training Accuracy= 0.509\n",
      "Epoch: 990, Minibatch Loss= 0.7127, Training Accuracy= 0.509\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5049\n",
      "Replication: 8: \n",
      "Epoch: 0, Minibatch Loss= 0.7008, Training Accuracy= 0.497\n",
      "Epoch: 10, Minibatch Loss= 0.6981, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Minibatch Loss= 0.6975, Training Accuracy= 0.497\n",
      "Epoch: 30, Minibatch Loss= 0.6971, Training Accuracy= 0.497\n",
      "Epoch: 40, Minibatch Loss= 0.6968, Training Accuracy= 0.497\n",
      "Epoch: 50, Minibatch Loss= 0.6966, Training Accuracy= 0.497\n",
      "Epoch: 60, Minibatch Loss= 0.6965, Training Accuracy= 0.497\n",
      "Epoch: 70, Minibatch Loss= 0.6965, Training Accuracy= 0.497\n",
      "Epoch: 80, Minibatch Loss= 0.6964, Training Accuracy= 0.497\n",
      "Epoch: 90, Minibatch Loss= 0.6964, Training Accuracy= 0.497\n",
      "Epoch: 100, Minibatch Loss= 0.6963, Training Accuracy= 0.497\n",
      "Epoch: 110, Minibatch Loss= 0.6963, Training Accuracy= 0.497\n",
      "Epoch: 120, Minibatch Loss= 0.6963, Training Accuracy= 0.497\n",
      "Epoch: 130, Minibatch Loss= 0.6963, Training Accuracy= 0.497\n",
      "Epoch: 140, Minibatch Loss= 0.6962, Training Accuracy= 0.497\n",
      "Epoch: 150, Minibatch Loss= 0.6962, Training Accuracy= 0.497\n",
      "Epoch: 160, Minibatch Loss= 0.6962, Training Accuracy= 0.497\n",
      "Epoch: 170, Minibatch Loss= 0.6962, Training Accuracy= 0.497\n",
      "Epoch: 180, Minibatch Loss= 0.6961, Training Accuracy= 0.497\n",
      "Epoch: 190, Minibatch Loss= 0.4979, Training Accuracy= 0.627\n",
      "Epoch: 200, Minibatch Loss= 0.1349, Training Accuracy= 0.967\n",
      "Epoch: 210, Minibatch Loss= 0.0473, Training Accuracy= 0.984\n",
      "Epoch: 220, Minibatch Loss= 0.0078, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Minibatch Loss= 0.6929, Training Accuracy= 0.524\n",
      "Epoch: 10, Minibatch Loss= 0.6928, Training Accuracy= 0.525\n",
      "Epoch: 20, Minibatch Loss= 0.6927, Training Accuracy= 0.464\n",
      "Epoch: 30, Minibatch Loss= 0.6927, Training Accuracy= 0.431\n",
      "Epoch: 40, Minibatch Loss= 0.6927, Training Accuracy= 0.431\n",
      "Epoch: 50, Minibatch Loss= 0.6927, Training Accuracy= 0.385\n",
      "Epoch: 60, Minibatch Loss= 0.6927, Training Accuracy= 0.385\n",
      "Epoch: 70, Minibatch Loss= 0.6927, Training Accuracy= 0.385\n",
      "Epoch: 80, Minibatch Loss= 0.6927, Training Accuracy= 0.370\n",
      "Epoch: 90, Minibatch Loss= 0.6927, Training Accuracy= 0.370\n",
      "Epoch: 100, Minibatch Loss= 0.6927, Training Accuracy= 0.385\n",
      "Epoch: 110, Minibatch Loss= 0.6927, Training Accuracy= 0.385\n",
      "Epoch: 120, Minibatch Loss= 0.6927, Training Accuracy= 0.385\n",
      "Epoch: 130, Minibatch Loss= 0.6927, Training Accuracy= 0.385\n",
      "Epoch: 140, Minibatch Loss= 0.6927, Training Accuracy= 0.419\n",
      "Epoch: 150, Minibatch Loss= 0.6926, Training Accuracy= 0.468\n",
      "Epoch: 160, Minibatch Loss= 0.3413, Training Accuracy= 0.896\n",
      "Epoch: 170, Minibatch Loss= 0.0387, Training Accuracy= 0.986\n",
      "Epoch: 180, Minibatch Loss= 0.0150, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0072, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0044, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.7\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 1000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "minibatch_losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                minibatch_losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 1.0, 1.0, 1.0, 1.0, 0.49259999, 0.50019997, 0.50489998, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  0.84977\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.00229496911168\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEoCAYAAABPQRaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac4a5f6690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minibatch_losses_1st_replication\n",
    "plt.plot(minibatch_losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, minibacth loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
