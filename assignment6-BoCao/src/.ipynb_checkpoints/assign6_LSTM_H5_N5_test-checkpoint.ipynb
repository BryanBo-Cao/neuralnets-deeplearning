{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 5\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Minibatch Loss= 0.6936, Training Accuracy= 0.467\n",
      "Epoch: 10, Minibatch Loss= 0.6931, Training Accuracy= 0.534\n",
      "Epoch: 20, Minibatch Loss= 0.6931, Training Accuracy= 0.534\n",
      "Epoch: 30, Minibatch Loss= 0.6931, Training Accuracy= 0.534\n",
      "Epoch: 40, Minibatch Loss= 0.6931, Training Accuracy= 0.534\n",
      "Epoch: 50, Minibatch Loss= 0.6931, Training Accuracy= 0.472\n",
      "Epoch: 60, Minibatch Loss= 0.6931, Training Accuracy= 0.440\n",
      "Epoch: 70, Minibatch Loss= 0.6931, Training Accuracy= 0.440\n",
      "Epoch: 80, Minibatch Loss= 0.6931, Training Accuracy= 0.440\n",
      "Epoch: 90, Minibatch Loss= 0.6931, Training Accuracy= 0.472\n",
      "Epoch: 100, Minibatch Loss= 0.6931, Training Accuracy= 0.472\n",
      "Epoch: 110, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 120, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 130, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 140, Minibatch Loss= 0.6930, Training Accuracy= 0.537\n",
      "Epoch: 150, Minibatch Loss= 0.6930, Training Accuracy= 0.537\n",
      "Epoch: 160, Minibatch Loss= 0.6930, Training Accuracy= 0.537\n",
      "Epoch: 170, Minibatch Loss= 0.6930, Training Accuracy= 0.537\n",
      "Epoch: 180, Minibatch Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 190, Minibatch Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 200, Minibatch Loss= 0.6680, Training Accuracy= 0.534\n",
      "Epoch: 210, Minibatch Loss= 0.1408, Training Accuracy= 0.966\n",
      "Epoch: 220, Minibatch Loss= 0.0202, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0049, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Minibatch Loss= 0.6986, Training Accuracy= 0.504\n",
      "Epoch: 10, Minibatch Loss= 0.6964, Training Accuracy= 0.504\n",
      "Epoch: 20, Minibatch Loss= 0.6955, Training Accuracy= 0.504\n",
      "Epoch: 30, Minibatch Loss= 0.6950, Training Accuracy= 0.539\n",
      "Epoch: 40, Minibatch Loss= 0.6946, Training Accuracy= 0.539\n",
      "Epoch: 50, Minibatch Loss= 0.6944, Training Accuracy= 0.539\n",
      "Epoch: 60, Minibatch Loss= 0.6942, Training Accuracy= 0.539\n",
      "Epoch: 70, Minibatch Loss= 0.6941, Training Accuracy= 0.539\n",
      "Epoch: 80, Minibatch Loss= 0.6940, Training Accuracy= 0.509\n",
      "Epoch: 90, Minibatch Loss= 0.6938, Training Accuracy= 0.509\n",
      "Epoch: 100, Minibatch Loss= 0.6937, Training Accuracy= 0.509\n",
      "Epoch: 110, Minibatch Loss= 0.6738, Training Accuracy= 0.609\n",
      "Epoch: 120, Minibatch Loss= 0.1137, Training Accuracy= 0.971\n",
      "Epoch: 130, Minibatch Loss= 0.0123, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0046, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 2: \n",
      "Epoch: 0, Minibatch Loss= 0.7151, Training Accuracy= 0.501\n",
      "Epoch: 10, Minibatch Loss= 0.7018, Training Accuracy= 0.501\n",
      "Epoch: 20, Minibatch Loss= 0.7000, Training Accuracy= 0.501\n",
      "Epoch: 30, Minibatch Loss= 0.6991, Training Accuracy= 0.501\n",
      "Epoch: 40, Minibatch Loss= 0.6986, Training Accuracy= 0.501\n",
      "Epoch: 50, Minibatch Loss= 0.6982, Training Accuracy= 0.501\n",
      "Epoch: 60, Minibatch Loss= 0.6980, Training Accuracy= 0.501\n",
      "Epoch: 70, Minibatch Loss= 0.6977, Training Accuracy= 0.501\n",
      "Epoch: 80, Minibatch Loss= 0.6976, Training Accuracy= 0.501\n",
      "Epoch: 90, Minibatch Loss= 0.6975, Training Accuracy= 0.501\n",
      "Epoch: 100, Minibatch Loss= 0.6974, Training Accuracy= 0.501\n",
      "Epoch: 110, Minibatch Loss= 0.6489, Training Accuracy= 0.630\n",
      "Epoch: 120, Minibatch Loss= 0.6980, Training Accuracy= 0.475\n",
      "Epoch: 130, Minibatch Loss= 0.5514, Training Accuracy= 0.655\n",
      "Epoch: 140, Minibatch Loss= 0.0127, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 680, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Minibatch Loss= 0.6949, Training Accuracy= 0.506\n",
      "Epoch: 10, Minibatch Loss= 0.6935, Training Accuracy= 0.506\n",
      "Epoch: 20, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 30, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 40, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 50, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 60, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 70, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 80, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 90, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 100, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 110, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 120, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 130, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 140, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 150, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 160, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 170, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 180, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 190, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 200, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 210, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 220, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 230, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 240, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 250, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 260, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 270, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 280, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 290, Minibatch Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 300, Minibatch Loss= 0.6907, Training Accuracy= 0.468\n",
      "Epoch: 310, Minibatch Loss= 0.1265, Training Accuracy= 0.968\n",
      "Epoch: 320, Minibatch Loss= 0.0236, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0050, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Minibatch Loss= 0.7146, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Minibatch Loss= 0.7059, Training Accuracy= 0.500\n",
      "Epoch: 20, Minibatch Loss= 0.7044, Training Accuracy= 0.500\n",
      "Epoch: 30, Minibatch Loss= 0.7037, Training Accuracy= 0.500\n",
      "Epoch: 40, Minibatch Loss= 0.7033, Training Accuracy= 0.500\n",
      "Epoch: 50, Minibatch Loss= 0.7031, Training Accuracy= 0.500\n",
      "Epoch: 60, Minibatch Loss= 0.7029, Training Accuracy= 0.500\n",
      "Epoch: 70, Minibatch Loss= 0.7029, Training Accuracy= 0.500\n",
      "Epoch: 80, Minibatch Loss= 0.7028, Training Accuracy= 0.500\n",
      "Epoch: 90, Minibatch Loss= 0.7028, Training Accuracy= 0.500\n",
      "Epoch: 100, Minibatch Loss= 0.7027, Training Accuracy= 0.500\n",
      "Epoch: 110, Minibatch Loss= 0.7027, Training Accuracy= 0.500\n",
      "Epoch: 120, Minibatch Loss= 0.7027, Training Accuracy= 0.500\n",
      "Epoch: 130, Minibatch Loss= 0.7027, Training Accuracy= 0.500\n",
      "Epoch: 140, Minibatch Loss= 0.7027, Training Accuracy= 0.500\n",
      "Epoch: 150, Minibatch Loss= 0.7027, Training Accuracy= 0.500\n",
      "Epoch: 160, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 170, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 180, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 190, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 200, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 210, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 220, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 230, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 240, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 250, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 260, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 270, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 280, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 290, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 300, Minibatch Loss= 0.7027, Training Accuracy= 0.500\n",
      "Epoch: 310, Minibatch Loss= 0.7205, Training Accuracy= 0.469\n",
      "Epoch: 320, Minibatch Loss= 0.0199, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0032, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Minibatch Loss= 0.6939, Training Accuracy= 0.492\n",
      "Epoch: 10, Minibatch Loss= 0.6933, Training Accuracy= 0.522\n",
      "Epoch: 20, Minibatch Loss= 0.6931, Training Accuracy= 0.473\n",
      "Epoch: 30, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 40, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 50, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 60, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 70, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 80, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 90, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 100, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 110, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 120, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 130, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 140, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 150, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 160, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 170, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 180, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 190, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 200, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 210, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 220, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 230, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 240, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 250, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 260, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 270, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 280, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 290, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 300, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 310, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 320, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 330, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 340, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 360, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 370, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 380, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 390, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 400, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 410, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 420, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 430, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 440, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 450, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 460, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 470, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 480, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 490, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 500, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 510, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 520, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 530, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 540, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 550, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 560, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 570, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 580, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 590, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 600, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 610, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 620, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 630, Minibatch Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 640, Minibatch Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 650, Minibatch Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 660, Minibatch Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 670, Minibatch Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 680, Minibatch Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 690, Minibatch Loss= 0.6927, Training Accuracy= 0.573\n",
      "Epoch: 700, Minibatch Loss= 0.6919, Training Accuracy= 0.573\n",
      "Epoch: 710, Minibatch Loss= 0.1421, Training Accuracy= 0.940\n",
      "Epoch: 720, Minibatch Loss= 0.0059, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Minibatch Loss= 0.7569, Training Accuracy= 0.506\n",
      "Epoch: 10, Minibatch Loss= 0.7173, Training Accuracy= 0.506\n",
      "Epoch: 20, Minibatch Loss= 0.7122, Training Accuracy= 0.506\n",
      "Epoch: 30, Minibatch Loss= 0.7101, Training Accuracy= 0.506\n",
      "Epoch: 40, Minibatch Loss= 0.7090, Training Accuracy= 0.506\n",
      "Epoch: 50, Minibatch Loss= 0.7084, Training Accuracy= 0.506\n",
      "Epoch: 60, Minibatch Loss= 0.7079, Training Accuracy= 0.506\n",
      "Epoch: 70, Minibatch Loss= 0.7077, Training Accuracy= 0.506\n",
      "Epoch: 80, Minibatch Loss= 0.7075, Training Accuracy= 0.506\n",
      "Epoch: 90, Minibatch Loss= 0.7074, Training Accuracy= 0.506\n",
      "Epoch: 100, Minibatch Loss= 0.7074, Training Accuracy= 0.506\n",
      "Epoch: 110, Minibatch Loss= 0.7075, Training Accuracy= 0.506\n",
      "Epoch: 120, Minibatch Loss= 0.7076, Training Accuracy= 0.506\n",
      "Epoch: 130, Minibatch Loss= 0.2841, Training Accuracy= 0.848\n",
      "Epoch: 140, Minibatch Loss= 0.0087, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0034, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Minibatch Loss= 0.6935, Training Accuracy= 0.399\n",
      "Epoch: 10, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 20, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 30, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 40, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 50, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 60, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 70, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 80, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 90, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 100, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 110, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 120, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 130, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 140, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 150, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 160, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 170, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 180, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 190, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 200, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 210, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 220, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 230, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 240, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 250, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 260, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 270, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 280, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 290, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 300, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 310, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 320, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 330, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 340, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 350, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 360, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 370, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 380, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 390, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 400, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 410, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 420, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 430, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 440, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 450, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 460, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 470, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 480, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 490, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 500, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 510, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 520, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 530, Minibatch Loss= 0.6937, Training Accuracy= 0.464\n",
      "Epoch: 540, Minibatch Loss= 0.6932, Training Accuracy= 0.628\n",
      "Epoch: 550, Minibatch Loss= 0.1801, Training Accuracy= 0.935\n",
      "Epoch: 560, Minibatch Loss= 0.0096, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0034, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 8: \n",
      "Epoch: 0, Minibatch Loss= 0.6969, Training Accuracy= 0.502\n",
      "Epoch: 10, Minibatch Loss= 0.6948, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Minibatch Loss= 0.6945, Training Accuracy= 0.502\n",
      "Epoch: 30, Minibatch Loss= 0.6944, Training Accuracy= 0.502\n",
      "Epoch: 40, Minibatch Loss= 0.6943, Training Accuracy= 0.502\n",
      "Epoch: 50, Minibatch Loss= 0.6942, Training Accuracy= 0.502\n",
      "Epoch: 60, Minibatch Loss= 0.6942, Training Accuracy= 0.502\n",
      "Epoch: 70, Minibatch Loss= 0.6942, Training Accuracy= 0.502\n",
      "Epoch: 80, Minibatch Loss= 0.6941, Training Accuracy= 0.502\n",
      "Epoch: 90, Minibatch Loss= 0.6941, Training Accuracy= 0.502\n",
      "Epoch: 100, Minibatch Loss= 0.6941, Training Accuracy= 0.502\n",
      "Epoch: 110, Minibatch Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 120, Minibatch Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 130, Minibatch Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 140, Minibatch Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 150, Minibatch Loss= 0.6936, Training Accuracy= 0.506\n",
      "Epoch: 160, Minibatch Loss= 0.0667, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0045, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Minibatch Loss= 0.7667, Training Accuracy= 0.499\n",
      "Epoch: 10, Minibatch Loss= 0.7178, Training Accuracy= 0.499\n",
      "Epoch: 20, Minibatch Loss= 0.7118, Training Accuracy= 0.499\n",
      "Epoch: 30, Minibatch Loss= 0.7091, Training Accuracy= 0.499\n",
      "Epoch: 40, Minibatch Loss= 0.7076, Training Accuracy= 0.499\n",
      "Epoch: 50, Minibatch Loss= 0.7066, Training Accuracy= 0.499\n",
      "Epoch: 60, Minibatch Loss= 0.7060, Training Accuracy= 0.499\n",
      "Epoch: 70, Minibatch Loss= 0.7055, Training Accuracy= 0.499\n",
      "Epoch: 80, Minibatch Loss= 0.7051, Training Accuracy= 0.499\n",
      "Epoch: 90, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 100, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 110, Minibatch Loss= 0.7044, Training Accuracy= 0.499\n",
      "Epoch: 120, Minibatch Loss= 0.7042, Training Accuracy= 0.499\n",
      "Epoch: 130, Minibatch Loss= 0.6767, Training Accuracy= 0.533\n",
      "Epoch: 140, Minibatch Loss= 0.0399, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0050, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.7\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 1000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "minibatch_losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                minibatch_losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  1.0\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.0\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEoCAYAAABPQRaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58b2895410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minibatch_losses_1st_replication\n",
    "plt.plot(minibatch_losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, minibacth loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
