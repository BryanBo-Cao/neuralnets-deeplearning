{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 10\n",
    "N = 10\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.7194, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.6977, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.6953, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.6943, Training Accuracy= 0.499\n",
      "Epoch: 40, Loss= 0.6939, Training Accuracy= 0.504\n",
      "Epoch: 50, Loss= 0.6936, Training Accuracy= 0.503\n",
      "Epoch: 60, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 80, Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 100, Loss= 0.6932, Training Accuracy= 0.515\n",
      "Epoch: 110, Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 120, Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 130, Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 140, Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 150, Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 160, Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 170, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 180, Loss= 0.6931, Training Accuracy= 0.510\n",
      "Epoch: 190, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 200, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 210, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 220, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 230, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 240, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 250, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 260, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 270, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 280, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 290, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 300, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 310, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 320, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 330, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 340, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 350, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 360, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 370, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 380, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 390, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 400, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 410, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 420, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 430, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 440, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 450, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 460, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 470, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 480, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 490, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 500, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 510, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 520, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 530, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 540, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 550, Loss= 0.6931, Training Accuracy= 0.498\n",
      "Epoch: 560, Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 570, Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 580, Loss= 0.6931, Training Accuracy= 0.499\n",
      "Epoch: 590, Loss= 0.6931, Training Accuracy= 0.497\n",
      "Epoch: 600, Loss= 0.6931, Training Accuracy= 0.495\n",
      "Epoch: 610, Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 620, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 630, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 640, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 650, Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 660, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 670, Loss= 0.6930, Training Accuracy= 0.515\n",
      "Epoch: 680, Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 690, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 700, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 710, Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 720, Loss= 0.6935, Training Accuracy= 0.517\n",
      "Epoch: 730, Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 740, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 750, Loss= 0.6925, Training Accuracy= 0.522\n",
      "Epoch: 760, Loss= 0.6924, Training Accuracy= 0.513\n",
      "Epoch: 770, Loss= 0.6925, Training Accuracy= 0.516\n",
      "Epoch: 780, Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 790, Loss= 0.6926, Training Accuracy= 0.524\n",
      "Epoch: 800, Loss= 0.6853, Training Accuracy= 0.545\n",
      "Epoch: 810, Loss= 0.6788, Training Accuracy= 0.595\n",
      "Epoch: 820, Loss= 0.5580, Training Accuracy= 0.704\n",
      "Epoch: 830, Loss= 0.7045, Training Accuracy= 0.502\n",
      "Epoch: 840, Loss= 0.7032, Training Accuracy= 0.502\n",
      "Epoch: 850, Loss= 0.6953, Training Accuracy= 0.501\n",
      "Epoch: 860, Loss= 0.0066, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.7606, Training Accuracy= 0.500\n",
      "Epoch: 10, Loss= 0.7073, Training Accuracy= 0.500\n",
      "Epoch: 20, Loss= 0.7008, Training Accuracy= 0.500\n",
      "Epoch: 30, Loss= 0.6976, Training Accuracy= 0.500\n",
      "Epoch: 40, Loss= 0.6959, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 0.6949, Training Accuracy= 0.500\n",
      "Epoch: 60, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.6940, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.6938, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 100, Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 110, Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 120, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 140, Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 150, Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 160, Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 170, Loss= 0.6933, Training Accuracy= 0.493\n",
      "Epoch: 180, Loss= 0.6932, Training Accuracy= 0.496\n",
      "Epoch: 190, Loss= 0.6932, Training Accuracy= 0.497\n",
      "Epoch: 200, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 230, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 240, Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 250, Loss= 0.6932, Training Accuracy= 0.497\n",
      "Epoch: 260, Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 270, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 280, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 290, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 310, Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 320, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 330, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 340, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 350, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 360, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 370, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 380, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 390, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 400, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 410, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 420, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 430, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 440, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 450, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 460, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 470, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 480, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 490, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 500, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 510, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 520, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 530, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 540, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 550, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 560, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 570, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 580, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 590, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 600, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 610, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 620, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 630, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 640, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 650, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 660, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 670, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 680, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 690, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 700, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 710, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 720, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 730, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 740, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 750, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 760, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 770, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 780, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 790, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 800, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 810, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 820, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 830, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 840, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 850, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 860, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 870, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 880, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 890, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 900, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 910, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 920, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 930, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 940, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 950, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 960, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 970, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 980, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 990, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1000, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1010, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1020, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1030, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1040, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1050, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1060, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1070, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1080, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1090, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1100, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1110, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 1120, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1130, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 1140, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 1150, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 1160, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 1170, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1180, Loss= 0.6932, Training Accuracy= 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1190, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1200, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1210, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1220, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1230, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1240, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 1250, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1260, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 1270, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1280, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1290, Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 1300, Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 1310, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 1320, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1330, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1340, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1350, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1360, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1370, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1380, Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 1390, Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 1400, Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 1410, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 1420, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 1430, Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 1440, Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 1450, Loss= 0.6928, Training Accuracy= 0.518\n",
      "Epoch: 1460, Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 1470, Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 1480, Loss= 0.6929, Training Accuracy= 0.515\n",
      "Epoch: 1490, Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 1500, Loss= 0.6934, Training Accuracy= 0.514\n",
      "Epoch: 1510, Loss= 0.6940, Training Accuracy= 0.514\n",
      "Epoch: 1520, Loss= 0.6950, Training Accuracy= 0.514\n",
      "Epoch: 1530, Loss= 0.6949, Training Accuracy= 0.526\n",
      "Epoch: 1540, Loss= 0.7104, Training Accuracy= 0.509\n",
      "Epoch: 1550, Loss= 0.5398, Training Accuracy= 0.743\n",
      "Epoch: 1560, Loss= 0.8864, Training Accuracy= 0.501\n",
      "Epoch: 1570, Loss= 0.8847, Training Accuracy= 0.509\n",
      "Epoch: 1580, Loss= 0.8630, Training Accuracy= 0.510\n",
      "Epoch: 1590, Loss= 0.8521, Training Accuracy= 0.516\n",
      "Epoch: 1600, Loss= 0.8608, Training Accuracy= 0.515\n",
      "Epoch: 1610, Loss= 0.8430, Training Accuracy= 0.516\n",
      "Epoch: 1620, Loss= 0.8369, Training Accuracy= 0.516\n",
      "Epoch: 1630, Loss= 0.8271, Training Accuracy= 0.516\n",
      "Epoch: 1640, Loss= 0.8281, Training Accuracy= 0.516\n",
      "Epoch: 1650, Loss= 0.8518, Training Accuracy= 0.510\n",
      "Epoch: 1660, Loss= 0.8289, Training Accuracy= 0.514\n",
      "Epoch: 1670, Loss= 0.8358, Training Accuracy= 0.500\n",
      "Epoch: 1680, Loss= 0.8285, Training Accuracy= 0.500\n",
      "Epoch: 1690, Loss= 0.8823, Training Accuracy= 0.500\n",
      "Epoch: 1700, Loss= 0.8974, Training Accuracy= 0.503\n",
      "Epoch: 1710, Loss= 0.9089, Training Accuracy= 0.503\n",
      "Epoch: 1720, Loss= 0.9131, Training Accuracy= 0.503\n",
      "Epoch: 1730, Loss= 0.9152, Training Accuracy= 0.503\n",
      "Epoch: 1740, Loss= 0.9159, Training Accuracy= 0.503\n",
      "Epoch: 1750, Loss= 0.9145, Training Accuracy= 0.503\n",
      "Epoch: 1760, Loss= 0.9132, Training Accuracy= 0.503\n",
      "Epoch: 1770, Loss= 0.9126, Training Accuracy= 0.503\n",
      "Epoch: 1780, Loss= 0.9181, Training Accuracy= 0.503\n",
      "Epoch: 1790, Loss= 0.9162, Training Accuracy= 0.500\n",
      "Epoch: 1800, Loss= 0.9149, Training Accuracy= 0.500\n",
      "Epoch: 1810, Loss= 0.9145, Training Accuracy= 0.500\n",
      "Epoch: 1820, Loss= 0.9139, Training Accuracy= 0.500\n",
      "Epoch: 1830, Loss= 0.9129, Training Accuracy= 0.500\n",
      "Epoch: 1840, Loss= 0.9104, Training Accuracy= 0.500\n",
      "Epoch: 1850, Loss= 0.9016, Training Accuracy= 0.500\n",
      "Epoch: 1860, Loss= 0.9164, Training Accuracy= 0.500\n",
      "Epoch: 1870, Loss= 0.9154, Training Accuracy= 0.500\n",
      "Epoch: 1880, Loss= 0.9150, Training Accuracy= 0.500\n",
      "Epoch: 1890, Loss= 0.9147, Training Accuracy= 0.500\n",
      "Epoch: 1900, Loss= 0.9144, Training Accuracy= 0.500\n",
      "Epoch: 1910, Loss= 0.9140, Training Accuracy= 0.500\n",
      "Epoch: 1920, Loss= 0.9135, Training Accuracy= 0.500\n",
      "Epoch: 1930, Loss= 0.9128, Training Accuracy= 0.500\n",
      "Epoch: 1940, Loss= 0.9118, Training Accuracy= 0.500\n",
      "Epoch: 1950, Loss= 0.9098, Training Accuracy= 0.500\n",
      "Epoch: 1960, Loss= 0.9052, Training Accuracy= 0.500\n",
      "Epoch: 1970, Loss= 0.8905, Training Accuracy= 0.500\n",
      "Epoch: 1980, Loss= 0.8645, Training Accuracy= 0.500\n",
      "Epoch: 1990, Loss= 0.8441, Training Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4952\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.7532, Training Accuracy= 0.505\n",
      "Epoch: 10, Loss= 0.7123, Training Accuracy= 0.505\n",
      "Epoch: 20, Loss= 0.7071, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 40, Loss= 0.7029, Training Accuracy= 0.505\n",
      "Epoch: 50, Loss= 0.7021, Training Accuracy= 0.505\n",
      "Epoch: 60, Loss= 0.7016, Training Accuracy= 0.505\n",
      "Epoch: 70, Loss= 0.7013, Training Accuracy= 0.505\n",
      "Epoch: 80, Loss= 0.7010, Training Accuracy= 0.505\n",
      "Epoch: 90, Loss= 0.7007, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.7002, Training Accuracy= 0.505\n",
      "Epoch: 110, Loss= 0.6997, Training Accuracy= 0.505\n",
      "Epoch: 120, Loss= 0.6996, Training Accuracy= 0.505\n",
      "Epoch: 130, Loss= 0.6984, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.6975, Training Accuracy= 0.520\n",
      "Epoch: 150, Loss= 0.7058, Training Accuracy= 0.507\n",
      "Epoch: 160, Loss= 0.6964, Training Accuracy= 0.537\n",
      "Epoch: 170, Loss= 0.7718, Training Accuracy= 0.513\n",
      "Epoch: 180, Loss= 0.7668, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.7573, Training Accuracy= 0.505\n",
      "Epoch: 200, Loss= 0.7561, Training Accuracy= 0.505\n",
      "Epoch: 210, Loss= 0.7559, Training Accuracy= 0.505\n",
      "Epoch: 220, Loss= 0.7558, Training Accuracy= 0.505\n",
      "Epoch: 230, Loss= 0.7557, Training Accuracy= 0.505\n",
      "Epoch: 240, Loss= 0.7556, Training Accuracy= 0.505\n",
      "Epoch: 250, Loss= 0.7555, Training Accuracy= 0.505\n",
      "Epoch: 260, Loss= 0.7554, Training Accuracy= 0.505\n",
      "Epoch: 270, Loss= 0.7553, Training Accuracy= 0.505\n",
      "Epoch: 280, Loss= 0.7551, Training Accuracy= 0.505\n",
      "Epoch: 290, Loss= 0.7549, Training Accuracy= 0.505\n",
      "Epoch: 300, Loss= 0.7545, Training Accuracy= 0.505\n",
      "Epoch: 310, Loss= 0.7537, Training Accuracy= 0.505\n",
      "Epoch: 320, Loss= 0.7519, Training Accuracy= 0.505\n",
      "Epoch: 330, Loss= 0.7476, Training Accuracy= 0.505\n",
      "Epoch: 340, Loss= 0.7442, Training Accuracy= 0.505\n",
      "Epoch: 350, Loss= 0.7426, Training Accuracy= 0.505\n",
      "Epoch: 360, Loss= 0.7415, Training Accuracy= 0.505\n",
      "Epoch: 370, Loss= 0.7407, Training Accuracy= 0.505\n",
      "Epoch: 380, Loss= 0.7402, Training Accuracy= 0.505\n",
      "Epoch: 390, Loss= 0.7396, Training Accuracy= 0.505\n",
      "Epoch: 400, Loss= 0.7390, Training Accuracy= 0.505\n",
      "Epoch: 410, Loss= 0.7384, Training Accuracy= 0.505\n",
      "Epoch: 420, Loss= 0.7379, Training Accuracy= 0.505\n",
      "Epoch: 430, Loss= 0.7376, Training Accuracy= 0.505\n",
      "Epoch: 440, Loss= 0.7376, Training Accuracy= 0.505\n",
      "Epoch: 450, Loss= 0.7390, Training Accuracy= 0.505\n",
      "Epoch: 460, Loss= 0.7404, Training Accuracy= 0.505\n",
      "Epoch: 470, Loss= 0.7391, Training Accuracy= 0.505\n",
      "Epoch: 480, Loss= 0.7424, Training Accuracy= 0.505\n",
      "Epoch: 490, Loss= 0.7377, Training Accuracy= 0.505\n",
      "Epoch: 500, Loss= 0.7420, Training Accuracy= 0.505\n",
      "Epoch: 510, Loss= 0.7330, Training Accuracy= 0.505\n",
      "Epoch: 520, Loss= 0.7293, Training Accuracy= 0.505\n",
      "Epoch: 530, Loss= 0.7222, Training Accuracy= 0.505\n",
      "Epoch: 540, Loss= 0.7610, Training Accuracy= 0.505\n",
      "Epoch: 550, Loss= 0.7461, Training Accuracy= 0.502\n",
      "Epoch: 560, Loss= 0.7193, Training Accuracy= 0.505\n",
      "Epoch: 570, Loss= 0.7205, Training Accuracy= 0.505\n",
      "Epoch: 580, Loss= 0.7204, Training Accuracy= 0.505\n",
      "Epoch: 590, Loss= 0.7248, Training Accuracy= 0.505\n",
      "Epoch: 600, Loss= 0.7228, Training Accuracy= 0.505\n",
      "Epoch: 610, Loss= 0.7169, Training Accuracy= 0.505\n",
      "Epoch: 620, Loss= 0.7550, Training Accuracy= 0.505\n",
      "Epoch: 630, Loss= 0.7702, Training Accuracy= 0.505\n",
      "Epoch: 640, Loss= 0.7704, Training Accuracy= 0.505\n",
      "Epoch: 650, Loss= 0.7702, Training Accuracy= 0.505\n",
      "Epoch: 660, Loss= 0.7696, Training Accuracy= 0.505\n",
      "Epoch: 670, Loss= 0.7607, Training Accuracy= 0.505\n",
      "Epoch: 680, Loss= 0.7561, Training Accuracy= 0.505\n",
      "Epoch: 690, Loss= 0.7557, Training Accuracy= 0.505\n",
      "Epoch: 700, Loss= 0.7553, Training Accuracy= 0.505\n",
      "Epoch: 710, Loss= 0.7547, Training Accuracy= 0.505\n",
      "Epoch: 720, Loss= 0.7533, Training Accuracy= 0.505\n",
      "Epoch: 730, Loss= 0.7521, Training Accuracy= 0.505\n",
      "Epoch: 740, Loss= 0.7498, Training Accuracy= 0.505\n",
      "Epoch: 750, Loss= 0.7465, Training Accuracy= 0.505\n",
      "Epoch: 760, Loss= 0.7433, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 770, Loss= 0.7412, Training Accuracy= 0.505\n",
      "Epoch: 780, Loss= 0.7426, Training Accuracy= 0.505\n",
      "Epoch: 790, Loss= 0.7462, Training Accuracy= 0.505\n",
      "Epoch: 800, Loss= 0.7455, Training Accuracy= 0.505\n",
      "Epoch: 810, Loss= 0.7461, Training Accuracy= 0.505\n",
      "Epoch: 820, Loss= 0.7463, Training Accuracy= 0.505\n",
      "Epoch: 830, Loss= 0.7464, Training Accuracy= 0.505\n",
      "Epoch: 840, Loss= 0.7468, Training Accuracy= 0.505\n",
      "Epoch: 850, Loss= 0.7466, Training Accuracy= 0.505\n",
      "Epoch: 860, Loss= 0.7465, Training Accuracy= 0.505\n",
      "Epoch: 870, Loss= 0.7463, Training Accuracy= 0.505\n",
      "Epoch: 880, Loss= 0.7460, Training Accuracy= 0.505\n",
      "Epoch: 890, Loss= 0.7458, Training Accuracy= 0.505\n",
      "Epoch: 900, Loss= 0.7441, Training Accuracy= 0.505\n",
      "Epoch: 910, Loss= 0.7436, Training Accuracy= 0.505\n",
      "Epoch: 920, Loss= 0.7431, Training Accuracy= 0.505\n",
      "Epoch: 930, Loss= 0.7427, Training Accuracy= 0.505\n",
      "Epoch: 940, Loss= 0.7425, Training Accuracy= 0.505\n",
      "Epoch: 950, Loss= 0.7425, Training Accuracy= 0.505\n",
      "Epoch: 960, Loss= 0.7426, Training Accuracy= 0.505\n",
      "Epoch: 970, Loss= 0.7432, Training Accuracy= 0.505\n",
      "Epoch: 980, Loss= 0.7431, Training Accuracy= 0.505\n",
      "Epoch: 990, Loss= 0.7426, Training Accuracy= 0.505\n",
      "Epoch: 1000, Loss= 0.7430, Training Accuracy= 0.505\n",
      "Epoch: 1010, Loss= 0.7406, Training Accuracy= 0.505\n",
      "Epoch: 1020, Loss= 0.7391, Training Accuracy= 0.505\n",
      "Epoch: 1030, Loss= 0.7400, Training Accuracy= 0.505\n",
      "Epoch: 1040, Loss= 0.7393, Training Accuracy= 0.505\n",
      "Epoch: 1050, Loss= 0.7379, Training Accuracy= 0.505\n",
      "Epoch: 1060, Loss= 0.7356, Training Accuracy= 0.505\n",
      "Epoch: 1070, Loss= 0.7367, Training Accuracy= 0.505\n",
      "Epoch: 1080, Loss= 0.7510, Training Accuracy= 0.505\n",
      "Epoch: 1090, Loss= 0.7351, Training Accuracy= 0.505\n",
      "Epoch: 1100, Loss= 0.7311, Training Accuracy= 0.505\n",
      "Epoch: 1110, Loss= 0.7290, Training Accuracy= 0.505\n",
      "Epoch: 1120, Loss= 0.7323, Training Accuracy= 0.505\n",
      "Epoch: 1130, Loss= 0.7344, Training Accuracy= 0.505\n",
      "Epoch: 1140, Loss= 0.7327, Training Accuracy= 0.505\n",
      "Epoch: 1150, Loss= 0.7294, Training Accuracy= 0.505\n",
      "Epoch: 1160, Loss= 0.7545, Training Accuracy= 0.505\n",
      "Epoch: 1170, Loss= 0.7550, Training Accuracy= 0.505\n",
      "Epoch: 1180, Loss= 0.7531, Training Accuracy= 0.505\n",
      "Epoch: 1190, Loss= 0.7519, Training Accuracy= 0.505\n",
      "Epoch: 1200, Loss= 0.7498, Training Accuracy= 0.505\n",
      "Epoch: 1210, Loss= 0.7403, Training Accuracy= 0.505\n",
      "Epoch: 1220, Loss= 0.7271, Training Accuracy= 0.505\n",
      "Epoch: 1230, Loss= 0.7134, Training Accuracy= 0.505\n",
      "Epoch: 1240, Loss= 0.7109, Training Accuracy= 0.505\n",
      "Epoch: 1250, Loss= 0.7091, Training Accuracy= 0.505\n",
      "Epoch: 1260, Loss= 0.7079, Training Accuracy= 0.505\n",
      "Epoch: 1270, Loss= 0.7357, Training Accuracy= 0.505\n",
      "Epoch: 1280, Loss= 0.7347, Training Accuracy= 0.505\n",
      "Epoch: 1290, Loss= 0.7321, Training Accuracy= 0.505\n",
      "Epoch: 1300, Loss= 0.7304, Training Accuracy= 0.505\n",
      "Epoch: 1310, Loss= 0.7321, Training Accuracy= 0.505\n",
      "Epoch: 1320, Loss= 0.7311, Training Accuracy= 0.507\n",
      "Epoch: 1330, Loss= 0.7265, Training Accuracy= 0.505\n",
      "Epoch: 1340, Loss= 0.7230, Training Accuracy= 0.505\n",
      "Epoch: 1350, Loss= 0.7219, Training Accuracy= 0.515\n",
      "Epoch: 1360, Loss= 0.7607, Training Accuracy= 0.505\n",
      "Epoch: 1370, Loss= 0.7481, Training Accuracy= 0.505\n",
      "Epoch: 1380, Loss= 0.7505, Training Accuracy= 0.505\n",
      "Epoch: 1390, Loss= 0.7411, Training Accuracy= 0.505\n",
      "Epoch: 1400, Loss= 0.7391, Training Accuracy= 0.505\n",
      "Epoch: 1410, Loss= 0.7378, Training Accuracy= 0.505\n",
      "Epoch: 1420, Loss= 0.7367, Training Accuracy= 0.505\n",
      "Epoch: 1430, Loss= 0.7357, Training Accuracy= 0.505\n",
      "Epoch: 1440, Loss= 0.7361, Training Accuracy= 0.505\n",
      "Epoch: 1450, Loss= 0.7200, Training Accuracy= 0.505\n",
      "Epoch: 1460, Loss= 0.7362, Training Accuracy= 0.505\n",
      "Epoch: 1470, Loss= 0.7389, Training Accuracy= 0.505\n",
      "Epoch: 1480, Loss= 0.7517, Training Accuracy= 0.505\n",
      "Epoch: 1490, Loss= 0.7511, Training Accuracy= 0.505\n",
      "Epoch: 1500, Loss= 0.7479, Training Accuracy= 0.505\n",
      "Epoch: 1510, Loss= 0.7485, Training Accuracy= 0.505\n",
      "Epoch: 1520, Loss= 0.7620, Training Accuracy= 0.505\n",
      "Epoch: 1530, Loss= 0.7608, Training Accuracy= 0.505\n",
      "Epoch: 1540, Loss= 0.7585, Training Accuracy= 0.505\n",
      "Epoch: 1550, Loss= 0.7575, Training Accuracy= 0.505\n",
      "Epoch: 1560, Loss= 0.7507, Training Accuracy= 0.505\n",
      "Epoch: 1570, Loss= 0.7496, Training Accuracy= 0.505\n",
      "Epoch: 1580, Loss= 0.7450, Training Accuracy= 0.505\n",
      "Epoch: 1590, Loss= 0.7437, Training Accuracy= 0.505\n",
      "Epoch: 1600, Loss= 0.7337, Training Accuracy= 0.505\n",
      "Epoch: 1610, Loss= 0.7400, Training Accuracy= 0.505\n",
      "Epoch: 1620, Loss= 0.7503, Training Accuracy= 0.505\n",
      "Epoch: 1630, Loss= 0.7679, Training Accuracy= 0.505\n",
      "Epoch: 1640, Loss= 0.7677, Training Accuracy= 0.505\n",
      "Epoch: 1650, Loss= 0.7669, Training Accuracy= 0.505\n",
      "Epoch: 1660, Loss= 0.7654, Training Accuracy= 0.505\n",
      "Epoch: 1670, Loss= 0.7619, Training Accuracy= 0.505\n",
      "Epoch: 1680, Loss= 0.7590, Training Accuracy= 0.505\n",
      "Epoch: 1690, Loss= 0.7474, Training Accuracy= 0.505\n",
      "Epoch: 1700, Loss= 0.7587, Training Accuracy= 0.505\n",
      "Epoch: 1710, Loss= 0.7762, Training Accuracy= 0.505\n",
      "Epoch: 1720, Loss= 0.7559, Training Accuracy= 0.505\n",
      "Epoch: 1730, Loss= 0.7534, Training Accuracy= 0.505\n",
      "Epoch: 1740, Loss= 0.7522, Training Accuracy= 0.505\n",
      "Epoch: 1750, Loss= 0.7519, Training Accuracy= 0.505\n",
      "Epoch: 1760, Loss= 0.7528, Training Accuracy= 0.505\n",
      "Epoch: 1770, Loss= 0.7523, Training Accuracy= 0.505\n",
      "Epoch: 1780, Loss= 0.7630, Training Accuracy= 0.505\n",
      "Epoch: 1790, Loss= 0.7576, Training Accuracy= 0.505\n",
      "Epoch: 1800, Loss= 0.7555, Training Accuracy= 0.505\n",
      "Epoch: 1810, Loss= 0.7547, Training Accuracy= 0.505\n",
      "Epoch: 1820, Loss= 0.7540, Training Accuracy= 0.505\n",
      "Epoch: 1830, Loss= 0.7534, Training Accuracy= 0.505\n",
      "Epoch: 1840, Loss= 0.7529, Training Accuracy= 0.505\n",
      "Epoch: 1850, Loss= 0.7527, Training Accuracy= 0.505\n",
      "Epoch: 1860, Loss= 0.7562, Training Accuracy= 0.505\n",
      "Epoch: 1870, Loss= 0.7558, Training Accuracy= 0.505\n",
      "Epoch: 1880, Loss= 0.7560, Training Accuracy= 0.505\n",
      "Epoch: 1890, Loss= 0.7563, Training Accuracy= 0.505\n",
      "Epoch: 1900, Loss= 0.7563, Training Accuracy= 0.505\n",
      "Epoch: 1910, Loss= 0.7562, Training Accuracy= 0.505\n",
      "Epoch: 1920, Loss= 0.7559, Training Accuracy= 0.505\n",
      "Epoch: 1930, Loss= 0.7551, Training Accuracy= 0.505\n",
      "Epoch: 1940, Loss= 0.7522, Training Accuracy= 0.505\n",
      "Epoch: 1950, Loss= 0.7513, Training Accuracy= 0.505\n",
      "Epoch: 1960, Loss= 0.7510, Training Accuracy= 0.505\n",
      "Epoch: 1970, Loss= 0.7506, Training Accuracy= 0.505\n",
      "Epoch: 1980, Loss= 0.7503, Training Accuracy= 0.505\n",
      "Epoch: 1990, Loss= 0.7501, Training Accuracy= 0.505\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5035\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.7281, Training Accuracy= 0.490\n",
      "Epoch: 10, Loss= 0.7088, Training Accuracy= 0.490\n",
      "Epoch: 20, Loss= 0.7040, Training Accuracy= 0.490\n",
      "Epoch: 30, Loss= 0.7003, Training Accuracy= 0.490\n",
      "Epoch: 40, Loss= 0.6974, Training Accuracy= 0.490\n",
      "Epoch: 50, Loss= 0.6960, Training Accuracy= 0.491\n",
      "Epoch: 60, Loss= 0.6953, Training Accuracy= 0.491\n",
      "Epoch: 70, Loss= 0.6948, Training Accuracy= 0.490\n",
      "Epoch: 80, Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 100, Loss= 0.6939, Training Accuracy= 0.506\n",
      "Epoch: 110, Loss= 0.6937, Training Accuracy= 0.513\n",
      "Epoch: 120, Loss= 0.6935, Training Accuracy= 0.509\n",
      "Epoch: 130, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 150, Loss= 0.6925, Training Accuracy= 0.531\n",
      "Epoch: 160, Loss= 0.6916, Training Accuracy= 0.536\n",
      "Epoch: 170, Loss= 0.6851, Training Accuracy= 0.560\n",
      "Epoch: 180, Loss= 0.6757, Training Accuracy= 0.576\n",
      "Epoch: 190, Loss= 0.7207, Training Accuracy= 0.514\n",
      "Epoch: 200, Loss= 0.7221, Training Accuracy= 0.505\n",
      "Epoch: 210, Loss= 0.7166, Training Accuracy= 0.506\n",
      "Epoch: 220, Loss= 0.7162, Training Accuracy= 0.507\n",
      "Epoch: 230, Loss= 0.7147, Training Accuracy= 0.507\n",
      "Epoch: 240, Loss= 0.7130, Training Accuracy= 0.507\n",
      "Epoch: 250, Loss= 0.7124, Training Accuracy= 0.506\n",
      "Epoch: 260, Loss= 0.7118, Training Accuracy= 0.505\n",
      "Epoch: 270, Loss= 0.7115, Training Accuracy= 0.505\n",
      "Epoch: 280, Loss= 0.7111, Training Accuracy= 0.505\n",
      "Epoch: 290, Loss= 0.7094, Training Accuracy= 0.508\n",
      "Epoch: 300, Loss= 0.7115, Training Accuracy= 0.505\n",
      "Epoch: 310, Loss= 0.7058, Training Accuracy= 0.509\n",
      "Epoch: 320, Loss= 0.7108, Training Accuracy= 0.507\n",
      "Epoch: 330, Loss= 0.7555, Training Accuracy= 0.505\n",
      "Epoch: 340, Loss= 0.6961, Training Accuracy= 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, Loss= 0.7557, Training Accuracy= 0.490\n",
      "Epoch: 360, Loss= 0.7464, Training Accuracy= 0.490\n",
      "Epoch: 370, Loss= 0.7375, Training Accuracy= 0.488\n",
      "Epoch: 380, Loss= 0.7567, Training Accuracy= 0.490\n",
      "Epoch: 390, Loss= 0.7520, Training Accuracy= 0.490\n",
      "Epoch: 400, Loss= 0.7635, Training Accuracy= 0.493\n",
      "Epoch: 410, Loss= 0.7495, Training Accuracy= 0.492\n",
      "Epoch: 420, Loss= 0.7518, Training Accuracy= 0.491\n",
      "Epoch: 430, Loss= 0.7648, Training Accuracy= 0.496\n",
      "Epoch: 440, Loss= 0.7610, Training Accuracy= 0.498\n",
      "Epoch: 450, Loss= 0.7674, Training Accuracy= 0.496\n",
      "Epoch: 460, Loss= 0.7705, Training Accuracy= 0.490\n",
      "Epoch: 470, Loss= 0.7665, Training Accuracy= 0.490\n",
      "Epoch: 480, Loss= 0.7594, Training Accuracy= 0.490\n",
      "Epoch: 490, Loss= 0.7555, Training Accuracy= 0.490\n",
      "Epoch: 500, Loss= 0.7487, Training Accuracy= 0.490\n",
      "Epoch: 510, Loss= 0.7448, Training Accuracy= 0.490\n",
      "Epoch: 520, Loss= 0.7437, Training Accuracy= 0.490\n",
      "Epoch: 530, Loss= 0.7415, Training Accuracy= 0.490\n",
      "Epoch: 540, Loss= 0.7340, Training Accuracy= 0.495\n",
      "Epoch: 550, Loss= 0.7262, Training Accuracy= 0.516\n",
      "Epoch: 560, Loss= 0.7538, Training Accuracy= 0.490\n",
      "Epoch: 570, Loss= 0.6850, Training Accuracy= 0.539\n",
      "Epoch: 580, Loss= 0.7229, Training Accuracy= 0.520\n",
      "Epoch: 590, Loss= 0.7712, Training Accuracy= 0.490\n",
      "Epoch: 600, Loss= 0.7711, Training Accuracy= 0.490\n",
      "Epoch: 610, Loss= 0.7698, Training Accuracy= 0.490\n",
      "Epoch: 620, Loss= 0.7656, Training Accuracy= 0.490\n",
      "Epoch: 630, Loss= 0.7591, Training Accuracy= 0.490\n",
      "Epoch: 640, Loss= 0.7527, Training Accuracy= 0.490\n",
      "Epoch: 650, Loss= 0.7512, Training Accuracy= 0.490\n",
      "Epoch: 660, Loss= 0.7503, Training Accuracy= 0.491\n",
      "Epoch: 670, Loss= 0.7488, Training Accuracy= 0.492\n",
      "Epoch: 680, Loss= 0.7485, Training Accuracy= 0.492\n",
      "Epoch: 690, Loss= 0.7486, Training Accuracy= 0.492\n",
      "Epoch: 700, Loss= 0.7489, Training Accuracy= 0.492\n",
      "Epoch: 710, Loss= 0.7491, Training Accuracy= 0.492\n",
      "Epoch: 720, Loss= 0.7494, Training Accuracy= 0.492\n",
      "Epoch: 730, Loss= 0.7496, Training Accuracy= 0.493\n",
      "Epoch: 740, Loss= 0.7497, Training Accuracy= 0.493\n",
      "Epoch: 750, Loss= 0.7498, Training Accuracy= 0.493\n",
      "Epoch: 760, Loss= 0.7496, Training Accuracy= 0.493\n",
      "Epoch: 770, Loss= 0.7493, Training Accuracy= 0.493\n",
      "Epoch: 780, Loss= 0.7488, Training Accuracy= 0.493\n",
      "Epoch: 790, Loss= 0.7482, Training Accuracy= 0.493\n",
      "Epoch: 800, Loss= 0.7476, Training Accuracy= 0.493\n",
      "Epoch: 810, Loss= 0.7464, Training Accuracy= 0.493\n",
      "Epoch: 820, Loss= 0.7452, Training Accuracy= 0.493\n",
      "Epoch: 830, Loss= 0.7441, Training Accuracy= 0.493\n",
      "Epoch: 840, Loss= 0.7433, Training Accuracy= 0.493\n",
      "Epoch: 850, Loss= 0.7433, Training Accuracy= 0.493\n",
      "Epoch: 860, Loss= 0.7423, Training Accuracy= 0.493\n",
      "Epoch: 870, Loss= 0.7403, Training Accuracy= 0.495\n",
      "Epoch: 880, Loss= 0.7719, Training Accuracy= 0.490\n",
      "Epoch: 890, Loss= 0.7715, Training Accuracy= 0.490\n",
      "Epoch: 900, Loss= 0.7708, Training Accuracy= 0.490\n",
      "Epoch: 910, Loss= 0.7704, Training Accuracy= 0.490\n",
      "Epoch: 920, Loss= 0.7702, Training Accuracy= 0.490\n",
      "Epoch: 930, Loss= 0.7698, Training Accuracy= 0.490\n",
      "Epoch: 940, Loss= 0.7702, Training Accuracy= 0.490\n",
      "Epoch: 950, Loss= 0.7695, Training Accuracy= 0.490\n",
      "Epoch: 960, Loss= 0.7694, Training Accuracy= 0.490\n",
      "Epoch: 970, Loss= 0.7692, Training Accuracy= 0.490\n",
      "Epoch: 980, Loss= 0.7690, Training Accuracy= 0.490\n",
      "Epoch: 990, Loss= 0.7688, Training Accuracy= 0.490\n",
      "Epoch: 1000, Loss= 0.7690, Training Accuracy= 0.490\n",
      "Epoch: 1010, Loss= 0.7594, Training Accuracy= 0.490\n",
      "Epoch: 1020, Loss= 0.7574, Training Accuracy= 0.490\n",
      "Epoch: 1030, Loss= 0.7568, Training Accuracy= 0.490\n",
      "Epoch: 1040, Loss= 0.7565, Training Accuracy= 0.490\n",
      "Epoch: 1050, Loss= 0.7562, Training Accuracy= 0.490\n",
      "Epoch: 1060, Loss= 0.7559, Training Accuracy= 0.490\n",
      "Epoch: 1070, Loss= 0.7552, Training Accuracy= 0.490\n",
      "Epoch: 1080, Loss= 0.7551, Training Accuracy= 0.490\n",
      "Epoch: 1090, Loss= 0.7516, Training Accuracy= 0.490\n",
      "Epoch: 1100, Loss= 0.7496, Training Accuracy= 0.490\n",
      "Epoch: 1110, Loss= 0.7499, Training Accuracy= 0.490\n",
      "Epoch: 1120, Loss= 0.7495, Training Accuracy= 0.490\n",
      "Epoch: 1130, Loss= 0.7502, Training Accuracy= 0.490\n",
      "Epoch: 1140, Loss= 0.7502, Training Accuracy= 0.490\n",
      "Epoch: 1150, Loss= 0.7501, Training Accuracy= 0.490\n",
      "Epoch: 1160, Loss= 0.7501, Training Accuracy= 0.490\n",
      "Epoch: 1170, Loss= 0.7501, Training Accuracy= 0.490\n",
      "Epoch: 1180, Loss= 0.7434, Training Accuracy= 0.490\n",
      "Epoch: 1190, Loss= 0.7440, Training Accuracy= 0.490\n",
      "Epoch: 1200, Loss= 0.7448, Training Accuracy= 0.490\n",
      "Epoch: 1210, Loss= 0.7448, Training Accuracy= 0.490\n",
      "Epoch: 1220, Loss= 0.7447, Training Accuracy= 0.490\n",
      "Epoch: 1230, Loss= 0.7472, Training Accuracy= 0.490\n",
      "Epoch: 1240, Loss= 0.7514, Training Accuracy= 0.490\n",
      "Epoch: 1250, Loss= 0.7513, Training Accuracy= 0.490\n",
      "Epoch: 1260, Loss= 0.7514, Training Accuracy= 0.490\n",
      "Epoch: 1270, Loss= 0.7486, Training Accuracy= 0.490\n",
      "Epoch: 1280, Loss= 0.7512, Training Accuracy= 0.490\n",
      "Epoch: 1290, Loss= 0.7512, Training Accuracy= 0.490\n",
      "Epoch: 1300, Loss= 0.7662, Training Accuracy= 0.490\n",
      "Epoch: 1310, Loss= 0.7498, Training Accuracy= 0.490\n",
      "Epoch: 1320, Loss= 0.7494, Training Accuracy= 0.490\n",
      "Epoch: 1330, Loss= 0.7451, Training Accuracy= 0.490\n",
      "Epoch: 1340, Loss= 0.7444, Training Accuracy= 0.490\n",
      "Epoch: 1350, Loss= 0.7637, Training Accuracy= 0.490\n",
      "Epoch: 1360, Loss= 0.7647, Training Accuracy= 0.490\n",
      "Epoch: 1370, Loss= 0.7648, Training Accuracy= 0.490\n",
      "Epoch: 1380, Loss= 0.7408, Training Accuracy= 0.490\n",
      "Epoch: 1390, Loss= 0.7537, Training Accuracy= 0.490\n",
      "Epoch: 1400, Loss= 0.7398, Training Accuracy= 0.490\n",
      "Epoch: 1410, Loss= 0.7388, Training Accuracy= 0.490\n",
      "Epoch: 1420, Loss= 0.7444, Training Accuracy= 0.490\n",
      "Epoch: 1430, Loss= 0.7507, Training Accuracy= 0.490\n",
      "Epoch: 1440, Loss= 0.7454, Training Accuracy= 0.492\n",
      "Epoch: 1450, Loss= 0.7518, Training Accuracy= 0.490\n",
      "Epoch: 1460, Loss= 0.7241, Training Accuracy= 0.494\n",
      "Epoch: 1470, Loss= 0.7184, Training Accuracy= 0.490\n",
      "Epoch: 1480, Loss= 0.7159, Training Accuracy= 0.491\n",
      "Epoch: 1490, Loss= 0.7163, Training Accuracy= 0.491\n",
      "Epoch: 1500, Loss= 0.7160, Training Accuracy= 0.490\n",
      "Epoch: 1510, Loss= 0.7162, Training Accuracy= 0.492\n",
      "Epoch: 1520, Loss= 0.7152, Training Accuracy= 0.490\n",
      "Epoch: 1530, Loss= 0.7154, Training Accuracy= 0.490\n",
      "Epoch: 1540, Loss= 0.7149, Training Accuracy= 0.490\n",
      "Epoch: 1550, Loss= 0.7185, Training Accuracy= 0.491\n",
      "Epoch: 1560, Loss= 0.7190, Training Accuracy= 0.490\n",
      "Epoch: 1570, Loss= 0.7199, Training Accuracy= 0.490\n",
      "Epoch: 1580, Loss= 0.7134, Training Accuracy= 0.490\n",
      "Epoch: 1590, Loss= 0.7157, Training Accuracy= 0.490\n",
      "Epoch: 1600, Loss= 0.7158, Training Accuracy= 0.490\n",
      "Epoch: 1610, Loss= 0.7162, Training Accuracy= 0.490\n",
      "Epoch: 1620, Loss= 0.7167, Training Accuracy= 0.490\n",
      "Epoch: 1630, Loss= 0.7205, Training Accuracy= 0.490\n",
      "Epoch: 1640, Loss= 0.7202, Training Accuracy= 0.490\n",
      "Epoch: 1650, Loss= 0.7192, Training Accuracy= 0.490\n",
      "Epoch: 1660, Loss= 0.7187, Training Accuracy= 0.490\n",
      "Epoch: 1670, Loss= 0.7189, Training Accuracy= 0.490\n",
      "Epoch: 1680, Loss= 0.7188, Training Accuracy= 0.490\n",
      "Epoch: 1690, Loss= 0.7240, Training Accuracy= 0.490\n",
      "Epoch: 1700, Loss= 0.7228, Training Accuracy= 0.490\n",
      "Epoch: 1710, Loss= 0.7222, Training Accuracy= 0.490\n",
      "Epoch: 1720, Loss= 0.7219, Training Accuracy= 0.490\n",
      "Epoch: 1730, Loss= 0.7215, Training Accuracy= 0.490\n",
      "Epoch: 1740, Loss= 0.7217, Training Accuracy= 0.490\n",
      "Epoch: 1750, Loss= 0.7217, Training Accuracy= 0.490\n",
      "Epoch: 1760, Loss= 0.7218, Training Accuracy= 0.490\n",
      "Epoch: 1770, Loss= 0.7218, Training Accuracy= 0.490\n",
      "Epoch: 1780, Loss= 0.7219, Training Accuracy= 0.490\n",
      "Epoch: 1790, Loss= 0.7220, Training Accuracy= 0.490\n",
      "Epoch: 1800, Loss= 0.7222, Training Accuracy= 0.490\n",
      "Epoch: 1810, Loss= 0.7224, Training Accuracy= 0.490\n",
      "Epoch: 1820, Loss= 0.7225, Training Accuracy= 0.490\n",
      "Epoch: 1830, Loss= 0.7226, Training Accuracy= 0.490\n",
      "Epoch: 1840, Loss= 0.7227, Training Accuracy= 0.490\n",
      "Epoch: 1850, Loss= 0.7228, Training Accuracy= 0.490\n",
      "Epoch: 1860, Loss= 0.7229, Training Accuracy= 0.490\n",
      "Epoch: 1870, Loss= 0.7230, Training Accuracy= 0.490\n",
      "Epoch: 1880, Loss= 0.7230, Training Accuracy= 0.490\n",
      "Epoch: 1890, Loss= 0.7230, Training Accuracy= 0.490\n",
      "Epoch: 1900, Loss= 0.7231, Training Accuracy= 0.490\n",
      "Epoch: 1910, Loss= 0.7234, Training Accuracy= 0.490\n",
      "Epoch: 1920, Loss= 0.7236, Training Accuracy= 0.490\n",
      "Epoch: 1930, Loss= 0.7245, Training Accuracy= 0.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1940, Loss= 0.7249, Training Accuracy= 0.490\n",
      "Epoch: 1950, Loss= 0.7241, Training Accuracy= 0.490\n",
      "Epoch: 1960, Loss= 0.7235, Training Accuracy= 0.490\n",
      "Epoch: 1970, Loss= 0.7123, Training Accuracy= 0.490\n",
      "Epoch: 1980, Loss= 0.7153, Training Accuracy= 0.490\n",
      "Epoch: 1990, Loss= 0.7183, Training Accuracy= 0.490\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.513\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.7385, Training Accuracy= 0.500\n",
      "Epoch: 10, Loss= 0.7071, Training Accuracy= 0.503\n",
      "Epoch: 20, Loss= 0.7042, Training Accuracy= 0.508\n",
      "Epoch: 30, Loss= 0.7022, Training Accuracy= 0.503\n",
      "Epoch: 40, Loss= 0.7007, Training Accuracy= 0.507\n",
      "Epoch: 50, Loss= 0.6994, Training Accuracy= 0.508\n",
      "Epoch: 60, Loss= 0.6981, Training Accuracy= 0.507\n",
      "Epoch: 70, Loss= 0.6971, Training Accuracy= 0.508\n",
      "Epoch: 80, Loss= 0.6962, Training Accuracy= 0.507\n",
      "Epoch: 90, Loss= 0.6956, Training Accuracy= 0.506\n",
      "Epoch: 100, Loss= 0.6951, Training Accuracy= 0.511\n",
      "Epoch: 110, Loss= 0.6947, Training Accuracy= 0.508\n",
      "Epoch: 120, Loss= 0.6944, Training Accuracy= 0.505\n",
      "Epoch: 130, Loss= 0.6942, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.6939, Training Accuracy= 0.504\n",
      "Epoch: 150, Loss= 0.6938, Training Accuracy= 0.507\n",
      "Epoch: 160, Loss= 0.6938, Training Accuracy= 0.505\n",
      "Epoch: 170, Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 180, Loss= 0.6940, Training Accuracy= 0.511\n",
      "Epoch: 190, Loss= 0.6942, Training Accuracy= 0.509\n",
      "Epoch: 200, Loss= 0.6943, Training Accuracy= 0.497\n",
      "Epoch: 210, Loss= 0.6945, Training Accuracy= 0.500\n",
      "Epoch: 220, Loss= 0.6945, Training Accuracy= 0.504\n",
      "Epoch: 230, Loss= 0.6945, Training Accuracy= 0.510\n",
      "Epoch: 240, Loss= 0.6944, Training Accuracy= 0.511\n",
      "Epoch: 250, Loss= 0.6923, Training Accuracy= 0.521\n",
      "Epoch: 260, Loss= 0.7615, Training Accuracy= 0.523\n",
      "Epoch: 270, Loss= 1.2731, Training Accuracy= 0.495\n",
      "Epoch: 280, Loss= 0.0066, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1530, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 0.7724, Training Accuracy= 0.506\n",
      "Epoch: 10, Loss= 0.7564, Training Accuracy= 0.506\n",
      "Epoch: 20, Loss= 0.7539, Training Accuracy= 0.506\n",
      "Epoch: 30, Loss= 0.7532, Training Accuracy= 0.506\n",
      "Epoch: 40, Loss= 0.7527, Training Accuracy= 0.506\n",
      "Epoch: 50, Loss= 0.7524, Training Accuracy= 0.506\n",
      "Epoch: 60, Loss= 0.7523, Training Accuracy= 0.506\n",
      "Epoch: 70, Loss= 0.7522, Training Accuracy= 0.506\n",
      "Epoch: 80, Loss= 0.7519, Training Accuracy= 0.506\n",
      "Epoch: 90, Loss= 0.7508, Training Accuracy= 0.506\n",
      "Epoch: 100, Loss= 0.7480, Training Accuracy= 0.506\n",
      "Epoch: 110, Loss= 0.7441, Training Accuracy= 0.506\n",
      "Epoch: 120, Loss= 0.7409, Training Accuracy= 0.506\n",
      "Epoch: 130, Loss= 0.7386, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.7362, Training Accuracy= 0.506\n",
      "Epoch: 150, Loss= 0.7336, Training Accuracy= 0.506\n",
      "Epoch: 160, Loss= 0.7321, Training Accuracy= 0.506\n",
      "Epoch: 170, Loss= 0.7317, Training Accuracy= 0.506\n",
      "Epoch: 180, Loss= 0.7313, Training Accuracy= 0.506\n",
      "Epoch: 190, Loss= 0.7310, Training Accuracy= 0.506\n",
      "Epoch: 200, Loss= 0.7308, Training Accuracy= 0.506\n",
      "Epoch: 210, Loss= 0.7308, Training Accuracy= 0.506\n",
      "Epoch: 220, Loss= 0.7308, Training Accuracy= 0.506\n",
      "Epoch: 230, Loss= 0.7006, Training Accuracy= 0.540\n",
      "Epoch: 240, Loss= 0.7811, Training Accuracy= 0.506\n",
      "Epoch: 250, Loss= 0.7631, Training Accuracy= 0.507\n",
      "Epoch: 260, Loss= 0.7612, Training Accuracy= 0.507\n",
      "Epoch: 270, Loss= 0.7608, Training Accuracy= 0.507\n",
      "Epoch: 280, Loss= 0.7605, Training Accuracy= 0.509\n",
      "Epoch: 290, Loss= 0.7592, Training Accuracy= 0.509\n",
      "Epoch: 300, Loss= 0.7559, Training Accuracy= 0.510\n",
      "Epoch: 310, Loss= 0.7563, Training Accuracy= 0.510\n",
      "Epoch: 320, Loss= 0.7572, Training Accuracy= 0.510\n",
      "Epoch: 330, Loss= 0.7558, Training Accuracy= 0.511\n",
      "Epoch: 340, Loss= 0.7523, Training Accuracy= 0.517\n",
      "Epoch: 350, Loss= 0.7425, Training Accuracy= 0.524\n",
      "Epoch: 360, Loss= 0.8028, Training Accuracy= 0.506\n",
      "Epoch: 370, Loss= 0.7984, Training Accuracy= 0.506\n",
      "Epoch: 380, Loss= 0.7929, Training Accuracy= 0.506\n",
      "Epoch: 390, Loss= 0.7850, Training Accuracy= 0.506\n",
      "Epoch: 400, Loss= 0.7780, Training Accuracy= 0.506\n",
      "Epoch: 410, Loss= 0.7747, Training Accuracy= 0.506\n",
      "Epoch: 420, Loss= 0.7728, Training Accuracy= 0.506\n",
      "Epoch: 430, Loss= 0.7714, Training Accuracy= 0.506\n",
      "Epoch: 440, Loss= 0.7702, Training Accuracy= 0.506\n",
      "Epoch: 450, Loss= 0.7691, Training Accuracy= 0.506\n",
      "Epoch: 460, Loss= 0.7680, Training Accuracy= 0.506\n",
      "Epoch: 470, Loss= 0.7669, Training Accuracy= 0.506\n",
      "Epoch: 480, Loss= 0.7660, Training Accuracy= 0.506\n",
      "Epoch: 490, Loss= 0.7654, Training Accuracy= 0.506\n",
      "Epoch: 500, Loss= 0.7650, Training Accuracy= 0.506\n",
      "Epoch: 510, Loss= 0.7646, Training Accuracy= 0.506\n",
      "Epoch: 520, Loss= 0.7642, Training Accuracy= 0.506\n",
      "Epoch: 530, Loss= 0.7639, Training Accuracy= 0.506\n",
      "Epoch: 540, Loss= 0.7637, Training Accuracy= 0.506\n",
      "Epoch: 550, Loss= 0.7637, Training Accuracy= 0.506\n",
      "Epoch: 560, Loss= 0.7637, Training Accuracy= 0.506\n",
      "Epoch: 570, Loss= 0.7637, Training Accuracy= 0.506\n",
      "Epoch: 580, Loss= 0.7637, Training Accuracy= 0.506\n",
      "Epoch: 590, Loss= 0.7637, Training Accuracy= 0.506\n",
      "Epoch: 600, Loss= 0.7636, Training Accuracy= 0.506\n",
      "Epoch: 610, Loss= 0.7635, Training Accuracy= 0.506\n",
      "Epoch: 620, Loss= 0.7634, Training Accuracy= 0.506\n",
      "Epoch: 630, Loss= 0.7633, Training Accuracy= 0.506\n",
      "Epoch: 640, Loss= 0.7632, Training Accuracy= 0.506\n",
      "Epoch: 650, Loss= 0.7631, Training Accuracy= 0.506\n",
      "Epoch: 660, Loss= 0.7629, Training Accuracy= 0.506\n",
      "Epoch: 670, Loss= 0.7626, Training Accuracy= 0.506\n",
      "Epoch: 680, Loss= 0.7614, Training Accuracy= 0.506\n",
      "Epoch: 690, Loss= 0.7602, Training Accuracy= 0.506\n",
      "Epoch: 700, Loss= 0.7632, Training Accuracy= 0.507\n",
      "Epoch: 710, Loss= 0.7562, Training Accuracy= 0.508\n",
      "Epoch: 720, Loss= 0.7662, Training Accuracy= 0.506\n",
      "Epoch: 730, Loss= 0.7663, Training Accuracy= 0.506\n",
      "Epoch: 740, Loss= 0.7663, Training Accuracy= 0.506\n",
      "Epoch: 750, Loss= 0.7664, Training Accuracy= 0.506\n",
      "Epoch: 760, Loss= 0.7665, Training Accuracy= 0.506\n",
      "Epoch: 770, Loss= 0.7666, Training Accuracy= 0.506\n",
      "Epoch: 780, Loss= 0.7667, Training Accuracy= 0.506\n",
      "Epoch: 790, Loss= 0.7668, Training Accuracy= 0.506\n",
      "Epoch: 800, Loss= 0.7667, Training Accuracy= 0.506\n",
      "Epoch: 810, Loss= 0.7613, Training Accuracy= 0.503\n",
      "Epoch: 820, Loss= 0.7516, Training Accuracy= 0.522\n",
      "Epoch: 830, Loss= 0.7493, Training Accuracy= 0.522\n",
      "Epoch: 840, Loss= 0.7451, Training Accuracy= 0.528\n",
      "Epoch: 850, Loss= 0.6474, Training Accuracy= 0.631\n",
      "Epoch: 860, Loss= 0.0298, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0097, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0058, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0004, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1120, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.6961, Training Accuracy= 0.487\n",
      "Epoch: 10, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 20, Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 30, Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 40, Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 50, Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 60, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 70, Loss= 0.6924, Training Accuracy= 0.513\n",
      "Epoch: 80, Loss= 0.6923, Training Accuracy= 0.522\n",
      "Epoch: 90, Loss= 0.6922, Training Accuracy= 0.528\n",
      "Epoch: 100, Loss= 0.6921, Training Accuracy= 0.529\n",
      "Epoch: 110, Loss= 0.6920, Training Accuracy= 0.525\n",
      "Epoch: 120, Loss= 0.6918, Training Accuracy= 0.519\n",
      "Epoch: 130, Loss= 0.6917, Training Accuracy= 0.520\n",
      "Epoch: 140, Loss= 0.6917, Training Accuracy= 0.522\n",
      "Epoch: 150, Loss= 0.6916, Training Accuracy= 0.523\n",
      "Epoch: 160, Loss= 0.6914, Training Accuracy= 0.518\n",
      "Epoch: 170, Loss= 0.6913, Training Accuracy= 0.508\n",
      "Epoch: 180, Loss= 0.6911, Training Accuracy= 0.520\n",
      "Epoch: 190, Loss= 0.6909, Training Accuracy= 0.522\n",
      "Epoch: 200, Loss= 0.6905, Training Accuracy= 0.528\n",
      "Epoch: 210, Loss= 0.6905, Training Accuracy= 0.526\n",
      "Epoch: 220, Loss= 0.6928, Training Accuracy= 0.539\n",
      "Epoch: 230, Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 240, Loss= 0.6876, Training Accuracy= 0.509\n",
      "Epoch: 250, Loss= 0.6642, Training Accuracy= 0.539\n",
      "Epoch: 260, Loss= 0.6764, Training Accuracy= 0.518\n",
      "Epoch: 270, Loss= 0.6793, Training Accuracy= 0.512\n",
      "Epoch: 280, Loss= 0.6769, Training Accuracy= 0.527\n",
      "Epoch: 290, Loss= 0.6940, Training Accuracy= 0.501\n",
      "Epoch: 300, Loss= 0.6939, Training Accuracy= 0.497\n",
      "Epoch: 310, Loss= 0.6939, Training Accuracy= 0.497\n",
      "Epoch: 320, Loss= 0.6940, Training Accuracy= 0.497\n",
      "Epoch: 330, Loss= 0.6941, Training Accuracy= 0.496\n",
      "Epoch: 340, Loss= 0.6942, Training Accuracy= 0.494\n",
      "Epoch: 350, Loss= 0.6942, Training Accuracy= 0.493\n",
      "Epoch: 360, Loss= 0.6942, Training Accuracy= 0.496\n",
      "Epoch: 370, Loss= 0.6941, Training Accuracy= 0.495\n",
      "Epoch: 380, Loss= 0.6940, Training Accuracy= 0.496\n",
      "Epoch: 390, Loss= 0.6939, Training Accuracy= 0.501\n",
      "Epoch: 400, Loss= 0.6938, Training Accuracy= 0.497\n",
      "Epoch: 410, Loss= 0.6937, Training Accuracy= 0.498\n",
      "Epoch: 420, Loss= 0.6937, Training Accuracy= 0.498\n",
      "Epoch: 430, Loss= 0.6936, Training Accuracy= 0.498\n",
      "Epoch: 440, Loss= 0.6936, Training Accuracy= 0.498\n",
      "Epoch: 450, Loss= 0.6935, Training Accuracy= 0.494\n",
      "Epoch: 460, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 470, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 480, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 490, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 500, Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 510, Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 520, Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 530, Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 540, Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 550, Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 560, Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 570, Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 580, Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 590, Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 600, Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 610, Loss= 0.6937, Training Accuracy= 0.500\n",
      "Epoch: 620, Loss= 0.6937, Training Accuracy= 0.500\n",
      "Epoch: 630, Loss= 0.6938, Training Accuracy= 0.500\n",
      "Epoch: 640, Loss= 0.6938, Training Accuracy= 0.502\n",
      "Epoch: 650, Loss= 0.6938, Training Accuracy= 0.504\n",
      "Epoch: 660, Loss= 0.6936, Training Accuracy= 0.507\n",
      "Epoch: 670, Loss= 0.6936, Training Accuracy= 0.505\n",
      "Epoch: 680, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 690, Loss= 0.6938, Training Accuracy= 0.506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 700, Loss= 0.6939, Training Accuracy= 0.498\n",
      "Epoch: 710, Loss= 0.7037, Training Accuracy= 0.504\n",
      "Epoch: 720, Loss= 0.6843, Training Accuracy= 0.524\n",
      "Epoch: 730, Loss= 0.2910, Training Accuracy= 0.915\n",
      "Epoch: 740, Loss= 0.0394, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 0.7005, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 20, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 30, Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 40, Loss= 0.6923, Training Accuracy= 0.499\n",
      "Epoch: 50, Loss= 0.6921, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6919, Training Accuracy= 0.520\n",
      "Epoch: 70, Loss= 0.6918, Training Accuracy= 0.522\n",
      "Epoch: 80, Loss= 0.6916, Training Accuracy= 0.517\n",
      "Epoch: 90, Loss= 0.6915, Training Accuracy= 0.530\n",
      "Epoch: 100, Loss= 0.6914, Training Accuracy= 0.535\n",
      "Epoch: 110, Loss= 0.6912, Training Accuracy= 0.529\n",
      "Epoch: 120, Loss= 0.6911, Training Accuracy= 0.525\n",
      "Epoch: 130, Loss= 0.6910, Training Accuracy= 0.526\n",
      "Epoch: 140, Loss= 0.6908, Training Accuracy= 0.523\n",
      "Epoch: 150, Loss= 0.6907, Training Accuracy= 0.522\n",
      "Epoch: 160, Loss= 0.6904, Training Accuracy= 0.532\n",
      "Epoch: 170, Loss= 0.6897, Training Accuracy= 0.531\n",
      "Epoch: 180, Loss= 0.6851, Training Accuracy= 0.566\n",
      "Epoch: 190, Loss= 0.6759, Training Accuracy= 0.620\n",
      "Epoch: 200, Loss= 0.8902, Training Accuracy= 0.501\n",
      "Epoch: 210, Loss= 0.7315, Training Accuracy= 0.489\n",
      "Epoch: 220, Loss= 0.7310, Training Accuracy= 0.489\n",
      "Epoch: 230, Loss= 0.7279, Training Accuracy= 0.494\n",
      "Epoch: 240, Loss= 0.7328, Training Accuracy= 0.489\n",
      "Epoch: 250, Loss= 0.7316, Training Accuracy= 0.489\n",
      "Epoch: 260, Loss= 0.7283, Training Accuracy= 0.489\n",
      "Epoch: 270, Loss= 0.7298, Training Accuracy= 0.489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280, Loss= 0.7302, Training Accuracy= 0.489\n",
      "Epoch: 290, Loss= 0.7305, Training Accuracy= 0.488\n",
      "Epoch: 300, Loss= 0.7251, Training Accuracy= 0.489\n",
      "Epoch: 310, Loss= 0.6922, Training Accuracy= 0.510\n",
      "Epoch: 320, Loss= 0.6972, Training Accuracy= 0.489\n",
      "Epoch: 330, Loss= 0.6982, Training Accuracy= 0.501\n",
      "Epoch: 340, Loss= 0.6899, Training Accuracy= 0.512\n",
      "Epoch: 350, Loss= 0.6874, Training Accuracy= 0.510\n",
      "Epoch: 360, Loss= 0.7002, Training Accuracy= 0.504\n",
      "Epoch: 370, Loss= 0.7000, Training Accuracy= 0.509\n",
      "Epoch: 380, Loss= 0.7087, Training Accuracy= 0.511\n",
      "Epoch: 390, Loss= 0.6979, Training Accuracy= 0.493\n",
      "Epoch: 400, Loss= 0.6966, Training Accuracy= 0.502\n",
      "Epoch: 410, Loss= 0.6958, Training Accuracy= 0.489\n",
      "Epoch: 420, Loss= 0.6923, Training Accuracy= 0.500\n",
      "Epoch: 430, Loss= 0.6943, Training Accuracy= 0.502\n",
      "Epoch: 440, Loss= 0.6943, Training Accuracy= 0.501\n",
      "Epoch: 450, Loss= 0.6905, Training Accuracy= 0.504\n",
      "Epoch: 460, Loss= 0.6892, Training Accuracy= 0.510\n",
      "Epoch: 470, Loss= 0.6885, Training Accuracy= 0.505\n",
      "Epoch: 480, Loss= 0.6844, Training Accuracy= 0.515\n",
      "Epoch: 490, Loss= 0.6782, Training Accuracy= 0.526\n",
      "Epoch: 500, Loss= 0.6973, Training Accuracy= 0.493\n",
      "Epoch: 510, Loss= 0.6992, Training Accuracy= 0.489\n",
      "Epoch: 520, Loss= 0.6982, Training Accuracy= 0.489\n",
      "Epoch: 530, Loss= 0.6979, Training Accuracy= 0.489\n",
      "Epoch: 540, Loss= 0.6977, Training Accuracy= 0.489\n",
      "Epoch: 550, Loss= 0.6977, Training Accuracy= 0.489\n",
      "Epoch: 560, Loss= 0.6977, Training Accuracy= 0.489\n",
      "Epoch: 570, Loss= 0.6978, Training Accuracy= 0.489\n",
      "Epoch: 580, Loss= 0.6980, Training Accuracy= 0.489\n",
      "Epoch: 590, Loss= 0.6980, Training Accuracy= 0.489\n",
      "Epoch: 600, Loss= 0.6980, Training Accuracy= 0.489\n",
      "Epoch: 610, Loss= 0.6979, Training Accuracy= 0.493\n",
      "Epoch: 620, Loss= 0.6979, Training Accuracy= 0.493\n",
      "Epoch: 630, Loss= 0.6978, Training Accuracy= 0.493\n",
      "Epoch: 640, Loss= 0.6978, Training Accuracy= 0.493\n",
      "Epoch: 650, Loss= 0.6978, Training Accuracy= 0.493\n",
      "Epoch: 660, Loss= 0.6977, Training Accuracy= 0.493\n",
      "Epoch: 670, Loss= 0.6977, Training Accuracy= 0.493\n",
      "Epoch: 680, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 690, Loss= 0.6975, Training Accuracy= 0.498\n",
      "Epoch: 700, Loss= 0.6974, Training Accuracy= 0.498\n",
      "Epoch: 710, Loss= 0.6974, Training Accuracy= 0.498\n",
      "Epoch: 720, Loss= 0.6974, Training Accuracy= 0.498\n",
      "Epoch: 730, Loss= 0.6974, Training Accuracy= 0.498\n",
      "Epoch: 740, Loss= 0.6975, Training Accuracy= 0.498\n",
      "Epoch: 750, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 760, Loss= 0.6975, Training Accuracy= 0.496\n",
      "Epoch: 770, Loss= 0.6975, Training Accuracy= 0.494\n",
      "Epoch: 780, Loss= 0.6972, Training Accuracy= 0.495\n",
      "Epoch: 790, Loss= 0.6981, Training Accuracy= 0.498\n",
      "Epoch: 800, Loss= 0.6980, Training Accuracy= 0.492\n",
      "Epoch: 810, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 820, Loss= 0.7003, Training Accuracy= 0.489\n",
      "Epoch: 830, Loss= 0.7006, Training Accuracy= 0.489\n",
      "Epoch: 840, Loss= 0.7005, Training Accuracy= 0.489\n",
      "Epoch: 850, Loss= 0.7005, Training Accuracy= 0.489\n",
      "Epoch: 860, Loss= 0.7003, Training Accuracy= 0.489\n",
      "Epoch: 870, Loss= 0.6996, Training Accuracy= 0.494\n",
      "Epoch: 880, Loss= 0.6992, Training Accuracy= 0.493\n",
      "Epoch: 890, Loss= 0.6994, Training Accuracy= 0.494\n",
      "Epoch: 900, Loss= 0.6995, Training Accuracy= 0.496\n",
      "Epoch: 910, Loss= 0.6976, Training Accuracy= 0.494\n",
      "Epoch: 920, Loss= 0.6936, Training Accuracy= 0.498\n",
      "Epoch: 930, Loss= 0.6921, Training Accuracy= 0.498\n",
      "Epoch: 940, Loss= 0.6896, Training Accuracy= 0.501\n",
      "Epoch: 950, Loss= 0.6865, Training Accuracy= 0.508\n",
      "Epoch: 960, Loss= 0.6960, Training Accuracy= 0.513\n",
      "Epoch: 970, Loss= 0.6934, Training Accuracy= 0.515\n",
      "Epoch: 980, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 990, Loss= 0.6972, Training Accuracy= 0.506\n",
      "Epoch: 1000, Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 1010, Loss= 0.6920, Training Accuracy= 0.510\n",
      "Epoch: 1020, Loss= 0.6923, Training Accuracy= 0.506\n",
      "Epoch: 1030, Loss= 0.6894, Training Accuracy= 0.523\n",
      "Epoch: 1040, Loss= 0.6969, Training Accuracy= 0.491\n",
      "Epoch: 1050, Loss= 0.6895, Training Accuracy= 0.504\n",
      "Epoch: 1060, Loss= 0.6821, Training Accuracy= 0.520\n",
      "Epoch: 1070, Loss= 0.7180, Training Accuracy= 0.494\n",
      "Epoch: 1080, Loss= 0.7654, Training Accuracy= 0.502\n",
      "Epoch: 1090, Loss= 0.7642, Training Accuracy= 0.502\n",
      "Epoch: 1100, Loss= 0.7632, Training Accuracy= 0.502\n",
      "Epoch: 1110, Loss= 0.7588, Training Accuracy= 0.504\n",
      "Epoch: 1120, Loss= 0.7545, Training Accuracy= 0.508\n",
      "Epoch: 1130, Loss= 0.7515, Training Accuracy= 0.509\n",
      "Epoch: 1140, Loss= 0.6986, Training Accuracy= 0.493\n",
      "Epoch: 1150, Loss= 0.7112, Training Accuracy= 0.489\n",
      "Epoch: 1160, Loss= 0.7122, Training Accuracy= 0.489\n",
      "Epoch: 1170, Loss= 0.7110, Training Accuracy= 0.489\n",
      "Epoch: 1180, Loss= 0.7035, Training Accuracy= 0.489\n",
      "Epoch: 1190, Loss= 0.7029, Training Accuracy= 0.489\n",
      "Epoch: 1200, Loss= 0.7028, Training Accuracy= 0.489\n",
      "Epoch: 1210, Loss= 0.7038, Training Accuracy= 0.489\n",
      "Epoch: 1220, Loss= 0.7043, Training Accuracy= 0.489\n",
      "Epoch: 1230, Loss= 0.7041, Training Accuracy= 0.489\n",
      "Epoch: 1240, Loss= 0.7040, Training Accuracy= 0.490\n",
      "Epoch: 1250, Loss= 0.7045, Training Accuracy= 0.489\n",
      "Epoch: 1260, Loss= 0.7114, Training Accuracy= 0.489\n",
      "Epoch: 1270, Loss= 0.7206, Training Accuracy= 0.491\n",
      "Epoch: 1280, Loss= 0.7248, Training Accuracy= 0.493\n",
      "Epoch: 1290, Loss= 0.7169, Training Accuracy= 0.492\n",
      "Epoch: 1300, Loss= 0.7258, Training Accuracy= 0.493\n",
      "Epoch: 1310, Loss= 0.7233, Training Accuracy= 0.492\n",
      "Epoch: 1320, Loss= 0.7184, Training Accuracy= 0.495\n",
      "Epoch: 1330, Loss= 0.7277, Training Accuracy= 0.492\n",
      "Epoch: 1340, Loss= 0.7190, Training Accuracy= 0.484\n",
      "Epoch: 1350, Loss= 0.7062, Training Accuracy= 0.499\n",
      "Epoch: 1360, Loss= 0.7065, Training Accuracy= 0.499\n",
      "Epoch: 1370, Loss= 0.7102, Training Accuracy= 0.495\n",
      "Epoch: 1380, Loss= 0.7037, Training Accuracy= 0.494\n",
      "Epoch: 1390, Loss= 0.7035, Training Accuracy= 0.497\n",
      "Epoch: 1400, Loss= 0.6977, Training Accuracy= 0.500\n",
      "Epoch: 1410, Loss= 0.6974, Training Accuracy= 0.500\n",
      "Epoch: 1420, Loss= 0.7084, Training Accuracy= 0.492\n",
      "Epoch: 1430, Loss= 0.7001, Training Accuracy= 0.487\n",
      "Epoch: 1440, Loss= 0.6955, Training Accuracy= 0.497\n",
      "Epoch: 1450, Loss= 0.7085, Training Accuracy= 0.492\n",
      "Epoch: 1460, Loss= 0.7029, Training Accuracy= 0.492\n",
      "Epoch: 1470, Loss= 0.7027, Training Accuracy= 0.492\n",
      "Epoch: 1480, Loss= 0.7026, Training Accuracy= 0.492\n",
      "Epoch: 1490, Loss= 0.7024, Training Accuracy= 0.492\n",
      "Epoch: 1500, Loss= 0.7022, Training Accuracy= 0.492\n",
      "Epoch: 1510, Loss= 0.7017, Training Accuracy= 0.492\n",
      "Epoch: 1520, Loss= 0.7011, Training Accuracy= 0.492\n",
      "Epoch: 1530, Loss= 0.7009, Training Accuracy= 0.492\n",
      "Epoch: 1540, Loss= 0.7009, Training Accuracy= 0.492\n",
      "Epoch: 1550, Loss= 0.7006, Training Accuracy= 0.491\n",
      "Epoch: 1560, Loss= 0.7004, Training Accuracy= 0.494\n",
      "Epoch: 1570, Loss= 0.7002, Training Accuracy= 0.495\n",
      "Epoch: 1580, Loss= 0.7003, Training Accuracy= 0.492\n",
      "Epoch: 1590, Loss= 0.7000, Training Accuracy= 0.497\n",
      "Epoch: 1600, Loss= 0.7012, Training Accuracy= 0.492\n",
      "Epoch: 1610, Loss= 0.7002, Training Accuracy= 0.495\n",
      "Epoch: 1620, Loss= 0.6999, Training Accuracy= 0.497\n",
      "Epoch: 1630, Loss= 0.6998, Training Accuracy= 0.497\n",
      "Epoch: 1640, Loss= 0.6996, Training Accuracy= 0.497\n",
      "Epoch: 1650, Loss= 0.6996, Training Accuracy= 0.498\n",
      "Epoch: 1660, Loss= 0.6974, Training Accuracy= 0.498\n",
      "Epoch: 1670, Loss= 0.7003, Training Accuracy= 0.497\n",
      "Epoch: 1680, Loss= 0.6995, Training Accuracy= 0.498\n",
      "Epoch: 1690, Loss= 0.6994, Training Accuracy= 0.494\n",
      "Epoch: 1700, Loss= 0.6996, Training Accuracy= 0.497\n",
      "Epoch: 1710, Loss= 0.6997, Training Accuracy= 0.497\n",
      "Epoch: 1720, Loss= 0.6995, Training Accuracy= 0.498\n",
      "Epoch: 1730, Loss= 0.6993, Training Accuracy= 0.496\n",
      "Epoch: 1740, Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 1750, Loss= 0.6989, Training Accuracy= 0.498\n",
      "Epoch: 1760, Loss= 0.6987, Training Accuracy= 0.495\n",
      "Epoch: 1770, Loss= 0.6984, Training Accuracy= 0.497\n",
      "Epoch: 1780, Loss= 0.6987, Training Accuracy= 0.497\n",
      "Epoch: 1790, Loss= 0.6983, Training Accuracy= 0.497\n",
      "Epoch: 1800, Loss= 0.7004, Training Accuracy= 0.489\n",
      "Epoch: 1810, Loss= 0.7005, Training Accuracy= 0.490\n",
      "Epoch: 1820, Loss= 0.7018, Training Accuracy= 0.489\n",
      "Epoch: 1830, Loss= 0.7005, Training Accuracy= 0.489\n",
      "Epoch: 1840, Loss= 0.7084, Training Accuracy= 0.489\n",
      "Epoch: 1850, Loss= 0.7057, Training Accuracy= 0.489\n",
      "Epoch: 1860, Loss= 0.7044, Training Accuracy= 0.489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1870, Loss= 0.6933, Training Accuracy= 0.523\n",
      "Epoch: 1880, Loss= 0.6947, Training Accuracy= 0.496\n",
      "Epoch: 1890, Loss= 0.6936, Training Accuracy= 0.506\n",
      "Epoch: 1900, Loss= 0.6962, Training Accuracy= 0.501\n",
      "Epoch: 1910, Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 1920, Loss= 0.6920, Training Accuracy= 0.521\n",
      "Epoch: 1930, Loss= 0.6954, Training Accuracy= 0.495\n",
      "Epoch: 1940, Loss= 0.6959, Training Accuracy= 0.494\n",
      "Epoch: 1950, Loss= 0.6955, Training Accuracy= 0.497\n",
      "Epoch: 1960, Loss= 0.6957, Training Accuracy= 0.496\n",
      "Epoch: 1970, Loss= 0.6966, Training Accuracy= 0.496\n",
      "Epoch: 1980, Loss= 0.6965, Training Accuracy= 0.496\n",
      "Epoch: 1990, Loss= 0.6963, Training Accuracy= 0.496\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5018\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 0.6959, Training Accuracy= 0.501\n",
      "Epoch: 10, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 20, Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.6933, Training Accuracy= 0.495\n",
      "Epoch: 40, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 50, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 60, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 70, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 80, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 90, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 100, Loss= 0.6930, Training Accuracy= 0.514\n",
      "Epoch: 110, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 120, Loss= 0.6927, Training Accuracy= 0.526\n",
      "Epoch: 130, Loss= 0.6925, Training Accuracy= 0.523\n",
      "Epoch: 140, Loss= 0.6923, Training Accuracy= 0.524\n",
      "Epoch: 150, Loss= 0.6921, Training Accuracy= 0.525\n",
      "Epoch: 160, Loss= 0.6919, Training Accuracy= 0.524\n",
      "Epoch: 170, Loss= 0.6918, Training Accuracy= 0.529\n",
      "Epoch: 180, Loss= 0.6916, Training Accuracy= 0.530\n",
      "Epoch: 190, Loss= 0.6914, Training Accuracy= 0.532\n",
      "Epoch: 200, Loss= 0.6912, Training Accuracy= 0.528\n",
      "Epoch: 210, Loss= 0.6911, Training Accuracy= 0.528\n",
      "Epoch: 220, Loss= 0.6912, Training Accuracy= 0.537\n",
      "Epoch: 230, Loss= 0.6915, Training Accuracy= 0.536\n",
      "Epoch: 240, Loss= 0.6921, Training Accuracy= 0.538\n",
      "Epoch: 250, Loss= 0.6931, Training Accuracy= 0.528\n",
      "Epoch: 260, Loss= 0.6906, Training Accuracy= 0.553\n",
      "Epoch: 270, Loss= 0.6886, Training Accuracy= 0.558\n",
      "Epoch: 280, Loss= 0.7185, Training Accuracy= 0.484\n",
      "Epoch: 290, Loss= 0.7650, Training Accuracy= 0.529\n",
      "Epoch: 300, Loss= 0.0096, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.0042, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1460, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.7892, Training Accuracy= 0.505\n",
      "Epoch: 10, Loss= 0.7599, Training Accuracy= 0.505\n",
      "Epoch: 20, Loss= 0.7532, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.7491, Training Accuracy= 0.505\n",
      "Epoch: 40, Loss= 0.7457, Training Accuracy= 0.505\n",
      "Epoch: 50, Loss= 0.7428, Training Accuracy= 0.505\n",
      "Epoch: 60, Loss= 0.7401, Training Accuracy= 0.505\n",
      "Epoch: 70, Loss= 0.7375, Training Accuracy= 0.505\n",
      "Epoch: 80, Loss= 0.7353, Training Accuracy= 0.505\n",
      "Epoch: 90, Loss= 0.7340, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.7329, Training Accuracy= 0.505\n",
      "Epoch: 110, Loss= 0.7319, Training Accuracy= 0.505\n",
      "Epoch: 120, Loss= 0.7313, Training Accuracy= 0.505\n",
      "Epoch: 130, Loss= 0.7310, Training Accuracy= 0.505\n",
      "Epoch: 140, Loss= 0.7307, Training Accuracy= 0.505\n",
      "Epoch: 150, Loss= 0.7302, Training Accuracy= 0.505\n",
      "Epoch: 160, Loss= 0.7289, Training Accuracy= 0.505\n",
      "Epoch: 170, Loss= 0.7273, Training Accuracy= 0.505\n",
      "Epoch: 180, Loss= 0.7299, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.7733, Training Accuracy= 0.505\n",
      "Epoch: 200, Loss= 0.7720, Training Accuracy= 0.505\n",
      "Epoch: 210, Loss= 0.7750, Training Accuracy= 0.505\n",
      "Epoch: 220, Loss= 0.7739, Training Accuracy= 0.506\n",
      "Epoch: 230, Loss= 0.7536, Training Accuracy= 0.507\n",
      "Epoch: 240, Loss= 0.0214, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1050, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.275\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 2000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a RNN cell with tensorflow\n",
    "    rnn_cell = rnn.BasicRNNCell(num_hidden)\n",
    "\n",
    "    # Get RNN cell output\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 0.49520001, 0.50349998, 0.51300001, 1.0, 1.0, 1.0, 0.5018, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  0.80135\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.00243328869343\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ce29447d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
