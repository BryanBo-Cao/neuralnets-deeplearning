{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 10\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.7237, Training Accuracy= 0.496\n",
      "Epoch: 10, Loss= 0.7196, Training Accuracy= 0.496\n",
      "Epoch: 20, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 30, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 40, Loss= 0.7196, Training Accuracy= 0.496\n",
      "Epoch: 50, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 60, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 70, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 80, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 90, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 100, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 110, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 120, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 130, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 140, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 150, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 160, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 170, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 180, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 190, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 200, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 210, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 220, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 230, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 240, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 250, Loss= 0.7202, Training Accuracy= 0.496\n",
      "Epoch: 260, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 270, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 280, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 290, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 300, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 310, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 320, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 330, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 340, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 350, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 360, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 370, Loss= 0.7202, Training Accuracy= 0.496\n",
      "Epoch: 380, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 390, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 400, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 410, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 420, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 430, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 440, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 450, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 460, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 470, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 480, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 490, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 500, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 510, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 520, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 530, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 540, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 550, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 560, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 570, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 580, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 590, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 600, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 610, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 620, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 630, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 640, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 650, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 660, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 670, Loss= 0.7201, Training Accuracy= 0.496\n",
      "Epoch: 680, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 690, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 700, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 710, Loss= 0.7198, Training Accuracy= 0.496\n",
      "Epoch: 720, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 730, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 740, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 750, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 760, Loss= 0.7198, Training Accuracy= 0.496\n",
      "Epoch: 770, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 780, Loss= 0.7197, Training Accuracy= 0.496\n",
      "Epoch: 790, Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 800, Loss= 0.7198, Training Accuracy= 0.496\n",
      "Epoch: 810, Loss= 0.7198, Training Accuracy= 0.496\n",
      "Epoch: 820, Loss= 0.7200, Training Accuracy= 0.496\n",
      "Epoch: 830, Loss= 0.7197, Training Accuracy= 0.496\n",
      "Epoch: 840, Loss= 0.7196, Training Accuracy= 0.496\n",
      "Epoch: 850, Loss= 0.7198, Training Accuracy= 0.496\n",
      "Epoch: 860, Loss= 0.7196, Training Accuracy= 0.496\n",
      "Epoch: 870, Loss= 0.7197, Training Accuracy= 0.496\n",
      "Epoch: 880, Loss= 0.7198, Training Accuracy= 0.496\n",
      "Epoch: 890, Loss= 0.7196, Training Accuracy= 0.496\n",
      "Epoch: 900, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 910, Loss= 0.7197, Training Accuracy= 0.496\n",
      "Epoch: 920, Loss= 0.7197, Training Accuracy= 0.496\n",
      "Epoch: 930, Loss= 0.7196, Training Accuracy= 0.496\n",
      "Epoch: 940, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 950, Loss= 0.7197, Training Accuracy= 0.496\n",
      "Epoch: 960, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 970, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 980, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 990, Loss= 0.7197, Training Accuracy= 0.496\n",
      "Epoch: 1000, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1010, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1020, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1030, Loss= 0.7196, Training Accuracy= 0.496\n",
      "Epoch: 1040, Loss= 0.7196, Training Accuracy= 0.496\n",
      "Epoch: 1050, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1060, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1070, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1080, Loss= 0.7196, Training Accuracy= 0.496\n",
      "Epoch: 1090, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1100, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1110, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1120, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1130, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1140, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1150, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1160, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1170, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1180, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1190, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1200, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1210, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1220, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1230, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1240, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1250, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1260, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1270, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1280, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1290, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1300, Loss= 0.7196, Training Accuracy= 0.496\n",
      "Epoch: 1310, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1320, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1330, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1340, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1350, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1360, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1370, Loss= 0.7192, Training Accuracy= 0.496\n",
      "Epoch: 1380, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1390, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1400, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1410, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1420, Loss= 0.7192, Training Accuracy= 0.496\n",
      "Epoch: 1430, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1440, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1450, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1460, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1470, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1480, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1490, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1500, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1510, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1520, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1530, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1540, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1550, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1560, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1570, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1580, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1590, Loss= 0.7194, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1610, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1620, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1630, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1640, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1650, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1660, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1670, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1680, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1690, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1700, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1710, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1720, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1730, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1740, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1750, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1760, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1770, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1780, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1790, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1800, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1810, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1820, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1830, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1840, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1850, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1860, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1870, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1880, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1890, Loss= 0.7192, Training Accuracy= 0.496\n",
      "Epoch: 1900, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1910, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1920, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1930, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1940, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1950, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1960, Loss= 0.7195, Training Accuracy= 0.496\n",
      "Epoch: 1970, Loss= 0.7194, Training Accuracy= 0.496\n",
      "Epoch: 1980, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Epoch: 1990, Loss= 0.7193, Training Accuracy= 0.496\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4983\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.7333, Training Accuracy= 0.501\n",
      "Epoch: 10, Loss= 0.7035, Training Accuracy= 0.515\n",
      "Epoch: 20, Loss= 0.7137, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.7091, Training Accuracy= 0.506\n",
      "Epoch: 40, Loss= 0.7044, Training Accuracy= 0.507\n",
      "Epoch: 50, Loss= 0.7435, Training Accuracy= 0.517\n",
      "Epoch: 60, Loss= 0.9838, Training Accuracy= 0.499\n",
      "Epoch: 70, Loss= 1.0873, Training Accuracy= 0.502\n",
      "Epoch: 80, Loss= 1.0870, Training Accuracy= 0.502\n",
      "Epoch: 90, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 100, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 120, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 130, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 150, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 160, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 170, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 180, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 190, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 200, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 230, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 240, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 250, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 260, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 270, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 280, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 290, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 300, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 310, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 320, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 330, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 340, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 350, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 360, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 370, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 380, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 390, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 400, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 410, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 420, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 430, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 440, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 450, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 460, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 470, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 480, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 490, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 500, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 510, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 520, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 530, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 540, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 550, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 560, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 570, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 580, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 590, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 600, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 610, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 620, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 630, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 640, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 650, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 660, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 670, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 680, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 690, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 700, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 710, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 720, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 730, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 740, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 750, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 760, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 770, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 780, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 790, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 800, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 810, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 820, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 830, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 840, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 850, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 860, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 870, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 880, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 890, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 900, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 910, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 920, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 930, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 940, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 950, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 960, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 970, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 980, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 990, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1000, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1010, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1020, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1030, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1040, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1050, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1060, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1070, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1080, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1090, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1100, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1110, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1120, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1130, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1140, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1150, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1160, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1170, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1180, Loss= 1.2483, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1190, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1200, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1210, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1220, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1230, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1240, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1250, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1260, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1270, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1280, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1290, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1300, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1310, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1320, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1330, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1340, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1350, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1360, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1370, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1380, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1390, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1400, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1410, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1420, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1430, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1440, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1450, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1460, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1470, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1480, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1490, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1500, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1510, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1520, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1530, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1540, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1550, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1560, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1570, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1580, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1590, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1600, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1610, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1620, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1630, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1640, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1650, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1660, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1670, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1680, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1690, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1700, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1710, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1720, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1730, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1740, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1750, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1760, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1770, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1780, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1790, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1800, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1810, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1820, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1830, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1840, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1850, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1860, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1870, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1880, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1890, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1900, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1910, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1920, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1930, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1940, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1950, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1960, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1970, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1980, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Epoch: 1990, Loss= 1.2483, Training Accuracy= 0.502\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5074\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.7081, Training Accuracy= 0.495\n",
      "Epoch: 10, Loss= 0.6932, Training Accuracy= 0.489\n",
      "Epoch: 20, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 30, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 40, Loss= 0.6931, Training Accuracy= 0.494\n",
      "Epoch: 50, Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 60, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 80, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 90, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 100, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 110, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 120, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 130, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 140, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 150, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 160, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 170, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 180, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 190, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 200, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 210, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 220, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 230, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 240, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 250, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 260, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 270, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 280, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 290, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 300, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 310, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 320, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 330, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 340, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 350, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 360, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 370, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 380, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 390, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 400, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 410, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 420, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 430, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 440, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 450, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 460, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 470, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 480, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 490, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 500, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 510, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 520, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 530, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 540, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 550, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 560, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 570, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 580, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 590, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 600, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 610, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 620, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 630, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 640, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 650, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 660, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 670, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 680, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 690, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 700, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 710, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 720, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 730, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 740, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 750, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 760, Loss= 0.6932, Training Accuracy= 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 770, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 780, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 790, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 800, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 810, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 820, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 830, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 840, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 850, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 860, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 870, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 880, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 890, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 900, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 910, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 920, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 930, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 940, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 950, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 960, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 970, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 980, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 990, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1000, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1010, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1020, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1030, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1040, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1050, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1060, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1070, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1080, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1090, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1100, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1110, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1120, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1130, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1140, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1150, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1160, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1170, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1180, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1190, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1200, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1210, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1220, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1230, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1240, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1250, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1260, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1270, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1280, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1290, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1300, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1310, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1320, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1330, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1340, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1350, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1360, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1370, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1380, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1390, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1400, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1410, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1420, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1430, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1440, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1450, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1460, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1470, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1480, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1490, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1500, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1510, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1520, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1530, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1540, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1550, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1560, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1570, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1580, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1590, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1600, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1610, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1620, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1630, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1640, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1650, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1660, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1670, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1680, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1690, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1700, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1710, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1720, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1730, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1740, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1750, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1760, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1770, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1780, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1790, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1800, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1810, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1820, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1830, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1840, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1850, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1860, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1870, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1880, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1890, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1900, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1910, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1920, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1930, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1940, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1950, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1960, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1970, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1980, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1990, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4957\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 1.4883, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 2.1041, Training Accuracy= 0.503\n",
      "Epoch: 20, Loss= 2.1041, Training Accuracy= 0.503\n",
      "Epoch: 30, Loss= 2.1043, Training Accuracy= 0.503\n",
      "Epoch: 40, Loss= 2.1044, Training Accuracy= 0.503\n",
      "Epoch: 50, Loss= 2.1044, Training Accuracy= 0.503\n",
      "Epoch: 60, Loss= 2.1043, Training Accuracy= 0.503\n",
      "Epoch: 70, Loss= 2.1036, Training Accuracy= 0.503\n",
      "Epoch: 80, Loss= 0.7916, Training Accuracy= 0.509\n",
      "Epoch: 90, Loss= 0.8133, Training Accuracy= 0.498\n",
      "Epoch: 100, Loss= 2.8013, Training Accuracy= 0.503\n",
      "Epoch: 110, Loss= 2.7882, Training Accuracy= 0.503\n",
      "Epoch: 120, Loss= 2.7859, Training Accuracy= 0.503\n",
      "Epoch: 130, Loss= 2.7849, Training Accuracy= 0.503\n",
      "Epoch: 140, Loss= 2.7845, Training Accuracy= 0.503\n",
      "Epoch: 150, Loss= 2.7841, Training Accuracy= 0.503\n",
      "Epoch: 160, Loss= 2.7839, Training Accuracy= 0.503\n",
      "Epoch: 170, Loss= 2.7837, Training Accuracy= 0.503\n",
      "Epoch: 180, Loss= 2.7835, Training Accuracy= 0.503\n",
      "Epoch: 190, Loss= 0.7808, Training Accuracy= 0.503\n",
      "Epoch: 200, Loss= 3.6946, Training Accuracy= 0.503\n",
      "Epoch: 210, Loss= 3.6946, Training Accuracy= 0.503\n",
      "Epoch: 220, Loss= 3.6946, Training Accuracy= 0.503\n",
      "Epoch: 230, Loss= 3.6946, Training Accuracy= 0.503\n",
      "Epoch: 240, Loss= 3.6946, Training Accuracy= 0.503\n",
      "Epoch: 250, Loss= 3.6946, Training Accuracy= 0.503\n",
      "Epoch: 260, Loss= 3.6946, Training Accuracy= 0.503\n",
      "Epoch: 270, Loss= 3.6945, Training Accuracy= 0.503\n",
      "Epoch: 280, Loss= 3.6944, Training Accuracy= 0.503\n",
      "Epoch: 290, Loss= 2.8724, Training Accuracy= 0.503\n",
      "Epoch: 300, Loss= 2.9277, Training Accuracy= 0.503\n",
      "Epoch: 310, Loss= 2.9226, Training Accuracy= 0.503\n",
      "Epoch: 320, Loss= 2.9204, Training Accuracy= 0.503\n",
      "Epoch: 330, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 340, Loss= 2.9356, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 360, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 370, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 380, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 390, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 400, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 410, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 420, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 430, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 440, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 450, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 460, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 470, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 480, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 490, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 500, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 510, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 520, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 530, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 540, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 550, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 560, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 570, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 580, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 590, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 600, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 610, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 620, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 630, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 640, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 650, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 660, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 670, Loss= 2.9356, Training Accuracy= 0.503\n",
      "Epoch: 680, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 690, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 700, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 710, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 720, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 730, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 740, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 750, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 760, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 770, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 780, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 790, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 800, Loss= 3.0500, Training Accuracy= 0.503\n",
      "Epoch: 810, Loss= 3.0771, Training Accuracy= 0.503\n",
      "Epoch: 820, Loss= 2.9096, Training Accuracy= 0.503\n",
      "Epoch: 830, Loss= 2.9097, Training Accuracy= 0.503\n",
      "Epoch: 840, Loss= 3.6946, Training Accuracy= 0.503\n",
      "Epoch: 850, Loss= 3.6946, Training Accuracy= 0.503\n",
      "Epoch: 860, Loss= 3.6945, Training Accuracy= 0.503\n",
      "Epoch: 870, Loss= 3.6945, Training Accuracy= 0.503\n",
      "Epoch: 880, Loss= 3.6943, Training Accuracy= 0.503\n",
      "Epoch: 890, Loss= 2.9296, Training Accuracy= 0.503\n",
      "Epoch: 900, Loss= 2.9294, Training Accuracy= 0.503\n",
      "Epoch: 910, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 920, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 930, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 940, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 950, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 960, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 970, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 980, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 990, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1000, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1010, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1020, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1030, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1040, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1050, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1060, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1070, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1080, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1090, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1100, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1110, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1120, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1130, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1140, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1150, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1160, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1170, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1180, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1190, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1200, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1210, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1220, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1230, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1240, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1250, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1260, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1270, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1280, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1290, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1300, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1310, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1320, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1330, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1340, Loss= 2.9293, Training Accuracy= 0.503\n",
      "Epoch: 1350, Loss= 2.9292, Training Accuracy= 0.503\n",
      "Epoch: 1360, Loss= 2.9292, Training Accuracy= 0.503\n",
      "Epoch: 1370, Loss= 2.9114, Training Accuracy= 0.503\n",
      "Epoch: 1380, Loss= 2.0945, Training Accuracy= 0.503\n",
      "Epoch: 1390, Loss= 2.0953, Training Accuracy= 0.503\n",
      "Epoch: 1400, Loss= 2.0957, Training Accuracy= 0.503\n",
      "Epoch: 1410, Loss= 2.0959, Training Accuracy= 0.503\n",
      "Epoch: 1420, Loss= 2.0961, Training Accuracy= 0.503\n",
      "Epoch: 1430, Loss= 2.0962, Training Accuracy= 0.503\n",
      "Epoch: 1440, Loss= 2.0962, Training Accuracy= 0.503\n",
      "Epoch: 1450, Loss= 2.0963, Training Accuracy= 0.503\n",
      "Epoch: 1460, Loss= 2.0963, Training Accuracy= 0.503\n",
      "Epoch: 1470, Loss= 2.0963, Training Accuracy= 0.503\n",
      "Epoch: 1480, Loss= 2.0963, Training Accuracy= 0.503\n",
      "Epoch: 1490, Loss= 2.0963, Training Accuracy= 0.503\n",
      "Epoch: 1500, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1510, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1520, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1530, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1540, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1550, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1560, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1570, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1580, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1590, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1600, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1610, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1620, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1630, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1640, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1650, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1660, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1670, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1680, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1690, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1700, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1710, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1720, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1730, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1740, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1750, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1760, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1770, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1780, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1790, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1800, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1810, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1820, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1830, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1840, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1850, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1860, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1870, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1880, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1890, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1900, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1910, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1920, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1930, Loss= 2.0964, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1940, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1950, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1960, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1970, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1980, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Epoch: 1990, Loss= 2.0964, Training Accuracy= 0.503\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5002\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.6934, Training Accuracy= 0.493\n",
      "Epoch: 10, Loss= 1.6496, Training Accuracy= 0.501\n",
      "Epoch: 20, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 30, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 40, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 50, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 60, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 70, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 80, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 90, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 100, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 110, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 120, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 130, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 140, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 150, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 160, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 170, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 180, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 190, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 200, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 210, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 220, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 230, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 240, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 250, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 260, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 270, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 280, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 290, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 300, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 310, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 320, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 330, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 340, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 350, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 360, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 370, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 380, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 390, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 400, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 410, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 420, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 430, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 440, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 450, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 460, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 470, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 480, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 490, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 500, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 510, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 520, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 530, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 540, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 550, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 560, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 570, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 580, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 590, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 600, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 610, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 620, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 630, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 640, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 650, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 660, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 670, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 680, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 690, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 700, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 710, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 720, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 730, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 740, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 750, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 760, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 770, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 780, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 790, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 800, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 810, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 820, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 830, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 840, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 850, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 860, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 870, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 880, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 890, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 900, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 910, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 920, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 930, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 940, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 950, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 960, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 970, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 980, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 990, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1000, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1010, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1020, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1030, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1040, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1050, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1060, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1070, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1080, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1090, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1100, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1110, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1120, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1130, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1140, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1150, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1160, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1170, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1180, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1190, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1200, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1210, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1220, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1230, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1240, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1250, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1260, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1270, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1280, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1290, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1300, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1310, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1320, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1330, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1340, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1350, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1360, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1370, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1380, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1390, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1400, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1410, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1420, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1430, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1440, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1450, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1460, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1470, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1480, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1490, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1500, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1510, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1520, Loss= 1.4632, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1530, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1540, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1550, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1560, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1570, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1580, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1590, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1600, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1610, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1620, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1630, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1640, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1650, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1660, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1670, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1680, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1690, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1700, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1710, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1720, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1730, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1740, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1750, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1760, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1770, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1780, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1790, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1800, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1810, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1820, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1830, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1840, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1850, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1860, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1870, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1880, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1890, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1900, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1910, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1920, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1930, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1940, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1950, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1960, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1970, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1980, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Epoch: 1990, Loss= 1.4632, Training Accuracy= 0.501\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4867\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 0.8681, Training Accuracy= 0.500\n",
      "Epoch: 10, Loss= 0.9229, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 30, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 40, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 50, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 60, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 70, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 80, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 90, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 100, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 110, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 120, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 130, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 140, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 150, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 160, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 170, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 180, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 190, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 200, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 210, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 220, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 230, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 240, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 250, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 260, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 270, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 280, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 290, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 300, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 310, Loss= 0.7612, Training Accuracy= 0.498\n",
      "Epoch: 320, Loss= 0.7612, Training Accuracy= 0.498\n",
      "Epoch: 330, Loss= 0.7612, Training Accuracy= 0.498\n",
      "Epoch: 340, Loss= 0.7612, Training Accuracy= 0.498\n",
      "Epoch: 350, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 360, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 370, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 380, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 390, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 400, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 410, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 420, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 430, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 440, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 450, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 460, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 470, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 480, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 490, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 500, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 510, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 520, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 530, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 540, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 550, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 560, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 570, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 580, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 590, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 600, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 610, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 620, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 630, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 640, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 650, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 660, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 670, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 680, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 690, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 700, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 710, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 720, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 730, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 740, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 750, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 760, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 770, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 780, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 790, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 800, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 810, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 820, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 830, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 840, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 850, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 860, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 870, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 880, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 890, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 900, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 910, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 920, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 930, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 940, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 950, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 960, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 970, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 980, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 990, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1000, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1010, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1020, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1030, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1040, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1050, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1060, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1070, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1080, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1090, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1100, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1110, Loss= 0.7611, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1120, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1130, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1140, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1150, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1160, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1170, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1180, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1190, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1200, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1210, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1220, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1230, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1240, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1250, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1260, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1270, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1280, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1290, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1300, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1310, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1320, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1330, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1340, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1350, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1360, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1370, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1380, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1390, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1400, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1410, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1420, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1430, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1440, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1450, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1460, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1470, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1480, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1490, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1500, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1510, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1520, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1530, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1540, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1550, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1560, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1570, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1580, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1590, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1600, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1610, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1620, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1630, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1640, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1650, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1660, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1670, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1680, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1690, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1700, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1710, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1720, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1730, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1740, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1750, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1760, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1770, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1780, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1790, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1800, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1810, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1820, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1830, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1840, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1850, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1860, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1870, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1880, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1890, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1900, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1910, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1920, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1930, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1940, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1950, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1960, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1970, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1980, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Epoch: 1990, Loss= 0.7611, Training Accuracy= 0.498\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5002\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.7287, Training Accuracy= 0.505\n",
      "Epoch: 10, Loss= 0.9119, Training Accuracy= 0.504\n",
      "Epoch: 20, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 30, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 40, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 60, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 100, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 110, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 120, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 140, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 150, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 160, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 190, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 200, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 210, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 220, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 230, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 250, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 260, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 270, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 280, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 290, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 300, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 310, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 320, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 330, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 340, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 350, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 360, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 370, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 380, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 390, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 400, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 410, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 420, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 430, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 440, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 450, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 460, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 470, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 480, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 490, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 500, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 510, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 520, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 530, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 540, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 550, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 560, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 570, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 580, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 590, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 600, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 610, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 620, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 630, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 640, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 650, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 660, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 670, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 680, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 690, Loss= 1.1789, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 700, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 710, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 720, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 730, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 740, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 750, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 760, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 770, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 780, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 790, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 800, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 810, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 820, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 830, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 840, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 850, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 860, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 870, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 880, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 890, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 900, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 910, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 920, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 930, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 940, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 950, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 960, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 970, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 980, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 990, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1000, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1010, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1020, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1030, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1040, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1050, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1060, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1070, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1080, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1090, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1100, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1110, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1120, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1130, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1140, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1150, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1160, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1170, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1180, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1190, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1200, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1210, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1220, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1230, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1240, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1250, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1260, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1270, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1280, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1290, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1300, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1310, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1320, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1330, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1340, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1350, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1360, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1370, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1380, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1390, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1400, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1410, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1420, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1430, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1440, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1450, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1460, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1470, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1480, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1490, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1500, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1510, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1520, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1530, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1540, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1550, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1560, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1570, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1580, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1590, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1600, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1610, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1620, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1630, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1640, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1650, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1660, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1670, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1680, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1690, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1700, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1710, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1720, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1730, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1740, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1750, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1760, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1770, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1780, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1790, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1800, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1810, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1820, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1830, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1840, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1850, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1860, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1870, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1880, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1890, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1900, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1910, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1920, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1930, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1940, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1950, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1960, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1970, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1980, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Epoch: 1990, Loss= 1.1789, Training Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5039\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 3.0546, Training Accuracy= 0.500\n",
      "Epoch: 10, Loss= 2.4648, Training Accuracy= 0.500\n",
      "Epoch: 20, Loss= 2.4637, Training Accuracy= 0.500\n",
      "Epoch: 30, Loss= 2.4631, Training Accuracy= 0.500\n",
      "Epoch: 40, Loss= 2.4628, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 2.4625, Training Accuracy= 0.500\n",
      "Epoch: 60, Loss= 2.4623, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 2.4621, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 2.4619, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 2.4617, Training Accuracy= 0.500\n",
      "Epoch: 100, Loss= 2.4616, Training Accuracy= 0.500\n",
      "Epoch: 110, Loss= 2.4615, Training Accuracy= 0.500\n",
      "Epoch: 120, Loss= 2.4613, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 2.4612, Training Accuracy= 0.500\n",
      "Epoch: 140, Loss= 2.4611, Training Accuracy= 0.500\n",
      "Epoch: 150, Loss= 2.4610, Training Accuracy= 0.500\n",
      "Epoch: 160, Loss= 2.4609, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 2.4609, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 2.4608, Training Accuracy= 0.500\n",
      "Epoch: 190, Loss= 2.4607, Training Accuracy= 0.500\n",
      "Epoch: 200, Loss= 2.4606, Training Accuracy= 0.500\n",
      "Epoch: 210, Loss= 2.4606, Training Accuracy= 0.500\n",
      "Epoch: 220, Loss= 2.4606, Training Accuracy= 0.500\n",
      "Epoch: 230, Loss= 2.4605, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 2.4605, Training Accuracy= 0.500\n",
      "Epoch: 250, Loss= 2.4604, Training Accuracy= 0.500\n",
      "Epoch: 260, Loss= 2.4604, Training Accuracy= 0.500\n",
      "Epoch: 270, Loss= 2.4603, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280, Loss= 2.4603, Training Accuracy= 0.500\n",
      "Epoch: 290, Loss= 2.4603, Training Accuracy= 0.500\n",
      "Epoch: 300, Loss= 2.4602, Training Accuracy= 0.500\n",
      "Epoch: 310, Loss= 2.4602, Training Accuracy= 0.500\n",
      "Epoch: 320, Loss= 2.4602, Training Accuracy= 0.500\n",
      "Epoch: 330, Loss= 2.4602, Training Accuracy= 0.500\n",
      "Epoch: 340, Loss= 2.4601, Training Accuracy= 0.500\n",
      "Epoch: 350, Loss= 2.4601, Training Accuracy= 0.500\n",
      "Epoch: 360, Loss= 2.4601, Training Accuracy= 0.500\n",
      "Epoch: 370, Loss= 2.4601, Training Accuracy= 0.500\n",
      "Epoch: 380, Loss= 2.4601, Training Accuracy= 0.500\n",
      "Epoch: 390, Loss= 2.4600, Training Accuracy= 0.500\n",
      "Epoch: 400, Loss= 2.4600, Training Accuracy= 0.500\n",
      "Epoch: 410, Loss= 2.4600, Training Accuracy= 0.500\n",
      "Epoch: 420, Loss= 2.4600, Training Accuracy= 0.500\n",
      "Epoch: 430, Loss= 2.4600, Training Accuracy= 0.500\n",
      "Epoch: 440, Loss= 2.4599, Training Accuracy= 0.500\n",
      "Epoch: 450, Loss= 2.4599, Training Accuracy= 0.500\n",
      "Epoch: 460, Loss= 2.4599, Training Accuracy= 0.500\n",
      "Epoch: 470, Loss= 2.4599, Training Accuracy= 0.500\n",
      "Epoch: 480, Loss= 2.4599, Training Accuracy= 0.500\n",
      "Epoch: 490, Loss= 2.4599, Training Accuracy= 0.500\n",
      "Epoch: 500, Loss= 2.4599, Training Accuracy= 0.500\n",
      "Epoch: 510, Loss= 2.4599, Training Accuracy= 0.500\n",
      "Epoch: 520, Loss= 2.4598, Training Accuracy= 0.500\n",
      "Epoch: 530, Loss= 2.4598, Training Accuracy= 0.500\n",
      "Epoch: 540, Loss= 2.4598, Training Accuracy= 0.500\n",
      "Epoch: 550, Loss= 2.4598, Training Accuracy= 0.500\n",
      "Epoch: 560, Loss= 2.4598, Training Accuracy= 0.500\n",
      "Epoch: 570, Loss= 2.4598, Training Accuracy= 0.500\n",
      "Epoch: 580, Loss= 2.4598, Training Accuracy= 0.500\n",
      "Epoch: 590, Loss= 2.4598, Training Accuracy= 0.500\n",
      "Epoch: 600, Loss= 2.4598, Training Accuracy= 0.500\n",
      "Epoch: 610, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 620, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 630, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 640, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 650, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 660, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 670, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 680, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 690, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 700, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 710, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 720, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 730, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 740, Loss= 2.4597, Training Accuracy= 0.500\n",
      "Epoch: 750, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 760, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 770, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 780, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 790, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 800, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 810, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 820, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 830, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 840, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 850, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 860, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 870, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 880, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 890, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 900, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 910, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 920, Loss= 2.4596, Training Accuracy= 0.500\n",
      "Epoch: 930, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 940, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 950, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 960, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 970, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 980, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 990, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1000, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1010, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1020, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1030, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1040, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1050, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1060, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1070, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1080, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1090, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1100, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1110, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1120, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1130, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1140, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1150, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1160, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1170, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1180, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1190, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1200, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1210, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1220, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1230, Loss= 2.4595, Training Accuracy= 0.500\n",
      "Epoch: 1240, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1250, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1260, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1270, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1280, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1290, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1300, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1310, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1320, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1330, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1340, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1350, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1360, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1370, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1380, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1390, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1400, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1410, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1420, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1430, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1440, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1450, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1460, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1470, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1480, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1490, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1500, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1510, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1520, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1530, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1540, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1550, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1560, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1570, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1580, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1590, Loss= 2.4594, Training Accuracy= 0.500\n",
      "Epoch: 1600, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1610, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1620, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1630, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1640, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1650, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1660, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1670, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1680, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1690, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1700, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1710, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1720, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1730, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1740, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1750, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1760, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1770, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1780, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1790, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1800, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1810, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1820, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1830, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1840, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1850, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1860, Loss= 2.4593, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1870, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1880, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1890, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1900, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1910, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1920, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1930, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1940, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1950, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1960, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1970, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1980, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Epoch: 1990, Loss= 2.4593, Training Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4971\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 0.6935, Training Accuracy= 0.503\n",
      "Epoch: 10, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 30, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 40, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 50, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 60, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 70, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 80, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 90, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 100, Loss= 0.6931, Training Accuracy= 0.495\n",
      "Epoch: 110, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 120, Loss= 0.6931, Training Accuracy= 0.495\n",
      "Epoch: 130, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 150, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 160, Loss= 0.6931, Training Accuracy= 0.510\n",
      "Epoch: 170, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 180, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 200, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 210, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 220, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 230, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 240, Loss= 0.6931, Training Accuracy= 0.510\n",
      "Epoch: 250, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 260, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 270, Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 280, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 290, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 300, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 310, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 320, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 330, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 340, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 350, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 360, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 370, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 380, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 390, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 400, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 410, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 420, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 430, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 440, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 450, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 460, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 470, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 480, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 490, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 500, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 510, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 520, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 530, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 540, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 550, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 560, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 570, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 580, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 590, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 600, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 610, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 620, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 630, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 640, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 650, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 660, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 670, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 680, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 690, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 700, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 710, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 720, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 730, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 740, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 750, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 760, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 770, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 780, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 790, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 800, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 810, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 820, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 830, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 840, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 850, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 860, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 870, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 880, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 890, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 900, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 910, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 920, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 930, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 940, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 950, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 960, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 970, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 980, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 990, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1000, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1010, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1020, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1030, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1040, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1050, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1060, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1070, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1080, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1090, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1100, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1110, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1120, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1130, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1140, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1150, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1160, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1170, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1180, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1190, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1200, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1210, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1220, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1230, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1240, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1250, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1260, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1270, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1280, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1290, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1300, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1310, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1320, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1330, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1340, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1350, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1360, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1370, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1380, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1390, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1400, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1410, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1420, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1430, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1440, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1450, Loss= 0.6931, Training Accuracy= 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1460, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1470, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1480, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1490, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1500, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1510, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1520, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1530, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1540, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1550, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1560, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1570, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1580, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1590, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1600, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1610, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1620, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1630, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1640, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1650, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1660, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1670, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1680, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1690, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1700, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1710, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1720, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1730, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1740, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1750, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1760, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1770, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1780, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1790, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1800, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1810, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1820, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1830, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1840, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1850, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1860, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1870, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1880, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1890, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1900, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1910, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1920, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1930, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1940, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1950, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1960, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1970, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1980, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1990, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5014\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.8334, Training Accuracy= 0.500\n",
      "Epoch: 10, Loss= 0.7178, Training Accuracy= 0.500\n",
      "Epoch: 20, Loss= 0.7176, Training Accuracy= 0.500\n",
      "Epoch: 30, Loss= 0.7175, Training Accuracy= 0.500\n",
      "Epoch: 40, Loss= 0.7175, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 60, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 100, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 110, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 120, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 140, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 150, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 160, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 190, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 200, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 210, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 220, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 230, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 250, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 260, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 270, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 280, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 290, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 300, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 310, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 320, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 330, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 340, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 350, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 360, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 370, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 380, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 390, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 400, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 410, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 420, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 430, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 440, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 450, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 460, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 470, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 480, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 490, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 500, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 510, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 520, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 530, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 540, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 550, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 560, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 570, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 580, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 590, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 600, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 610, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 620, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 630, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 640, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 650, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 660, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 670, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 680, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 690, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 700, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 710, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 720, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 730, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 740, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 750, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 760, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 770, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 780, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 790, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 800, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 810, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 820, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 830, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 840, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 850, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 860, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 870, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 880, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 890, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 900, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 910, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 920, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 930, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 940, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 950, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 960, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 970, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 980, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 990, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1000, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1010, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1020, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1030, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1040, Loss= 0.7174, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1050, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1060, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1070, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1080, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1090, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1100, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1110, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1120, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1130, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1140, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1150, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1160, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1170, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1180, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1190, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1200, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1210, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1220, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1230, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1240, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1250, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1260, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1270, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1280, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1290, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1300, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1310, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1320, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1330, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1340, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1350, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1360, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1370, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1380, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1390, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1400, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1410, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1420, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1430, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1440, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1450, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1460, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1470, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1480, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1490, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1500, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1510, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1520, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1530, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1540, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1550, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1560, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1570, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1580, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1590, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1600, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1610, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1620, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1630, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1640, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1650, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1660, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1670, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1680, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1690, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1700, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1710, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1720, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1730, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1740, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1750, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1760, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1770, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1780, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1790, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1800, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1810, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1820, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1830, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1840, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1850, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1860, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1870, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1880, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1890, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1900, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1910, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1920, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1930, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1940, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1950, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1960, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1970, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1980, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Epoch: 1990, Loss= 0.7174, Training Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4982\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 1.75\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 2000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a RNN cell with tensorflow\n",
    "    rnn_cell = rnn.BasicRNNCell(num_hidden)\n",
    "\n",
    "    # Get RNN cell output\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [0.49829999, 0.50739998, 0.4957, 0.50019997, 0.4867, 0.50019997, 0.50389999, 0.4971, 0.50139999, 0.4982]\n",
      "mean of test_accuracies_10replications:  0.49891\n",
      "standard deviation of test_accuracies_10replications_std_mean:  5.19661838189e-05\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe61225d790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
