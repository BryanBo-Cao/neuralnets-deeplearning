{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 2\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 10, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 20, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 40, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 10, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 20, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 40, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 2: \n",
      "Epoch: 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 10, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 20, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 40, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 10, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 20, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 40, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 10, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 20, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 40, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 10, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 20, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 40, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 10, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 20, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 40, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 10, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 20, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 40, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 8: \n",
      "Epoch: 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 10, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 20, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 40, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 10, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 20, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 40, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.0035\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 500\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 1 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a RNN cell with tensorflow\n",
    "    rnn_cell = rnn.BasicRNNCell(num_hidden)\n",
    "\n",
    "    # Get RNN cell output\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = tf.contrib.layers.fully_connected(RNN(X, weights, biases), 1)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "minibatch_losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                minibatch_losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  1.0\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.0\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEoCAYAAACpaN3LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK4FPCjwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc440652790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minibatch_losses_1st_replication\n",
    "plt.plot(minibatch_losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, minibacth loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
