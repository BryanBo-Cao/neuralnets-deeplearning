{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 25\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Minibatch Loss= 2.4146, Training Accuracy= 0.494\n",
      "Epoch: 10, Minibatch Loss= 2.4108, Training Accuracy= 0.494\n",
      "Epoch: 20, Minibatch Loss= 2.4107, Training Accuracy= 0.494\n",
      "Epoch: 30, Minibatch Loss= 2.4106, Training Accuracy= 0.494\n",
      "Epoch: 40, Minibatch Loss= 2.4106, Training Accuracy= 0.494\n",
      "Epoch: 50, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 60, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 70, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 80, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 90, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 100, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 110, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 120, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 130, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 140, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 150, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 160, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 170, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 180, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 190, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 200, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 210, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 220, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 230, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 240, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 250, Minibatch Loss= 2.4105, Training Accuracy= 0.494\n",
      "Epoch: 260, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 270, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 280, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 290, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 300, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 310, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 320, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 330, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 340, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 350, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 360, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 370, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 380, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 390, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 400, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 410, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 420, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 430, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 440, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 450, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 460, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 470, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 480, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 490, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 500, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 510, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 520, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 530, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 540, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 550, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 560, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 570, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 580, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 590, Minibatch Loss= 2.4104, Training Accuracy= 0.494\n",
      "Epoch: 600, Minibatch Loss= 2.4103, Training Accuracy= 0.494\n",
      "Epoch: 610, Minibatch Loss= 2.4103, Training Accuracy= 0.494\n",
      "Epoch: 620, Minibatch Loss= 2.4103, Training Accuracy= 0.494\n",
      "Epoch: 630, Minibatch Loss= 2.4103, Training Accuracy= 0.494\n",
      "Epoch: 640, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 650, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 660, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 670, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 680, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 690, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 700, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 710, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 720, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 730, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 740, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 750, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 760, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 770, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 780, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 790, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 800, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 810, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 820, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 830, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 840, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 850, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 860, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 870, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 880, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 890, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 900, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 910, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 920, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 930, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 940, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 950, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 960, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 970, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 980, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 990, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1000, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1010, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1020, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1030, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1040, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1050, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1060, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1070, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1080, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1090, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1100, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1110, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1120, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1130, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1140, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1150, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1160, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1170, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1180, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1190, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1200, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1210, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1220, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1230, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1240, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1250, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1260, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1270, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1280, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1290, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1300, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1310, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1320, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1330, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1350, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1360, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1370, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1380, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1390, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1400, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1410, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1420, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1430, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1440, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1450, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1460, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1470, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1480, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1490, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1500, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1510, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1520, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1530, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1540, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1550, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1560, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1570, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1580, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1590, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1600, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1610, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1620, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1630, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1640, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1650, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1660, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1670, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1680, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1690, Minibatch Loss= 2.4102, Training Accuracy= 0.494\n",
      "Epoch: 1700, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1710, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1720, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1730, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1740, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1750, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1760, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1770, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1780, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1790, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1800, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1810, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1820, Minibatch Loss= 2.4101, Training Accuracy= 0.494\n",
      "Epoch: 1830, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1840, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1850, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1860, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1870, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1880, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1890, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1900, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1910, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1920, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1930, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1940, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1950, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 1960, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 1970, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 1980, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 1990, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2000, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2010, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2020, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2030, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2040, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2050, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2060, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2070, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2080, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2090, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2100, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2110, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2120, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2130, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2140, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2150, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2160, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2170, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2180, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2190, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2200, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2210, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2220, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2230, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2240, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2250, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2260, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2270, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2280, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2290, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2300, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2310, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2320, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2330, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2340, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2350, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2360, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2370, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2380, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2390, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2400, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2410, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2420, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2430, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2440, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2450, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2460, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2470, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2480, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2490, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2500, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2510, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2520, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2530, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2540, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2550, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2560, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2570, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2580, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2590, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2600, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2610, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2620, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2630, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2640, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2650, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2660, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2670, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2680, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2690, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2700, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2710, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2720, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2730, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2740, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2750, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2760, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2770, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2780, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2790, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2800, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2810, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2820, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2830, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2840, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2850, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2860, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2870, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2880, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2890, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2900, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2910, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2920, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2930, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2940, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2950, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2960, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2970, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2980, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 2990, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3000, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3010, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3020, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3030, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3040, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3050, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3060, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3070, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3080, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3090, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3100, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3110, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3120, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3130, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3140, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3150, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3160, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3170, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3180, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3190, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3200, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3210, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3220, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3230, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3240, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3250, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3260, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3270, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3280, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3290, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3300, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3310, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3320, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3330, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3340, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3350, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3360, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3370, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3380, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3390, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3400, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3410, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3420, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3430, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3440, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3450, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3460, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3470, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3480, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3490, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3500, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3510, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3520, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3530, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3540, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3550, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3560, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3570, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3580, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3590, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3600, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3610, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3620, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3630, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3640, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3650, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3660, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3670, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3680, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3690, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3700, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3710, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3720, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3730, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3740, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3750, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3760, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3770, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3780, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3790, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3800, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3810, Minibatch Loss= 2.4099, Training Accuracy= 0.494\n",
      "Epoch: 3820, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3830, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3840, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3850, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3860, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3870, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3880, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3890, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3900, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3910, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3920, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3930, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3940, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3950, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3960, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3970, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3980, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 3990, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4010, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4020, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4030, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4040, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4050, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4060, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4070, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4080, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4090, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4100, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4110, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4120, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4130, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4140, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4150, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4160, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4170, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4180, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4190, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4200, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4210, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4220, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4230, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4240, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4250, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4260, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4270, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4280, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4290, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4300, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4310, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4320, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4330, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4340, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4350, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4360, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4370, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4380, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4390, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4400, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4410, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4420, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4430, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4440, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4450, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4460, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4470, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4480, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4490, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4500, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4510, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4520, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4530, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4540, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4550, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4560, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4570, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4580, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4590, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4600, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4610, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4620, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4630, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4640, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4650, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4660, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4670, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4680, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4690, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4700, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4710, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4720, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4730, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4740, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4750, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4760, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4770, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4780, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4790, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4800, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4810, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4820, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4830, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4840, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4850, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4860, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4870, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4880, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4890, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4900, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4910, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4920, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4930, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4940, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4950, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4960, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4970, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4980, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Epoch: 4990, Minibatch Loss= 2.4100, Training Accuracy= 0.494\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5003\n",
      "Replication: 1: \n",
      "Epoch: 0, Minibatch Loss= 2.4418, Training Accuracy= 0.490\n",
      "Epoch: 10, Minibatch Loss= 2.4374, Training Accuracy= 0.490\n",
      "Epoch: 20, Minibatch Loss= 2.4372, Training Accuracy= 0.490\n",
      "Epoch: 30, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 40, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 50, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 60, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 70, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 80, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 90, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 100, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 110, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 120, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 130, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 140, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 150, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 160, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 170, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 180, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 190, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 200, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 210, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 220, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 230, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 240, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 250, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 260, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 270, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 280, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 290, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 300, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 310, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 330, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 340, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 350, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 360, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 370, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 380, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 390, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 400, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 410, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 420, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 430, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 440, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 450, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 460, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 470, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 480, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 490, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 500, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 510, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 520, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 530, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 540, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 550, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 560, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 570, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 580, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 590, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 600, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 610, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 620, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 630, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 640, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 650, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 660, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 670, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 680, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 690, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 700, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 710, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 720, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 730, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 740, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 750, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 760, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 770, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 780, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 790, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 800, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 810, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 820, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 830, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 840, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 850, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 860, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 870, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 880, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 890, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 900, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 910, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 920, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 930, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 940, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 950, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 960, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 970, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 980, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 990, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1000, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1010, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1020, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1030, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1040, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1050, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1060, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1070, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1080, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1090, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1100, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1110, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1120, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1130, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1140, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1150, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1160, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1170, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1180, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1190, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1200, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1210, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1220, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1230, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1240, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1250, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1260, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1270, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1280, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1290, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1300, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1310, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1320, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1330, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1340, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1350, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1360, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1370, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1380, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1390, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1400, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1410, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1420, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1430, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1440, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1450, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1460, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1470, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1480, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1490, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1500, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1510, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1520, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1530, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1540, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1550, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1560, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1570, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1580, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1590, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1600, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1610, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1620, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1630, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1640, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1650, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1660, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1670, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1680, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1690, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1700, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1710, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1720, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1730, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1740, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1750, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1760, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1770, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1780, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1790, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1800, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1810, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1820, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1830, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1840, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1850, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1860, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1870, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1880, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1890, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1900, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1910, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1920, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1930, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1940, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1950, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1960, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1970, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1980, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 1990, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2000, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2010, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2020, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2030, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2040, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2050, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2060, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2070, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2080, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2090, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2100, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2110, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2120, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2130, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2140, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2150, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2160, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2170, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2180, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2190, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2200, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2210, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2220, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2230, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2240, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2250, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2260, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2270, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2280, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2290, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2300, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2310, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2320, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2330, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2340, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2350, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2360, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2370, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2380, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2390, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2400, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2410, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2420, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2430, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2440, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2450, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2460, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2470, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2480, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2490, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2500, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2510, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2520, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2530, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2540, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2550, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2560, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2570, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2580, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2590, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2600, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2610, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2620, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2630, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2640, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2650, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2660, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2670, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2680, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2690, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2700, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2710, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2720, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2730, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2740, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2750, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2760, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2770, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2780, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2790, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2800, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2810, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2820, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2830, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2840, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2850, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2860, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2870, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2880, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2890, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2900, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2910, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2920, Minibatch Loss= 2.4370, Training Accuracy= 0.490\n",
      "Epoch: 2930, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 2940, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 2950, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 2960, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 2970, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 2980, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2990, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3000, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3010, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3020, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3030, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3040, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3050, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3060, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3070, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3080, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3090, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3100, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3110, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3120, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3130, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3140, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3150, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3160, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3170, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3180, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3190, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3200, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3210, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3220, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3230, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3240, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3250, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3260, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3270, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3280, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3290, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3300, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3310, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3320, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3330, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3340, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3350, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3360, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3370, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3380, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3390, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3400, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3410, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3420, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3430, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3440, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3450, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3460, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3470, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3480, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3490, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3500, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3510, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3520, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3530, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3540, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3550, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3560, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3570, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3580, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3590, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3600, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3610, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3620, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3630, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3640, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3650, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3660, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3670, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3680, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3690, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3700, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3710, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3720, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3730, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3740, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3750, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3760, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3770, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3780, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3790, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3800, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3810, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3820, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3830, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3840, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3850, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3860, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3870, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3880, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3890, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3900, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3910, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3920, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3930, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3940, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3950, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3960, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3970, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3980, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 3990, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4000, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4010, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4020, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4030, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4040, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4050, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4060, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4070, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4080, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4090, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4100, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4110, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4120, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4130, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4140, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4150, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4160, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4170, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4180, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4190, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4200, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4210, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4220, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4230, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4240, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4250, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4260, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4270, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4280, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4290, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4300, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4310, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4320, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4330, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4340, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4350, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4360, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4370, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4380, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4390, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4400, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4410, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4420, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4430, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4440, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4450, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4460, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4470, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4480, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4490, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4500, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4510, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4520, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4530, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4540, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4550, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4560, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4570, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4580, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4590, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4600, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4610, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4620, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4630, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4640, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4650, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4660, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4670, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4680, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4690, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4700, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4710, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4720, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4730, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4740, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4750, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4760, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4770, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4780, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4790, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4800, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4810, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4820, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4830, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4840, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4850, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4860, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4870, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4880, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4890, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4900, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4910, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4920, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4930, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4940, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4950, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4960, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4970, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4980, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Epoch: 4990, Minibatch Loss= 2.4371, Training Accuracy= 0.490\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4978\n",
      "Replication: 2: \n",
      "Epoch: 0, Minibatch Loss= 1.2000, Training Accuracy= 0.503\n",
      "Epoch: 10, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 20, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 30, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 40, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 50, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 60, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 70, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 80, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 90, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 100, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 110, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 120, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 130, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 140, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 150, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 160, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 170, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 180, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 190, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 200, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 210, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 220, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 230, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 240, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 250, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 260, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 270, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 280, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 290, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 300, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 310, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 320, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 330, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 340, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 350, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 360, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 370, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 380, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 390, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 400, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 410, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 420, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 430, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 440, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 450, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 460, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 470, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 480, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 490, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 500, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 510, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 520, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 530, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 540, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 550, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 560, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 570, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 580, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 590, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 600, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 610, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 620, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 630, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 640, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 650, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 660, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 670, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 680, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 690, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 700, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 710, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 720, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 730, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 740, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 750, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 760, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 770, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 780, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 790, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 800, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 810, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 820, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 830, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 840, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 850, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 860, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 870, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 880, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 890, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 900, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 910, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 920, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 930, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 940, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 950, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 960, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 970, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 980, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 990, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1000, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1010, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1020, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1030, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1040, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1050, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1060, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1070, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1080, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1090, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1100, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1110, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1120, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1130, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1140, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1150, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1160, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1170, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1180, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1190, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1200, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1210, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1220, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1230, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1240, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1250, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1260, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1270, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1280, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1290, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1300, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1310, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1320, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1330, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1340, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1350, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1360, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1370, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1380, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1390, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1400, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1410, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1420, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1430, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1440, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1450, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1460, Minibatch Loss= 1.1980, Training Accuracy= 0.503\n",
      "Epoch: 1470, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1480, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1490, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1500, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1510, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1520, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1530, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1540, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1550, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1560, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1570, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1580, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1590, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1600, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1610, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1620, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1630, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1640, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1650, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1660, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1670, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1680, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1690, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1700, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1710, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1720, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1730, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1740, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1750, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1760, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1770, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1780, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1790, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1800, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1810, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1820, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1830, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1840, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1850, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1860, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1870, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1880, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1890, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1900, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1910, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1920, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1930, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1940, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1950, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1960, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1970, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1980, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 1990, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2000, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2010, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2020, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2030, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2040, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2050, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2060, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2070, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2080, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2090, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2100, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2110, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2120, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2130, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2140, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2150, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2160, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2170, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2180, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2190, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2200, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2210, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2220, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2230, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2240, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2250, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2260, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2270, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2280, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2290, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2300, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2310, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2320, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2330, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2340, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2350, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2360, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2370, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2380, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2390, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2400, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2410, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2420, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2430, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2440, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2450, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2460, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2470, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2480, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2490, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2500, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2510, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2520, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2530, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2540, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2550, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2560, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2570, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2580, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2590, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2600, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2610, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2620, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2630, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2640, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2650, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2660, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2670, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2680, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2690, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2700, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2710, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2720, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2730, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2740, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2750, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2760, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2770, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2780, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2790, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2800, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2810, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2820, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2830, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2840, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2850, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2860, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2870, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2880, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2890, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2900, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2910, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2920, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2930, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2940, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2950, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2960, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2970, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2980, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 2990, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3000, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3010, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3020, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3030, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3040, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3050, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3060, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3070, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3080, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3090, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3100, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3110, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3120, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3130, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3140, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3150, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3160, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3170, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3180, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3190, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3200, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3210, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3220, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3230, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3240, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3250, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3260, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3270, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3280, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3290, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3300, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3310, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3320, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3330, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3340, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3350, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3360, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3370, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3380, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3390, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3400, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3410, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3420, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3430, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3440, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3450, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3460, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3470, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3480, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3490, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3500, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3510, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3520, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3530, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3540, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3550, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3560, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3570, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3580, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3590, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3600, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3610, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3620, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3630, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3640, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3650, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3660, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3670, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3680, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3690, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3700, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3710, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3720, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3730, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3740, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3750, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3760, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3770, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3780, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3790, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3800, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3810, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3820, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3830, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3840, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3850, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3860, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3870, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3880, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3890, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3900, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3910, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3920, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3930, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3940, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3950, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3960, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3970, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3980, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 3990, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4000, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4010, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4020, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4030, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4040, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4050, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4060, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4070, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4080, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4090, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4100, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4110, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4120, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4130, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4140, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4150, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4160, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4170, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4180, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4190, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4200, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4210, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4220, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4230, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4240, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4250, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4260, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4270, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4280, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4290, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4300, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4310, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4320, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4330, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4340, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4350, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4360, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4370, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4380, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4390, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4400, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4410, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4420, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4430, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4440, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4450, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4460, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4470, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4480, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4490, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4500, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4510, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4520, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4530, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4540, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4550, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4560, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4570, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4580, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4590, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4600, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4610, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4620, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4630, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4640, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4650, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4660, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4670, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4680, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4690, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4700, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4710, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4720, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4730, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4740, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4750, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4760, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4770, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4780, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4790, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4800, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4810, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4820, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4830, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4840, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4850, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4860, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4870, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4880, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4890, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4900, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4910, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4920, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4930, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4940, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4950, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4960, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4970, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4980, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Epoch: 4990, Minibatch Loss= 1.1981, Training Accuracy= 0.503\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5016\n",
      "Replication: 3: \n",
      "Epoch: 0, Minibatch Loss= 1.5138, Training Accuracy= 0.511\n",
      "Epoch: 10, Minibatch Loss= 1.5100, Training Accuracy= 0.511\n",
      "Epoch: 20, Minibatch Loss= 1.5099, Training Accuracy= 0.511\n",
      "Epoch: 30, Minibatch Loss= 1.5098, Training Accuracy= 0.511\n",
      "Epoch: 40, Minibatch Loss= 1.5098, Training Accuracy= 0.511\n",
      "Epoch: 50, Minibatch Loss= 1.5098, Training Accuracy= 0.511\n",
      "Epoch: 60, Minibatch Loss= 1.5098, Training Accuracy= 0.511\n",
      "Epoch: 70, Minibatch Loss= 1.5098, Training Accuracy= 0.511\n",
      "Epoch: 80, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 90, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 100, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 110, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 120, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 130, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 140, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 150, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 160, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 170, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 180, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 190, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 200, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 210, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 220, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 230, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 240, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 250, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 260, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 270, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 280, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 290, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 300, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 310, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 320, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 330, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 340, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 350, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 360, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 370, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 380, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 390, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 400, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 410, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 420, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 430, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 440, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 450, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 460, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 470, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 480, Minibatch Loss= 1.5097, Training Accuracy= 0.511\n",
      "Epoch: 490, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 500, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 510, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 520, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 530, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 540, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 550, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 560, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 570, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 580, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 590, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 600, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 610, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 620, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 630, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 640, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 650, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 660, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 670, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 680, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 690, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 700, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 710, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 720, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 730, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 740, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 750, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 760, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 770, Minibatch Loss= 1.5096, Training Accuracy= 0.511\n",
      "Epoch: 780, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 790, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 800, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 810, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 820, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 830, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 840, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 850, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 860, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 870, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 880, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 890, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 900, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 910, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 920, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 930, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 940, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 950, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 960, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 970, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 980, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 990, Minibatch Loss= 1.5095, Training Accuracy= 0.511\n",
      "Epoch: 1000, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1010, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1020, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1030, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1040, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1050, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1060, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1070, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1080, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1090, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1100, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1110, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1120, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1130, Minibatch Loss= 1.5094, Training Accuracy= 0.511\n",
      "Epoch: 1140, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1150, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1160, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1170, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1180, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1190, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1200, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1210, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1220, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1230, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1240, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1250, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1260, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1270, Minibatch Loss= 1.5093, Training Accuracy= 0.511\n",
      "Epoch: 1280, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1290, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1300, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1310, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1320, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1330, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1340, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1350, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1360, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1370, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1380, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1390, Minibatch Loss= 1.5092, Training Accuracy= 0.511\n",
      "Epoch: 1400, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1410, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1420, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1430, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1440, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1450, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1460, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1470, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1480, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1490, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1500, Minibatch Loss= 1.5091, Training Accuracy= 0.511\n",
      "Epoch: 1510, Minibatch Loss= 1.5090, Training Accuracy= 0.511\n",
      "Epoch: 1520, Minibatch Loss= 1.5090, Training Accuracy= 0.511\n",
      "Epoch: 1530, Minibatch Loss= 1.5090, Training Accuracy= 0.511\n",
      "Epoch: 1540, Minibatch Loss= 1.5090, Training Accuracy= 0.511\n",
      "Epoch: 1550, Minibatch Loss= 1.5090, Training Accuracy= 0.511\n",
      "Epoch: 1560, Minibatch Loss= 1.5090, Training Accuracy= 0.511\n",
      "Epoch: 1570, Minibatch Loss= 1.5090, Training Accuracy= 0.511\n",
      "Epoch: 1580, Minibatch Loss= 1.5090, Training Accuracy= 0.511\n",
      "Epoch: 1590, Minibatch Loss= 1.5090, Training Accuracy= 0.511\n",
      "Epoch: 1600, Minibatch Loss= 1.5089, Training Accuracy= 0.511\n",
      "Epoch: 1610, Minibatch Loss= 1.5089, Training Accuracy= 0.511\n",
      "Epoch: 1620, Minibatch Loss= 1.5089, Training Accuracy= 0.511\n",
      "Epoch: 1630, Minibatch Loss= 1.5089, Training Accuracy= 0.511\n",
      "Epoch: 1640, Minibatch Loss= 1.5089, Training Accuracy= 0.511\n",
      "Epoch: 1650, Minibatch Loss= 1.5089, Training Accuracy= 0.511\n",
      "Epoch: 1660, Minibatch Loss= 1.5089, Training Accuracy= 0.511\n",
      "Epoch: 1670, Minibatch Loss= 1.5089, Training Accuracy= 0.511\n",
      "Epoch: 1680, Minibatch Loss= 1.5089, Training Accuracy= 0.511\n",
      "Epoch: 1690, Minibatch Loss= 1.5088, Training Accuracy= 0.511\n",
      "Epoch: 1700, Minibatch Loss= 1.5088, Training Accuracy= 0.511\n",
      "Epoch: 1710, Minibatch Loss= 1.5088, Training Accuracy= 0.511\n",
      "Epoch: 1720, Minibatch Loss= 1.5088, Training Accuracy= 0.511\n",
      "Epoch: 1730, Minibatch Loss= 1.5088, Training Accuracy= 0.511\n",
      "Epoch: 1740, Minibatch Loss= 1.5088, Training Accuracy= 0.511\n",
      "Epoch: 1750, Minibatch Loss= 1.5088, Training Accuracy= 0.511\n",
      "Epoch: 1760, Minibatch Loss= 1.5088, Training Accuracy= 0.511\n",
      "Epoch: 1770, Minibatch Loss= 1.5088, Training Accuracy= 0.511\n",
      "Epoch: 1780, Minibatch Loss= 1.5088, Training Accuracy= 0.511\n",
      "Epoch: 1790, Minibatch Loss= 1.5087, Training Accuracy= 0.511\n",
      "Epoch: 1800, Minibatch Loss= 1.5087, Training Accuracy= 0.511\n",
      "Epoch: 1810, Minibatch Loss= 1.5087, Training Accuracy= 0.511\n",
      "Epoch: 1820, Minibatch Loss= 1.5087, Training Accuracy= 0.511\n",
      "Epoch: 1830, Minibatch Loss= 1.5087, Training Accuracy= 0.511\n",
      "Epoch: 1840, Minibatch Loss= 1.5087, Training Accuracy= 0.511\n",
      "Epoch: 1850, Minibatch Loss= 1.5087, Training Accuracy= 0.511\n",
      "Epoch: 1860, Minibatch Loss= 1.5087, Training Accuracy= 0.511\n",
      "Epoch: 1870, Minibatch Loss= 1.5087, Training Accuracy= 0.511\n",
      "Epoch: 1880, Minibatch Loss= 1.5086, Training Accuracy= 0.511\n",
      "Epoch: 1890, Minibatch Loss= 1.5086, Training Accuracy= 0.511\n",
      "Epoch: 1900, Minibatch Loss= 1.5086, Training Accuracy= 0.511\n",
      "Epoch: 1910, Minibatch Loss= 1.5086, Training Accuracy= 0.511\n",
      "Epoch: 1920, Minibatch Loss= 1.5086, Training Accuracy= 0.511\n",
      "Epoch: 1930, Minibatch Loss= 1.5086, Training Accuracy= 0.511\n",
      "Epoch: 1940, Minibatch Loss= 1.5086, Training Accuracy= 0.511\n",
      "Epoch: 1950, Minibatch Loss= 1.5086, Training Accuracy= 0.511\n",
      "Epoch: 1960, Minibatch Loss= 1.5086, Training Accuracy= 0.511\n",
      "Epoch: 1970, Minibatch Loss= 1.5085, Training Accuracy= 0.511\n",
      "Epoch: 1980, Minibatch Loss= 1.5085, Training Accuracy= 0.511\n",
      "Epoch: 1990, Minibatch Loss= 1.5085, Training Accuracy= 0.511\n",
      "Epoch: 2000, Minibatch Loss= 1.5085, Training Accuracy= 0.511\n",
      "Epoch: 2010, Minibatch Loss= 1.5085, Training Accuracy= 0.511\n",
      "Epoch: 2020, Minibatch Loss= 1.5085, Training Accuracy= 0.511\n",
      "Epoch: 2030, Minibatch Loss= 1.5085, Training Accuracy= 0.511\n",
      "Epoch: 2040, Minibatch Loss= 1.5085, Training Accuracy= 0.511\n",
      "Epoch: 2050, Minibatch Loss= 1.5084, Training Accuracy= 0.511\n",
      "Epoch: 2060, Minibatch Loss= 1.5084, Training Accuracy= 0.511\n",
      "Epoch: 2070, Minibatch Loss= 1.5084, Training Accuracy= 0.511\n",
      "Epoch: 2080, Minibatch Loss= 1.5084, Training Accuracy= 0.511\n",
      "Epoch: 2090, Minibatch Loss= 1.5084, Training Accuracy= 0.511\n",
      "Epoch: 2100, Minibatch Loss= 1.5084, Training Accuracy= 0.511\n",
      "Epoch: 2110, Minibatch Loss= 1.5084, Training Accuracy= 0.511\n",
      "Epoch: 2120, Minibatch Loss= 1.5084, Training Accuracy= 0.511\n",
      "Epoch: 2130, Minibatch Loss= 1.5083, Training Accuracy= 0.511\n",
      "Epoch: 2140, Minibatch Loss= 1.5083, Training Accuracy= 0.511\n",
      "Epoch: 2150, Minibatch Loss= 1.5083, Training Accuracy= 0.511\n",
      "Epoch: 2160, Minibatch Loss= 1.5083, Training Accuracy= 0.511\n",
      "Epoch: 2170, Minibatch Loss= 1.5083, Training Accuracy= 0.511\n",
      "Epoch: 2180, Minibatch Loss= 1.5083, Training Accuracy= 0.511\n",
      "Epoch: 2190, Minibatch Loss= 1.5083, Training Accuracy= 0.511\n",
      "Epoch: 2200, Minibatch Loss= 1.5083, Training Accuracy= 0.511\n",
      "Epoch: 2210, Minibatch Loss= 1.5083, Training Accuracy= 0.511\n",
      "Epoch: 2220, Minibatch Loss= 1.5082, Training Accuracy= 0.511\n",
      "Epoch: 2230, Minibatch Loss= 1.5082, Training Accuracy= 0.511\n",
      "Epoch: 2240, Minibatch Loss= 1.5082, Training Accuracy= 0.511\n",
      "Epoch: 2250, Minibatch Loss= 1.5082, Training Accuracy= 0.511\n",
      "Epoch: 2260, Minibatch Loss= 1.5082, Training Accuracy= 0.511\n",
      "Epoch: 2270, Minibatch Loss= 1.5082, Training Accuracy= 0.511\n",
      "Epoch: 2280, Minibatch Loss= 1.5082, Training Accuracy= 0.511\n",
      "Epoch: 2290, Minibatch Loss= 1.5082, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2300, Minibatch Loss= 1.5082, Training Accuracy= 0.511\n",
      "Epoch: 2310, Minibatch Loss= 1.5081, Training Accuracy= 0.511\n",
      "Epoch: 2320, Minibatch Loss= 1.5081, Training Accuracy= 0.511\n",
      "Epoch: 2330, Minibatch Loss= 1.5081, Training Accuracy= 0.511\n",
      "Epoch: 2340, Minibatch Loss= 1.5081, Training Accuracy= 0.511\n",
      "Epoch: 2350, Minibatch Loss= 1.5081, Training Accuracy= 0.511\n",
      "Epoch: 2360, Minibatch Loss= 1.5081, Training Accuracy= 0.511\n",
      "Epoch: 2370, Minibatch Loss= 1.5081, Training Accuracy= 0.511\n",
      "Epoch: 2380, Minibatch Loss= 1.5081, Training Accuracy= 0.511\n",
      "Epoch: 2390, Minibatch Loss= 1.5081, Training Accuracy= 0.511\n",
      "Epoch: 2400, Minibatch Loss= 1.5080, Training Accuracy= 0.511\n",
      "Epoch: 2410, Minibatch Loss= 1.5080, Training Accuracy= 0.511\n",
      "Epoch: 2420, Minibatch Loss= 1.5080, Training Accuracy= 0.511\n",
      "Epoch: 2430, Minibatch Loss= 1.5080, Training Accuracy= 0.511\n",
      "Epoch: 2440, Minibatch Loss= 1.5080, Training Accuracy= 0.511\n",
      "Epoch: 2450, Minibatch Loss= 1.5080, Training Accuracy= 0.511\n",
      "Epoch: 2460, Minibatch Loss= 1.5080, Training Accuracy= 0.511\n",
      "Epoch: 2470, Minibatch Loss= 1.5080, Training Accuracy= 0.511\n",
      "Epoch: 2480, Minibatch Loss= 1.5080, Training Accuracy= 0.511\n",
      "Epoch: 2490, Minibatch Loss= 1.5080, Training Accuracy= 0.511\n",
      "Epoch: 2500, Minibatch Loss= 1.5079, Training Accuracy= 0.511\n",
      "Epoch: 2510, Minibatch Loss= 1.5079, Training Accuracy= 0.511\n",
      "Epoch: 2520, Minibatch Loss= 1.5079, Training Accuracy= 0.511\n",
      "Epoch: 2530, Minibatch Loss= 1.5079, Training Accuracy= 0.511\n",
      "Epoch: 2540, Minibatch Loss= 1.5079, Training Accuracy= 0.511\n",
      "Epoch: 2550, Minibatch Loss= 1.5079, Training Accuracy= 0.511\n",
      "Epoch: 2560, Minibatch Loss= 1.5079, Training Accuracy= 0.511\n",
      "Epoch: 2570, Minibatch Loss= 1.5079, Training Accuracy= 0.511\n",
      "Epoch: 2580, Minibatch Loss= 1.5079, Training Accuracy= 0.511\n",
      "Epoch: 2590, Minibatch Loss= 1.5079, Training Accuracy= 0.511\n",
      "Epoch: 2600, Minibatch Loss= 1.5078, Training Accuracy= 0.511\n",
      "Epoch: 2610, Minibatch Loss= 1.5078, Training Accuracy= 0.511\n",
      "Epoch: 2620, Minibatch Loss= 1.5078, Training Accuracy= 0.511\n",
      "Epoch: 2630, Minibatch Loss= 1.5078, Training Accuracy= 0.511\n",
      "Epoch: 2640, Minibatch Loss= 1.5078, Training Accuracy= 0.511\n",
      "Epoch: 2650, Minibatch Loss= 1.5078, Training Accuracy= 0.511\n",
      "Epoch: 2660, Minibatch Loss= 1.5078, Training Accuracy= 0.511\n",
      "Epoch: 2670, Minibatch Loss= 1.5078, Training Accuracy= 0.511\n",
      "Epoch: 2680, Minibatch Loss= 1.5078, Training Accuracy= 0.511\n",
      "Epoch: 2690, Minibatch Loss= 1.5078, Training Accuracy= 0.511\n",
      "Epoch: 2700, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2710, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2720, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2730, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2740, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2750, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2760, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2770, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2780, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2790, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2800, Minibatch Loss= 1.5077, Training Accuracy= 0.511\n",
      "Epoch: 2810, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2820, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2830, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2840, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2850, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2860, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2870, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2880, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2890, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2900, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2910, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2920, Minibatch Loss= 1.5076, Training Accuracy= 0.511\n",
      "Epoch: 2930, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 2940, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 2950, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 2960, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 2970, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 2980, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 2990, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 3000, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 3010, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 3020, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 3030, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 3040, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 3050, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 3060, Minibatch Loss= 1.5075, Training Accuracy= 0.511\n",
      "Epoch: 3070, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3080, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3090, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3100, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3110, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3120, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3130, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3140, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3150, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3160, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3170, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3180, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3190, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3200, Minibatch Loss= 1.5074, Training Accuracy= 0.511\n",
      "Epoch: 3210, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3220, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3230, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3240, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3250, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3260, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3270, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3280, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3290, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3300, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3310, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3320, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3330, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3340, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3350, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3360, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3370, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3380, Minibatch Loss= 1.5073, Training Accuracy= 0.511\n",
      "Epoch: 3390, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3400, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3410, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3420, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3430, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3440, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3450, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3460, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3470, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3480, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3490, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3500, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3510, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3520, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3530, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3540, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3550, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3560, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3570, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3580, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3590, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3600, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3610, Minibatch Loss= 1.5072, Training Accuracy= 0.511\n",
      "Epoch: 3620, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3630, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3640, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3650, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3660, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3670, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3680, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3690, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3700, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3710, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3720, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3730, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3740, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3750, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3760, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3770, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3780, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3790, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3800, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3810, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3820, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3830, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3840, Minibatch Loss= 1.5071, Training Accuracy= 0.511\n",
      "Epoch: 3850, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3860, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3870, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3880, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3890, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3900, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3910, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3920, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3930, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3940, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3950, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3960, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3970, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3980, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 3990, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4000, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4010, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4020, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4030, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4040, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4050, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4060, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4070, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4080, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4090, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4100, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4110, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4120, Minibatch Loss= 1.5070, Training Accuracy= 0.511\n",
      "Epoch: 4130, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4140, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4150, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4160, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4170, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4180, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4190, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4200, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4210, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4220, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4230, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4240, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4250, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4260, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4270, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4280, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4290, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4300, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4310, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4320, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4330, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4340, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4350, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4360, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4370, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4380, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4390, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4400, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4410, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4420, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4430, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4440, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4450, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4460, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4470, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4480, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4490, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4500, Minibatch Loss= 1.5069, Training Accuracy= 0.511\n",
      "Epoch: 4510, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4520, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4530, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4540, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4550, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4560, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4570, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4580, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4590, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4600, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4610, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4620, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4630, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4640, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4650, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4660, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4670, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4680, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4690, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4700, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4710, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4720, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4730, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4740, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4750, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4760, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4770, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4780, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4790, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4800, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4810, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4820, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4830, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4840, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4850, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4860, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4870, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4880, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4890, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4900, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4910, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4920, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4930, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4940, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4950, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4960, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4970, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4980, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Epoch: 4990, Minibatch Loss= 1.5068, Training Accuracy= 0.511\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4983\n",
      "Replication: 4: \n",
      "Epoch: 0, Minibatch Loss= 1.1516, Training Accuracy= 0.504\n",
      "Epoch: 10, Minibatch Loss= 1.1501, Training Accuracy= 0.504\n",
      "Epoch: 20, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 30, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 40, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 50, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 60, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 70, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 80, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 90, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 100, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 110, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 120, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 130, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 140, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 150, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 160, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 170, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 180, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 190, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 200, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 210, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 220, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 230, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 240, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 250, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 260, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 270, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 280, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 290, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 300, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 310, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 320, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 330, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 340, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 350, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 360, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 370, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 380, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 390, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 400, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 410, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 420, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 430, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 440, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 450, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 460, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 470, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 480, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 490, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 500, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 510, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 520, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 530, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 540, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 550, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 560, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 570, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 580, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 590, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 600, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 610, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 620, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 630, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 640, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 650, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 660, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 670, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 680, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 690, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 700, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 710, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 720, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 730, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 740, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 750, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 760, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 770, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 780, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 790, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 800, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 810, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 820, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 830, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 840, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 850, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 860, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 870, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 880, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 890, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 900, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 910, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 920, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 930, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 940, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 950, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 960, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 970, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 980, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 990, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1000, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1010, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1020, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1030, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1040, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1050, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1060, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1070, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1080, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1090, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1100, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1110, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1120, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1130, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1140, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1150, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1160, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1170, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1180, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1190, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1200, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1210, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1220, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1230, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1240, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1250, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1260, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1270, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1280, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1290, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1300, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1310, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1320, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1330, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1340, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1350, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1360, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1370, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1380, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1390, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1400, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1410, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1420, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1430, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1440, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1450, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1460, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1470, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1480, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1490, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1500, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1510, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1520, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1530, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1540, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1550, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1560, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1570, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1580, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1590, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1600, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1610, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1620, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1630, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1640, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1650, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1660, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1670, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1680, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1690, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1700, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1710, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1720, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1730, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1740, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1750, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1760, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1770, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1780, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1790, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1800, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1810, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1820, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1830, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1840, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1850, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1860, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1870, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1880, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1890, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1900, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1910, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1920, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1930, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1940, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1950, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1960, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1970, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1980, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 1990, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2000, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2010, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2020, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2030, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2040, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2050, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2060, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2070, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2080, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2090, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2100, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2110, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2120, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2130, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2140, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2150, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2160, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2170, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2180, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2190, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2200, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2210, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2220, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2230, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2240, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2250, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2260, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2270, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2280, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2290, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2300, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2310, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2320, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2330, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2340, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2350, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2360, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2370, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2380, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2390, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2400, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2410, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2420, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2430, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2440, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2450, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2460, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2470, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2480, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2490, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2500, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2510, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2520, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2530, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2540, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2550, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2560, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2570, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2580, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2590, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2600, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2610, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2620, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2630, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2640, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2650, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2660, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2670, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2680, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2690, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2700, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2710, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2720, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2730, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2740, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2750, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2760, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2770, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2780, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2790, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2800, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2810, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2820, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2830, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 2840, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 2850, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 2860, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2870, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2880, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2890, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2900, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2910, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2920, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2930, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 2940, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2950, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2960, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2970, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 2980, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 2990, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3000, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3010, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3020, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3030, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3040, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3050, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3060, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3070, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3080, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3090, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3100, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3110, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3120, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3130, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3140, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3150, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3160, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3170, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3180, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3190, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3200, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3210, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3220, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3230, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3240, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3250, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3260, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3270, Minibatch Loss= 1.1499, Training Accuracy= 0.504\n",
      "Epoch: 3280, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3290, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3300, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3310, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3320, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3330, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3340, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3350, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3360, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3370, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3380, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3390, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3400, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3410, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3420, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3430, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3440, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3450, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3460, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3470, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3480, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3490, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3500, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3510, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3520, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3530, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3540, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3550, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3560, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3570, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3580, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3590, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3600, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3610, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3620, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3630, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3640, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3650, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3660, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3670, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3680, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3690, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3700, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3710, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3720, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3730, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3740, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3750, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3760, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3770, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3780, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3790, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3800, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3810, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3820, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3830, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3840, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3850, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3860, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3870, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3880, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3890, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3900, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3910, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3920, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3930, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3940, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3950, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3960, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3970, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3980, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 3990, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4000, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4010, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4020, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4030, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4040, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4050, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4060, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4070, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4080, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4090, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4100, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4110, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4120, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4130, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4140, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4150, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4160, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4170, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4180, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4190, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4200, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4210, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4220, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4230, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4240, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4250, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4260, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4270, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4280, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4290, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4300, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4310, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4320, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4330, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4340, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4350, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4360, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4370, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4380, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4390, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4400, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4410, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4420, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4430, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4440, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4450, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4460, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4470, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4480, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4490, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4500, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4510, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4520, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4530, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4540, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4550, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4560, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4570, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4580, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4590, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4600, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4610, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4620, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4630, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4640, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4650, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4660, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4670, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4680, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4690, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4700, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4710, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4720, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4730, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4740, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4750, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4760, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4770, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4780, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4790, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4800, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4810, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4820, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4830, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4840, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4850, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4860, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4870, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4880, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4890, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4900, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4910, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4920, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4930, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4940, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4950, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4960, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4970, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4980, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Epoch: 4990, Minibatch Loss= 1.1500, Training Accuracy= 0.504\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5107\n",
      "Replication: 5: \n",
      "Epoch: 0, Minibatch Loss= 1.3577, Training Accuracy= 0.495\n",
      "Epoch: 10, Minibatch Loss= 1.3543, Training Accuracy= 0.495\n",
      "Epoch: 20, Minibatch Loss= 1.3542, Training Accuracy= 0.495\n",
      "Epoch: 30, Minibatch Loss= 1.3541, Training Accuracy= 0.495\n",
      "Epoch: 40, Minibatch Loss= 1.3541, Training Accuracy= 0.495\n",
      "Epoch: 50, Minibatch Loss= 1.3541, Training Accuracy= 0.495\n",
      "Epoch: 60, Minibatch Loss= 1.3541, Training Accuracy= 0.495\n",
      "Epoch: 70, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 80, Minibatch Loss= 1.3541, Training Accuracy= 0.495\n",
      "Epoch: 90, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 100, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 110, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 120, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 130, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 140, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 150, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 160, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 170, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 180, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 190, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 200, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 210, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 220, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 230, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 240, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 250, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 260, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 280, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 290, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 300, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 310, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 320, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 330, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 340, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 350, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 360, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 370, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 380, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 390, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 400, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 410, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 420, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 430, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 440, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 450, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 460, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 470, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 480, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 490, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 500, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 510, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 520, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 530, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 540, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 550, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 560, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 570, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 580, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 590, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 600, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 610, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 620, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 630, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 640, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 650, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 660, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 670, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 680, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 690, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 700, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 710, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 720, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 730, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 740, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 750, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 760, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 770, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 780, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 790, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 800, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 810, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 820, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 830, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 840, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 850, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 860, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 870, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 880, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 890, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 900, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 910, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 920, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 930, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 940, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 950, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 960, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 970, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 980, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 990, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1000, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1010, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1020, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1030, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1040, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1050, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1060, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1070, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1080, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1090, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1100, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1110, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1120, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1130, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1140, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1150, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1160, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1170, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1180, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1190, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1200, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1210, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1220, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1230, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1240, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1250, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1260, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1270, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1280, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1290, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1300, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1310, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1320, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1330, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1340, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1350, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1360, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1370, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1380, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1390, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1400, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1410, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1420, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1430, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1440, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1450, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1460, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1470, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1480, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1490, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1500, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1510, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1520, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1530, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1540, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1550, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1560, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1570, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1580, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1590, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1600, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1610, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1620, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1630, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1640, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1650, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1660, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1670, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1680, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1690, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1700, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1710, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1720, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1730, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1740, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1750, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1760, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1770, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1780, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1790, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1800, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1810, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1820, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1830, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1840, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1850, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1860, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1870, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1880, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1890, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1900, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1910, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1920, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1930, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1940, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1950, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1960, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1970, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1980, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 1990, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2000, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2010, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2020, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2030, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2040, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2050, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2060, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2070, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2080, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2090, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2100, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2110, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2120, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2130, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2140, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2150, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2160, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2170, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2180, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2190, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2200, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2210, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2220, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2230, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2240, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2250, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2260, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2270, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2280, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2290, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2300, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2310, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2320, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2330, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2340, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2350, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2360, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2370, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2380, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2390, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2400, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2410, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2420, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2430, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2440, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2450, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2460, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2470, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2480, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2490, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2500, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2510, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2520, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2530, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2540, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2550, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2560, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2570, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2580, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2590, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2600, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2610, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2620, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2630, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2640, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2650, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2660, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2670, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2680, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2690, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2700, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2710, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2720, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2730, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2740, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2750, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2760, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2770, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2780, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2790, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2800, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2810, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2820, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2830, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2840, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2850, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2860, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2870, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2880, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2890, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2900, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2910, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2920, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2930, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2940, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2950, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2960, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2970, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2980, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 2990, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3000, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3010, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3020, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3030, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3040, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3050, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3060, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3070, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3080, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3090, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3100, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3110, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3120, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3130, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3140, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3150, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3160, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3170, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3180, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3190, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3200, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3210, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3220, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3230, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3240, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3250, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3260, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3270, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3280, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3290, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3300, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3310, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3320, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3330, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3340, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3350, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3360, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3370, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3380, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3390, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3400, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3410, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3420, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3430, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3440, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3450, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3460, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3470, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3480, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3490, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3500, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3510, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3520, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3530, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3540, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3550, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3560, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3570, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3580, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3590, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3600, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3610, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3620, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3630, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3640, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3650, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3660, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3670, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3680, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3690, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3700, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3710, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3720, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3730, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3740, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3750, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3760, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3770, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3780, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3790, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3800, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3810, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3820, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3830, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3840, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3850, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3860, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3870, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3880, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3890, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3900, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3910, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3920, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3930, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3940, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3950, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3960, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3970, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3980, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 3990, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4000, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4010, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4020, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4030, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4040, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4050, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4060, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4070, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4080, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4090, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4100, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4110, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4120, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4130, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4140, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4150, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4160, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4170, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4180, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4190, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4200, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4210, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4220, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4230, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4240, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4250, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4260, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4270, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4280, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4290, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4300, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4310, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4320, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4330, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4340, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4350, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4360, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4370, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4380, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4390, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4400, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4410, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4420, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4430, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4440, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4450, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4460, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4470, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4480, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4490, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4500, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4510, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4520, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4530, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4540, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4550, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4560, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4570, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4580, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4590, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4600, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4610, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4620, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4630, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4640, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4650, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4660, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4670, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4680, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4690, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4700, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4710, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4720, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4730, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4740, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4750, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4760, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4770, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4780, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4790, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4800, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4810, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4820, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4830, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4840, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4850, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4860, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4870, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4880, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4890, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4900, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4910, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4920, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4930, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4940, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4950, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4960, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4970, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4980, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Epoch: 4990, Minibatch Loss= 1.3540, Training Accuracy= 0.495\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4985\n",
      "Replication: 6: \n",
      "Epoch: 0, Minibatch Loss= 2.4097, Training Accuracy= 0.497\n",
      "Epoch: 10, Minibatch Loss= 2.4091, Training Accuracy= 0.497\n",
      "Epoch: 20, Minibatch Loss= 2.4091, Training Accuracy= 0.497\n",
      "Epoch: 30, Minibatch Loss= 2.4092, Training Accuracy= 0.497\n",
      "Epoch: 40, Minibatch Loss= 2.4092, Training Accuracy= 0.497\n",
      "Epoch: 50, Minibatch Loss= 2.4092, Training Accuracy= 0.497\n",
      "Epoch: 60, Minibatch Loss= 2.4092, Training Accuracy= 0.497\n",
      "Epoch: 70, Minibatch Loss= 2.4092, Training Accuracy= 0.497\n",
      "Epoch: 80, Minibatch Loss= 2.4092, Training Accuracy= 0.497\n",
      "Epoch: 90, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 100, Minibatch Loss= 2.4092, Training Accuracy= 0.497\n",
      "Epoch: 110, Minibatch Loss= 2.4092, Training Accuracy= 0.497\n",
      "Epoch: 120, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 130, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 140, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 150, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 160, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 170, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 180, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 190, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 200, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 210, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 220, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 230, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 240, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 250, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 260, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 270, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 280, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 290, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 300, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 310, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 320, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 330, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 340, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 350, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 360, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 370, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 380, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 390, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 400, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 410, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 420, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 430, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 440, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 450, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 460, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 470, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 480, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 490, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 500, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 510, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 520, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 530, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 540, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 550, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 560, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 570, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 580, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 590, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 610, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 620, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 630, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 640, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 650, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 660, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 670, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 680, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 690, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 700, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 710, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 720, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 730, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 740, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 750, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 760, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 770, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 780, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 790, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 800, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 810, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 820, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 830, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 840, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 850, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 860, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 870, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 880, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 890, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 900, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 910, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 920, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 930, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 940, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 950, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 960, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 970, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 980, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 990, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1000, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1010, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1020, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1030, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1040, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1050, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1060, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1070, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1080, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1090, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1100, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1110, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1120, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1130, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1140, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1150, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1160, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1170, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1180, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1190, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1200, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1210, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1220, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1230, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1240, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1250, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1260, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1270, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1280, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1290, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1300, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1310, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1320, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1330, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1340, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1350, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1360, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1370, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1380, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1390, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1400, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1410, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1420, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1430, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1440, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1450, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1460, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1470, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1480, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1490, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1500, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1510, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1520, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1530, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1540, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1550, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1560, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1570, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1580, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1590, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1600, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1610, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1620, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1630, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1640, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1650, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1660, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1670, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1680, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1690, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1700, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1710, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1720, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1730, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1740, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1750, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1760, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1770, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1780, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1790, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1800, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1810, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1820, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1830, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1840, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1850, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1860, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1870, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1880, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1890, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1900, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1910, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1920, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1930, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1940, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1950, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1960, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1970, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1980, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 1990, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2000, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2010, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2020, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2030, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2040, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2050, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2060, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2070, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2080, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2090, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2100, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2110, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2120, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2130, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2140, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2150, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2160, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2170, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2180, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2190, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2200, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2210, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2220, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2230, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2240, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2250, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2260, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2270, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2280, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2290, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2300, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2310, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2320, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2330, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2340, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2350, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2360, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2370, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2380, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2390, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2400, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2410, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2420, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2430, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2440, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2450, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2460, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2470, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2480, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2490, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2500, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2510, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2520, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2530, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2540, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2550, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2560, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2570, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2580, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2590, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2600, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2610, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2620, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2630, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2640, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2650, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2660, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2670, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2680, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2690, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2700, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2710, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2720, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2730, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2740, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2750, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2760, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2770, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2780, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2790, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2800, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2810, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2820, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2830, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2840, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2850, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2860, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2870, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2880, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2890, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2900, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2910, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2920, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2930, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2940, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2950, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2960, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2970, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2980, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 2990, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3000, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3010, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3020, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3030, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3040, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3050, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3060, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3070, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3080, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3090, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3100, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3110, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3120, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3130, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3140, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3150, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3160, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3170, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3180, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3190, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3200, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3210, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3220, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3230, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3240, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3250, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3260, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3270, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3280, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3290, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3300, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3310, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3320, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3330, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3340, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3350, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3360, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3370, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3380, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3390, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3400, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3410, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3420, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3430, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3440, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3450, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3460, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3470, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3480, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3490, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3500, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3510, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3520, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3530, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3540, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3550, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3560, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3570, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3580, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3590, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3600, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3610, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3620, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3630, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3640, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3650, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3660, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3670, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3680, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3690, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3700, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3710, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3720, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3730, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3740, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3750, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3760, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3770, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3780, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3790, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3800, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3810, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3820, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3830, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3840, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3850, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3860, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3870, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3880, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3890, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3900, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3910, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3920, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3930, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3940, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3950, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3960, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3970, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3980, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 3990, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4000, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4010, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4020, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4030, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4040, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4050, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4060, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4070, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4080, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4090, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4100, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4110, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4120, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4130, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4140, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4150, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4160, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4170, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4180, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4190, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4200, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4210, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4220, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4230, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4240, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4250, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4260, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4270, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4280, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4290, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4300, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4310, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4320, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4330, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4340, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4350, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4360, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4370, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4380, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4390, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4400, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4410, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4420, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4430, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4440, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4450, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4460, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4470, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4480, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4490, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4500, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4510, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4520, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4530, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4540, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4550, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4560, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4570, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4580, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4590, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4600, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4610, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4620, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4630, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4640, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4650, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4660, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4670, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4680, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4690, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4700, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4710, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4720, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4730, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4740, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4750, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4760, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4770, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4780, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4790, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4800, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4810, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4820, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4830, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4840, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4850, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4860, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4870, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4880, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4890, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4900, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4910, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4920, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4930, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4940, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4950, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4960, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4970, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4980, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Epoch: 4990, Minibatch Loss= 2.4093, Training Accuracy= 0.497\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5037\n",
      "Replication: 7: \n",
      "Epoch: 0, Minibatch Loss= 1.4969, Training Accuracy= 0.501\n",
      "Epoch: 10, Minibatch Loss= 1.4942, Training Accuracy= 0.501\n",
      "Epoch: 20, Minibatch Loss= 1.4941, Training Accuracy= 0.501\n",
      "Epoch: 30, Minibatch Loss= 1.4940, Training Accuracy= 0.501\n",
      "Epoch: 40, Minibatch Loss= 1.4940, Training Accuracy= 0.501\n",
      "Epoch: 50, Minibatch Loss= 1.4940, Training Accuracy= 0.501\n",
      "Epoch: 60, Minibatch Loss= 1.4940, Training Accuracy= 0.501\n",
      "Epoch: 70, Minibatch Loss= 1.4940, Training Accuracy= 0.501\n",
      "Epoch: 80, Minibatch Loss= 1.4940, Training Accuracy= 0.501\n",
      "Epoch: 90, Minibatch Loss= 1.4940, Training Accuracy= 0.501\n",
      "Epoch: 100, Minibatch Loss= 1.4940, Training Accuracy= 0.501\n",
      "Epoch: 110, Minibatch Loss= 1.4940, Training Accuracy= 0.501\n",
      "Epoch: 120, Minibatch Loss= 1.4940, Training Accuracy= 0.501\n",
      "Epoch: 130, Minibatch Loss= 1.4941, Training Accuracy= 0.501\n",
      "Epoch: 140, Minibatch Loss= 1.4941, Training Accuracy= 0.501\n",
      "Epoch: 150, Minibatch Loss= 1.4941, Training Accuracy= 0.501\n",
      "Epoch: 160, Minibatch Loss= 1.4941, Training Accuracy= 0.501\n",
      "Epoch: 170, Minibatch Loss= 1.4941, Training Accuracy= 0.501\n",
      "Epoch: 180, Minibatch Loss= 1.4942, Training Accuracy= 0.501\n",
      "Epoch: 190, Minibatch Loss= 1.4942, Training Accuracy= 0.501\n",
      "Epoch: 200, Minibatch Loss= 1.4942, Training Accuracy= 0.501\n",
      "Epoch: 210, Minibatch Loss= 1.4942, Training Accuracy= 0.501\n",
      "Epoch: 220, Minibatch Loss= 1.4943, Training Accuracy= 0.501\n",
      "Epoch: 230, Minibatch Loss= 1.4943, Training Accuracy= 0.501\n",
      "Epoch: 240, Minibatch Loss= 1.4944, Training Accuracy= 0.501\n",
      "Epoch: 250, Minibatch Loss= 1.4944, Training Accuracy= 0.501\n",
      "Epoch: 260, Minibatch Loss= 1.4945, Training Accuracy= 0.501\n",
      "Epoch: 270, Minibatch Loss= 1.4946, Training Accuracy= 0.501\n",
      "Epoch: 280, Minibatch Loss= 1.4948, Training Accuracy= 0.501\n",
      "Epoch: 290, Minibatch Loss= 1.4951, Training Accuracy= 0.501\n",
      "Epoch: 300, Minibatch Loss= 1.4956, Training Accuracy= 0.501\n",
      "Epoch: 310, Minibatch Loss= 1.4965, Training Accuracy= 0.501\n",
      "Epoch: 320, Minibatch Loss= 1.4977, Training Accuracy= 0.501\n",
      "Epoch: 330, Minibatch Loss= 1.4988, Training Accuracy= 0.501\n",
      "Epoch: 340, Minibatch Loss= 1.4997, Training Accuracy= 0.501\n",
      "Epoch: 350, Minibatch Loss= 1.5006, Training Accuracy= 0.501\n",
      "Epoch: 360, Minibatch Loss= 1.5016, Training Accuracy= 0.501\n",
      "Epoch: 370, Minibatch Loss= 1.5026, Training Accuracy= 0.501\n",
      "Epoch: 380, Minibatch Loss= 1.5035, Training Accuracy= 0.501\n",
      "Epoch: 390, Minibatch Loss= 1.5044, Training Accuracy= 0.501\n",
      "Epoch: 400, Minibatch Loss= 1.5053, Training Accuracy= 0.501\n",
      "Epoch: 410, Minibatch Loss= 1.5061, Training Accuracy= 0.501\n",
      "Epoch: 420, Minibatch Loss= 1.5068, Training Accuracy= 0.501\n",
      "Epoch: 430, Minibatch Loss= 1.5072, Training Accuracy= 0.501\n",
      "Epoch: 440, Minibatch Loss= 1.5076, Training Accuracy= 0.501\n",
      "Epoch: 450, Minibatch Loss= 1.5078, Training Accuracy= 0.501\n",
      "Epoch: 460, Minibatch Loss= 1.5081, Training Accuracy= 0.501\n",
      "Epoch: 470, Minibatch Loss= 1.5083, Training Accuracy= 0.501\n",
      "Epoch: 480, Minibatch Loss= 1.5085, Training Accuracy= 0.501\n",
      "Epoch: 490, Minibatch Loss= 1.5086, Training Accuracy= 0.501\n",
      "Epoch: 500, Minibatch Loss= 1.5087, Training Accuracy= 0.501\n",
      "Epoch: 510, Minibatch Loss= 1.5088, Training Accuracy= 0.501\n",
      "Epoch: 520, Minibatch Loss= 1.5089, Training Accuracy= 0.501\n",
      "Epoch: 530, Minibatch Loss= 1.5090, Training Accuracy= 0.501\n",
      "Epoch: 540, Minibatch Loss= 1.5091, Training Accuracy= 0.501\n",
      "Epoch: 550, Minibatch Loss= 1.5092, Training Accuracy= 0.501\n",
      "Epoch: 560, Minibatch Loss= 1.5093, Training Accuracy= 0.501\n",
      "Epoch: 570, Minibatch Loss= 1.5093, Training Accuracy= 0.501\n",
      "Epoch: 580, Minibatch Loss= 1.5094, Training Accuracy= 0.501\n",
      "Epoch: 590, Minibatch Loss= 1.5094, Training Accuracy= 0.501\n",
      "Epoch: 600, Minibatch Loss= 1.5095, Training Accuracy= 0.501\n",
      "Epoch: 610, Minibatch Loss= 1.5095, Training Accuracy= 0.501\n",
      "Epoch: 620, Minibatch Loss= 1.5095, Training Accuracy= 0.501\n",
      "Epoch: 630, Minibatch Loss= 1.5096, Training Accuracy= 0.501\n",
      "Epoch: 640, Minibatch Loss= 1.5096, Training Accuracy= 0.501\n",
      "Epoch: 650, Minibatch Loss= 1.5096, Training Accuracy= 0.501\n",
      "Epoch: 660, Minibatch Loss= 1.5097, Training Accuracy= 0.501\n",
      "Epoch: 670, Minibatch Loss= 1.5097, Training Accuracy= 0.501\n",
      "Epoch: 680, Minibatch Loss= 1.5097, Training Accuracy= 0.501\n",
      "Epoch: 690, Minibatch Loss= 1.5098, Training Accuracy= 0.501\n",
      "Epoch: 700, Minibatch Loss= 1.5098, Training Accuracy= 0.501\n",
      "Epoch: 710, Minibatch Loss= 1.5098, Training Accuracy= 0.501\n",
      "Epoch: 720, Minibatch Loss= 1.5098, Training Accuracy= 0.501\n",
      "Epoch: 730, Minibatch Loss= 1.5099, Training Accuracy= 0.501\n",
      "Epoch: 740, Minibatch Loss= 1.5099, Training Accuracy= 0.501\n",
      "Epoch: 750, Minibatch Loss= 1.5099, Training Accuracy= 0.501\n",
      "Epoch: 760, Minibatch Loss= 1.5099, Training Accuracy= 0.501\n",
      "Epoch: 770, Minibatch Loss= 1.5100, Training Accuracy= 0.501\n",
      "Epoch: 780, Minibatch Loss= 1.5100, Training Accuracy= 0.501\n",
      "Epoch: 790, Minibatch Loss= 1.5100, Training Accuracy= 0.501\n",
      "Epoch: 800, Minibatch Loss= 1.5100, Training Accuracy= 0.501\n",
      "Epoch: 810, Minibatch Loss= 1.5101, Training Accuracy= 0.501\n",
      "Epoch: 820, Minibatch Loss= 1.5101, Training Accuracy= 0.501\n",
      "Epoch: 830, Minibatch Loss= 1.5101, Training Accuracy= 0.501\n",
      "Epoch: 840, Minibatch Loss= 1.5102, Training Accuracy= 0.501\n",
      "Epoch: 850, Minibatch Loss= 1.5102, Training Accuracy= 0.501\n",
      "Epoch: 860, Minibatch Loss= 1.5103, Training Accuracy= 0.501\n",
      "Epoch: 870, Minibatch Loss= 1.5104, Training Accuracy= 0.501\n",
      "Epoch: 880, Minibatch Loss= 1.5105, Training Accuracy= 0.501\n",
      "Epoch: 890, Minibatch Loss= 1.5106, Training Accuracy= 0.501\n",
      "Epoch: 900, Minibatch Loss= 1.5107, Training Accuracy= 0.501\n",
      "Epoch: 910, Minibatch Loss= 1.5109, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 920, Minibatch Loss= 1.5110, Training Accuracy= 0.501\n",
      "Epoch: 930, Minibatch Loss= 1.5111, Training Accuracy= 0.501\n",
      "Epoch: 940, Minibatch Loss= 1.5112, Training Accuracy= 0.501\n",
      "Epoch: 950, Minibatch Loss= 1.5113, Training Accuracy= 0.501\n",
      "Epoch: 960, Minibatch Loss= 1.5115, Training Accuracy= 0.501\n",
      "Epoch: 970, Minibatch Loss= 1.5116, Training Accuracy= 0.501\n",
      "Epoch: 980, Minibatch Loss= 1.5118, Training Accuracy= 0.501\n",
      "Epoch: 990, Minibatch Loss= 1.5121, Training Accuracy= 0.501\n",
      "Epoch: 1000, Minibatch Loss= 1.5123, Training Accuracy= 0.501\n",
      "Epoch: 1010, Minibatch Loss= 1.5126, Training Accuracy= 0.501\n",
      "Epoch: 1020, Minibatch Loss= 1.5129, Training Accuracy= 0.501\n",
      "Epoch: 1030, Minibatch Loss= 1.5132, Training Accuracy= 0.501\n",
      "Epoch: 1040, Minibatch Loss= 1.5134, Training Accuracy= 0.501\n",
      "Epoch: 1050, Minibatch Loss= 1.5137, Training Accuracy= 0.501\n",
      "Epoch: 1060, Minibatch Loss= 1.5140, Training Accuracy= 0.501\n",
      "Epoch: 1070, Minibatch Loss= 1.5142, Training Accuracy= 0.501\n",
      "Epoch: 1080, Minibatch Loss= 1.5143, Training Accuracy= 0.501\n",
      "Epoch: 1090, Minibatch Loss= 1.5145, Training Accuracy= 0.501\n",
      "Epoch: 1100, Minibatch Loss= 1.5147, Training Accuracy= 0.501\n",
      "Epoch: 1110, Minibatch Loss= 1.5148, Training Accuracy= 0.501\n",
      "Epoch: 1120, Minibatch Loss= 1.5149, Training Accuracy= 0.501\n",
      "Epoch: 1130, Minibatch Loss= 1.5150, Training Accuracy= 0.501\n",
      "Epoch: 1140, Minibatch Loss= 1.5151, Training Accuracy= 0.501\n",
      "Epoch: 1150, Minibatch Loss= 1.5152, Training Accuracy= 0.501\n",
      "Epoch: 1160, Minibatch Loss= 1.5153, Training Accuracy= 0.501\n",
      "Epoch: 1170, Minibatch Loss= 1.5153, Training Accuracy= 0.501\n",
      "Epoch: 1180, Minibatch Loss= 1.5154, Training Accuracy= 0.501\n",
      "Epoch: 1190, Minibatch Loss= 1.5154, Training Accuracy= 0.501\n",
      "Epoch: 1200, Minibatch Loss= 1.5155, Training Accuracy= 0.501\n",
      "Epoch: 1210, Minibatch Loss= 1.5155, Training Accuracy= 0.501\n",
      "Epoch: 1220, Minibatch Loss= 1.5156, Training Accuracy= 0.501\n",
      "Epoch: 1230, Minibatch Loss= 1.5156, Training Accuracy= 0.501\n",
      "Epoch: 1240, Minibatch Loss= 1.5157, Training Accuracy= 0.501\n",
      "Epoch: 1250, Minibatch Loss= 1.5157, Training Accuracy= 0.501\n",
      "Epoch: 1260, Minibatch Loss= 1.5157, Training Accuracy= 0.501\n",
      "Epoch: 1270, Minibatch Loss= 1.5158, Training Accuracy= 0.501\n",
      "Epoch: 1280, Minibatch Loss= 1.5158, Training Accuracy= 0.501\n",
      "Epoch: 1290, Minibatch Loss= 1.5158, Training Accuracy= 0.501\n",
      "Epoch: 1300, Minibatch Loss= 1.5158, Training Accuracy= 0.501\n",
      "Epoch: 1310, Minibatch Loss= 1.5159, Training Accuracy= 0.501\n",
      "Epoch: 1320, Minibatch Loss= 1.5159, Training Accuracy= 0.501\n",
      "Epoch: 1330, Minibatch Loss= 1.5159, Training Accuracy= 0.501\n",
      "Epoch: 1340, Minibatch Loss= 1.5159, Training Accuracy= 0.501\n",
      "Epoch: 1350, Minibatch Loss= 1.5160, Training Accuracy= 0.501\n",
      "Epoch: 1360, Minibatch Loss= 1.5160, Training Accuracy= 0.501\n",
      "Epoch: 1370, Minibatch Loss= 1.5160, Training Accuracy= 0.501\n",
      "Epoch: 1380, Minibatch Loss= 1.5160, Training Accuracy= 0.501\n",
      "Epoch: 1390, Minibatch Loss= 1.5160, Training Accuracy= 0.501\n",
      "Epoch: 1400, Minibatch Loss= 1.5161, Training Accuracy= 0.501\n",
      "Epoch: 1410, Minibatch Loss= 1.5161, Training Accuracy= 0.501\n",
      "Epoch: 1420, Minibatch Loss= 1.5161, Training Accuracy= 0.501\n",
      "Epoch: 1430, Minibatch Loss= 1.5161, Training Accuracy= 0.501\n",
      "Epoch: 1440, Minibatch Loss= 1.5161, Training Accuracy= 0.501\n",
      "Epoch: 1450, Minibatch Loss= 1.5161, Training Accuracy= 0.501\n",
      "Epoch: 1460, Minibatch Loss= 1.5161, Training Accuracy= 0.501\n",
      "Epoch: 1470, Minibatch Loss= 1.5161, Training Accuracy= 0.501\n",
      "Epoch: 1480, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1490, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1500, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1510, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1520, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1530, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1540, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1550, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1560, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1570, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1580, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1590, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1600, Minibatch Loss= 1.5162, Training Accuracy= 0.501\n",
      "Epoch: 1610, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1620, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1630, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1640, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1650, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1660, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1670, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1680, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1690, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1700, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1710, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1720, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1730, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1740, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1750, Minibatch Loss= 1.5163, Training Accuracy= 0.501\n",
      "Epoch: 1760, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1770, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1780, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1790, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1800, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1810, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1820, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1830, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1840, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1850, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1860, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1870, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1880, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1890, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1900, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1910, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1920, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1930, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1940, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1950, Minibatch Loss= 1.5164, Training Accuracy= 0.501\n",
      "Epoch: 1960, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 1970, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 1980, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 1990, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2000, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2010, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2020, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2030, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2040, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2050, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2060, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2070, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2080, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2090, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2100, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2110, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2120, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2130, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2140, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2150, Minibatch Loss= 1.5165, Training Accuracy= 0.501\n",
      "Epoch: 2160, Minibatch Loss= 1.5166, Training Accuracy= 0.501\n",
      "Epoch: 2170, Minibatch Loss= 1.5166, Training Accuracy= 0.501\n",
      "Epoch: 2180, Minibatch Loss= 1.5166, Training Accuracy= 0.501\n",
      "Epoch: 2190, Minibatch Loss= 1.5166, Training Accuracy= 0.501\n",
      "Epoch: 2200, Minibatch Loss= 1.5166, Training Accuracy= 0.501\n",
      "Epoch: 2210, Minibatch Loss= 1.5166, Training Accuracy= 0.501\n",
      "Epoch: 2220, Minibatch Loss= 1.5166, Training Accuracy= 0.501\n",
      "Epoch: 2230, Minibatch Loss= 1.5166, Training Accuracy= 0.501\n",
      "Epoch: 2240, Minibatch Loss= 1.5166, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2250, Minibatch Loss= 1.5166, Training Accuracy= 0.501\n",
      "Epoch: 2260, Minibatch Loss= 1.5167, Training Accuracy= 0.501\n",
      "Epoch: 2270, Minibatch Loss= 1.5167, Training Accuracy= 0.501\n",
      "Epoch: 2280, Minibatch Loss= 1.5167, Training Accuracy= 0.501\n",
      "Epoch: 2290, Minibatch Loss= 1.5168, Training Accuracy= 0.501\n",
      "Epoch: 2300, Minibatch Loss= 1.5169, Training Accuracy= 0.501\n",
      "Epoch: 2310, Minibatch Loss= 1.5170, Training Accuracy= 0.501\n",
      "Epoch: 2320, Minibatch Loss= 1.5171, Training Accuracy= 0.501\n",
      "Epoch: 2330, Minibatch Loss= 1.5174, Training Accuracy= 0.501\n",
      "Epoch: 2340, Minibatch Loss= 1.5179, Training Accuracy= 0.501\n",
      "Epoch: 2350, Minibatch Loss= 1.5185, Training Accuracy= 0.501\n",
      "Epoch: 2360, Minibatch Loss= 1.5188, Training Accuracy= 0.501\n",
      "Epoch: 2370, Minibatch Loss= 1.5189, Training Accuracy= 0.501\n",
      "Epoch: 2380, Minibatch Loss= 1.5190, Training Accuracy= 0.501\n",
      "Epoch: 2390, Minibatch Loss= 1.5190, Training Accuracy= 0.501\n",
      "Epoch: 2400, Minibatch Loss= 1.5191, Training Accuracy= 0.501\n",
      "Epoch: 2410, Minibatch Loss= 1.5191, Training Accuracy= 0.501\n",
      "Epoch: 2420, Minibatch Loss= 1.5191, Training Accuracy= 0.501\n",
      "Epoch: 2430, Minibatch Loss= 1.5192, Training Accuracy= 0.501\n",
      "Epoch: 2440, Minibatch Loss= 1.5192, Training Accuracy= 0.501\n",
      "Epoch: 2450, Minibatch Loss= 1.5193, Training Accuracy= 0.501\n",
      "Epoch: 2460, Minibatch Loss= 1.5193, Training Accuracy= 0.501\n",
      "Epoch: 2470, Minibatch Loss= 1.5193, Training Accuracy= 0.501\n",
      "Epoch: 2480, Minibatch Loss= 1.5193, Training Accuracy= 0.501\n",
      "Epoch: 2490, Minibatch Loss= 1.5194, Training Accuracy= 0.501\n",
      "Epoch: 2500, Minibatch Loss= 1.5194, Training Accuracy= 0.501\n",
      "Epoch: 2510, Minibatch Loss= 1.5194, Training Accuracy= 0.501\n",
      "Epoch: 2520, Minibatch Loss= 1.5194, Training Accuracy= 0.501\n",
      "Epoch: 2530, Minibatch Loss= 1.5194, Training Accuracy= 0.501\n",
      "Epoch: 2540, Minibatch Loss= 1.5194, Training Accuracy= 0.501\n",
      "Epoch: 2550, Minibatch Loss= 1.5195, Training Accuracy= 0.501\n",
      "Epoch: 2560, Minibatch Loss= 1.5195, Training Accuracy= 0.501\n",
      "Epoch: 2570, Minibatch Loss= 1.5195, Training Accuracy= 0.501\n",
      "Epoch: 2580, Minibatch Loss= 1.5195, Training Accuracy= 0.501\n",
      "Epoch: 2590, Minibatch Loss= 1.5195, Training Accuracy= 0.501\n",
      "Epoch: 2600, Minibatch Loss= 1.5195, Training Accuracy= 0.501\n",
      "Epoch: 2610, Minibatch Loss= 1.5195, Training Accuracy= 0.501\n",
      "Epoch: 2620, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2630, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2640, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2650, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2660, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2670, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2680, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2690, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2700, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2710, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2720, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2730, Minibatch Loss= 1.5196, Training Accuracy= 0.501\n",
      "Epoch: 2740, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2750, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2760, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2770, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2780, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2790, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2800, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2810, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2820, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2830, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2840, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2850, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2860, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2870, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2880, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2890, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2900, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2910, Minibatch Loss= 1.5197, Training Accuracy= 0.501\n",
      "Epoch: 2920, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 2930, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 2940, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 2950, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 2960, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 2970, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 2980, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 2990, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3000, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3010, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3020, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3030, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3040, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3050, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3060, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3070, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3080, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3090, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3100, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3110, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3120, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3130, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3140, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3150, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3160, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3170, Minibatch Loss= 1.5198, Training Accuracy= 0.501\n",
      "Epoch: 3180, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3190, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3200, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3210, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3220, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3230, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3240, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3250, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3260, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3270, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3280, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3290, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3300, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3310, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3320, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3330, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3340, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3350, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3360, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3370, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3380, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3390, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3400, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3410, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3420, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3430, Minibatch Loss= 1.5199, Training Accuracy= 0.501\n",
      "Epoch: 3440, Minibatch Loss= 1.5200, Training Accuracy= 0.501\n",
      "Epoch: 3450, Minibatch Loss= 1.5200, Training Accuracy= 0.501\n",
      "Epoch: 3460, Minibatch Loss= 1.5200, Training Accuracy= 0.501\n",
      "Epoch: 3470, Minibatch Loss= 1.5200, Training Accuracy= 0.501\n",
      "Epoch: 3480, Minibatch Loss= 1.5200, Training Accuracy= 0.501\n",
      "Epoch: 3490, Minibatch Loss= 1.5200, Training Accuracy= 0.501\n",
      "Epoch: 3500, Minibatch Loss= 1.5200, Training Accuracy= 0.501\n",
      "Epoch: 3510, Minibatch Loss= 1.5201, Training Accuracy= 0.501\n",
      "Epoch: 3520, Minibatch Loss= 1.5201, Training Accuracy= 0.501\n",
      "Epoch: 3530, Minibatch Loss= 1.5201, Training Accuracy= 0.501\n",
      "Epoch: 3540, Minibatch Loss= 1.5201, Training Accuracy= 0.501\n",
      "Epoch: 3550, Minibatch Loss= 1.5201, Training Accuracy= 0.501\n",
      "Epoch: 3560, Minibatch Loss= 1.5201, Training Accuracy= 0.501\n",
      "Epoch: 3570, Minibatch Loss= 1.5201, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3580, Minibatch Loss= 1.5201, Training Accuracy= 0.501\n",
      "Epoch: 3590, Minibatch Loss= 1.5202, Training Accuracy= 0.501\n",
      "Epoch: 3600, Minibatch Loss= 1.5202, Training Accuracy= 0.501\n",
      "Epoch: 3610, Minibatch Loss= 1.5202, Training Accuracy= 0.501\n",
      "Epoch: 3620, Minibatch Loss= 1.5203, Training Accuracy= 0.501\n",
      "Epoch: 3630, Minibatch Loss= 1.5204, Training Accuracy= 0.501\n",
      "Epoch: 3640, Minibatch Loss= 1.5206, Training Accuracy= 0.501\n",
      "Epoch: 3650, Minibatch Loss= 1.5209, Training Accuracy= 0.501\n",
      "Epoch: 3660, Minibatch Loss= 1.5212, Training Accuracy= 0.501\n",
      "Epoch: 3670, Minibatch Loss= 1.5213, Training Accuracy= 0.501\n",
      "Epoch: 3680, Minibatch Loss= 1.5214, Training Accuracy= 0.501\n",
      "Epoch: 3690, Minibatch Loss= 1.5215, Training Accuracy= 0.501\n",
      "Epoch: 3700, Minibatch Loss= 1.5215, Training Accuracy= 0.501\n",
      "Epoch: 3710, Minibatch Loss= 1.5215, Training Accuracy= 0.501\n",
      "Epoch: 3720, Minibatch Loss= 1.5215, Training Accuracy= 0.501\n",
      "Epoch: 3730, Minibatch Loss= 1.5216, Training Accuracy= 0.501\n",
      "Epoch: 3740, Minibatch Loss= 1.5216, Training Accuracy= 0.501\n",
      "Epoch: 3750, Minibatch Loss= 1.5216, Training Accuracy= 0.501\n",
      "Epoch: 3760, Minibatch Loss= 1.5216, Training Accuracy= 0.501\n",
      "Epoch: 3770, Minibatch Loss= 1.5216, Training Accuracy= 0.501\n",
      "Epoch: 3780, Minibatch Loss= 1.5216, Training Accuracy= 0.501\n",
      "Epoch: 3790, Minibatch Loss= 1.5216, Training Accuracy= 0.501\n",
      "Epoch: 3800, Minibatch Loss= 1.5217, Training Accuracy= 0.501\n",
      "Epoch: 3810, Minibatch Loss= 1.5217, Training Accuracy= 0.501\n",
      "Epoch: 3820, Minibatch Loss= 1.5217, Training Accuracy= 0.501\n",
      "Epoch: 3830, Minibatch Loss= 1.5217, Training Accuracy= 0.501\n",
      "Epoch: 3840, Minibatch Loss= 1.5217, Training Accuracy= 0.501\n",
      "Epoch: 3850, Minibatch Loss= 1.5217, Training Accuracy= 0.501\n",
      "Epoch: 3860, Minibatch Loss= 1.5217, Training Accuracy= 0.501\n",
      "Epoch: 3870, Minibatch Loss= 1.5217, Training Accuracy= 0.501\n",
      "Epoch: 3880, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3890, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3900, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3910, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3920, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3930, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3940, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3950, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3960, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3970, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3980, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 3990, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 4000, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 4010, Minibatch Loss= 1.5218, Training Accuracy= 0.501\n",
      "Epoch: 4020, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4030, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4040, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4050, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4060, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4070, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4080, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4090, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4100, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4110, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4120, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4130, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4140, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4150, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4160, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4170, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4180, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4190, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4200, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4210, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4220, Minibatch Loss= 1.5219, Training Accuracy= 0.501\n",
      "Epoch: 4230, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4240, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4250, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4260, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4270, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4280, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4290, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4300, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4310, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4320, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4330, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4340, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4350, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4360, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4370, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4380, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4390, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4400, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4410, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4420, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4430, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4440, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4450, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4460, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4470, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4480, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4490, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4500, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4510, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4520, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4530, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4540, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4550, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4560, Minibatch Loss= 1.5220, Training Accuracy= 0.501\n",
      "Epoch: 4570, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4580, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4590, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4600, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4610, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4620, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4630, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4640, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4650, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4660, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4670, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4680, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4690, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4700, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4710, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4720, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4730, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4740, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4750, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4760, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4770, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4780, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4790, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4800, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4810, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4820, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4830, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4840, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4850, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4860, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4870, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4880, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4890, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4900, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4910, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4920, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4930, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4940, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4950, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4960, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4970, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4980, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Epoch: 4990, Minibatch Loss= 1.5221, Training Accuracy= 0.501\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4944\n",
      "Replication: 8: \n",
      "Epoch: 0, Minibatch Loss= 0.9583, Training Accuracy= 0.491\n",
      "Epoch: 10, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 20, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 30, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 40, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 50, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 60, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 70, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 80, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 90, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 100, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 110, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 120, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 130, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 140, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 150, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 160, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 170, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 180, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 190, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 200, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 210, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 220, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 230, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 240, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 250, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 260, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 270, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 280, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 290, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 300, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 310, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 320, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 330, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 340, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 350, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 360, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 370, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 380, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 390, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 400, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 410, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 420, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 430, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 440, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 450, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 460, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 470, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 480, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 490, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 500, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 510, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 520, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 530, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 540, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 550, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 560, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 570, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 580, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 590, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 600, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 610, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 620, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 630, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 640, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 650, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 660, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 670, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 680, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 690, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 700, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 710, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 720, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 730, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 740, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 750, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 760, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 770, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 780, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 790, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 800, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 810, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 820, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 830, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 840, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 850, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 860, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 870, Minibatch Loss= 0.9570, Training Accuracy= 0.491\n",
      "Epoch: 880, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 890, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 900, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 910, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 920, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 930, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 940, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 950, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 960, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 970, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 980, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 990, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1000, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1010, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1020, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1030, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1040, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1050, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1060, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1070, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1080, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1090, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1100, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1110, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1120, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1130, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1140, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1150, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1160, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1170, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1180, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1190, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1200, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1210, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1220, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1230, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1240, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1250, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1260, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1270, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1280, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1290, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1300, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1310, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1320, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1330, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1340, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1350, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1360, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1370, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1380, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1390, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1400, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1410, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1420, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1430, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1440, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1450, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1460, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1470, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1480, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1490, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1500, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1510, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1520, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1530, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1540, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1550, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1560, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1570, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1580, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1590, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1600, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1610, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1620, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1630, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1640, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1650, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1660, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1670, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1680, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1690, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1700, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1710, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1720, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1730, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1740, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1750, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1760, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1770, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1780, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1790, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1800, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1810, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1820, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1830, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1840, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1850, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1860, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1870, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1880, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1890, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1900, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1910, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1920, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1930, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1940, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1950, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1960, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1970, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1980, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 1990, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2000, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2010, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2020, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2030, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2040, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2050, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2060, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2070, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2080, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2090, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2100, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2110, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2120, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2130, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2140, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2150, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2160, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2170, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2180, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2190, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2200, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2210, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2220, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2230, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2240, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2250, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2260, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2270, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2280, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2290, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2300, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2310, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2320, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2330, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2340, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2350, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2360, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2370, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2380, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2390, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2400, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2410, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2420, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2430, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2440, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2450, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2460, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2470, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2480, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2490, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2500, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2510, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2520, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2530, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2540, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2550, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2560, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2570, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2580, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2590, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2600, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2610, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2620, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2630, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2640, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2650, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2660, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2670, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2680, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2690, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2700, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2710, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2720, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2730, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2740, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2750, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2760, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2770, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2780, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2790, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2800, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2810, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2820, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2830, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2840, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2850, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2860, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2870, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2880, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2890, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2900, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2910, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2920, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2930, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2940, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2950, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2960, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2970, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2980, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 2990, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3000, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3010, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3020, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3030, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3040, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3050, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3060, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3070, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3080, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3090, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3100, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3110, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3120, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3130, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3140, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3150, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3160, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3170, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3180, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3190, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3200, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3210, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3220, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3230, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3240, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3250, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3260, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3270, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3280, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3290, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3300, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3310, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3320, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3330, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3340, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3350, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3360, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3370, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3380, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3390, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3400, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3410, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3420, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3430, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3440, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3450, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3460, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3470, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3480, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3490, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3500, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3510, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3520, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3530, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3540, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3550, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3560, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3570, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3580, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3590, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3600, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3610, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3620, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3630, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3640, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3650, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3660, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3670, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3680, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3690, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3700, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3710, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3720, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3730, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3740, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3750, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3760, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3770, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3780, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3790, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3800, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3810, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3820, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3830, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3840, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3850, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3860, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3870, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3880, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3890, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3900, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3910, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3920, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3930, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3940, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3950, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3960, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3970, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3980, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 3990, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4000, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4010, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4020, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4030, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4040, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4050, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4060, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4070, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4080, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4090, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4100, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4110, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4120, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4130, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4140, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4150, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4160, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4170, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4180, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4190, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4200, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4210, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4220, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4230, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4240, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4250, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4260, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4270, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4280, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4290, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4300, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4310, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4320, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4330, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4340, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4350, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4360, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4370, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4380, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4390, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4400, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4410, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4420, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4430, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4440, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4450, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4460, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4470, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4480, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4490, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4500, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4510, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4520, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4530, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4540, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4550, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4560, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4570, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4580, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4590, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4600, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4610, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4620, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4630, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4640, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4650, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4660, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4670, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4680, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4690, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4700, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4710, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4720, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4730, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4740, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4750, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4760, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4770, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4780, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4790, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4800, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4810, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4820, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4830, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4840, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4850, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4860, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4870, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4880, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4890, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4900, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4910, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4920, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4930, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4940, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4950, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4960, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4970, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4980, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Epoch: 4990, Minibatch Loss= 0.9571, Training Accuracy= 0.491\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4991\n",
      "Replication: 9: \n",
      "Epoch: 0, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 10, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 20, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 30, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 40, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 50, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 60, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 70, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 80, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 90, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 100, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 110, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 120, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 130, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 140, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 150, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 160, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 170, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 180, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 190, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 200, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 210, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 230, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 240, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 250, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 260, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 270, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 280, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 290, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 300, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 310, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 320, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 330, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 340, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 350, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 360, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 370, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 380, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 390, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 400, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 410, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 420, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 430, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 440, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 450, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 460, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 470, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 480, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 490, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 500, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 510, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 520, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 530, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 540, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 550, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 560, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 570, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 580, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 590, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 600, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 610, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 620, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 630, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 640, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 650, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 660, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 670, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 680, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 690, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 700, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 710, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 720, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 730, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 740, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 750, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 760, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 770, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 780, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 790, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 800, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 810, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 820, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 830, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 840, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 850, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 860, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 870, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 880, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 890, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 900, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 910, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 920, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 930, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 940, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 950, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 960, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 970, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 980, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 990, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1000, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1010, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1020, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1030, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1040, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1050, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1060, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1070, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1080, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1090, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1100, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1110, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1120, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1130, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1140, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1150, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1160, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1170, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1180, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1190, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1200, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1210, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1220, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1230, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1240, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1250, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1260, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1270, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1280, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1290, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1300, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1310, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1320, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1330, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1340, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1350, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1360, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1370, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1380, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1390, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1400, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1410, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1420, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1430, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1440, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1450, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1460, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1470, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1480, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1490, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1500, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1510, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1520, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1530, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1540, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1550, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1560, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1570, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1580, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1590, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1600, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1610, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1620, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1630, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1640, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1650, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1660, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1670, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1680, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1690, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1700, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1710, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1720, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1730, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1740, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1750, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1760, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1770, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1780, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1790, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1800, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1810, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1820, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1830, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1840, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1850, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1860, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1870, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1880, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1890, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1900, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1910, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1920, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1930, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1940, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1950, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1960, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1970, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1980, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 1990, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2000, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2010, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2020, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2030, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2040, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2050, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2060, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2070, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2080, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2090, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2100, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2110, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2120, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2130, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2140, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2150, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2160, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2170, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2180, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2190, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2200, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2210, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2220, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2230, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2240, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2250, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2260, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2270, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2280, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2290, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2300, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2310, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2320, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2330, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2340, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2350, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2360, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2370, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2380, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2390, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2400, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2410, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2420, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2430, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2440, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2450, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2460, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2470, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2480, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2490, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2500, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2510, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2520, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 2530, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2540, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2550, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2560, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2570, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2580, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2590, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2600, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2610, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2620, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2630, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2640, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2650, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2660, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2670, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2680, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2690, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2700, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2710, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2720, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2730, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2740, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2750, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2760, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2770, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2780, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2790, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2800, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2810, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2820, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2830, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2840, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2850, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2860, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2870, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2880, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2890, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2900, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2910, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2920, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2930, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2940, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2950, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2960, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2970, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2980, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 2990, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3000, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3010, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3020, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3030, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3040, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3050, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3060, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3070, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3080, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3090, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3100, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3110, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3120, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3130, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3140, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3150, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3160, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3170, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3180, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3190, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3200, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3210, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3220, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3230, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3240, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3250, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3260, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3270, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3280, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3290, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3300, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3310, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3320, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3330, Minibatch Loss= 0.8573, Training Accuracy= 0.496\n",
      "Epoch: 3340, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 3350, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 3360, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 3370, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 3380, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 3390, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 3400, Minibatch Loss= 0.8574, Training Accuracy= 0.496\n",
      "Epoch: 3410, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3420, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3430, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3440, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3450, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3460, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3470, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3480, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3490, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3500, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3510, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3520, Minibatch Loss= 0.8575, Training Accuracy= 0.496\n",
      "Epoch: 3530, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3540, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3550, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3560, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3570, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3580, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3590, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3600, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3610, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3620, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3630, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3640, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3650, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3660, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3670, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3680, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3690, Minibatch Loss= 0.8576, Training Accuracy= 0.496\n",
      "Epoch: 3700, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3710, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3720, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3730, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3740, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3750, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3760, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3770, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3780, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3790, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3800, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3810, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3820, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3830, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3840, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3850, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3860, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3870, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3880, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3890, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3900, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3910, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3920, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3930, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3940, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3950, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3960, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3970, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3980, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 3990, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 4000, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 4010, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 4020, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 4030, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 4040, Minibatch Loss= 0.8577, Training Accuracy= 0.496\n",
      "Epoch: 4050, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4060, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4070, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4080, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4090, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4100, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4110, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4120, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4130, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4140, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4150, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4160, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4170, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4180, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4190, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4200, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4210, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4220, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4230, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4240, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4250, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4260, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4270, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4280, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4290, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4300, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4310, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4320, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4330, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4340, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4350, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4360, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4370, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4380, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4390, Minibatch Loss= 0.8578, Training Accuracy= 0.496\n",
      "Epoch: 4400, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4410, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4420, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4430, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4440, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4450, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4460, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4470, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4480, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4490, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4500, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4510, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4520, Minibatch Loss= 0.8579, Training Accuracy= 0.496\n",
      "Epoch: 4530, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4540, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4550, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4560, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4570, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4580, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4590, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4600, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4610, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4620, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4630, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4640, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4650, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4660, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4670, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4680, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4690, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4700, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4710, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4720, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4730, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4740, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4750, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4760, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4770, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4780, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4790, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4800, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4810, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4820, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4830, Minibatch Loss= 0.8580, Training Accuracy= 0.496\n",
      "Epoch: 4840, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4850, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4860, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4870, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4880, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4890, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4900, Minibatch Loss= 0.8581, Training Accuracy= 0.496\n",
      "Epoch: 4910, Minibatch Loss= 0.8582, Training Accuracy= 0.496\n",
      "Epoch: 4920, Minibatch Loss= 0.8582, Training Accuracy= 0.496\n",
      "Epoch: 4930, Minibatch Loss= 0.8582, Training Accuracy= 0.496\n",
      "Epoch: 4940, Minibatch Loss= 0.8582, Training Accuracy= 0.496\n",
      "Epoch: 4950, Minibatch Loss= 0.8582, Training Accuracy= 0.496\n",
      "Epoch: 4960, Minibatch Loss= 0.8582, Training Accuracy= 0.496\n",
      "Epoch: 4970, Minibatch Loss= 0.8582, Training Accuracy= 0.496\n",
      "Epoch: 4980, Minibatch Loss= 0.8582, Training Accuracy= 0.496\n",
      "Epoch: 4990, Minibatch Loss= 0.8582, Training Accuracy= 0.496\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5015\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 7.85\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 5000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "minibatch_losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                minibatch_losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [0.50029999, 0.49779999, 0.50160003, 0.49829999, 0.51069999, 0.49849999, 0.50370002, 0.49439999, 0.4991, 0.50150001]\n",
      "mean of test_accuracies_10replications:  0.50059\n",
      "standard deviation of test_accuracies_10replications_std_mean:  4.14426298812e-05\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEoCAYAAABPQRaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njoiIGJRkHBERMSj/H7YNHvOyG+GgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb93e995750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minibatch_losses_1st_replication\n",
    "plt.plot(minibatch_losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, minibacth loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
