{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 50\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 10, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 20, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 30, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 40, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 50, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 60, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 70, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 80, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 90, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 100, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 110, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 120, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 130, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 140, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 150, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 160, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 170, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 180, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 190, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 200, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 210, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 220, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 230, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 240, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 250, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 260, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 270, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 280, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 290, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 300, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 310, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 320, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 330, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 340, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 350, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 360, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 370, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 380, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 390, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 400, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 410, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 420, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 430, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 440, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 450, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 460, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 470, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 480, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 490, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 500, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 510, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 520, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 530, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 540, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 550, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 560, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 570, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 580, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 590, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 600, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 610, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 620, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 630, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 640, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 650, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 660, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 670, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 680, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 690, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 700, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 710, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 720, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 730, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 740, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 750, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 760, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 770, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 780, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 790, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 800, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 810, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 820, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 830, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 840, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 850, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 860, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 870, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 880, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 890, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 900, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 910, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 920, Minibatch Loss= 2.3469, Training Accuracy= 0.499\n",
      "Epoch: 930, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 940, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 950, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 960, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 970, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 980, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 990, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1000, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1010, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1020, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1030, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1040, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1050, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1060, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1070, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1080, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1090, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1100, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1110, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1120, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1130, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1140, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1150, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1160, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1170, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1180, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1190, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1200, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1210, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1220, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1230, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1240, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1250, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1260, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1270, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1280, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1290, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1300, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1310, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1320, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1330, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1350, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1360, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1370, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1380, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1390, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1400, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1410, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1420, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1430, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1440, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1450, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1460, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1470, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1480, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1490, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1500, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1510, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1520, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1530, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1540, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1550, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1560, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1570, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1580, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1590, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1600, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1610, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1620, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1630, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1640, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1650, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1660, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1670, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1680, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1690, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1700, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1710, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1720, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1730, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1740, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1750, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1760, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1770, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1780, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1790, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1800, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1810, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1820, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1830, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1840, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1850, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1860, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1870, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1880, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1890, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1900, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1910, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1920, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1930, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1940, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1950, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1960, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1970, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1980, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 1990, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2000, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2010, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2020, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2030, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2040, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2050, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2060, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2070, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2080, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2090, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2100, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2110, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2120, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2130, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2140, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2150, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2160, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2170, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2180, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2190, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2200, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2210, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2220, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2230, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2240, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2250, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2260, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2270, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2280, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2290, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2300, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2310, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2320, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2330, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2340, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2350, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2360, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2370, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2380, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2390, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2400, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2410, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2420, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2430, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2440, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2450, Minibatch Loss= 2.3470, Training Accuracy= 0.499\n",
      "Epoch: 2460, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2470, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2480, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2490, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2500, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2510, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2520, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2530, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2540, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2550, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2560, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2570, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2580, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2590, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2600, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2610, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2620, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2630, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2640, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2650, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2660, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2670, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2680, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2690, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2700, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2710, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2720, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2730, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2740, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2750, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2760, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2770, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2780, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2790, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2800, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2810, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2820, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2830, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2840, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2850, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2860, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2870, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2880, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2890, Minibatch Loss= 2.3471, Training Accuracy= 0.499\n",
      "Epoch: 2900, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 2910, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 2920, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 2930, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 2940, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 2950, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 2960, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 2970, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 2980, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 2990, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3000, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3010, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3020, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3030, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3040, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3050, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3060, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3070, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3080, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3090, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3100, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3110, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3120, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3130, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3140, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3150, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3160, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3170, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3180, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3190, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3200, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3210, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3220, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3230, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3240, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3250, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3260, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3270, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3280, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3290, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3300, Minibatch Loss= 2.3472, Training Accuracy= 0.499\n",
      "Epoch: 3310, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3320, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3330, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3340, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3350, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3360, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3370, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3380, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3390, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3400, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3410, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3420, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3430, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3440, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3450, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3460, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3470, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3480, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3490, Minibatch Loss= 2.3473, Training Accuracy= 0.499\n",
      "Epoch: 3500, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3510, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3520, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3530, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3540, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3550, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3560, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3570, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3580, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3590, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3600, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3610, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3620, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3630, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3640, Minibatch Loss= 2.3474, Training Accuracy= 0.499\n",
      "Epoch: 3650, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3660, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3670, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3680, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3690, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3700, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3710, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3720, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3730, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3740, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3750, Minibatch Loss= 2.3475, Training Accuracy= 0.499\n",
      "Epoch: 3760, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3770, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3780, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3790, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3800, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3810, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3820, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3830, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3840, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3850, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3860, Minibatch Loss= 2.3476, Training Accuracy= 0.499\n",
      "Epoch: 3870, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3880, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3890, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3900, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3910, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3920, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3930, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3940, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3950, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3960, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3970, Minibatch Loss= 2.3477, Training Accuracy= 0.499\n",
      "Epoch: 3980, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 3990, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 4010, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 4020, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 4030, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 4040, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 4050, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 4060, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 4070, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 4080, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 4090, Minibatch Loss= 2.3478, Training Accuracy= 0.499\n",
      "Epoch: 4100, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4110, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4120, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4130, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4140, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4150, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4160, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4170, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4180, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4190, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4200, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4210, Minibatch Loss= 2.3479, Training Accuracy= 0.499\n",
      "Epoch: 4220, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4230, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4240, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4250, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4260, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4270, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4280, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4290, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4300, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4310, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4320, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4330, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4340, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4350, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4360, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4370, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4380, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4390, Minibatch Loss= 2.3480, Training Accuracy= 0.499\n",
      "Epoch: 4400, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4410, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4420, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4430, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4440, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4450, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4460, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4470, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4480, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4490, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4500, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4510, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4520, Minibatch Loss= 2.3481, Training Accuracy= 0.499\n",
      "Epoch: 4530, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4540, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4550, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4560, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4570, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4580, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4590, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4600, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4610, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4620, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4630, Minibatch Loss= 2.3482, Training Accuracy= 0.499\n",
      "Epoch: 4640, Minibatch Loss= 2.3483, Training Accuracy= 0.499\n",
      "Epoch: 4650, Minibatch Loss= 2.3483, Training Accuracy= 0.499\n",
      "Epoch: 4660, Minibatch Loss= 2.3483, Training Accuracy= 0.499\n",
      "Epoch: 4670, Minibatch Loss= 2.3483, Training Accuracy= 0.499\n",
      "Epoch: 4680, Minibatch Loss= 2.3483, Training Accuracy= 0.499\n",
      "Epoch: 4690, Minibatch Loss= 2.3483, Training Accuracy= 0.499\n",
      "Epoch: 4700, Minibatch Loss= 2.3484, Training Accuracy= 0.499\n",
      "Epoch: 4710, Minibatch Loss= 2.3484, Training Accuracy= 0.499\n",
      "Epoch: 4720, Minibatch Loss= 2.3484, Training Accuracy= 0.499\n",
      "Epoch: 4730, Minibatch Loss= 2.3484, Training Accuracy= 0.499\n",
      "Epoch: 4740, Minibatch Loss= 2.3485, Training Accuracy= 0.499\n",
      "Epoch: 4750, Minibatch Loss= 2.3485, Training Accuracy= 0.499\n",
      "Epoch: 4760, Minibatch Loss= 2.3485, Training Accuracy= 0.499\n",
      "Epoch: 4770, Minibatch Loss= 2.3486, Training Accuracy= 0.499\n",
      "Epoch: 4780, Minibatch Loss= 2.3486, Training Accuracy= 0.499\n",
      "Epoch: 4790, Minibatch Loss= 2.3486, Training Accuracy= 0.499\n",
      "Epoch: 4800, Minibatch Loss= 2.3487, Training Accuracy= 0.499\n",
      "Epoch: 4810, Minibatch Loss= 2.3487, Training Accuracy= 0.499\n",
      "Epoch: 4820, Minibatch Loss= 2.3488, Training Accuracy= 0.499\n",
      "Epoch: 4830, Minibatch Loss= 2.3488, Training Accuracy= 0.499\n",
      "Epoch: 4840, Minibatch Loss= 2.3488, Training Accuracy= 0.499\n",
      "Epoch: 4850, Minibatch Loss= 2.3488, Training Accuracy= 0.499\n",
      "Epoch: 4860, Minibatch Loss= 2.3489, Training Accuracy= 0.499\n",
      "Epoch: 4870, Minibatch Loss= 2.3489, Training Accuracy= 0.499\n",
      "Epoch: 4880, Minibatch Loss= 2.3489, Training Accuracy= 0.499\n",
      "Epoch: 4890, Minibatch Loss= 2.3489, Training Accuracy= 0.499\n",
      "Epoch: 4900, Minibatch Loss= 2.3490, Training Accuracy= 0.499\n",
      "Epoch: 4910, Minibatch Loss= 2.3490, Training Accuracy= 0.499\n",
      "Epoch: 4920, Minibatch Loss= 2.3490, Training Accuracy= 0.499\n",
      "Epoch: 4930, Minibatch Loss= 2.3490, Training Accuracy= 0.499\n",
      "Epoch: 4940, Minibatch Loss= 2.3490, Training Accuracy= 0.499\n",
      "Epoch: 4950, Minibatch Loss= 2.3490, Training Accuracy= 0.499\n",
      "Epoch: 4960, Minibatch Loss= 2.3491, Training Accuracy= 0.499\n",
      "Epoch: 4970, Minibatch Loss= 2.3491, Training Accuracy= 0.499\n",
      "Epoch: 4980, Minibatch Loss= 2.3490, Training Accuracy= 0.499\n",
      "Epoch: 4990, Minibatch Loss= 2.3491, Training Accuracy= 0.499\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5003\n",
      "Replication: 1: \n",
      "Epoch: 0, Minibatch Loss= 2.0916, Training Accuracy= 0.499\n",
      "Epoch: 10, Minibatch Loss= 2.0917, Training Accuracy= 0.499\n",
      "Epoch: 20, Minibatch Loss= 2.0918, Training Accuracy= 0.499\n",
      "Epoch: 30, Minibatch Loss= 2.0919, Training Accuracy= 0.499\n",
      "Epoch: 40, Minibatch Loss= 2.0919, Training Accuracy= 0.499\n",
      "Epoch: 50, Minibatch Loss= 2.0920, Training Accuracy= 0.499\n",
      "Epoch: 60, Minibatch Loss= 2.0920, Training Accuracy= 0.499\n",
      "Epoch: 70, Minibatch Loss= 2.0920, Training Accuracy= 0.499\n",
      "Epoch: 80, Minibatch Loss= 2.0920, Training Accuracy= 0.499\n",
      "Epoch: 90, Minibatch Loss= 2.0920, Training Accuracy= 0.499\n",
      "Epoch: 100, Minibatch Loss= 2.0920, Training Accuracy= 0.499\n",
      "Epoch: 110, Minibatch Loss= 2.0920, Training Accuracy= 0.499\n",
      "Epoch: 120, Minibatch Loss= 2.0921, Training Accuracy= 0.499\n",
      "Epoch: 130, Minibatch Loss= 2.0921, Training Accuracy= 0.499\n",
      "Epoch: 140, Minibatch Loss= 2.0921, Training Accuracy= 0.499\n",
      "Epoch: 150, Minibatch Loss= 2.0921, Training Accuracy= 0.499\n",
      "Epoch: 160, Minibatch Loss= 2.0921, Training Accuracy= 0.499\n",
      "Epoch: 170, Minibatch Loss= 2.0921, Training Accuracy= 0.499\n",
      "Epoch: 180, Minibatch Loss= 2.0921, Training Accuracy= 0.499\n",
      "Epoch: 190, Minibatch Loss= 2.0921, Training Accuracy= 0.499\n",
      "Epoch: 200, Minibatch Loss= 2.0921, Training Accuracy= 0.499\n",
      "Epoch: 210, Minibatch Loss= 2.0921, Training Accuracy= 0.499\n",
      "Epoch: 220, Minibatch Loss= 2.0922, Training Accuracy= 0.499\n",
      "Epoch: 230, Minibatch Loss= 2.0922, Training Accuracy= 0.499\n",
      "Epoch: 240, Minibatch Loss= 2.0922, Training Accuracy= 0.499\n",
      "Epoch: 250, Minibatch Loss= 2.0922, Training Accuracy= 0.499\n",
      "Epoch: 260, Minibatch Loss= 2.0922, Training Accuracy= 0.499\n",
      "Epoch: 270, Minibatch Loss= 2.0922, Training Accuracy= 0.499\n",
      "Epoch: 280, Minibatch Loss= 2.0922, Training Accuracy= 0.499\n",
      "Epoch: 290, Minibatch Loss= 2.0922, Training Accuracy= 0.499\n",
      "Epoch: 300, Minibatch Loss= 2.0922, Training Accuracy= 0.499\n",
      "Epoch: 310, Minibatch Loss= 2.0922, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320, Minibatch Loss= 2.0923, Training Accuracy= 0.499\n",
      "Epoch: 330, Minibatch Loss= 2.0923, Training Accuracy= 0.499\n",
      "Epoch: 340, Minibatch Loss= 2.0923, Training Accuracy= 0.499\n",
      "Epoch: 350, Minibatch Loss= 2.0923, Training Accuracy= 0.499\n",
      "Epoch: 360, Minibatch Loss= 2.0923, Training Accuracy= 0.499\n",
      "Epoch: 370, Minibatch Loss= 2.0923, Training Accuracy= 0.499\n",
      "Epoch: 380, Minibatch Loss= 2.0923, Training Accuracy= 0.499\n",
      "Epoch: 390, Minibatch Loss= 2.0924, Training Accuracy= 0.499\n",
      "Epoch: 400, Minibatch Loss= 2.0924, Training Accuracy= 0.499\n",
      "Epoch: 410, Minibatch Loss= 2.0924, Training Accuracy= 0.499\n",
      "Epoch: 420, Minibatch Loss= 2.0924, Training Accuracy= 0.499\n",
      "Epoch: 430, Minibatch Loss= 2.0924, Training Accuracy= 0.499\n",
      "Epoch: 440, Minibatch Loss= 2.0925, Training Accuracy= 0.499\n",
      "Epoch: 450, Minibatch Loss= 2.0925, Training Accuracy= 0.499\n",
      "Epoch: 460, Minibatch Loss= 2.0925, Training Accuracy= 0.499\n",
      "Epoch: 470, Minibatch Loss= 2.0925, Training Accuracy= 0.499\n",
      "Epoch: 480, Minibatch Loss= 2.0926, Training Accuracy= 0.499\n",
      "Epoch: 490, Minibatch Loss= 2.0926, Training Accuracy= 0.499\n",
      "Epoch: 500, Minibatch Loss= 2.0926, Training Accuracy= 0.499\n",
      "Epoch: 510, Minibatch Loss= 2.0927, Training Accuracy= 0.499\n",
      "Epoch: 520, Minibatch Loss= 2.0927, Training Accuracy= 0.499\n",
      "Epoch: 530, Minibatch Loss= 2.0928, Training Accuracy= 0.499\n",
      "Epoch: 540, Minibatch Loss= 2.0928, Training Accuracy= 0.499\n",
      "Epoch: 550, Minibatch Loss= 2.0929, Training Accuracy= 0.499\n",
      "Epoch: 560, Minibatch Loss= 2.0929, Training Accuracy= 0.499\n",
      "Epoch: 570, Minibatch Loss= 2.0930, Training Accuracy= 0.499\n",
      "Epoch: 580, Minibatch Loss= 2.0931, Training Accuracy= 0.499\n",
      "Epoch: 590, Minibatch Loss= 2.0931, Training Accuracy= 0.499\n",
      "Epoch: 600, Minibatch Loss= 2.0932, Training Accuracy= 0.499\n",
      "Epoch: 610, Minibatch Loss= 2.0932, Training Accuracy= 0.499\n",
      "Epoch: 620, Minibatch Loss= 2.0932, Training Accuracy= 0.499\n",
      "Epoch: 630, Minibatch Loss= 2.0933, Training Accuracy= 0.499\n",
      "Epoch: 640, Minibatch Loss= 2.0933, Training Accuracy= 0.499\n",
      "Epoch: 650, Minibatch Loss= 2.0933, Training Accuracy= 0.499\n",
      "Epoch: 660, Minibatch Loss= 2.0933, Training Accuracy= 0.499\n",
      "Epoch: 670, Minibatch Loss= 2.0933, Training Accuracy= 0.499\n",
      "Epoch: 680, Minibatch Loss= 2.0933, Training Accuracy= 0.499\n",
      "Epoch: 690, Minibatch Loss= 2.0933, Training Accuracy= 0.499\n",
      "Epoch: 700, Minibatch Loss= 2.0933, Training Accuracy= 0.499\n",
      "Epoch: 710, Minibatch Loss= 2.0933, Training Accuracy= 0.499\n",
      "Epoch: 720, Minibatch Loss= 2.0934, Training Accuracy= 0.499\n",
      "Epoch: 730, Minibatch Loss= 2.0934, Training Accuracy= 0.499\n",
      "Epoch: 740, Minibatch Loss= 2.0934, Training Accuracy= 0.499\n",
      "Epoch: 750, Minibatch Loss= 2.0934, Training Accuracy= 0.499\n",
      "Epoch: 760, Minibatch Loss= 2.0934, Training Accuracy= 0.499\n",
      "Epoch: 770, Minibatch Loss= 2.0934, Training Accuracy= 0.499\n",
      "Epoch: 780, Minibatch Loss= 2.0935, Training Accuracy= 0.499\n",
      "Epoch: 790, Minibatch Loss= 2.0935, Training Accuracy= 0.499\n",
      "Epoch: 800, Minibatch Loss= 2.0935, Training Accuracy= 0.499\n",
      "Epoch: 810, Minibatch Loss= 2.0936, Training Accuracy= 0.499\n",
      "Epoch: 820, Minibatch Loss= 2.0936, Training Accuracy= 0.499\n",
      "Epoch: 830, Minibatch Loss= 2.0936, Training Accuracy= 0.499\n",
      "Epoch: 840, Minibatch Loss= 2.0937, Training Accuracy= 0.499\n",
      "Epoch: 850, Minibatch Loss= 2.0937, Training Accuracy= 0.499\n",
      "Epoch: 860, Minibatch Loss= 2.0937, Training Accuracy= 0.499\n",
      "Epoch: 870, Minibatch Loss= 2.0938, Training Accuracy= 0.499\n",
      "Epoch: 880, Minibatch Loss= 2.0938, Training Accuracy= 0.499\n",
      "Epoch: 890, Minibatch Loss= 2.0938, Training Accuracy= 0.499\n",
      "Epoch: 900, Minibatch Loss= 2.0939, Training Accuracy= 0.499\n",
      "Epoch: 910, Minibatch Loss= 2.0939, Training Accuracy= 0.499\n",
      "Epoch: 920, Minibatch Loss= 2.0940, Training Accuracy= 0.499\n",
      "Epoch: 930, Minibatch Loss= 2.0940, Training Accuracy= 0.499\n",
      "Epoch: 940, Minibatch Loss= 2.0940, Training Accuracy= 0.499\n",
      "Epoch: 950, Minibatch Loss= 2.0941, Training Accuracy= 0.499\n",
      "Epoch: 960, Minibatch Loss= 2.0941, Training Accuracy= 0.499\n",
      "Epoch: 970, Minibatch Loss= 2.0942, Training Accuracy= 0.499\n",
      "Epoch: 980, Minibatch Loss= 2.0942, Training Accuracy= 0.499\n",
      "Epoch: 990, Minibatch Loss= 2.0942, Training Accuracy= 0.499\n",
      "Epoch: 1000, Minibatch Loss= 2.0943, Training Accuracy= 0.499\n",
      "Epoch: 1010, Minibatch Loss= 2.0943, Training Accuracy= 0.499\n",
      "Epoch: 1020, Minibatch Loss= 2.0943, Training Accuracy= 0.499\n",
      "Epoch: 1030, Minibatch Loss= 2.0944, Training Accuracy= 0.499\n",
      "Epoch: 1040, Minibatch Loss= 2.0944, Training Accuracy= 0.499\n",
      "Epoch: 1050, Minibatch Loss= 2.0944, Training Accuracy= 0.499\n",
      "Epoch: 1060, Minibatch Loss= 2.0944, Training Accuracy= 0.499\n",
      "Epoch: 1070, Minibatch Loss= 2.0945, Training Accuracy= 0.499\n",
      "Epoch: 1080, Minibatch Loss= 2.0945, Training Accuracy= 0.499\n",
      "Epoch: 1090, Minibatch Loss= 2.0945, Training Accuracy= 0.499\n",
      "Epoch: 1100, Minibatch Loss= 2.0945, Training Accuracy= 0.499\n",
      "Epoch: 1110, Minibatch Loss= 2.0946, Training Accuracy= 0.499\n",
      "Epoch: 1120, Minibatch Loss= 2.0946, Training Accuracy= 0.499\n",
      "Epoch: 1130, Minibatch Loss= 2.0946, Training Accuracy= 0.499\n",
      "Epoch: 1140, Minibatch Loss= 2.0946, Training Accuracy= 0.499\n",
      "Epoch: 1150, Minibatch Loss= 2.0946, Training Accuracy= 0.499\n",
      "Epoch: 1160, Minibatch Loss= 2.0946, Training Accuracy= 0.499\n",
      "Epoch: 1170, Minibatch Loss= 2.0947, Training Accuracy= 0.499\n",
      "Epoch: 1180, Minibatch Loss= 2.0947, Training Accuracy= 0.499\n",
      "Epoch: 1190, Minibatch Loss= 2.0947, Training Accuracy= 0.499\n",
      "Epoch: 1200, Minibatch Loss= 2.0947, Training Accuracy= 0.499\n",
      "Epoch: 1210, Minibatch Loss= 2.0947, Training Accuracy= 0.499\n",
      "Epoch: 1220, Minibatch Loss= 2.0947, Training Accuracy= 0.499\n",
      "Epoch: 1230, Minibatch Loss= 2.0947, Training Accuracy= 0.499\n",
      "Epoch: 1240, Minibatch Loss= 2.0948, Training Accuracy= 0.499\n",
      "Epoch: 1250, Minibatch Loss= 2.0948, Training Accuracy= 0.499\n",
      "Epoch: 1260, Minibatch Loss= 2.0948, Training Accuracy= 0.499\n",
      "Epoch: 1270, Minibatch Loss= 2.0948, Training Accuracy= 0.499\n",
      "Epoch: 1280, Minibatch Loss= 2.0948, Training Accuracy= 0.499\n",
      "Epoch: 1290, Minibatch Loss= 2.0948, Training Accuracy= 0.499\n",
      "Epoch: 1300, Minibatch Loss= 2.0948, Training Accuracy= 0.499\n",
      "Epoch: 1310, Minibatch Loss= 2.0948, Training Accuracy= 0.499\n",
      "Epoch: 1320, Minibatch Loss= 2.0948, Training Accuracy= 0.499\n",
      "Epoch: 1330, Minibatch Loss= 2.0948, Training Accuracy= 0.499\n",
      "Epoch: 1340, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1350, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1360, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1370, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1380, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1390, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1400, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1410, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1420, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1430, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1440, Minibatch Loss= 2.0949, Training Accuracy= 0.499\n",
      "Epoch: 1450, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1460, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1470, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1480, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1490, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1500, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1510, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1520, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1530, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1540, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1550, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1560, Minibatch Loss= 2.0950, Training Accuracy= 0.499\n",
      "Epoch: 1570, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n",
      "Epoch: 1580, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n",
      "Epoch: 1590, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n",
      "Epoch: 1600, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n",
      "Epoch: 1610, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n",
      "Epoch: 1620, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n",
      "Epoch: 1630, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n",
      "Epoch: 1640, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n",
      "Epoch: 1650, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1660, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n",
      "Epoch: 1670, Minibatch Loss= 2.0951, Training Accuracy= 0.499\n",
      "Epoch: 1680, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1690, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1700, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1710, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1720, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1730, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1740, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1750, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1760, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1770, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1780, Minibatch Loss= 2.0952, Training Accuracy= 0.499\n",
      "Epoch: 1790, Minibatch Loss= 2.0953, Training Accuracy= 0.499\n",
      "Epoch: 1800, Minibatch Loss= 2.0953, Training Accuracy= 0.499\n",
      "Epoch: 1810, Minibatch Loss= 2.0953, Training Accuracy= 0.499\n",
      "Epoch: 1820, Minibatch Loss= 2.0953, Training Accuracy= 0.499\n",
      "Epoch: 1830, Minibatch Loss= 2.0953, Training Accuracy= 0.499\n",
      "Epoch: 1840, Minibatch Loss= 2.0953, Training Accuracy= 0.499\n",
      "Epoch: 1850, Minibatch Loss= 2.0953, Training Accuracy= 0.499\n",
      "Epoch: 1860, Minibatch Loss= 2.0953, Training Accuracy= 0.499\n",
      "Epoch: 1870, Minibatch Loss= 2.0953, Training Accuracy= 0.499\n",
      "Epoch: 1880, Minibatch Loss= 2.0953, Training Accuracy= 0.499\n",
      "Epoch: 1890, Minibatch Loss= 2.0954, Training Accuracy= 0.499\n",
      "Epoch: 1900, Minibatch Loss= 2.0954, Training Accuracy= 0.499\n",
      "Epoch: 1910, Minibatch Loss= 2.0954, Training Accuracy= 0.499\n",
      "Epoch: 1920, Minibatch Loss= 2.0954, Training Accuracy= 0.499\n",
      "Epoch: 1930, Minibatch Loss= 2.0954, Training Accuracy= 0.499\n",
      "Epoch: 1940, Minibatch Loss= 2.0954, Training Accuracy= 0.499\n",
      "Epoch: 1950, Minibatch Loss= 2.0954, Training Accuracy= 0.499\n",
      "Epoch: 1960, Minibatch Loss= 2.0954, Training Accuracy= 0.499\n",
      "Epoch: 1970, Minibatch Loss= 2.0955, Training Accuracy= 0.499\n",
      "Epoch: 1980, Minibatch Loss= 2.0955, Training Accuracy= 0.499\n",
      "Epoch: 1990, Minibatch Loss= 2.0955, Training Accuracy= 0.499\n",
      "Epoch: 2000, Minibatch Loss= 2.0955, Training Accuracy= 0.499\n",
      "Epoch: 2010, Minibatch Loss= 2.0955, Training Accuracy= 0.499\n",
      "Epoch: 2020, Minibatch Loss= 2.0955, Training Accuracy= 0.499\n",
      "Epoch: 2030, Minibatch Loss= 2.0955, Training Accuracy= 0.499\n",
      "Epoch: 2040, Minibatch Loss= 2.0955, Training Accuracy= 0.499\n",
      "Epoch: 2050, Minibatch Loss= 2.0956, Training Accuracy= 0.499\n",
      "Epoch: 2060, Minibatch Loss= 2.0956, Training Accuracy= 0.499\n",
      "Epoch: 2070, Minibatch Loss= 2.0956, Training Accuracy= 0.499\n",
      "Epoch: 2080, Minibatch Loss= 2.0956, Training Accuracy= 0.499\n",
      "Epoch: 2090, Minibatch Loss= 2.0956, Training Accuracy= 0.499\n",
      "Epoch: 2100, Minibatch Loss= 2.0956, Training Accuracy= 0.499\n",
      "Epoch: 2110, Minibatch Loss= 2.0956, Training Accuracy= 0.499\n",
      "Epoch: 2120, Minibatch Loss= 2.0957, Training Accuracy= 0.499\n",
      "Epoch: 2130, Minibatch Loss= 2.0957, Training Accuracy= 0.499\n",
      "Epoch: 2140, Minibatch Loss= 2.0957, Training Accuracy= 0.499\n",
      "Epoch: 2150, Minibatch Loss= 2.0957, Training Accuracy= 0.499\n",
      "Epoch: 2160, Minibatch Loss= 2.0957, Training Accuracy= 0.499\n",
      "Epoch: 2170, Minibatch Loss= 2.0957, Training Accuracy= 0.499\n",
      "Epoch: 2180, Minibatch Loss= 2.0957, Training Accuracy= 0.499\n",
      "Epoch: 2190, Minibatch Loss= 2.0958, Training Accuracy= 0.499\n",
      "Epoch: 2200, Minibatch Loss= 2.0958, Training Accuracy= 0.499\n",
      "Epoch: 2210, Minibatch Loss= 2.0958, Training Accuracy= 0.499\n",
      "Epoch: 2220, Minibatch Loss= 2.0958, Training Accuracy= 0.499\n",
      "Epoch: 2230, Minibatch Loss= 2.0958, Training Accuracy= 0.499\n",
      "Epoch: 2240, Minibatch Loss= 2.0958, Training Accuracy= 0.499\n",
      "Epoch: 2250, Minibatch Loss= 2.0959, Training Accuracy= 0.499\n",
      "Epoch: 2260, Minibatch Loss= 2.0959, Training Accuracy= 0.499\n",
      "Epoch: 2270, Minibatch Loss= 2.0959, Training Accuracy= 0.499\n",
      "Epoch: 2280, Minibatch Loss= 2.0959, Training Accuracy= 0.499\n",
      "Epoch: 2290, Minibatch Loss= 2.0959, Training Accuracy= 0.499\n",
      "Epoch: 2300, Minibatch Loss= 2.0959, Training Accuracy= 0.499\n",
      "Epoch: 2310, Minibatch Loss= 2.0959, Training Accuracy= 0.499\n",
      "Epoch: 2320, Minibatch Loss= 2.0960, Training Accuracy= 0.499\n",
      "Epoch: 2330, Minibatch Loss= 2.0960, Training Accuracy= 0.499\n",
      "Epoch: 2340, Minibatch Loss= 2.0960, Training Accuracy= 0.499\n",
      "Epoch: 2350, Minibatch Loss= 2.0960, Training Accuracy= 0.499\n",
      "Epoch: 2360, Minibatch Loss= 2.0960, Training Accuracy= 0.499\n",
      "Epoch: 2370, Minibatch Loss= 2.0960, Training Accuracy= 0.499\n",
      "Epoch: 2380, Minibatch Loss= 2.0960, Training Accuracy= 0.499\n",
      "Epoch: 2390, Minibatch Loss= 2.0960, Training Accuracy= 0.499\n",
      "Epoch: 2400, Minibatch Loss= 2.0961, Training Accuracy= 0.499\n",
      "Epoch: 2410, Minibatch Loss= 2.0961, Training Accuracy= 0.499\n",
      "Epoch: 2420, Minibatch Loss= 2.0961, Training Accuracy= 0.499\n",
      "Epoch: 2430, Minibatch Loss= 2.0961, Training Accuracy= 0.499\n",
      "Epoch: 2440, Minibatch Loss= 2.0961, Training Accuracy= 0.499\n",
      "Epoch: 2450, Minibatch Loss= 2.0961, Training Accuracy= 0.499\n",
      "Epoch: 2460, Minibatch Loss= 2.0961, Training Accuracy= 0.499\n",
      "Epoch: 2470, Minibatch Loss= 2.0961, Training Accuracy= 0.499\n",
      "Epoch: 2480, Minibatch Loss= 2.0961, Training Accuracy= 0.499\n",
      "Epoch: 2490, Minibatch Loss= 2.0962, Training Accuracy= 0.499\n",
      "Epoch: 2500, Minibatch Loss= 2.0962, Training Accuracy= 0.499\n",
      "Epoch: 2510, Minibatch Loss= 2.0962, Training Accuracy= 0.499\n",
      "Epoch: 2520, Minibatch Loss= 2.0962, Training Accuracy= 0.499\n",
      "Epoch: 2530, Minibatch Loss= 2.0962, Training Accuracy= 0.499\n",
      "Epoch: 2540, Minibatch Loss= 2.0962, Training Accuracy= 0.499\n",
      "Epoch: 2550, Minibatch Loss= 2.0962, Training Accuracy= 0.499\n",
      "Epoch: 2560, Minibatch Loss= 2.0962, Training Accuracy= 0.499\n",
      "Epoch: 2570, Minibatch Loss= 2.0962, Training Accuracy= 0.499\n",
      "Epoch: 2580, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2590, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2600, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2610, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2620, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2630, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2640, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2650, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2660, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2670, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2680, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2690, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2700, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2710, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2720, Minibatch Loss= 2.0963, Training Accuracy= 0.499\n",
      "Epoch: 2730, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2740, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2750, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2760, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2770, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2780, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2790, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2800, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2810, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2820, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2830, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2840, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2850, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2860, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2870, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2880, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2890, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2900, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2910, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2920, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2930, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2940, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2950, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2960, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2970, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 2980, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2990, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3000, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3010, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3020, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3030, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3040, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3050, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3060, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3070, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3080, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3090, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3100, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3110, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3120, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3130, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3140, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3150, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3160, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3170, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3180, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3190, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3200, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3210, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3220, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3230, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3240, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3250, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3260, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3270, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3280, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3290, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3300, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3310, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3320, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3330, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3340, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3350, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3360, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3370, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3380, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3390, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3400, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3410, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3420, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3430, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3440, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3450, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3460, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3470, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3480, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3490, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3500, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3510, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3520, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3530, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3540, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3550, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3560, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3570, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3580, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3590, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3600, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3610, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3620, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3630, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3640, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3650, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3660, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3670, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3680, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3690, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3700, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3710, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3720, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3730, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3740, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3750, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3760, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3770, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3780, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3790, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3800, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3810, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3820, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3830, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3840, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3850, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3860, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3870, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3880, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3890, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3900, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3910, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3920, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3930, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3940, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3950, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3960, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3970, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 3980, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 3990, Minibatch Loss= 2.0964, Training Accuracy= 0.499\n",
      "Epoch: 4000, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4010, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4020, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4030, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4040, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4050, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4060, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4070, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4080, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4090, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4100, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4110, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4120, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4130, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4140, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4150, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4160, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4170, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4180, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4190, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4200, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4210, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4220, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4230, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4240, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4250, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4260, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4270, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4280, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4290, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4300, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4310, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4320, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4330, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4340, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4350, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4360, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4370, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4380, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4390, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4400, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4410, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4420, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4430, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4440, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4450, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4460, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4470, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4480, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4490, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4500, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4510, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4520, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4530, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4540, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4550, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4560, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4570, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4580, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4590, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4600, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4610, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4620, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4630, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4640, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4650, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4660, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4670, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4680, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4690, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4700, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4710, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4720, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4730, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4740, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4750, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4760, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4770, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4780, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4790, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4800, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4810, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4820, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4830, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4840, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4850, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4860, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4870, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4880, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4890, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4900, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4910, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4920, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4930, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4940, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4950, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4960, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4970, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4980, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Epoch: 4990, Minibatch Loss= 2.0965, Training Accuracy= 0.499\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5014\n",
      "Replication: 2: \n",
      "Epoch: 0, Minibatch Loss= 3.4330, Training Accuracy= 0.508\n",
      "Epoch: 10, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 20, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 30, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 40, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 50, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 60, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 70, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 80, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 90, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 100, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 110, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 120, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 130, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 140, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 150, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 160, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 170, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 180, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 190, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 200, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 210, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 220, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 230, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 240, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 250, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 260, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 270, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 280, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 290, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 300, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 310, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 320, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 330, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 340, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 350, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 360, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 370, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 380, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 390, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 400, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 410, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 420, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 430, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 440, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 450, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 460, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 470, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 480, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 490, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 500, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 510, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 520, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 530, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 540, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 550, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 560, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 570, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 580, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 590, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 600, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 610, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 620, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 630, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 640, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 650, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 660, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 670, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 680, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 690, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 700, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 710, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 720, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 730, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 740, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 750, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 760, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 770, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 780, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 790, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 800, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 810, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 820, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 830, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 840, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 850, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 860, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 870, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 880, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 890, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 900, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 910, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 920, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 930, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 940, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 950, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 960, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 970, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 980, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 990, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1000, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1010, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1020, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1030, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 1040, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 1050, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 1060, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 1070, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 1080, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1090, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1100, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1110, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1120, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1130, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1140, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1150, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1160, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1170, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1180, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1190, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 1200, Minibatch Loss= 3.4300, Training Accuracy= 0.508\n",
      "Epoch: 1210, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1220, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1230, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1240, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1250, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1260, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1270, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1280, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1290, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1300, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1310, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1320, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1330, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1340, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1350, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1360, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1370, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1380, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1390, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1400, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1410, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1420, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1430, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1440, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1450, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1460, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1470, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1480, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1490, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1500, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1510, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1520, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1530, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1540, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1550, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1560, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1570, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1580, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1590, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1600, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1610, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1620, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1630, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1640, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1650, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1660, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1670, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1680, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1690, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1700, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1710, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1720, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1730, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1740, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1750, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1760, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1770, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1780, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1790, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1800, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1810, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1820, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1830, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1840, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1850, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1860, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1870, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1880, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1890, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1900, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1910, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1920, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1930, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1940, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1950, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1960, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1970, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1980, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 1990, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2000, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2010, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2020, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2030, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2040, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2050, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2060, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2070, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2080, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2090, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2100, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2110, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2120, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2130, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2140, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2150, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2160, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2170, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2180, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2190, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2200, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2210, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2220, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2230, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2240, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2250, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2260, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2270, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2280, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2290, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2300, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2310, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2320, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2330, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2340, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2350, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2360, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2370, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2380, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2390, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2400, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2410, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2420, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2430, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2440, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2450, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2460, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2470, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2480, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2490, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2500, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2510, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2520, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2530, Minibatch Loss= 3.4301, Training Accuracy= 0.508\n",
      "Epoch: 2540, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2550, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2560, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2570, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2580, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2590, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2600, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2610, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2620, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2630, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2640, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2650, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2660, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2670, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2680, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2690, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2700, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2710, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2720, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2730, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2740, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2750, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2760, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2770, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2780, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2790, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2800, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2810, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2820, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2830, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2840, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2850, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2860, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2870, Minibatch Loss= 3.4302, Training Accuracy= 0.508\n",
      "Epoch: 2880, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2890, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2900, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2910, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2920, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2930, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2940, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2950, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2960, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2970, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2980, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 2990, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3000, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3010, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3020, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3030, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3040, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3050, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3060, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3070, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3080, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3090, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3100, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3110, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3120, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3130, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3140, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3150, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3160, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3170, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3180, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3190, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3200, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3210, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3220, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3230, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3240, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3250, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3260, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3270, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3280, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3290, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3300, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3310, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3320, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3330, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3340, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3350, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3360, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3370, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3380, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3390, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3400, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3410, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3420, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3430, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3440, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3450, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3460, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3470, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3480, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3490, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3500, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3510, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3520, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3530, Minibatch Loss= 3.4303, Training Accuracy= 0.508\n",
      "Epoch: 3540, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3550, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3560, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3570, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3580, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3590, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3600, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3610, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3620, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3630, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3640, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3650, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3660, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3670, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3680, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3690, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3700, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3710, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3720, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3730, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3740, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3750, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3760, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3770, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3780, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3790, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3800, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3810, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3820, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3830, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3840, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3850, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3860, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3870, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3880, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3890, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3900, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3910, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3920, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3930, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3940, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3950, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3960, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3970, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3980, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 3990, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4000, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4010, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4020, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4030, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4040, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4050, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4060, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4070, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4080, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4090, Minibatch Loss= 3.4304, Training Accuracy= 0.508\n",
      "Epoch: 4100, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4110, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4120, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4130, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4140, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4150, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4160, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4170, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4180, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4190, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4200, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4210, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4220, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4230, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4240, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4250, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4260, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4270, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4280, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4290, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4300, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4310, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4320, Minibatch Loss= 3.4305, Training Accuracy= 0.508\n",
      "Epoch: 4330, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4340, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4350, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4360, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4370, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4380, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4390, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4400, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4410, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4420, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4430, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4440, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4450, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4460, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4470, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4480, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4490, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4500, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4510, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4520, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4530, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4540, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4550, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4560, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4570, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4580, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4590, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4600, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4610, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4620, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4630, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4640, Minibatch Loss= 3.4306, Training Accuracy= 0.508\n",
      "Epoch: 4650, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4660, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4670, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4680, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4690, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4700, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4710, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4720, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4730, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4740, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4750, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4760, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4770, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4780, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4790, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4800, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4810, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4820, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4830, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4840, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4850, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4860, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4870, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4880, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4890, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4900, Minibatch Loss= 3.4308, Training Accuracy= 0.508\n",
      "Epoch: 4910, Minibatch Loss= 3.4308, Training Accuracy= 0.508\n",
      "Epoch: 4920, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4930, Minibatch Loss= 3.4307, Training Accuracy= 0.508\n",
      "Epoch: 4940, Minibatch Loss= 3.4308, Training Accuracy= 0.508\n",
      "Epoch: 4950, Minibatch Loss= 3.4308, Training Accuracy= 0.508\n",
      "Epoch: 4960, Minibatch Loss= 3.4308, Training Accuracy= 0.508\n",
      "Epoch: 4970, Minibatch Loss= 3.4308, Training Accuracy= 0.508\n",
      "Epoch: 4980, Minibatch Loss= 3.4308, Training Accuracy= 0.508\n",
      "Epoch: 4990, Minibatch Loss= 3.4308, Training Accuracy= 0.508\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4942\n",
      "Replication: 3: \n",
      "Epoch: 0, Minibatch Loss= 1.3373, Training Accuracy= 0.494\n",
      "Epoch: 10, Minibatch Loss= 1.3355, Training Accuracy= 0.494\n",
      "Epoch: 20, Minibatch Loss= 1.3355, Training Accuracy= 0.494\n",
      "Epoch: 30, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 40, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 50, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 60, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 70, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 80, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 90, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 100, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 110, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 120, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 130, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 140, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 150, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 160, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 170, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 180, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 190, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 200, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 210, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 220, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 230, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 240, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 250, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 260, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 270, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 280, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 290, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 300, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 310, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 320, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 330, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 340, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 350, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 360, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 370, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 380, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 390, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 400, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 410, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 420, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 430, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 440, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 450, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 460, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 470, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 480, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 490, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 500, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 510, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 520, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 530, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 540, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 550, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 560, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 570, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 580, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 590, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 600, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 610, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 620, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 630, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 640, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 650, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 660, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 670, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 680, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 690, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 700, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 710, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 720, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 730, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 740, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 750, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 760, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 770, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 780, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 790, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 800, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 810, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 820, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 830, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 840, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 850, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 860, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 870, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 880, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 890, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 900, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 910, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 920, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 930, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 940, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 950, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 960, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 970, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 980, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 990, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1000, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1010, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1020, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1030, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1040, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1050, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1060, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1070, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1080, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1090, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1100, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1110, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1120, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1130, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1140, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1150, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1160, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1170, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1180, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1190, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1200, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1210, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1220, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1230, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1240, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1250, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1260, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1270, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1280, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1290, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1300, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1310, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1320, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1330, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1340, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1350, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1360, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1370, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1380, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1390, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1400, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1410, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1420, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1430, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1440, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1450, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1460, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1470, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1480, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1490, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1500, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1510, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1520, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1530, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1540, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1550, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1560, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1570, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1580, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1590, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1600, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1610, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1620, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1630, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1640, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1650, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1660, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1670, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1680, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1690, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1700, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1710, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1720, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1730, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1740, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1750, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1760, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1770, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1780, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1790, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1800, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1810, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1820, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1830, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1840, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1850, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1860, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1870, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1880, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1890, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1900, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1910, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1920, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1930, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1940, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1950, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1960, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1970, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1980, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 1990, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2000, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2010, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2020, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2030, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2040, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2050, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2060, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2070, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2080, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2090, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2100, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2110, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2120, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2130, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2140, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2150, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2160, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2170, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2180, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2190, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2200, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2210, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2220, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2230, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2240, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2250, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2260, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2270, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2280, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2290, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2300, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2310, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2320, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2330, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2340, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2350, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2360, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2370, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2380, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2390, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2400, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2410, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2420, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2430, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2440, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2450, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2460, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2470, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2480, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2490, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2500, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2510, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2520, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2530, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2540, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2550, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2560, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2570, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2580, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2590, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2600, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2610, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2620, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2630, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2640, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2650, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2660, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2670, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2680, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2690, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2700, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2710, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2720, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2730, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2740, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2750, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2760, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2770, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2780, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2790, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2800, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2810, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2820, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2830, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2840, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2850, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2860, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2870, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2880, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2890, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2900, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2910, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2920, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2930, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2940, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2950, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2960, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2970, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2980, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 2990, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3000, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3010, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3020, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3030, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3040, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3050, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3060, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3070, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3080, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3090, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3100, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3110, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3120, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3130, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3140, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3150, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3160, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3170, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3180, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3190, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3200, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3210, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3220, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3230, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3240, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3250, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3260, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3270, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3280, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3290, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3300, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3310, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3320, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3330, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3340, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3350, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3360, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3370, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3380, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3390, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3400, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3410, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3420, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3430, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3440, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3450, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3460, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3470, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3480, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3490, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3500, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3510, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3520, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3530, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3540, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3550, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3560, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3570, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3580, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3590, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3600, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3610, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3620, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3630, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3640, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3650, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3660, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3670, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3680, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3690, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3700, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3710, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3720, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3730, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3740, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3750, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3760, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3770, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3780, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3790, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3800, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3810, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3820, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3830, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3840, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3850, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3860, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3870, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3880, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3890, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3900, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3910, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3920, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3930, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3940, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3950, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3960, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3970, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3980, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 3990, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4000, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4010, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4020, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4030, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4040, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4050, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4060, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4070, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4080, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4090, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4100, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4110, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4120, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4130, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4140, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4150, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4160, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4170, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4180, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4190, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4200, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4210, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4220, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4230, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4240, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4250, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4260, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4270, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4280, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4290, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4300, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4310, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4320, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4330, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4340, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4350, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4360, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4370, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4380, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4390, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4400, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4410, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4420, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4430, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4440, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4450, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4460, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4470, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4480, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4490, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4500, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4510, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4520, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4530, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4540, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4550, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4560, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4570, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4580, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4590, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4600, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4610, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4620, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4630, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4640, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4650, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4660, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4670, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4680, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4690, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4700, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4710, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4720, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4730, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4740, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4750, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4760, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4770, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4780, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4790, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4800, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4810, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4820, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4830, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4840, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4850, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4860, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4870, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4880, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4890, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4900, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4910, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4920, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4930, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4940, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4950, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4960, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4970, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4980, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Epoch: 4990, Minibatch Loss= 1.3354, Training Accuracy= 0.494\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5019\n",
      "Replication: 4: \n",
      "Epoch: 0, Minibatch Loss= 3.4148, Training Accuracy= 0.511\n",
      "Epoch: 10, Minibatch Loss= 3.4114, Training Accuracy= 0.511\n",
      "Epoch: 20, Minibatch Loss= 3.4109, Training Accuracy= 0.511\n",
      "Epoch: 30, Minibatch Loss= 3.4106, Training Accuracy= 0.511\n",
      "Epoch: 40, Minibatch Loss= 3.4102, Training Accuracy= 0.511\n",
      "Epoch: 50, Minibatch Loss= 3.4099, Training Accuracy= 0.511\n",
      "Epoch: 60, Minibatch Loss= 3.4096, Training Accuracy= 0.511\n",
      "Epoch: 70, Minibatch Loss= 3.4093, Training Accuracy= 0.511\n",
      "Epoch: 80, Minibatch Loss= 3.4090, Training Accuracy= 0.511\n",
      "Epoch: 90, Minibatch Loss= 3.4087, Training Accuracy= 0.511\n",
      "Epoch: 100, Minibatch Loss= 3.4084, Training Accuracy= 0.511\n",
      "Epoch: 110, Minibatch Loss= 3.4082, Training Accuracy= 0.511\n",
      "Epoch: 120, Minibatch Loss= 3.4079, Training Accuracy= 0.511\n",
      "Epoch: 130, Minibatch Loss= 3.4076, Training Accuracy= 0.511\n",
      "Epoch: 140, Minibatch Loss= 3.4074, Training Accuracy= 0.511\n",
      "Epoch: 150, Minibatch Loss= 3.4071, Training Accuracy= 0.511\n",
      "Epoch: 160, Minibatch Loss= 3.4069, Training Accuracy= 0.511\n",
      "Epoch: 170, Minibatch Loss= 3.4067, Training Accuracy= 0.511\n",
      "Epoch: 180, Minibatch Loss= 3.4065, Training Accuracy= 0.511\n",
      "Epoch: 190, Minibatch Loss= 3.4063, Training Accuracy= 0.511\n",
      "Epoch: 200, Minibatch Loss= 3.4061, Training Accuracy= 0.511\n",
      "Epoch: 210, Minibatch Loss= 3.4059, Training Accuracy= 0.511\n",
      "Epoch: 220, Minibatch Loss= 3.4058, Training Accuracy= 0.511\n",
      "Epoch: 230, Minibatch Loss= 3.4056, Training Accuracy= 0.511\n",
      "Epoch: 240, Minibatch Loss= 3.4056, Training Accuracy= 0.511\n",
      "Epoch: 250, Minibatch Loss= 3.4054, Training Accuracy= 0.511\n",
      "Epoch: 260, Minibatch Loss= 3.4054, Training Accuracy= 0.511\n",
      "Epoch: 270, Minibatch Loss= 3.4053, Training Accuracy= 0.511\n",
      "Epoch: 280, Minibatch Loss= 3.4052, Training Accuracy= 0.511\n",
      "Epoch: 290, Minibatch Loss= 3.4052, Training Accuracy= 0.511\n",
      "Epoch: 300, Minibatch Loss= 3.4051, Training Accuracy= 0.511\n",
      "Epoch: 310, Minibatch Loss= 3.4051, Training Accuracy= 0.511\n",
      "Epoch: 320, Minibatch Loss= 3.4051, Training Accuracy= 0.511\n",
      "Epoch: 330, Minibatch Loss= 3.4050, Training Accuracy= 0.511\n",
      "Epoch: 340, Minibatch Loss= 3.4050, Training Accuracy= 0.511\n",
      "Epoch: 350, Minibatch Loss= 3.4050, Training Accuracy= 0.511\n",
      "Epoch: 360, Minibatch Loss= 3.4049, Training Accuracy= 0.511\n",
      "Epoch: 370, Minibatch Loss= 3.4049, Training Accuracy= 0.511\n",
      "Epoch: 380, Minibatch Loss= 3.4049, Training Accuracy= 0.511\n",
      "Epoch: 390, Minibatch Loss= 3.4049, Training Accuracy= 0.511\n",
      "Epoch: 400, Minibatch Loss= 3.4049, Training Accuracy= 0.511\n",
      "Epoch: 410, Minibatch Loss= 3.4049, Training Accuracy= 0.511\n",
      "Epoch: 420, Minibatch Loss= 3.4049, Training Accuracy= 0.511\n",
      "Epoch: 430, Minibatch Loss= 3.4048, Training Accuracy= 0.511\n",
      "Epoch: 440, Minibatch Loss= 3.4048, Training Accuracy= 0.511\n",
      "Epoch: 450, Minibatch Loss= 3.4048, Training Accuracy= 0.511\n",
      "Epoch: 460, Minibatch Loss= 3.4047, Training Accuracy= 0.511\n",
      "Epoch: 470, Minibatch Loss= 3.4047, Training Accuracy= 0.511\n",
      "Epoch: 480, Minibatch Loss= 3.4046, Training Accuracy= 0.511\n",
      "Epoch: 490, Minibatch Loss= 3.4045, Training Accuracy= 0.511\n",
      "Epoch: 500, Minibatch Loss= 3.4044, Training Accuracy= 0.511\n",
      "Epoch: 510, Minibatch Loss= 3.4042, Training Accuracy= 0.511\n",
      "Epoch: 520, Minibatch Loss= 3.4040, Training Accuracy= 0.511\n",
      "Epoch: 530, Minibatch Loss= 3.4038, Training Accuracy= 0.511\n",
      "Epoch: 540, Minibatch Loss= 3.4036, Training Accuracy= 0.511\n",
      "Epoch: 550, Minibatch Loss= 3.4035, Training Accuracy= 0.511\n",
      "Epoch: 560, Minibatch Loss= 3.4035, Training Accuracy= 0.511\n",
      "Epoch: 570, Minibatch Loss= 3.4034, Training Accuracy= 0.511\n",
      "Epoch: 580, Minibatch Loss= 3.4034, Training Accuracy= 0.511\n",
      "Epoch: 590, Minibatch Loss= 3.4033, Training Accuracy= 0.511\n",
      "Epoch: 600, Minibatch Loss= 3.4032, Training Accuracy= 0.511\n",
      "Epoch: 610, Minibatch Loss= 3.4032, Training Accuracy= 0.511\n",
      "Epoch: 620, Minibatch Loss= 3.4031, Training Accuracy= 0.511\n",
      "Epoch: 630, Minibatch Loss= 3.4030, Training Accuracy= 0.511\n",
      "Epoch: 640, Minibatch Loss= 3.4029, Training Accuracy= 0.511\n",
      "Epoch: 650, Minibatch Loss= 3.4029, Training Accuracy= 0.511\n",
      "Epoch: 660, Minibatch Loss= 3.4029, Training Accuracy= 0.511\n",
      "Epoch: 670, Minibatch Loss= 3.4028, Training Accuracy= 0.511\n",
      "Epoch: 680, Minibatch Loss= 3.4028, Training Accuracy= 0.511\n",
      "Epoch: 690, Minibatch Loss= 3.4028, Training Accuracy= 0.511\n",
      "Epoch: 700, Minibatch Loss= 3.4028, Training Accuracy= 0.511\n",
      "Epoch: 710, Minibatch Loss= 3.4028, Training Accuracy= 0.511\n",
      "Epoch: 720, Minibatch Loss= 3.4027, Training Accuracy= 0.511\n",
      "Epoch: 730, Minibatch Loss= 3.4027, Training Accuracy= 0.511\n",
      "Epoch: 740, Minibatch Loss= 3.4027, Training Accuracy= 0.511\n",
      "Epoch: 750, Minibatch Loss= 3.4027, Training Accuracy= 0.511\n",
      "Epoch: 760, Minibatch Loss= 3.4027, Training Accuracy= 0.511\n",
      "Epoch: 770, Minibatch Loss= 3.4027, Training Accuracy= 0.511\n",
      "Epoch: 780, Minibatch Loss= 3.4027, Training Accuracy= 0.511\n",
      "Epoch: 790, Minibatch Loss= 3.4027, Training Accuracy= 0.511\n",
      "Epoch: 800, Minibatch Loss= 3.4027, Training Accuracy= 0.511\n",
      "Epoch: 810, Minibatch Loss= 3.4027, Training Accuracy= 0.511\n",
      "Epoch: 820, Minibatch Loss= 3.4026, Training Accuracy= 0.511\n",
      "Epoch: 830, Minibatch Loss= 3.4026, Training Accuracy= 0.511\n",
      "Epoch: 840, Minibatch Loss= 3.4026, Training Accuracy= 0.511\n",
      "Epoch: 850, Minibatch Loss= 3.4026, Training Accuracy= 0.511\n",
      "Epoch: 860, Minibatch Loss= 3.4026, Training Accuracy= 0.511\n",
      "Epoch: 870, Minibatch Loss= 3.4026, Training Accuracy= 0.511\n",
      "Epoch: 880, Minibatch Loss= 3.4026, Training Accuracy= 0.511\n",
      "Epoch: 890, Minibatch Loss= 3.4025, Training Accuracy= 0.511\n",
      "Epoch: 900, Minibatch Loss= 3.4025, Training Accuracy= 0.511\n",
      "Epoch: 910, Minibatch Loss= 3.4025, Training Accuracy= 0.511\n",
      "Epoch: 920, Minibatch Loss= 3.4025, Training Accuracy= 0.511\n",
      "Epoch: 930, Minibatch Loss= 3.4025, Training Accuracy= 0.511\n",
      "Epoch: 940, Minibatch Loss= 3.4024, Training Accuracy= 0.511\n",
      "Epoch: 950, Minibatch Loss= 3.4024, Training Accuracy= 0.511\n",
      "Epoch: 960, Minibatch Loss= 3.4024, Training Accuracy= 0.511\n",
      "Epoch: 970, Minibatch Loss= 3.4023, Training Accuracy= 0.511\n",
      "Epoch: 980, Minibatch Loss= 3.4022, Training Accuracy= 0.511\n",
      "Epoch: 990, Minibatch Loss= 3.4022, Training Accuracy= 0.511\n",
      "Epoch: 1000, Minibatch Loss= 3.4021, Training Accuracy= 0.511\n",
      "Epoch: 1010, Minibatch Loss= 3.4020, Training Accuracy= 0.511\n",
      "Epoch: 1020, Minibatch Loss= 3.4020, Training Accuracy= 0.511\n",
      "Epoch: 1030, Minibatch Loss= 3.4019, Training Accuracy= 0.511\n",
      "Epoch: 1040, Minibatch Loss= 3.4019, Training Accuracy= 0.511\n",
      "Epoch: 1050, Minibatch Loss= 3.4018, Training Accuracy= 0.511\n",
      "Epoch: 1060, Minibatch Loss= 3.4018, Training Accuracy= 0.511\n",
      "Epoch: 1070, Minibatch Loss= 3.4017, Training Accuracy= 0.511\n",
      "Epoch: 1080, Minibatch Loss= 3.4017, Training Accuracy= 0.511\n",
      "Epoch: 1090, Minibatch Loss= 3.4016, Training Accuracy= 0.511\n",
      "Epoch: 1100, Minibatch Loss= 3.4016, Training Accuracy= 0.511\n",
      "Epoch: 1110, Minibatch Loss= 3.4016, Training Accuracy= 0.511\n",
      "Epoch: 1120, Minibatch Loss= 3.4015, Training Accuracy= 0.511\n",
      "Epoch: 1130, Minibatch Loss= 3.4015, Training Accuracy= 0.511\n",
      "Epoch: 1140, Minibatch Loss= 3.4015, Training Accuracy= 0.511\n",
      "Epoch: 1150, Minibatch Loss= 3.4015, Training Accuracy= 0.511\n",
      "Epoch: 1160, Minibatch Loss= 3.4015, Training Accuracy= 0.511\n",
      "Epoch: 1170, Minibatch Loss= 3.4014, Training Accuracy= 0.511\n",
      "Epoch: 1180, Minibatch Loss= 3.4014, Training Accuracy= 0.511\n",
      "Epoch: 1190, Minibatch Loss= 3.4014, Training Accuracy= 0.511\n",
      "Epoch: 1200, Minibatch Loss= 3.4014, Training Accuracy= 0.511\n",
      "Epoch: 1210, Minibatch Loss= 3.4014, Training Accuracy= 0.511\n",
      "Epoch: 1220, Minibatch Loss= 3.4014, Training Accuracy= 0.511\n",
      "Epoch: 1230, Minibatch Loss= 3.4014, Training Accuracy= 0.511\n",
      "Epoch: 1240, Minibatch Loss= 3.4013, Training Accuracy= 0.511\n",
      "Epoch: 1250, Minibatch Loss= 3.4013, Training Accuracy= 0.511\n",
      "Epoch: 1260, Minibatch Loss= 3.4013, Training Accuracy= 0.511\n",
      "Epoch: 1270, Minibatch Loss= 3.4013, Training Accuracy= 0.511\n",
      "Epoch: 1280, Minibatch Loss= 3.4012, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1290, Minibatch Loss= 3.4012, Training Accuracy= 0.511\n",
      "Epoch: 1300, Minibatch Loss= 3.4012, Training Accuracy= 0.511\n",
      "Epoch: 1310, Minibatch Loss= 3.4011, Training Accuracy= 0.511\n",
      "Epoch: 1320, Minibatch Loss= 3.4011, Training Accuracy= 0.511\n",
      "Epoch: 1330, Minibatch Loss= 3.4010, Training Accuracy= 0.511\n",
      "Epoch: 1340, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 1350, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 1360, Minibatch Loss= 3.4005, Training Accuracy= 0.511\n",
      "Epoch: 1370, Minibatch Loss= 3.4003, Training Accuracy= 0.511\n",
      "Epoch: 1380, Minibatch Loss= 3.4001, Training Accuracy= 0.511\n",
      "Epoch: 1390, Minibatch Loss= 3.3999, Training Accuracy= 0.511\n",
      "Epoch: 1400, Minibatch Loss= 3.3997, Training Accuracy= 0.511\n",
      "Epoch: 1410, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 1420, Minibatch Loss= 3.3994, Training Accuracy= 0.511\n",
      "Epoch: 1430, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 1440, Minibatch Loss= 3.3992, Training Accuracy= 0.511\n",
      "Epoch: 1450, Minibatch Loss= 3.3992, Training Accuracy= 0.511\n",
      "Epoch: 1460, Minibatch Loss= 3.3991, Training Accuracy= 0.511\n",
      "Epoch: 1470, Minibatch Loss= 3.3991, Training Accuracy= 0.511\n",
      "Epoch: 1480, Minibatch Loss= 3.3991, Training Accuracy= 0.511\n",
      "Epoch: 1490, Minibatch Loss= 3.3990, Training Accuracy= 0.511\n",
      "Epoch: 1500, Minibatch Loss= 0.7981, Training Accuracy= 0.489\n",
      "Epoch: 1510, Minibatch Loss= 3.3990, Training Accuracy= 0.511\n",
      "Epoch: 1520, Minibatch Loss= 3.3990, Training Accuracy= 0.511\n",
      "Epoch: 1530, Minibatch Loss= 3.4006, Training Accuracy= 0.511\n",
      "Epoch: 1540, Minibatch Loss= 3.4018, Training Accuracy= 0.511\n",
      "Epoch: 1550, Minibatch Loss= 3.3997, Training Accuracy= 0.511\n",
      "Epoch: 1560, Minibatch Loss= 3.3990, Training Accuracy= 0.511\n",
      "Epoch: 1570, Minibatch Loss= 3.3992, Training Accuracy= 0.511\n",
      "Epoch: 1580, Minibatch Loss= 0.7981, Training Accuracy= 0.489\n",
      "Epoch: 1590, Minibatch Loss= 3.4006, Training Accuracy= 0.511\n",
      "Epoch: 1600, Minibatch Loss= 0.7981, Training Accuracy= 0.489\n",
      "Epoch: 1610, Minibatch Loss= 3.3991, Training Accuracy= 0.511\n",
      "Epoch: 1620, Minibatch Loss= 3.4005, Training Accuracy= 0.511\n",
      "Epoch: 1630, Minibatch Loss= 0.7981, Training Accuracy= 0.489\n",
      "Epoch: 1640, Minibatch Loss= 3.3990, Training Accuracy= 0.511\n",
      "Epoch: 1650, Minibatch Loss= 3.4005, Training Accuracy= 0.511\n",
      "Epoch: 1660, Minibatch Loss= 0.7982, Training Accuracy= 0.489\n",
      "Epoch: 1670, Minibatch Loss= 3.3989, Training Accuracy= 0.511\n",
      "Epoch: 1680, Minibatch Loss= 3.4003, Training Accuracy= 0.511\n",
      "Epoch: 1690, Minibatch Loss= 0.7982, Training Accuracy= 0.489\n",
      "Epoch: 1700, Minibatch Loss= 3.3988, Training Accuracy= 0.511\n",
      "Epoch: 1710, Minibatch Loss= 3.3987, Training Accuracy= 0.511\n",
      "Epoch: 1720, Minibatch Loss= 3.3986, Training Accuracy= 0.511\n",
      "Epoch: 1730, Minibatch Loss= 3.3986, Training Accuracy= 0.511\n",
      "Epoch: 1740, Minibatch Loss= 3.3985, Training Accuracy= 0.511\n",
      "Epoch: 1750, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 1760, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 1770, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 1780, Minibatch Loss= 3.3982, Training Accuracy= 0.511\n",
      "Epoch: 1790, Minibatch Loss= 3.3982, Training Accuracy= 0.511\n",
      "Epoch: 1800, Minibatch Loss= 3.3982, Training Accuracy= 0.511\n",
      "Epoch: 1810, Minibatch Loss= 3.3982, Training Accuracy= 0.511\n",
      "Epoch: 1820, Minibatch Loss= 3.3982, Training Accuracy= 0.511\n",
      "Epoch: 1830, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1840, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1850, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1860, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1870, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1880, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1890, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1900, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1910, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1920, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1930, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1940, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1950, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1960, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1970, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1980, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 1990, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 2000, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2010, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 2020, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 2030, Minibatch Loss= 3.3981, Training Accuracy= 0.511\n",
      "Epoch: 2040, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2050, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2060, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2070, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2080, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2090, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2100, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2110, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2120, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2130, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2140, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2150, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2160, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2170, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2180, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2190, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2200, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2210, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2220, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2230, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2240, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2250, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2260, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2270, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2280, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2290, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2300, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2310, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2320, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2330, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2340, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2350, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2360, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2370, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2380, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2390, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2400, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2410, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2420, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2430, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2440, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2450, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2460, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2470, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2480, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2490, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2500, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2510, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2520, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2530, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2540, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2550, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2560, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2570, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2580, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2590, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2600, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2610, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2620, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2630, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2640, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2650, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2660, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2670, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2680, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2690, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2700, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2710, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2720, Minibatch Loss= 3.3980, Training Accuracy= 0.511\n",
      "Epoch: 2730, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2740, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2750, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2760, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2770, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2780, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2790, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2800, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2810, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2820, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2830, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2840, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2850, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2860, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2870, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2880, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2890, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2900, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2910, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2920, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2930, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2940, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2950, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2960, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2970, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2980, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 2990, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3000, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3010, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3020, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3030, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3040, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3050, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3060, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3070, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3080, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3090, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3100, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3110, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3120, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3130, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3140, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3150, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3160, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3170, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3180, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3190, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3200, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3210, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3220, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3230, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3240, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3250, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3260, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 3270, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3280, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3290, Minibatch Loss= 3.4008, Training Accuracy= 0.511\n",
      "Epoch: 3300, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3310, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 3320, Minibatch Loss= 3.3994, Training Accuracy= 0.511\n",
      "Epoch: 3330, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 3340, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 3350, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3360, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 3370, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3380, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 3390, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3400, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 3410, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 3420, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 3430, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 3440, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3450, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3460, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3470, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3480, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3490, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3500, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 3510, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 3520, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 3530, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3540, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3550, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3560, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3570, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3580, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 3590, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 3600, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 3610, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 3620, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3630, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3640, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3650, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3660, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3670, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 3680, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 3690, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 3700, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3710, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 3720, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 3730, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 3740, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3750, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3760, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 3770, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 3780, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 3790, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3800, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3810, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3820, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3830, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 3840, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 3850, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 3860, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 3870, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 3880, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 3890, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3900, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3910, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 3920, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 3930, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 3940, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3950, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 3960, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 3970, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 3980, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 3990, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4000, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4010, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4020, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4030, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4040, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4050, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4060, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4070, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 4080, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4090, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4100, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4110, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4120, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4130, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4140, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4150, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4160, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 4170, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4180, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4190, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4200, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4210, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4220, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4230, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4240, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4250, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 4260, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4270, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4280, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4290, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4300, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4310, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4320, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4330, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4340, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 4350, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4360, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4370, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4380, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4390, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4400, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4410, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4420, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4430, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 4440, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4450, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4460, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4470, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4480, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4490, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4500, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4510, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4520, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 4530, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4540, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4550, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4560, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4570, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4580, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4590, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4600, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4610, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 4620, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4630, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4640, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4650, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4660, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4670, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4680, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4690, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4700, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 4710, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4720, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4730, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4740, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4750, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4760, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4770, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4780, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4790, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 4800, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4810, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4820, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4830, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4840, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4850, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4860, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4870, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4880, Minibatch Loss= 3.3995, Training Accuracy= 0.511\n",
      "Epoch: 4890, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4900, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Epoch: 4910, Minibatch Loss= 0.7985, Training Accuracy= 0.489\n",
      "Epoch: 4920, Minibatch Loss= 3.4007, Training Accuracy= 0.511\n",
      "Epoch: 4930, Minibatch Loss= 3.3993, Training Accuracy= 0.511\n",
      "Epoch: 4940, Minibatch Loss= 3.3983, Training Accuracy= 0.511\n",
      "Epoch: 4950, Minibatch Loss= 0.7984, Training Accuracy= 0.489\n",
      "Epoch: 4960, Minibatch Loss= 3.4009, Training Accuracy= 0.511\n",
      "Epoch: 4970, Minibatch Loss= 3.3994, Training Accuracy= 0.511\n",
      "Epoch: 4980, Minibatch Loss= 3.3984, Training Accuracy= 0.511\n",
      "Epoch: 4990, Minibatch Loss= 3.3979, Training Accuracy= 0.511\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4973\n",
      "Replication: 5: \n",
      "Epoch: 0, Minibatch Loss= 2.4422, Training Accuracy= 0.497\n",
      "Epoch: 10, Minibatch Loss= 2.4404, Training Accuracy= 0.497\n",
      "Epoch: 20, Minibatch Loss= 2.4403, Training Accuracy= 0.497\n",
      "Epoch: 30, Minibatch Loss= 2.4403, Training Accuracy= 0.497\n",
      "Epoch: 40, Minibatch Loss= 2.4403, Training Accuracy= 0.497\n",
      "Epoch: 50, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 60, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 70, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 80, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 90, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 100, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 110, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 120, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 130, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 140, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 150, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 160, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 170, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 180, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 190, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 200, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 210, Minibatch Loss= 2.4402, Training Accuracy= 0.497\n",
      "Epoch: 220, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 230, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 240, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 250, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 260, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 280, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 290, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 300, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 310, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 320, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 330, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 340, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 350, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 360, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 370, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 380, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 390, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 400, Minibatch Loss= 2.4401, Training Accuracy= 0.497\n",
      "Epoch: 410, Minibatch Loss= 2.4400, Training Accuracy= 0.497\n",
      "Epoch: 420, Minibatch Loss= 2.4400, Training Accuracy= 0.497\n",
      "Epoch: 430, Minibatch Loss= 2.4400, Training Accuracy= 0.497\n",
      "Epoch: 440, Minibatch Loss= 2.4400, Training Accuracy= 0.497\n",
      "Epoch: 450, Minibatch Loss= 2.4400, Training Accuracy= 0.497\n",
      "Epoch: 460, Minibatch Loss= 2.4400, Training Accuracy= 0.497\n",
      "Epoch: 470, Minibatch Loss= 2.4400, Training Accuracy= 0.497\n",
      "Epoch: 480, Minibatch Loss= 2.4399, Training Accuracy= 0.497\n",
      "Epoch: 490, Minibatch Loss= 2.4399, Training Accuracy= 0.497\n",
      "Epoch: 500, Minibatch Loss= 2.4399, Training Accuracy= 0.497\n",
      "Epoch: 510, Minibatch Loss= 2.4399, Training Accuracy= 0.497\n",
      "Epoch: 520, Minibatch Loss= 2.4398, Training Accuracy= 0.497\n",
      "Epoch: 530, Minibatch Loss= 2.4398, Training Accuracy= 0.497\n",
      "Epoch: 540, Minibatch Loss= 2.4398, Training Accuracy= 0.497\n",
      "Epoch: 550, Minibatch Loss= 2.4398, Training Accuracy= 0.497\n",
      "Epoch: 560, Minibatch Loss= 2.4398, Training Accuracy= 0.497\n",
      "Epoch: 570, Minibatch Loss= 2.4397, Training Accuracy= 0.497\n",
      "Epoch: 580, Minibatch Loss= 2.4397, Training Accuracy= 0.497\n",
      "Epoch: 590, Minibatch Loss= 2.4397, Training Accuracy= 0.497\n",
      "Epoch: 600, Minibatch Loss= 2.4397, Training Accuracy= 0.497\n",
      "Epoch: 610, Minibatch Loss= 2.4396, Training Accuracy= 0.497\n",
      "Epoch: 620, Minibatch Loss= 2.4396, Training Accuracy= 0.497\n",
      "Epoch: 630, Minibatch Loss= 2.4396, Training Accuracy= 0.497\n",
      "Epoch: 640, Minibatch Loss= 2.4395, Training Accuracy= 0.497\n",
      "Epoch: 650, Minibatch Loss= 2.4395, Training Accuracy= 0.497\n",
      "Epoch: 660, Minibatch Loss= 2.4394, Training Accuracy= 0.497\n",
      "Epoch: 670, Minibatch Loss= 2.4393, Training Accuracy= 0.497\n",
      "Epoch: 680, Minibatch Loss= 2.4393, Training Accuracy= 0.497\n",
      "Epoch: 690, Minibatch Loss= 2.4392, Training Accuracy= 0.497\n",
      "Epoch: 700, Minibatch Loss= 2.4391, Training Accuracy= 0.497\n",
      "Epoch: 710, Minibatch Loss= 2.4390, Training Accuracy= 0.497\n",
      "Epoch: 720, Minibatch Loss= 2.4390, Training Accuracy= 0.497\n",
      "Epoch: 730, Minibatch Loss= 2.4389, Training Accuracy= 0.497\n",
      "Epoch: 740, Minibatch Loss= 2.4388, Training Accuracy= 0.497\n",
      "Epoch: 750, Minibatch Loss= 2.4388, Training Accuracy= 0.497\n",
      "Epoch: 760, Minibatch Loss= 2.4388, Training Accuracy= 0.497\n",
      "Epoch: 770, Minibatch Loss= 2.4387, Training Accuracy= 0.497\n",
      "Epoch: 780, Minibatch Loss= 2.4387, Training Accuracy= 0.497\n",
      "Epoch: 790, Minibatch Loss= 2.4386, Training Accuracy= 0.497\n",
      "Epoch: 800, Minibatch Loss= 2.4386, Training Accuracy= 0.497\n",
      "Epoch: 810, Minibatch Loss= 2.4386, Training Accuracy= 0.497\n",
      "Epoch: 820, Minibatch Loss= 2.4385, Training Accuracy= 0.497\n",
      "Epoch: 830, Minibatch Loss= 2.4385, Training Accuracy= 0.497\n",
      "Epoch: 840, Minibatch Loss= 2.4385, Training Accuracy= 0.497\n",
      "Epoch: 850, Minibatch Loss= 2.4385, Training Accuracy= 0.497\n",
      "Epoch: 860, Minibatch Loss= 2.4384, Training Accuracy= 0.497\n",
      "Epoch: 870, Minibatch Loss= 2.4384, Training Accuracy= 0.497\n",
      "Epoch: 880, Minibatch Loss= 2.4384, Training Accuracy= 0.497\n",
      "Epoch: 890, Minibatch Loss= 2.4384, Training Accuracy= 0.497\n",
      "Epoch: 900, Minibatch Loss= 2.4384, Training Accuracy= 0.497\n",
      "Epoch: 910, Minibatch Loss= 2.4383, Training Accuracy= 0.497\n",
      "Epoch: 920, Minibatch Loss= 2.4383, Training Accuracy= 0.497\n",
      "Epoch: 930, Minibatch Loss= 2.4383, Training Accuracy= 0.497\n",
      "Epoch: 940, Minibatch Loss= 2.4383, Training Accuracy= 0.497\n",
      "Epoch: 950, Minibatch Loss= 2.4383, Training Accuracy= 0.497\n",
      "Epoch: 960, Minibatch Loss= 2.4383, Training Accuracy= 0.497\n",
      "Epoch: 970, Minibatch Loss= 2.4382, Training Accuracy= 0.497\n",
      "Epoch: 980, Minibatch Loss= 2.4382, Training Accuracy= 0.497\n",
      "Epoch: 990, Minibatch Loss= 2.4382, Training Accuracy= 0.497\n",
      "Epoch: 1000, Minibatch Loss= 2.4382, Training Accuracy= 0.497\n",
      "Epoch: 1010, Minibatch Loss= 2.4382, Training Accuracy= 0.497\n",
      "Epoch: 1020, Minibatch Loss= 2.4382, Training Accuracy= 0.497\n",
      "Epoch: 1030, Minibatch Loss= 2.4382, Training Accuracy= 0.497\n",
      "Epoch: 1040, Minibatch Loss= 2.4382, Training Accuracy= 0.497\n",
      "Epoch: 1050, Minibatch Loss= 2.4382, Training Accuracy= 0.497\n",
      "Epoch: 1060, Minibatch Loss= 2.4381, Training Accuracy= 0.497\n",
      "Epoch: 1070, Minibatch Loss= 2.4381, Training Accuracy= 0.497\n",
      "Epoch: 1080, Minibatch Loss= 2.4381, Training Accuracy= 0.497\n",
      "Epoch: 1090, Minibatch Loss= 2.4381, Training Accuracy= 0.497\n",
      "Epoch: 1100, Minibatch Loss= 2.4381, Training Accuracy= 0.497\n",
      "Epoch: 1110, Minibatch Loss= 2.4381, Training Accuracy= 0.497\n",
      "Epoch: 1120, Minibatch Loss= 2.4381, Training Accuracy= 0.497\n",
      "Epoch: 1130, Minibatch Loss= 2.4381, Training Accuracy= 0.497\n",
      "Epoch: 1140, Minibatch Loss= 2.4381, Training Accuracy= 0.497\n",
      "Epoch: 1150, Minibatch Loss= 2.4381, Training Accuracy= 0.497\n",
      "Epoch: 1160, Minibatch Loss= 2.4380, Training Accuracy= 0.497\n",
      "Epoch: 1170, Minibatch Loss= 2.4380, Training Accuracy= 0.497\n",
      "Epoch: 1180, Minibatch Loss= 2.4380, Training Accuracy= 0.497\n",
      "Epoch: 1190, Minibatch Loss= 2.4380, Training Accuracy= 0.497\n",
      "Epoch: 1200, Minibatch Loss= 2.4380, Training Accuracy= 0.497\n",
      "Epoch: 1210, Minibatch Loss= 2.4380, Training Accuracy= 0.497\n",
      "Epoch: 1220, Minibatch Loss= 2.4380, Training Accuracy= 0.497\n",
      "Epoch: 1230, Minibatch Loss= 2.4380, Training Accuracy= 0.497\n",
      "Epoch: 1240, Minibatch Loss= 2.4380, Training Accuracy= 0.497\n",
      "Epoch: 1250, Minibatch Loss= 2.4380, Training Accuracy= 0.497\n",
      "Epoch: 1260, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1270, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1280, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1290, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1300, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1310, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1320, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1330, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1340, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1350, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1360, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1370, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1380, Minibatch Loss= 2.4379, Training Accuracy= 0.497\n",
      "Epoch: 1390, Minibatch Loss= 2.4378, Training Accuracy= 0.497\n",
      "Epoch: 1400, Minibatch Loss= 2.4378, Training Accuracy= 0.497\n",
      "Epoch: 1410, Minibatch Loss= 2.4378, Training Accuracy= 0.497\n",
      "Epoch: 1420, Minibatch Loss= 2.4378, Training Accuracy= 0.497\n",
      "Epoch: 1430, Minibatch Loss= 2.4378, Training Accuracy= 0.497\n",
      "Epoch: 1440, Minibatch Loss= 2.4378, Training Accuracy= 0.497\n",
      "Epoch: 1450, Minibatch Loss= 2.4378, Training Accuracy= 0.497\n",
      "Epoch: 1460, Minibatch Loss= 2.4378, Training Accuracy= 0.497\n",
      "Epoch: 1470, Minibatch Loss= 2.4378, Training Accuracy= 0.497\n",
      "Epoch: 1480, Minibatch Loss= 2.4377, Training Accuracy= 0.497\n",
      "Epoch: 1490, Minibatch Loss= 2.4377, Training Accuracy= 0.497\n",
      "Epoch: 1500, Minibatch Loss= 2.4377, Training Accuracy= 0.497\n",
      "Epoch: 1510, Minibatch Loss= 2.4377, Training Accuracy= 0.497\n",
      "Epoch: 1520, Minibatch Loss= 2.4377, Training Accuracy= 0.497\n",
      "Epoch: 1530, Minibatch Loss= 2.4377, Training Accuracy= 0.497\n",
      "Epoch: 1540, Minibatch Loss= 2.4377, Training Accuracy= 0.497\n",
      "Epoch: 1550, Minibatch Loss= 2.4377, Training Accuracy= 0.497\n",
      "Epoch: 1560, Minibatch Loss= 2.4377, Training Accuracy= 0.497\n",
      "Epoch: 1570, Minibatch Loss= 2.4377, Training Accuracy= 0.497\n",
      "Epoch: 1580, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1590, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1600, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1610, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1620, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1630, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1640, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1650, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1660, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1670, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1680, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1690, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1700, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1710, Minibatch Loss= 2.4376, Training Accuracy= 0.497\n",
      "Epoch: 1720, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1730, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1740, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1750, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1760, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1770, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1780, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1790, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1800, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1810, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1820, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1830, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1840, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1850, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1860, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1870, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1880, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1890, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1900, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1910, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1920, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1930, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1940, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1950, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1960, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1970, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1980, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 1990, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 2000, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 2010, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 2020, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 2030, Minibatch Loss= 2.4375, Training Accuracy= 0.497\n",
      "Epoch: 2040, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2050, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2060, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2070, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2080, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2090, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2100, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2110, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2120, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2130, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2140, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2150, Minibatch Loss= 2.4374, Training Accuracy= 0.497\n",
      "Epoch: 2160, Minibatch Loss= 2.4373, Training Accuracy= 0.497\n",
      "Epoch: 2170, Minibatch Loss= 2.4373, Training Accuracy= 0.497\n",
      "Epoch: 2180, Minibatch Loss= 2.4373, Training Accuracy= 0.497\n",
      "Epoch: 2190, Minibatch Loss= 2.4373, Training Accuracy= 0.497\n",
      "Epoch: 2200, Minibatch Loss= 2.4372, Training Accuracy= 0.497\n",
      "Epoch: 2210, Minibatch Loss= 2.4372, Training Accuracy= 0.497\n",
      "Epoch: 2220, Minibatch Loss= 2.4372, Training Accuracy= 0.497\n",
      "Epoch: 2230, Minibatch Loss= 2.4371, Training Accuracy= 0.497\n",
      "Epoch: 2240, Minibatch Loss= 2.4371, Training Accuracy= 0.497\n",
      "Epoch: 2250, Minibatch Loss= 2.4371, Training Accuracy= 0.497\n",
      "Epoch: 2260, Minibatch Loss= 2.4370, Training Accuracy= 0.497\n",
      "Epoch: 2270, Minibatch Loss= 2.4370, Training Accuracy= 0.497\n",
      "Epoch: 2280, Minibatch Loss= 2.4370, Training Accuracy= 0.497\n",
      "Epoch: 2290, Minibatch Loss= 2.4369, Training Accuracy= 0.497\n",
      "Epoch: 2300, Minibatch Loss= 2.4369, Training Accuracy= 0.497\n",
      "Epoch: 2310, Minibatch Loss= 2.4369, Training Accuracy= 0.497\n",
      "Epoch: 2320, Minibatch Loss= 2.4369, Training Accuracy= 0.497\n",
      "Epoch: 2330, Minibatch Loss= 2.4369, Training Accuracy= 0.497\n",
      "Epoch: 2340, Minibatch Loss= 2.4368, Training Accuracy= 0.497\n",
      "Epoch: 2350, Minibatch Loss= 2.4368, Training Accuracy= 0.497\n",
      "Epoch: 2360, Minibatch Loss= 2.4368, Training Accuracy= 0.497\n",
      "Epoch: 2370, Minibatch Loss= 2.4368, Training Accuracy= 0.497\n",
      "Epoch: 2380, Minibatch Loss= 2.4368, Training Accuracy= 0.497\n",
      "Epoch: 2390, Minibatch Loss= 2.4368, Training Accuracy= 0.497\n",
      "Epoch: 2400, Minibatch Loss= 2.4368, Training Accuracy= 0.497\n",
      "Epoch: 2410, Minibatch Loss= 2.4367, Training Accuracy= 0.497\n",
      "Epoch: 2420, Minibatch Loss= 2.4367, Training Accuracy= 0.497\n",
      "Epoch: 2430, Minibatch Loss= 2.4367, Training Accuracy= 0.497\n",
      "Epoch: 2440, Minibatch Loss= 2.4367, Training Accuracy= 0.497\n",
      "Epoch: 2450, Minibatch Loss= 2.4367, Training Accuracy= 0.497\n",
      "Epoch: 2460, Minibatch Loss= 2.4367, Training Accuracy= 0.497\n",
      "Epoch: 2470, Minibatch Loss= 2.4367, Training Accuracy= 0.497\n",
      "Epoch: 2480, Minibatch Loss= 2.4367, Training Accuracy= 0.497\n",
      "Epoch: 2490, Minibatch Loss= 2.4366, Training Accuracy= 0.497\n",
      "Epoch: 2500, Minibatch Loss= 2.4366, Training Accuracy= 0.497\n",
      "Epoch: 2510, Minibatch Loss= 2.4366, Training Accuracy= 0.497\n",
      "Epoch: 2520, Minibatch Loss= 2.4366, Training Accuracy= 0.497\n",
      "Epoch: 2530, Minibatch Loss= 2.4366, Training Accuracy= 0.497\n",
      "Epoch: 2540, Minibatch Loss= 2.4366, Training Accuracy= 0.497\n",
      "Epoch: 2550, Minibatch Loss= 2.4366, Training Accuracy= 0.497\n",
      "Epoch: 2560, Minibatch Loss= 2.4366, Training Accuracy= 0.497\n",
      "Epoch: 2570, Minibatch Loss= 2.4366, Training Accuracy= 0.497\n",
      "Epoch: 2580, Minibatch Loss= 2.4366, Training Accuracy= 0.497\n",
      "Epoch: 2590, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2600, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2610, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2620, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2630, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2640, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2650, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2660, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2670, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2680, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2690, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2700, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2710, Minibatch Loss= 2.4365, Training Accuracy= 0.497\n",
      "Epoch: 2720, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2730, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2740, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2750, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2760, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2770, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2780, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2790, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2800, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2810, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2820, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2830, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2840, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2850, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2860, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2870, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2880, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2890, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2900, Minibatch Loss= 2.4364, Training Accuracy= 0.497\n",
      "Epoch: 2910, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 2920, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 2930, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2940, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 2950, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 2960, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 2970, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 2980, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 2990, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3000, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3010, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3020, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3030, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3040, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3050, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3060, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3070, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3080, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3090, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3100, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3110, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3120, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3130, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3140, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3150, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3160, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3170, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3180, Minibatch Loss= 2.4363, Training Accuracy= 0.497\n",
      "Epoch: 3190, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3200, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3210, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3220, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3230, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3240, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3250, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3260, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3270, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3280, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3290, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3300, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3310, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3320, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3330, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3340, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3350, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3360, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3370, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3380, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3390, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3400, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3410, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3420, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3430, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3440, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3450, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3460, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3470, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3480, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3490, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3500, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3510, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3520, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3530, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3540, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3550, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3560, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3570, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3580, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3590, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3600, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3610, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3620, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3630, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3640, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3650, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3660, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3670, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3680, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3690, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3700, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3710, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3720, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3730, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3740, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3750, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3760, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3770, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3780, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3790, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3800, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3810, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3820, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3830, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3840, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3850, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3860, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3870, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3880, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3890, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3900, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3910, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3920, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3930, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3940, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3950, Minibatch Loss= 2.4362, Training Accuracy= 0.497\n",
      "Epoch: 3960, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 3970, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 3980, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 3990, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4000, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4010, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4020, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4030, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4040, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4050, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4060, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4070, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4080, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4090, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4100, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4110, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4120, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4130, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4140, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4150, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4160, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4170, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4180, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4190, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4200, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4210, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4220, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4230, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4240, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4250, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4260, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4270, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4280, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4290, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4300, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4310, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4320, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4330, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4340, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4350, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4360, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4370, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4380, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4390, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4400, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4410, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4420, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4430, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4440, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4450, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4460, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4470, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4480, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4490, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4500, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4510, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4520, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4530, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4540, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4550, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4560, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4570, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4580, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4590, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4600, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4610, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4620, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4630, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4640, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4650, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4660, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4670, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4680, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4690, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4700, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4710, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4720, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4730, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4740, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4750, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4760, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4770, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4780, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4790, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4800, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4810, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4820, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4830, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4840, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4850, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4860, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4870, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4880, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4890, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4900, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4910, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4920, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4930, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4940, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4950, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4960, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4970, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4980, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Epoch: 4990, Minibatch Loss= 2.4361, Training Accuracy= 0.497\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5034\n",
      "Replication: 6: \n",
      "Epoch: 0, Minibatch Loss= 2.7340, Training Accuracy= 0.497\n",
      "Epoch: 10, Minibatch Loss= 2.7295, Training Accuracy= 0.497\n",
      "Epoch: 20, Minibatch Loss= 2.7293, Training Accuracy= 0.497\n",
      "Epoch: 30, Minibatch Loss= 2.7292, Training Accuracy= 0.497\n",
      "Epoch: 40, Minibatch Loss= 2.7292, Training Accuracy= 0.497\n",
      "Epoch: 50, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 60, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 70, Minibatch Loss= 2.7292, Training Accuracy= 0.497\n",
      "Epoch: 80, Minibatch Loss= 2.7292, Training Accuracy= 0.497\n",
      "Epoch: 90, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 100, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 110, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 120, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 130, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 140, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 150, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 160, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 170, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 180, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 190, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 200, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 210, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 220, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 230, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 240, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 250, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 260, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 270, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 280, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 290, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 300, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 310, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 320, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 330, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 340, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 350, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 360, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 370, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 380, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 390, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 400, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 410, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 420, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 430, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 440, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 450, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 460, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 470, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 480, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 490, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 500, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 510, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 520, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 530, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 540, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 550, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 560, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 570, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 580, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 590, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 610, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 620, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 630, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 640, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 650, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 660, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 670, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 680, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 690, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 700, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 710, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 720, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 730, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 740, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 750, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 760, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 770, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 780, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 790, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 800, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 810, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 820, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 830, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 840, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 850, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 860, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 870, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 880, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 890, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 900, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 910, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 920, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 930, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 940, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 950, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 960, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 970, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 980, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 990, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1000, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1010, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1020, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1030, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1040, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1050, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1060, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1070, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1080, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1090, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1100, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1110, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1120, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1130, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1140, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1150, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1160, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1170, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1180, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1190, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1200, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1210, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1220, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1230, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1240, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1250, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1260, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1270, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1280, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1290, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1300, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1310, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1320, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1330, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1340, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1350, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1360, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1370, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1380, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1390, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1400, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1410, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1420, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1430, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1440, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1450, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1460, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1470, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1480, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1490, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1500, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1510, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1520, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1530, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1540, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1550, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1560, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1570, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1580, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1590, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1600, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1610, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1620, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1630, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1640, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1650, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1660, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1670, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1680, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1690, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1700, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1710, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1720, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1730, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1740, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1750, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1760, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1770, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1780, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1790, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1800, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1810, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1820, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1830, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1840, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1850, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1860, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1870, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1880, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1890, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1900, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1910, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1920, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1930, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1940, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1950, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1960, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1970, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1980, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 1990, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2000, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2010, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2020, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2030, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2040, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2050, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2060, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2070, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2080, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2090, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2100, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2110, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2120, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2130, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2140, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2150, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2160, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2170, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2180, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2190, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2200, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2210, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2220, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2230, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2240, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2250, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2260, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2270, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2280, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2290, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2300, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2310, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2320, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2330, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2340, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2350, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2360, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2370, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2380, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2390, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2400, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2410, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2420, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2430, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2440, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2450, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2460, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2470, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2480, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2490, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2500, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2510, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2520, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2530, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2540, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2550, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2560, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2570, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2580, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2590, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2600, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2610, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2620, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2630, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2640, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2650, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2660, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2670, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2680, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2690, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2700, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2710, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2720, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2730, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2740, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2750, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2760, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2770, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2780, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2790, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2800, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2810, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2820, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2830, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2840, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2850, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2860, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2870, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2880, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2890, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2900, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2910, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2920, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2930, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2940, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2950, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2960, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2970, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2980, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 2990, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3000, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3010, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3020, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3030, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3040, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3050, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3060, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3070, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3080, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3090, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3100, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3110, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3120, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3130, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3140, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3150, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3160, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3170, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3180, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3190, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3200, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3210, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3220, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3230, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3240, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3250, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3260, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3270, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3280, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3290, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3300, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3310, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3320, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3330, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3340, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3350, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3360, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3370, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3380, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3390, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3400, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3410, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3420, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3430, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3440, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3450, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3460, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3470, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3480, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3490, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3500, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3510, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3520, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3530, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3540, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3550, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3560, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3570, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3580, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3590, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3600, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3610, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3620, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3630, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3640, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3650, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3660, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3670, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3680, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3690, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3700, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3710, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3720, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3730, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3740, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3750, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3760, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3770, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3780, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3790, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3800, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3810, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3820, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3830, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3840, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3850, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3860, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3870, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3880, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3890, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3900, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3910, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3920, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3930, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3940, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3950, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3960, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3970, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3980, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 3990, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4000, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4010, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4020, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4030, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4040, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4050, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4060, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4070, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4080, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4090, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4100, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4110, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4120, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4130, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4140, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4150, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4160, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4170, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4180, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4190, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4200, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4210, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4220, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4230, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4240, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4250, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4260, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4270, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4280, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4290, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4300, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4310, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4320, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4330, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4340, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4350, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4360, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4370, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4380, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4390, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4400, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4410, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4420, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4430, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4440, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4450, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4460, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4470, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4480, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4490, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4500, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4510, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4520, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4530, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4540, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4550, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4560, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4570, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4580, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4590, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4600, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4610, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4620, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4630, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4640, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4650, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4660, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4670, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4680, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4690, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4700, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4710, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4720, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4730, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4740, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4750, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4760, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4770, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4780, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4790, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4800, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4810, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4820, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4830, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4840, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4850, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4860, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4870, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4880, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4890, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4900, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4910, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4920, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4930, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4940, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4950, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4960, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4970, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4980, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Epoch: 4990, Minibatch Loss= 2.7291, Training Accuracy= 0.497\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5057\n",
      "Replication: 7: \n",
      "Epoch: 0, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 10, Minibatch Loss= 0.8010, Training Accuracy= 0.496\n",
      "Epoch: 20, Minibatch Loss= 0.8010, Training Accuracy= 0.496\n",
      "Epoch: 30, Minibatch Loss= 0.8010, Training Accuracy= 0.496\n",
      "Epoch: 40, Minibatch Loss= 0.8010, Training Accuracy= 0.496\n",
      "Epoch: 50, Minibatch Loss= 0.8010, Training Accuracy= 0.496\n",
      "Epoch: 60, Minibatch Loss= 0.8010, Training Accuracy= 0.496\n",
      "Epoch: 70, Minibatch Loss= 0.8010, Training Accuracy= 0.496\n",
      "Epoch: 80, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 90, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 100, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 110, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 120, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 130, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 140, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 150, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 160, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 170, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 180, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 190, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 200, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 210, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 220, Minibatch Loss= 0.8011, Training Accuracy= 0.496\n",
      "Epoch: 230, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 240, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 250, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 260, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 270, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 280, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 290, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 300, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 310, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 320, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 330, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 340, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 350, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 360, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 370, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 380, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 390, Minibatch Loss= 0.8012, Training Accuracy= 0.496\n",
      "Epoch: 400, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 410, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 420, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 430, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 440, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 450, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 460, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 470, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 480, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 490, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 500, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 510, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 520, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 530, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 540, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 550, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 560, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 570, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 580, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 590, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 600, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 610, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 620, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 630, Minibatch Loss= 0.8013, Training Accuracy= 0.496\n",
      "Epoch: 640, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 650, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 660, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 670, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 680, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 690, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 700, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 710, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 720, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 730, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 740, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 750, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 760, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 770, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 780, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 790, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 800, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 810, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 820, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 830, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 840, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 850, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 860, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 870, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 880, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 890, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 900, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 910, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 920, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 930, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 940, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 950, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 960, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 970, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 980, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 990, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1000, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1010, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1020, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1030, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1040, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1050, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1060, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1070, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1080, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1090, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1100, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1110, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1120, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1130, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1140, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1150, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1160, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1170, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1180, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1190, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1200, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1210, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1220, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1230, Minibatch Loss= 0.8014, Training Accuracy= 0.496\n",
      "Epoch: 1240, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1250, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1260, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1270, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1280, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1290, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1300, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1310, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1320, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1330, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1340, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1350, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1360, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1370, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1380, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1390, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1400, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1410, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1420, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1430, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1440, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1450, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1460, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1470, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1480, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1490, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1500, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1510, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1520, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1530, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1540, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1550, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1560, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1570, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1580, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1590, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1600, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1610, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1620, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1630, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1640, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1650, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1660, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1670, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1680, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1690, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1700, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1710, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1720, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1730, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1740, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1750, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1760, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1770, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1780, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1790, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1800, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1810, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1820, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1830, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1840, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1850, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1860, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1870, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1880, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1890, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1900, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1910, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1920, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1930, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1940, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1950, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1960, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1970, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1980, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 1990, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2000, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2010, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2020, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2030, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2040, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2050, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2060, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2070, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2080, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2090, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2100, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2110, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2120, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2130, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2140, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2150, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2160, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2170, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2180, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2190, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2200, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2210, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2220, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2230, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2240, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2250, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2260, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2270, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2280, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2290, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2300, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2310, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2320, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2330, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2340, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2350, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2360, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2370, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2380, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2390, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2400, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2410, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2420, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2430, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2440, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2450, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2460, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2470, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2480, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2490, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2500, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2510, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2520, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2530, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2540, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2550, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2560, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2570, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2580, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2590, Minibatch Loss= 0.8015, Training Accuracy= 0.496\n",
      "Epoch: 2600, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2610, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2620, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2630, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2640, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2650, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2660, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2670, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2680, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2690, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2700, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2710, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2720, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2730, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2740, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2750, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2760, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2770, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2780, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2790, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2800, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2810, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2820, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2830, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2840, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2850, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2860, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2870, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2880, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2890, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2900, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2910, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2920, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2930, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2940, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2950, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2960, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2970, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2980, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 2990, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3000, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3010, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3020, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3030, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3040, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3050, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3060, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3070, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3080, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3090, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3100, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3110, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3120, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3130, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3140, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3150, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3160, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3170, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3180, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3190, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3200, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3210, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3220, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3230, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3240, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3250, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3260, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3270, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3280, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3290, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3300, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3310, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3320, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3330, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3340, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3350, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3360, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3370, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3380, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3390, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3400, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3410, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3420, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3430, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3440, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3450, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3460, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3470, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3480, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3490, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3500, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3510, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3520, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3530, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3540, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3550, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3560, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3570, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3580, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3590, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3600, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3610, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3620, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3630, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3640, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3650, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3660, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3670, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3680, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3690, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3700, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3710, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3720, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3730, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3740, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3750, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3760, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3770, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3780, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3790, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3800, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3810, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3820, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3830, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3840, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3850, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3860, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3870, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3880, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3890, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3900, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3910, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3920, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3930, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3940, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3950, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3960, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3970, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3980, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 3990, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4000, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4010, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4020, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4030, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4040, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4050, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4060, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4070, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4080, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4090, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4100, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4110, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4120, Minibatch Loss= 0.8016, Training Accuracy= 0.496\n",
      "Epoch: 4130, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4140, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4150, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4160, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4170, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4180, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4190, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4200, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4210, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4220, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4230, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4240, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4250, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4260, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4270, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4280, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4290, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4300, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4310, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4320, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4330, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4340, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4350, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4360, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4370, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4380, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4390, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4400, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4410, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4420, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4430, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4440, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4450, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4460, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4470, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4480, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4490, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4500, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4510, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4520, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4530, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4540, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4550, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4560, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4570, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4580, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4590, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4600, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4610, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4620, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4630, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4640, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4650, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4660, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4670, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4680, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4690, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4700, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4710, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4720, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4730, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4740, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4750, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4760, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4770, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4780, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4790, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4800, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4810, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4820, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4830, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4840, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4850, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4860, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4870, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4880, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4890, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4900, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4910, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4920, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4930, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4940, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4950, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4960, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4970, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4980, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Epoch: 4990, Minibatch Loss= 0.8017, Training Accuracy= 0.496\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5029\n",
      "Replication: 8: \n",
      "Epoch: 0, Minibatch Loss= 2.0019, Training Accuracy= 0.512\n",
      "Epoch: 10, Minibatch Loss= 1.9999, Training Accuracy= 0.512\n",
      "Epoch: 20, Minibatch Loss= 1.9998, Training Accuracy= 0.512\n",
      "Epoch: 30, Minibatch Loss= 1.9997, Training Accuracy= 0.512\n",
      "Epoch: 40, Minibatch Loss= 1.9997, Training Accuracy= 0.512\n",
      "Epoch: 50, Minibatch Loss= 1.9997, Training Accuracy= 0.512\n",
      "Epoch: 60, Minibatch Loss= 1.9997, Training Accuracy= 0.512\n",
      "Epoch: 70, Minibatch Loss= 1.9997, Training Accuracy= 0.512\n",
      "Epoch: 80, Minibatch Loss= 1.9997, Training Accuracy= 0.512\n",
      "Epoch: 90, Minibatch Loss= 1.9997, Training Accuracy= 0.512\n",
      "Epoch: 100, Minibatch Loss= 1.9997, Training Accuracy= 0.512\n",
      "Epoch: 110, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 120, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 130, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 140, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 150, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 160, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 170, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 180, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 190, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 200, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 210, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 220, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 230, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 240, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 250, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 260, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 270, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 280, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 290, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 300, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 310, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 320, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 330, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 340, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 350, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 360, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 370, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 380, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 390, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 400, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 410, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 420, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 430, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 440, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 450, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 460, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 470, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 480, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 490, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 500, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 510, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 520, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 530, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 540, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 550, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 560, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 570, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 580, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 590, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 600, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 610, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 620, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 630, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 640, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 650, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 660, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 670, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 680, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 690, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 700, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 710, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 720, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 730, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 740, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 750, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 760, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 770, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 780, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 790, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 800, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 810, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 820, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 830, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 840, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 850, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 860, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 870, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 880, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 890, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 900, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 910, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 920, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 930, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 940, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 950, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 960, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 970, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 980, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 990, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1000, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1010, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1020, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1030, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1040, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1050, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1060, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1070, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1080, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1090, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1100, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1110, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1120, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1130, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1140, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1150, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1160, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1170, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1180, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1190, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1200, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1210, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1220, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1230, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1240, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1250, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1260, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1270, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1280, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1290, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1300, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1310, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1320, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1330, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1340, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1350, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1360, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1370, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1380, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1390, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1400, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1410, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1420, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1430, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1440, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1450, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1460, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1470, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1480, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1490, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1500, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1510, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1520, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1530, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1540, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1550, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1560, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1570, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1580, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1590, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1600, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1610, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1620, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1630, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1640, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1650, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1660, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1670, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1680, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1690, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1700, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1710, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1720, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1730, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1740, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1750, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1760, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1770, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1780, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1790, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1800, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1810, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1820, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1830, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1840, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1850, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1860, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1870, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1880, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1890, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1900, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1910, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1920, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1930, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1940, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1950, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1960, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1970, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1980, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 1990, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2000, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2010, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2020, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2030, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2040, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2050, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2060, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2070, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2080, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2090, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2100, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2110, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2120, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2130, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2140, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2150, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2160, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2170, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2180, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2190, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2200, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2210, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2220, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2230, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2240, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2250, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2260, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2270, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2280, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2290, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2300, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2310, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2320, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2330, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2340, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2350, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2360, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2370, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2380, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2390, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2400, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2410, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2420, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2430, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2440, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2450, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2460, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2470, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2480, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2490, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2500, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2510, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2520, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2530, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2540, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2550, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2560, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2570, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2580, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2590, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2600, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2610, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2620, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2630, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2640, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2650, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2660, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2670, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2680, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2690, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2700, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2710, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2720, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2730, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2740, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2750, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2760, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2770, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2780, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2790, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2800, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2810, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2820, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2830, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2840, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2850, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2860, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2870, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2880, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2890, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2900, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2910, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2920, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2930, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2940, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2950, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2960, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2970, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2980, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 2990, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3000, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3010, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3020, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3030, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3040, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3050, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3060, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3070, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3080, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3090, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3100, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3110, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3120, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3130, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3140, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3150, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3160, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3170, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3180, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3190, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3200, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3210, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3220, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3230, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3240, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3250, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3260, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3270, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3280, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3290, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3300, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3310, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3320, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3330, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3340, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3350, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3360, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3370, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3380, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3390, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3400, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3410, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3420, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3430, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3440, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3450, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3460, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3470, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3480, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3490, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3500, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3510, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3520, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3530, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3540, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3550, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3560, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3570, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3580, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3590, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3600, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3610, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3620, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3630, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3640, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3650, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3660, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3670, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3680, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3690, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3700, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3710, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3720, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3730, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3740, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3750, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3760, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3770, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3780, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3790, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3800, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3810, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3820, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3830, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3840, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3850, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3860, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3870, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3880, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3890, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3900, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3910, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3920, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3930, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3940, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3950, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3960, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3970, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3980, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 3990, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4000, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4010, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4020, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4030, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4040, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4050, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4060, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4070, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4080, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4090, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4100, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4110, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4120, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4130, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4140, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4150, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4160, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4170, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4180, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4190, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4200, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4210, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4220, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4230, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4240, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4250, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4260, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4270, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4280, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4290, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4300, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4310, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4320, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4330, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4340, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4350, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4360, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4370, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4380, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4390, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4400, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4410, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4420, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4430, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4440, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4450, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4460, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4470, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4480, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4490, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4500, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4510, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4520, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4530, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4540, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4550, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4560, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4570, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4580, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4590, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4600, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4610, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4620, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4630, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4640, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4650, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4660, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4670, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4680, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4690, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4700, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4710, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4720, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4730, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4740, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4750, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4760, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4770, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4780, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4790, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4800, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4810, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4820, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4830, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4840, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4850, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4860, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4870, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4880, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4890, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4900, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4910, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4920, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4930, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4940, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4950, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4960, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4970, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4980, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Epoch: 4990, Minibatch Loss= 1.9996, Training Accuracy= 0.512\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4996\n",
      "Replication: 9: \n",
      "Epoch: 0, Minibatch Loss= 2.5336, Training Accuracy= 0.498\n",
      "Epoch: 10, Minibatch Loss= 2.5292, Training Accuracy= 0.498\n",
      "Epoch: 20, Minibatch Loss= 2.5290, Training Accuracy= 0.498\n",
      "Epoch: 30, Minibatch Loss= 2.5290, Training Accuracy= 0.498\n",
      "Epoch: 40, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 50, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 60, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 70, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 80, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 90, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 100, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 110, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 120, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 130, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 140, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 150, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 160, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 170, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 180, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 190, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 200, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 210, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 230, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 240, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 250, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 260, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 270, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 280, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 290, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 300, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 310, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 320, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 330, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 340, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 350, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 360, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 370, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 380, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 390, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 400, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 410, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 420, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 430, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 440, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 450, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 460, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 470, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 480, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 490, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 500, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 510, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 520, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 530, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 540, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 550, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 560, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 570, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 580, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 590, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 600, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 610, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 620, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 630, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 640, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 650, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 660, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 670, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 680, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 690, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 700, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 710, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 720, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 730, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 740, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 750, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 760, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 770, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 780, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 790, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 800, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 810, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 820, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 830, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 840, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 850, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 860, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 870, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 880, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 890, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 900, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 910, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 920, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 930, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 940, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 950, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 960, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 970, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 980, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 990, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1000, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1010, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1020, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1030, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1040, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1050, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1060, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1070, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1080, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1090, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 1100, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1110, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 1120, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 1130, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 1140, Minibatch Loss= 2.5288, Training Accuracy= 0.498\n",
      "Epoch: 1150, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1160, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1170, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1180, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1190, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1200, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1210, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1220, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1230, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1240, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1250, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1260, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1270, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1280, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1290, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1300, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1310, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1320, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1330, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1340, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1350, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1360, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1370, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1380, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1390, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1400, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1410, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1420, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1430, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1440, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1450, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1460, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1470, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1480, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1490, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1500, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1510, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1520, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1530, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1540, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1550, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1560, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1570, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1580, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1590, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1600, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1610, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1620, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1630, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1640, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1650, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1660, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1670, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1680, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1690, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1700, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1710, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1720, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1730, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1740, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1750, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1760, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1770, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1780, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1790, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1800, Minibatch Loss= 2.5289, Training Accuracy= 0.498\n",
      "Epoch: 1810, Minibatch Loss= 2.5290, Training Accuracy= 0.498\n",
      "Epoch: 1820, Minibatch Loss= 2.5290, Training Accuracy= 0.498\n",
      "Epoch: 1830, Minibatch Loss= 2.5290, Training Accuracy= 0.498\n",
      "Epoch: 1840, Minibatch Loss= 2.5290, Training Accuracy= 0.498\n",
      "Epoch: 1850, Minibatch Loss= 2.5290, Training Accuracy= 0.498\n",
      "Epoch: 1860, Minibatch Loss= 2.5290, Training Accuracy= 0.498\n",
      "Epoch: 1870, Minibatch Loss= 2.5290, Training Accuracy= 0.498\n",
      "Epoch: 1880, Minibatch Loss= 2.5291, Training Accuracy= 0.498\n",
      "Epoch: 1890, Minibatch Loss= 2.5291, Training Accuracy= 0.498\n",
      "Epoch: 1900, Minibatch Loss= 2.5291, Training Accuracy= 0.498\n",
      "Epoch: 1910, Minibatch Loss= 2.5291, Training Accuracy= 0.498\n",
      "Epoch: 1920, Minibatch Loss= 2.5292, Training Accuracy= 0.498\n",
      "Epoch: 1930, Minibatch Loss= 2.5292, Training Accuracy= 0.498\n",
      "Epoch: 1940, Minibatch Loss= 2.5292, Training Accuracy= 0.498\n",
      "Epoch: 1950, Minibatch Loss= 2.5292, Training Accuracy= 0.498\n",
      "Epoch: 1960, Minibatch Loss= 2.5293, Training Accuracy= 0.498\n",
      "Epoch: 1970, Minibatch Loss= 2.5293, Training Accuracy= 0.498\n",
      "Epoch: 1980, Minibatch Loss= 2.5293, Training Accuracy= 0.498\n",
      "Epoch: 1990, Minibatch Loss= 2.5293, Training Accuracy= 0.498\n",
      "Epoch: 2000, Minibatch Loss= 2.5294, Training Accuracy= 0.498\n",
      "Epoch: 2010, Minibatch Loss= 2.5294, Training Accuracy= 0.498\n",
      "Epoch: 2020, Minibatch Loss= 2.5294, Training Accuracy= 0.498\n",
      "Epoch: 2030, Minibatch Loss= 2.5294, Training Accuracy= 0.498\n",
      "Epoch: 2040, Minibatch Loss= 2.5294, Training Accuracy= 0.498\n",
      "Epoch: 2050, Minibatch Loss= 2.5295, Training Accuracy= 0.498\n",
      "Epoch: 2060, Minibatch Loss= 2.5295, Training Accuracy= 0.498\n",
      "Epoch: 2070, Minibatch Loss= 2.5295, Training Accuracy= 0.498\n",
      "Epoch: 2080, Minibatch Loss= 2.5295, Training Accuracy= 0.498\n",
      "Epoch: 2090, Minibatch Loss= 2.5295, Training Accuracy= 0.498\n",
      "Epoch: 2100, Minibatch Loss= 2.5295, Training Accuracy= 0.498\n",
      "Epoch: 2110, Minibatch Loss= 2.5295, Training Accuracy= 0.498\n",
      "Epoch: 2120, Minibatch Loss= 2.5296, Training Accuracy= 0.498\n",
      "Epoch: 2130, Minibatch Loss= 2.5296, Training Accuracy= 0.498\n",
      "Epoch: 2140, Minibatch Loss= 2.5296, Training Accuracy= 0.498\n",
      "Epoch: 2150, Minibatch Loss= 2.5296, Training Accuracy= 0.498\n",
      "Epoch: 2160, Minibatch Loss= 2.5296, Training Accuracy= 0.498\n",
      "Epoch: 2170, Minibatch Loss= 2.5296, Training Accuracy= 0.498\n",
      "Epoch: 2180, Minibatch Loss= 2.5296, Training Accuracy= 0.498\n",
      "Epoch: 2190, Minibatch Loss= 2.5296, Training Accuracy= 0.498\n",
      "Epoch: 2200, Minibatch Loss= 2.5296, Training Accuracy= 0.498\n",
      "Epoch: 2210, Minibatch Loss= 2.5297, Training Accuracy= 0.498\n",
      "Epoch: 2220, Minibatch Loss= 2.5297, Training Accuracy= 0.498\n",
      "Epoch: 2230, Minibatch Loss= 2.5297, Training Accuracy= 0.498\n",
      "Epoch: 2240, Minibatch Loss= 2.5297, Training Accuracy= 0.498\n",
      "Epoch: 2250, Minibatch Loss= 2.5298, Training Accuracy= 0.498\n",
      "Epoch: 2260, Minibatch Loss= 2.5298, Training Accuracy= 0.498\n",
      "Epoch: 2270, Minibatch Loss= 2.5298, Training Accuracy= 0.498\n",
      "Epoch: 2280, Minibatch Loss= 2.5299, Training Accuracy= 0.498\n",
      "Epoch: 2290, Minibatch Loss= 2.5300, Training Accuracy= 0.498\n",
      "Epoch: 2300, Minibatch Loss= 2.5301, Training Accuracy= 0.498\n",
      "Epoch: 2310, Minibatch Loss= 2.5303, Training Accuracy= 0.498\n",
      "Epoch: 2320, Minibatch Loss= 2.5305, Training Accuracy= 0.498\n",
      "Epoch: 2330, Minibatch Loss= 2.5307, Training Accuracy= 0.498\n",
      "Epoch: 2340, Minibatch Loss= 2.5308, Training Accuracy= 0.498\n",
      "Epoch: 2350, Minibatch Loss= 2.5309, Training Accuracy= 0.498\n",
      "Epoch: 2360, Minibatch Loss= 2.5310, Training Accuracy= 0.498\n",
      "Epoch: 2370, Minibatch Loss= 2.5311, Training Accuracy= 0.498\n",
      "Epoch: 2380, Minibatch Loss= 2.5312, Training Accuracy= 0.498\n",
      "Epoch: 2390, Minibatch Loss= 2.5312, Training Accuracy= 0.498\n",
      "Epoch: 2400, Minibatch Loss= 2.5313, Training Accuracy= 0.498\n",
      "Epoch: 2410, Minibatch Loss= 2.5313, Training Accuracy= 0.498\n",
      "Epoch: 2420, Minibatch Loss= 2.5314, Training Accuracy= 0.498\n",
      "Epoch: 2430, Minibatch Loss= 2.5314, Training Accuracy= 0.498\n",
      "Epoch: 2440, Minibatch Loss= 2.5314, Training Accuracy= 0.498\n",
      "Epoch: 2450, Minibatch Loss= 2.5314, Training Accuracy= 0.498\n",
      "Epoch: 2460, Minibatch Loss= 2.5315, Training Accuracy= 0.498\n",
      "Epoch: 2470, Minibatch Loss= 2.5315, Training Accuracy= 0.498\n",
      "Epoch: 2480, Minibatch Loss= 2.5315, Training Accuracy= 0.498\n",
      "Epoch: 2490, Minibatch Loss= 2.5315, Training Accuracy= 0.498\n",
      "Epoch: 2500, Minibatch Loss= 2.5315, Training Accuracy= 0.498\n",
      "Epoch: 2510, Minibatch Loss= 2.5316, Training Accuracy= 0.498\n",
      "Epoch: 2520, Minibatch Loss= 2.5316, Training Accuracy= 0.498\n",
      "Epoch: 2530, Minibatch Loss= 2.5316, Training Accuracy= 0.498\n",
      "Epoch: 2540, Minibatch Loss= 2.5316, Training Accuracy= 0.498\n",
      "Epoch: 2550, Minibatch Loss= 2.5316, Training Accuracy= 0.498\n",
      "Epoch: 2560, Minibatch Loss= 2.5316, Training Accuracy= 0.498\n",
      "Epoch: 2570, Minibatch Loss= 2.5316, Training Accuracy= 0.498\n",
      "Epoch: 2580, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2590, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2600, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2610, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2620, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2630, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2640, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2650, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2660, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2670, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2680, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2690, Minibatch Loss= 2.5317, Training Accuracy= 0.498\n",
      "Epoch: 2700, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2710, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2720, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2730, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2740, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2750, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2760, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2770, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2780, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2790, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2800, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2810, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2820, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2830, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2840, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2850, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2860, Minibatch Loss= 2.5318, Training Accuracy= 0.498\n",
      "Epoch: 2870, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2880, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2890, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2900, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2910, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2920, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2930, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2940, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2950, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2960, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2970, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2980, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 2990, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3000, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3010, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3020, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3030, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3040, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3050, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3060, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3070, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3080, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3090, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3100, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3110, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3120, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3130, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3140, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3150, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3160, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3170, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3180, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3190, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3200, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3210, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3220, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3230, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3240, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3250, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3260, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3270, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3280, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3290, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3300, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3310, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3320, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3330, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3340, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3350, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3360, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3370, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3380, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3390, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3400, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3410, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3420, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3430, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3440, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3450, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3460, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3470, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3480, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3490, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3500, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3510, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3520, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3530, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3540, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3550, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3560, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3570, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3580, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3590, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3600, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3610, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3620, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3630, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3640, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3650, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3660, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3670, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3680, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3690, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3700, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3710, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3720, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3730, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3740, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3750, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3760, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3770, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3780, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3790, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3800, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3810, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3820, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3830, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3840, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3850, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3860, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3870, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3880, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3890, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3900, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3910, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3920, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3930, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3940, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3950, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3960, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3970, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3980, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 3990, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4000, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4010, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4020, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4030, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4040, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4050, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4060, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4070, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4080, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4090, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4100, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4110, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4120, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4130, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4140, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4150, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4160, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4170, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4180, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4190, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4200, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4210, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4220, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4230, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4240, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4250, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4260, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4270, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4280, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4290, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4300, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4310, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4320, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4330, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4340, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4350, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4360, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4370, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4380, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4390, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4400, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4410, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4420, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4430, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4440, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4450, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4460, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4470, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4480, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4490, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4500, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4510, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4520, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4530, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4540, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4550, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4560, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4570, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4580, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4590, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4600, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4610, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4620, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4630, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4640, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4650, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4660, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4670, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4680, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4690, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4700, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4710, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4720, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4730, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4740, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4750, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4760, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4770, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4780, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4790, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4800, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4810, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4820, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4830, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4840, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4850, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4860, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4870, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4880, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4890, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4900, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4910, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4920, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4930, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4940, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4950, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4960, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4970, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4980, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Epoch: 4990, Minibatch Loss= 2.5319, Training Accuracy= 0.498\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4997\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 7.85\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 5000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "minibatch_losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                minibatch_losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [0.50029999, 0.50139999, 0.49419999, 0.50190002, 0.4973, 0.50340003, 0.50569999, 0.5029, 0.49959999, 0.49970001]\n",
      "mean of test_accuracies_10replications:  0.50064\n",
      "standard deviation of test_accuracies_10replications_std_mean:  3.08551848866e-05\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEoCAYAAABPQRaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a5d598810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minibatch_losses_1st_replication\n",
    "plt.plot(minibatch_losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, minibacth loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
