{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 10\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.6946, Training Accuracy= 0.512\n",
      "Epoch: 10, Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 20, Loss= 0.6926, Training Accuracy= 0.504\n",
      "Epoch: 30, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 40, Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 50, Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 60, Loss= 0.6925, Training Accuracy= 0.517\n",
      "Epoch: 70, Loss= 0.6925, Training Accuracy= 0.521\n",
      "Epoch: 80, Loss= 0.6925, Training Accuracy= 0.525\n",
      "Epoch: 90, Loss= 0.6924, Training Accuracy= 0.529\n",
      "Epoch: 100, Loss= 0.6924, Training Accuracy= 0.527\n",
      "Epoch: 110, Loss= 0.6921, Training Accuracy= 0.512\n",
      "Epoch: 120, Loss= 0.6885, Training Accuracy= 0.533\n",
      "Epoch: 130, Loss= 0.6574, Training Accuracy= 0.651\n",
      "Epoch: 140, Loss= 0.4184, Training Accuracy= 0.779\n",
      "Epoch: 150, Loss= 0.3472, Training Accuracy= 0.858\n",
      "Epoch: 160, Loss= 0.3325, Training Accuracy= 0.859\n",
      "Epoch: 170, Loss= 0.3316, Training Accuracy= 0.859\n",
      "Epoch: 180, Loss= 0.0721, Training Accuracy= 0.974\n",
      "Epoch: 190, Loss= 0.0258, Training Accuracy= 1.000\n",
      "Epoch: 200, Loss= 0.0145, Training Accuracy= 1.000\n",
      "Epoch: 210, Loss= 0.0099, Training Accuracy= 1.000\n",
      "Epoch: 220, Loss= 0.0075, Training Accuracy= 1.000\n",
      "Epoch: 230, Loss= 0.0060, Training Accuracy= 1.000\n",
      "Epoch: 240, Loss= 0.0050, Training Accuracy= 1.000\n",
      "Epoch: 250, Loss= 0.0043, Training Accuracy= 1.000\n",
      "Epoch: 260, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 270, Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 280, Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 290, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 300, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 310, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 320, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 330, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 340, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 350, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 360, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 370, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 380, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0002, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2000, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2010, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2020, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2030, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2040, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2050, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2060, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2070, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2080, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2090, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2100, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2110, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2120, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2130, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2140, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2150, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2160, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2170, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2180, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2190, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2200, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2210, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2220, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2230, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2240, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2250, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2260, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2280, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3000, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3010, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3020, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3030, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3040, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3050, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3060, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3070, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3080, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3090, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3100, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3110, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3120, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3130, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3140, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3150, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3160, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3170, Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3180, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3190, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3200, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3210, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3220, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3230, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3240, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3250, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3260, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3270, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3280, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3290, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3300, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3310, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3320, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3330, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3340, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3350, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3360, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3370, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3380, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3390, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.6953, Training Accuracy= 0.512\n",
      "Epoch: 10, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 20, Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 30, Loss= 0.6930, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 50, Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 60, Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 70, Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 80, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 90, Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 100, Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 120, Loss= 0.6929, Training Accuracy= 0.495\n",
      "Epoch: 130, Loss= 0.6929, Training Accuracy= 0.494\n",
      "Epoch: 140, Loss= 0.6929, Training Accuracy= 0.495\n",
      "Epoch: 150, Loss= 0.6929, Training Accuracy= 0.498\n",
      "Epoch: 160, Loss= 0.6929, Training Accuracy= 0.503\n",
      "Epoch: 170, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 180, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 190, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 200, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 210, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 220, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 230, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 240, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 250, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 260, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 270, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 280, Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 290, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 300, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 310, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 320, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 330, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 340, Loss= 0.6929, Training Accuracy= 0.501\n",
      "Epoch: 350, Loss= 0.6929, Training Accuracy= 0.500\n",
      "Epoch: 360, Loss= 0.6929, Training Accuracy= 0.498\n",
      "Epoch: 370, Loss= 0.6929, Training Accuracy= 0.497\n",
      "Epoch: 380, Loss= 0.6928, Training Accuracy= 0.493\n",
      "Epoch: 390, Loss= 0.6928, Training Accuracy= 0.489\n",
      "Epoch: 400, Loss= 0.6928, Training Accuracy= 0.486\n",
      "Epoch: 410, Loss= 0.6928, Training Accuracy= 0.489\n",
      "Epoch: 420, Loss= 0.6928, Training Accuracy= 0.491\n",
      "Epoch: 430, Loss= 0.6928, Training Accuracy= 0.492\n",
      "Epoch: 440, Loss= 0.6928, Training Accuracy= 0.498\n",
      "Epoch: 450, Loss= 0.6928, Training Accuracy= 0.501\n",
      "Epoch: 460, Loss= 0.6928, Training Accuracy= 0.502\n",
      "Epoch: 470, Loss= 0.6928, Training Accuracy= 0.503\n",
      "Epoch: 480, Loss= 0.6928, Training Accuracy= 0.506\n",
      "Epoch: 490, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 500, Loss= 0.6928, Training Accuracy= 0.518\n",
      "Epoch: 510, Loss= 0.6928, Training Accuracy= 0.521\n",
      "Epoch: 520, Loss= 0.6928, Training Accuracy= 0.522\n",
      "Epoch: 530, Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 540, Loss= 0.6928, Training Accuracy= 0.520\n",
      "Epoch: 550, Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 560, Loss= 0.6927, Training Accuracy= 0.517\n",
      "Epoch: 570, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 580, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 590, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 600, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 610, Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 620, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 630, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 640, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 650, Loss= 0.6927, Training Accuracy= 0.502\n",
      "Epoch: 660, Loss= 0.6927, Training Accuracy= 0.503\n",
      "Epoch: 670, Loss= 0.6927, Training Accuracy= 0.502\n",
      "Epoch: 680, Loss= 0.6926, Training Accuracy= 0.504\n",
      "Epoch: 690, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 700, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 710, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 720, Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 730, Loss= 0.6926, Training Accuracy= 0.510\n",
      "Epoch: 740, Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 750, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 760, Loss= 0.6925, Training Accuracy= 0.510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 770, Loss= 0.6925, Training Accuracy= 0.513\n",
      "Epoch: 780, Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 790, Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 800, Loss= 0.6925, Training Accuracy= 0.518\n",
      "Epoch: 810, Loss= 0.6925, Training Accuracy= 0.520\n",
      "Epoch: 820, Loss= 0.6925, Training Accuracy= 0.520\n",
      "Epoch: 830, Loss= 0.6925, Training Accuracy= 0.521\n",
      "Epoch: 840, Loss= 0.6924, Training Accuracy= 0.516\n",
      "Epoch: 850, Loss= 0.6924, Training Accuracy= 0.516\n",
      "Epoch: 860, Loss= 0.6924, Training Accuracy= 0.521\n",
      "Epoch: 870, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 880, Loss= 0.6924, Training Accuracy= 0.517\n",
      "Epoch: 890, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 900, Loss= 0.6923, Training Accuracy= 0.518\n",
      "Epoch: 910, Loss= 0.6923, Training Accuracy= 0.518\n",
      "Epoch: 920, Loss= 0.6923, Training Accuracy= 0.520\n",
      "Epoch: 930, Loss= 0.6923, Training Accuracy= 0.522\n",
      "Epoch: 940, Loss= 0.6923, Training Accuracy= 0.525\n",
      "Epoch: 950, Loss= 0.6922, Training Accuracy= 0.525\n",
      "Epoch: 960, Loss= 0.6922, Training Accuracy= 0.528\n",
      "Epoch: 970, Loss= 0.6922, Training Accuracy= 0.524\n",
      "Epoch: 980, Loss= 0.6922, Training Accuracy= 0.525\n",
      "Epoch: 990, Loss= 0.6921, Training Accuracy= 0.523\n",
      "Epoch: 1000, Loss= 0.6921, Training Accuracy= 0.524\n",
      "Epoch: 1010, Loss= 0.6921, Training Accuracy= 0.521\n",
      "Epoch: 1020, Loss= 0.6920, Training Accuracy= 0.523\n",
      "Epoch: 1030, Loss= 0.6920, Training Accuracy= 0.520\n",
      "Epoch: 1040, Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 1050, Loss= 0.6920, Training Accuracy= 0.523\n",
      "Epoch: 1060, Loss= 0.6919, Training Accuracy= 0.526\n",
      "Epoch: 1070, Loss= 0.6919, Training Accuracy= 0.524\n",
      "Epoch: 1080, Loss= 0.6919, Training Accuracy= 0.523\n",
      "Epoch: 1090, Loss= 0.6918, Training Accuracy= 0.522\n",
      "Epoch: 1100, Loss= 0.6918, Training Accuracy= 0.517\n",
      "Epoch: 1110, Loss= 0.6917, Training Accuracy= 0.522\n",
      "Epoch: 1120, Loss= 0.6917, Training Accuracy= 0.522\n",
      "Epoch: 1130, Loss= 0.6917, Training Accuracy= 0.520\n",
      "Epoch: 1140, Loss= 0.6916, Training Accuracy= 0.520\n",
      "Epoch: 1150, Loss= 0.6915, Training Accuracy= 0.521\n",
      "Epoch: 1160, Loss= 0.6915, Training Accuracy= 0.517\n",
      "Epoch: 1170, Loss= 0.6915, Training Accuracy= 0.518\n",
      "Epoch: 1180, Loss= 0.6914, Training Accuracy= 0.519\n",
      "Epoch: 1190, Loss= 0.6914, Training Accuracy= 0.526\n",
      "Epoch: 1200, Loss= 0.6913, Training Accuracy= 0.530\n",
      "Epoch: 1210, Loss= 0.6912, Training Accuracy= 0.538\n",
      "Epoch: 1220, Loss= 0.6912, Training Accuracy= 0.534\n",
      "Epoch: 1230, Loss= 0.6911, Training Accuracy= 0.532\n",
      "Epoch: 1240, Loss= 0.6909, Training Accuracy= 0.532\n",
      "Epoch: 1250, Loss= 0.6907, Training Accuracy= 0.526\n",
      "Epoch: 1260, Loss= 0.6904, Training Accuracy= 0.532\n",
      "Epoch: 1270, Loss= 0.6896, Training Accuracy= 0.526\n",
      "Epoch: 1280, Loss= 0.6878, Training Accuracy= 0.549\n",
      "Epoch: 1290, Loss= 0.6856, Training Accuracy= 0.553\n",
      "Epoch: 1300, Loss= 0.6814, Training Accuracy= 0.554\n",
      "Epoch: 1310, Loss= 0.6644, Training Accuracy= 0.582\n",
      "Epoch: 1320, Loss= 0.6418, Training Accuracy= 0.588\n",
      "Epoch: 1330, Loss= 0.6784, Training Accuracy= 0.526\n",
      "Epoch: 1340, Loss= 0.6607, Training Accuracy= 0.516\n",
      "Epoch: 1350, Loss= 0.6783, Training Accuracy= 0.521\n",
      "Epoch: 1360, Loss= 0.6903, Training Accuracy= 0.512\n",
      "Epoch: 1370, Loss= 0.6879, Training Accuracy= 0.498\n",
      "Epoch: 1380, Loss= 0.6855, Training Accuracy= 0.497\n",
      "Epoch: 1390, Loss= 0.6848, Training Accuracy= 0.498\n",
      "Epoch: 1400, Loss= 0.6848, Training Accuracy= 0.500\n",
      "Epoch: 1410, Loss= 0.6840, Training Accuracy= 0.491\n",
      "Epoch: 1420, Loss= 0.6826, Training Accuracy= 0.503\n",
      "Epoch: 1430, Loss= 0.6816, Training Accuracy= 0.507\n",
      "Epoch: 1440, Loss= 0.6810, Training Accuracy= 0.516\n",
      "Epoch: 1450, Loss= 0.6971, Training Accuracy= 0.497\n",
      "Epoch: 1460, Loss= 0.6952, Training Accuracy= 0.501\n",
      "Epoch: 1470, Loss= 0.6949, Training Accuracy= 0.503\n",
      "Epoch: 1480, Loss= 0.6946, Training Accuracy= 0.504\n",
      "Epoch: 1490, Loss= 0.6943, Training Accuracy= 0.504\n",
      "Epoch: 1500, Loss= 0.6942, Training Accuracy= 0.504\n",
      "Epoch: 1510, Loss= 0.6940, Training Accuracy= 0.504\n",
      "Epoch: 1520, Loss= 0.6939, Training Accuracy= 0.504\n",
      "Epoch: 1530, Loss= 0.6938, Training Accuracy= 0.504\n",
      "Epoch: 1540, Loss= 0.6937, Training Accuracy= 0.504\n",
      "Epoch: 1550, Loss= 0.6936, Training Accuracy= 0.504\n",
      "Epoch: 1560, Loss= 0.6935, Training Accuracy= 0.504\n",
      "Epoch: 1570, Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 1580, Loss= 0.6934, Training Accuracy= 0.510\n",
      "Epoch: 1590, Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 1600, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 1610, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 1620, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 1630, Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 1640, Loss= 0.6925, Training Accuracy= 0.507\n",
      "Epoch: 1650, Loss= 0.6888, Training Accuracy= 0.535\n",
      "Epoch: 1660, Loss= 0.6386, Training Accuracy= 0.644\n",
      "Epoch: 1670, Loss= 0.6276, Training Accuracy= 0.643\n",
      "Epoch: 1680, Loss= 0.6273, Training Accuracy= 0.643\n",
      "Epoch: 1690, Loss= 0.6255, Training Accuracy= 0.646\n",
      "Epoch: 1700, Loss= 0.6228, Training Accuracy= 0.646\n",
      "Epoch: 1710, Loss= 0.5949, Training Accuracy= 0.662\n",
      "Epoch: 1720, Loss= 0.3787, Training Accuracy= 0.880\n",
      "Epoch: 1730, Loss= 0.3685, Training Accuracy= 0.880\n",
      "Epoch: 1740, Loss= 0.3677, Training Accuracy= 0.880\n",
      "Epoch: 1750, Loss= 0.3673, Training Accuracy= 0.880\n",
      "Epoch: 1760, Loss= 0.3670, Training Accuracy= 0.880\n",
      "Epoch: 1770, Loss= 0.3667, Training Accuracy= 0.880\n",
      "Epoch: 1780, Loss= 0.3664, Training Accuracy= 0.880\n",
      "Epoch: 1790, Loss= 0.3662, Training Accuracy= 0.880\n",
      "Epoch: 1800, Loss= 0.3660, Training Accuracy= 0.880\n",
      "Epoch: 1810, Loss= 0.3658, Training Accuracy= 0.880\n",
      "Epoch: 1820, Loss= 0.3664, Training Accuracy= 0.880\n",
      "Epoch: 1830, Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 1840, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 1850, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 1860, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 1870, Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1880, Loss= 0.6930, Training Accuracy= 0.495\n",
      "Epoch: 1890, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 1900, Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1910, Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1920, Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1930, Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1940, Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1950, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 1960, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 1970, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 1980, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 1990, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2000, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2010, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2020, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2030, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2040, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2050, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2060, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2070, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2080, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 2090, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2100, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2110, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2120, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 2130, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 2140, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 2150, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 2160, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2170, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2180, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2190, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2200, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2210, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2220, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2230, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2240, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2250, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2260, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2270, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2280, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2290, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2300, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2310, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2320, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2330, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2340, Loss= 0.6930, Training Accuracy= 0.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2350, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2360, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2370, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2380, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2390, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2400, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2410, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2420, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2430, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2440, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2450, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2460, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2470, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2480, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2490, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2500, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2510, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2520, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2530, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2540, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 2550, Loss= 0.6922, Training Accuracy= 0.508\n",
      "Epoch: 2560, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 2570, Loss= 0.6911, Training Accuracy= 0.507\n",
      "Epoch: 2580, Loss= 0.6202, Training Accuracy= 0.590\n",
      "Epoch: 2590, Loss= 0.5946, Training Accuracy= 0.592\n",
      "Epoch: 2600, Loss= 0.5892, Training Accuracy= 0.586\n",
      "Epoch: 2610, Loss= 0.5870, Training Accuracy= 0.582\n",
      "Epoch: 2620, Loss= 0.5858, Training Accuracy= 0.591\n",
      "Epoch: 2630, Loss= 0.5851, Training Accuracy= 0.591\n",
      "Epoch: 2640, Loss= 0.5846, Training Accuracy= 0.591\n",
      "Epoch: 2650, Loss= 0.5843, Training Accuracy= 0.591\n",
      "Epoch: 2660, Loss= 0.5841, Training Accuracy= 0.591\n",
      "Epoch: 2670, Loss= 0.5840, Training Accuracy= 0.591\n",
      "Epoch: 2680, Loss= 0.5839, Training Accuracy= 0.591\n",
      "Epoch: 2690, Loss= 0.5839, Training Accuracy= 0.591\n",
      "Epoch: 2700, Loss= 0.5838, Training Accuracy= 0.590\n",
      "Epoch: 2710, Loss= 0.5838, Training Accuracy= 0.591\n",
      "Epoch: 2720, Loss= 0.5838, Training Accuracy= 0.589\n",
      "Epoch: 2730, Loss= 0.5838, Training Accuracy= 0.595\n",
      "Epoch: 2740, Loss= 0.5838, Training Accuracy= 0.595\n",
      "Epoch: 2750, Loss= 0.5838, Training Accuracy= 0.595\n",
      "Epoch: 2760, Loss= 0.5838, Training Accuracy= 0.595\n",
      "Epoch: 2770, Loss= 0.5838, Training Accuracy= 0.594\n",
      "Epoch: 2780, Loss= 0.5838, Training Accuracy= 0.594\n",
      "Epoch: 2790, Loss= 0.5839, Training Accuracy= 0.595\n",
      "Epoch: 2800, Loss= 0.5839, Training Accuracy= 0.596\n",
      "Epoch: 2810, Loss= 0.5839, Training Accuracy= 0.596\n",
      "Epoch: 2820, Loss= 0.5839, Training Accuracy= 0.596\n",
      "Epoch: 2830, Loss= 0.5839, Training Accuracy= 0.596\n",
      "Epoch: 2840, Loss= 0.5839, Training Accuracy= 0.596\n",
      "Epoch: 2850, Loss= 0.5839, Training Accuracy= 0.596\n",
      "Epoch: 2860, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 2870, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 2880, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 2890, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 2900, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 2910, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 2920, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 2930, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 2940, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 2950, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 2960, Loss= 0.5840, Training Accuracy= 0.597\n",
      "Epoch: 2970, Loss= 0.5840, Training Accuracy= 0.597\n",
      "Epoch: 2980, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 2990, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3000, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3010, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3020, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3030, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3040, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3050, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3060, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3070, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3080, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3090, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3100, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3110, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3120, Loss= 0.5841, Training Accuracy= 0.597\n",
      "Epoch: 3130, Loss= 0.5840, Training Accuracy= 0.597\n",
      "Epoch: 3140, Loss= 0.5840, Training Accuracy= 0.598\n",
      "Epoch: 3150, Loss= 0.5840, Training Accuracy= 0.597\n",
      "Epoch: 3160, Loss= 0.5840, Training Accuracy= 0.597\n",
      "Epoch: 3170, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 3180, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 3190, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 3200, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 3210, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 3220, Loss= 0.5840, Training Accuracy= 0.596\n",
      "Epoch: 3230, Loss= 0.5840, Training Accuracy= 0.576\n",
      "Epoch: 3240, Loss= 0.5840, Training Accuracy= 0.576\n",
      "Epoch: 3250, Loss= 0.5840, Training Accuracy= 0.576\n",
      "Epoch: 3260, Loss= 0.5840, Training Accuracy= 0.576\n",
      "Epoch: 3270, Loss= 0.5840, Training Accuracy= 0.576\n",
      "Epoch: 3280, Loss= 0.5840, Training Accuracy= 0.576\n",
      "Epoch: 3290, Loss= 0.5840, Training Accuracy= 0.576\n",
      "Epoch: 3300, Loss= 0.5839, Training Accuracy= 0.576\n",
      "Epoch: 3310, Loss= 0.5839, Training Accuracy= 0.576\n",
      "Epoch: 3320, Loss= 0.5839, Training Accuracy= 0.576\n",
      "Epoch: 3330, Loss= 0.5839, Training Accuracy= 0.576\n",
      "Epoch: 3340, Loss= 0.5839, Training Accuracy= 0.576\n",
      "Epoch: 3350, Loss= 0.5839, Training Accuracy= 0.576\n",
      "Epoch: 3360, Loss= 0.5839, Training Accuracy= 0.576\n",
      "Epoch: 3370, Loss= 0.5839, Training Accuracy= 0.576\n",
      "Epoch: 3380, Loss= 0.5839, Training Accuracy= 0.576\n",
      "Epoch: 3390, Loss= 0.5838, Training Accuracy= 0.576\n",
      "Epoch: 3400, Loss= 0.5838, Training Accuracy= 0.575\n",
      "Epoch: 3410, Loss= 0.5838, Training Accuracy= 0.575\n",
      "Epoch: 3420, Loss= 0.5837, Training Accuracy= 0.575\n",
      "Epoch: 3430, Loss= 0.5837, Training Accuracy= 0.593\n",
      "Epoch: 3440, Loss= 0.5835, Training Accuracy= 0.593\n",
      "Epoch: 3450, Loss= 0.5831, Training Accuracy= 0.605\n",
      "Epoch: 3460, Loss= 0.5825, Training Accuracy= 0.610\n",
      "Epoch: 3470, Loss= 0.5818, Training Accuracy= 0.613\n",
      "Epoch: 3480, Loss= 0.5811, Training Accuracy= 0.598\n",
      "Epoch: 3490, Loss= 0.5812, Training Accuracy= 0.598\n",
      "Epoch: 3500, Loss= 0.5811, Training Accuracy= 0.599\n",
      "Epoch: 3510, Loss= 0.8858, Training Accuracy= 0.598\n",
      "Epoch: 3520, Loss= 0.7263, Training Accuracy= 0.508\n",
      "Epoch: 3530, Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 3540, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3550, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3560, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3570, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3580, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3590, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3600, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3610, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3620, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3630, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3640, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3650, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3660, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3670, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3680, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3690, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3700, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3710, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3720, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3730, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3740, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3750, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3760, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3770, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3780, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3790, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3800, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3810, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3820, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3830, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3840, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3850, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3860, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3870, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3880, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3890, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3900, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3910, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3920, Loss= 0.6934, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3930, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3940, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3950, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3960, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3970, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3980, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 3990, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4964\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 0.6949, Training Accuracy= 0.496\n",
      "Epoch: 20, Loss= 0.6948, Training Accuracy= 0.496\n",
      "Epoch: 30, Loss= 0.6947, Training Accuracy= 0.496\n",
      "Epoch: 40, Loss= 0.6947, Training Accuracy= 0.496\n",
      "Epoch: 50, Loss= 0.6946, Training Accuracy= 0.496\n",
      "Epoch: 60, Loss= 0.6946, Training Accuracy= 0.496\n",
      "Epoch: 70, Loss= 0.6945, Training Accuracy= 0.496\n",
      "Epoch: 80, Loss= 0.6945, Training Accuracy= 0.496\n",
      "Epoch: 90, Loss= 0.6945, Training Accuracy= 0.496\n",
      "Epoch: 100, Loss= 0.6944, Training Accuracy= 0.496\n",
      "Epoch: 110, Loss= 0.6944, Training Accuracy= 0.496\n",
      "Epoch: 120, Loss= 0.6944, Training Accuracy= 0.496\n",
      "Epoch: 130, Loss= 0.6944, Training Accuracy= 0.496\n",
      "Epoch: 140, Loss= 0.6943, Training Accuracy= 0.496\n",
      "Epoch: 150, Loss= 0.6943, Training Accuracy= 0.496\n",
      "Epoch: 160, Loss= 0.6943, Training Accuracy= 0.496\n",
      "Epoch: 170, Loss= 0.6943, Training Accuracy= 0.496\n",
      "Epoch: 180, Loss= 0.6942, Training Accuracy= 0.496\n",
      "Epoch: 190, Loss= 0.6942, Training Accuracy= 0.496\n",
      "Epoch: 200, Loss= 0.6942, Training Accuracy= 0.496\n",
      "Epoch: 210, Loss= 0.6942, Training Accuracy= 0.496\n",
      "Epoch: 220, Loss= 0.6942, Training Accuracy= 0.496\n",
      "Epoch: 230, Loss= 0.6942, Training Accuracy= 0.496\n",
      "Epoch: 240, Loss= 0.6941, Training Accuracy= 0.496\n",
      "Epoch: 250, Loss= 0.6941, Training Accuracy= 0.496\n",
      "Epoch: 260, Loss= 0.6941, Training Accuracy= 0.496\n",
      "Epoch: 270, Loss= 0.6941, Training Accuracy= 0.496\n",
      "Epoch: 280, Loss= 0.6941, Training Accuracy= 0.496\n",
      "Epoch: 290, Loss= 0.6941, Training Accuracy= 0.496\n",
      "Epoch: 300, Loss= 0.6940, Training Accuracy= 0.496\n",
      "Epoch: 310, Loss= 0.6940, Training Accuracy= 0.496\n",
      "Epoch: 320, Loss= 0.6940, Training Accuracy= 0.496\n",
      "Epoch: 330, Loss= 0.6940, Training Accuracy= 0.496\n",
      "Epoch: 340, Loss= 0.6940, Training Accuracy= 0.496\n",
      "Epoch: 350, Loss= 0.6940, Training Accuracy= 0.496\n",
      "Epoch: 360, Loss= 0.6940, Training Accuracy= 0.496\n",
      "Epoch: 370, Loss= 0.6940, Training Accuracy= 0.496\n",
      "Epoch: 380, Loss= 0.6939, Training Accuracy= 0.496\n",
      "Epoch: 390, Loss= 0.6939, Training Accuracy= 0.496\n",
      "Epoch: 400, Loss= 0.6939, Training Accuracy= 0.496\n",
      "Epoch: 410, Loss= 0.6939, Training Accuracy= 0.496\n",
      "Epoch: 420, Loss= 0.6939, Training Accuracy= 0.496\n",
      "Epoch: 430, Loss= 0.6939, Training Accuracy= 0.496\n",
      "Epoch: 440, Loss= 0.6939, Training Accuracy= 0.496\n",
      "Epoch: 450, Loss= 0.6939, Training Accuracy= 0.496\n",
      "Epoch: 460, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 470, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 480, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 490, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 500, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 510, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 520, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 530, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 540, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 550, Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 560, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 570, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 580, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 590, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 600, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 610, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 620, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 630, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 640, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 650, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 660, Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 670, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 680, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 690, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 700, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 710, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 720, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 730, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 740, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 750, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 760, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 770, Loss= 0.6935, Training Accuracy= 0.496\n",
      "Epoch: 780, Loss= 0.6935, Training Accuracy= 0.496\n",
      "Epoch: 790, Loss= 0.6935, Training Accuracy= 0.495\n",
      "Epoch: 800, Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 810, Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 820, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 830, Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 840, Loss= 0.6935, Training Accuracy= 0.494\n",
      "Epoch: 850, Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 860, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 870, Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 880, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 890, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 900, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 910, Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 920, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 930, Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 940, Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 950, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 960, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 970, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 980, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 990, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1000, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 1010, Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 1020, Loss= 0.6931, Training Accuracy= 0.517\n",
      "Epoch: 1030, Loss= 0.6931, Training Accuracy= 0.519\n",
      "Epoch: 1040, Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 1050, Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 1060, Loss= 0.6931, Training Accuracy= 0.517\n",
      "Epoch: 1070, Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 1080, Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 1090, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 1100, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1110, Loss= 0.6931, Training Accuracy= 0.498\n",
      "Epoch: 1120, Loss= 0.6931, Training Accuracy= 0.498\n",
      "Epoch: 1130, Loss= 0.6931, Training Accuracy= 0.499\n",
      "Epoch: 1140, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1150, Loss= 0.6931, Training Accuracy= 0.500\n",
      "Epoch: 1160, Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 1170, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1180, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1190, Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 1200, Loss= 0.6931, Training Accuracy= 0.500\n",
      "Epoch: 1210, Loss= 0.6931, Training Accuracy= 0.499\n",
      "Epoch: 1220, Loss= 0.6931, Training Accuracy= 0.497\n",
      "Epoch: 1230, Loss= 0.6931, Training Accuracy= 0.499\n",
      "Epoch: 1240, Loss= 0.6931, Training Accuracy= 0.497\n",
      "Epoch: 1250, Loss= 0.6930, Training Accuracy= 0.497\n",
      "Epoch: 1260, Loss= 0.6930, Training Accuracy= 0.500\n",
      "Epoch: 1270, Loss= 0.6930, Training Accuracy= 0.500\n",
      "Epoch: 1280, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 1290, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 1300, Loss= 0.6930, Training Accuracy= 0.500\n",
      "Epoch: 1310, Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 1320, Loss= 0.6930, Training Accuracy= 0.500\n",
      "Epoch: 1330, Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 1340, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 1350, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 1360, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 1370, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 1380, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 1390, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 1400, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 1410, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 1420, Loss= 0.6928, Training Accuracy= 0.506\n",
      "Epoch: 1430, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 1440, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 1450, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 1460, Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 1470, Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 1480, Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 1490, Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 1500, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 1510, Loss= 0.6927, Training Accuracy= 0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1520, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 1530, Loss= 0.6927, Training Accuracy= 0.514\n",
      "Epoch: 1540, Loss= 0.6927, Training Accuracy= 0.514\n",
      "Epoch: 1550, Loss= 0.6927, Training Accuracy= 0.516\n",
      "Epoch: 1560, Loss= 0.6927, Training Accuracy= 0.517\n",
      "Epoch: 1570, Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 1580, Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 1590, Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 1600, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 1610, Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 1620, Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 1630, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 1640, Loss= 0.6925, Training Accuracy= 0.513\n",
      "Epoch: 1650, Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 1660, Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 1670, Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 1680, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 1690, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 1700, Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 1710, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 1720, Loss= 0.6924, Training Accuracy= 0.509\n",
      "Epoch: 1730, Loss= 0.6924, Training Accuracy= 0.509\n",
      "Epoch: 1740, Loss= 0.6924, Training Accuracy= 0.514\n",
      "Epoch: 1750, Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 1760, Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 1770, Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 1780, Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 1790, Loss= 0.6924, Training Accuracy= 0.514\n",
      "Epoch: 1800, Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 1810, Loss= 0.6923, Training Accuracy= 0.512\n",
      "Epoch: 1820, Loss= 0.6923, Training Accuracy= 0.511\n",
      "Epoch: 1830, Loss= 0.6923, Training Accuracy= 0.511\n",
      "Epoch: 1840, Loss= 0.6923, Training Accuracy= 0.516\n",
      "Epoch: 1850, Loss= 0.6923, Training Accuracy= 0.513\n",
      "Epoch: 1860, Loss= 0.6923, Training Accuracy= 0.512\n",
      "Epoch: 1870, Loss= 0.6923, Training Accuracy= 0.512\n",
      "Epoch: 1880, Loss= 0.6923, Training Accuracy= 0.510\n",
      "Epoch: 1890, Loss= 0.6923, Training Accuracy= 0.511\n",
      "Epoch: 1900, Loss= 0.6923, Training Accuracy= 0.511\n",
      "Epoch: 1910, Loss= 0.6923, Training Accuracy= 0.516\n",
      "Epoch: 1920, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 1930, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 1940, Loss= 0.6922, Training Accuracy= 0.521\n",
      "Epoch: 1950, Loss= 0.6922, Training Accuracy= 0.524\n",
      "Epoch: 1960, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 1970, Loss= 0.6922, Training Accuracy= 0.521\n",
      "Epoch: 1980, Loss= 0.6922, Training Accuracy= 0.521\n",
      "Epoch: 1990, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 2000, Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 2010, Loss= 0.6922, Training Accuracy= 0.518\n",
      "Epoch: 2020, Loss= 0.6922, Training Accuracy= 0.517\n",
      "Epoch: 2030, Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 2040, Loss= 0.6922, Training Accuracy= 0.516\n",
      "Epoch: 2050, Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 2060, Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 2070, Loss= 0.6922, Training Accuracy= 0.518\n",
      "Epoch: 2080, Loss= 0.6922, Training Accuracy= 0.517\n",
      "Epoch: 2090, Loss= 0.6922, Training Accuracy= 0.517\n",
      "Epoch: 2100, Loss= 0.6922, Training Accuracy= 0.515\n",
      "Epoch: 2110, Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 2120, Loss= 0.6918, Training Accuracy= 0.526\n",
      "Epoch: 2130, Loss= 0.6917, Training Accuracy= 0.520\n",
      "Epoch: 2140, Loss= 0.6916, Training Accuracy= 0.515\n",
      "Epoch: 2150, Loss= 0.6916, Training Accuracy= 0.514\n",
      "Epoch: 2160, Loss= 0.6915, Training Accuracy= 0.516\n",
      "Epoch: 2170, Loss= 0.6915, Training Accuracy= 0.518\n",
      "Epoch: 2180, Loss= 0.6914, Training Accuracy= 0.513\n",
      "Epoch: 2190, Loss= 0.6913, Training Accuracy= 0.516\n",
      "Epoch: 2200, Loss= 0.6913, Training Accuracy= 0.515\n",
      "Epoch: 2210, Loss= 0.6912, Training Accuracy= 0.518\n",
      "Epoch: 2220, Loss= 0.6911, Training Accuracy= 0.521\n",
      "Epoch: 2230, Loss= 0.6910, Training Accuracy= 0.529\n",
      "Epoch: 2240, Loss= 0.6910, Training Accuracy= 0.532\n",
      "Epoch: 2250, Loss= 0.6909, Training Accuracy= 0.531\n",
      "Epoch: 2260, Loss= 0.6908, Training Accuracy= 0.529\n",
      "Epoch: 2270, Loss= 0.6908, Training Accuracy= 0.526\n",
      "Epoch: 2280, Loss= 0.6907, Training Accuracy= 0.531\n",
      "Epoch: 2290, Loss= 0.6907, Training Accuracy= 0.533\n",
      "Epoch: 2300, Loss= 0.6904, Training Accuracy= 0.531\n",
      "Epoch: 2310, Loss= 0.6904, Training Accuracy= 0.534\n",
      "Epoch: 2320, Loss= 0.6909, Training Accuracy= 0.528\n",
      "Epoch: 2330, Loss= 0.6908, Training Accuracy= 0.533\n",
      "Epoch: 2340, Loss= 0.6906, Training Accuracy= 0.527\n",
      "Epoch: 2350, Loss= 0.6905, Training Accuracy= 0.524\n",
      "Epoch: 2360, Loss= 0.6907, Training Accuracy= 0.520\n",
      "Epoch: 2370, Loss= 0.6894, Training Accuracy= 0.527\n",
      "Epoch: 2380, Loss= 0.6891, Training Accuracy= 0.532\n",
      "Epoch: 2390, Loss= 0.6875, Training Accuracy= 0.547\n",
      "Epoch: 2400, Loss= 0.6896, Training Accuracy= 0.520\n",
      "Epoch: 2410, Loss= 0.6930, Training Accuracy= 0.516\n",
      "Epoch: 2420, Loss= 0.6873, Training Accuracy= 0.526\n",
      "Epoch: 2430, Loss= 0.6907, Training Accuracy= 0.527\n",
      "Epoch: 2440, Loss= 0.6911, Training Accuracy= 0.525\n",
      "Epoch: 2450, Loss= 0.6911, Training Accuracy= 0.525\n",
      "Epoch: 2460, Loss= 0.6883, Training Accuracy= 0.528\n",
      "Epoch: 2470, Loss= 0.6884, Training Accuracy= 0.536\n",
      "Epoch: 2480, Loss= 0.6723, Training Accuracy= 0.573\n",
      "Epoch: 2490, Loss= 0.6903, Training Accuracy= 0.545\n",
      "Epoch: 2500, Loss= 0.6849, Training Accuracy= 0.549\n",
      "Epoch: 2510, Loss= 0.6874, Training Accuracy= 0.538\n",
      "Epoch: 2520, Loss= 0.6717, Training Accuracy= 0.580\n",
      "Epoch: 2530, Loss= 0.6462, Training Accuracy= 0.617\n",
      "Epoch: 2540, Loss= 0.6943, Training Accuracy= 0.502\n",
      "Epoch: 2550, Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 2560, Loss= 0.6928, Training Accuracy= 0.501\n",
      "Epoch: 2570, Loss= 0.6926, Training Accuracy= 0.500\n",
      "Epoch: 2580, Loss= 0.6924, Training Accuracy= 0.501\n",
      "Epoch: 2590, Loss= 0.6923, Training Accuracy= 0.501\n",
      "Epoch: 2600, Loss= 0.6920, Training Accuracy= 0.503\n",
      "Epoch: 2610, Loss= 0.6908, Training Accuracy= 0.504\n",
      "Epoch: 2620, Loss= 0.6901, Training Accuracy= 0.507\n",
      "Epoch: 2630, Loss= 0.6896, Training Accuracy= 0.507\n",
      "Epoch: 2640, Loss= 0.6893, Training Accuracy= 0.507\n",
      "Epoch: 2650, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 2660, Loss= 0.6881, Training Accuracy= 0.510\n",
      "Epoch: 2670, Loss= 0.6876, Training Accuracy= 0.512\n",
      "Epoch: 2680, Loss= 0.6872, Training Accuracy= 0.511\n",
      "Epoch: 2690, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 2700, Loss= 0.6902, Training Accuracy= 0.505\n",
      "Epoch: 2710, Loss= 0.6887, Training Accuracy= 0.509\n",
      "Epoch: 2720, Loss= 0.6884, Training Accuracy= 0.512\n",
      "Epoch: 2730, Loss= 0.6879, Training Accuracy= 0.510\n",
      "Epoch: 2740, Loss= 0.6872, Training Accuracy= 0.511\n",
      "Epoch: 2750, Loss= 0.6897, Training Accuracy= 0.505\n",
      "Epoch: 2760, Loss= 0.6892, Training Accuracy= 0.504\n",
      "Epoch: 2770, Loss= 0.6890, Training Accuracy= 0.504\n",
      "Epoch: 2780, Loss= 0.6888, Training Accuracy= 0.504\n",
      "Epoch: 2790, Loss= 0.6886, Training Accuracy= 0.504\n",
      "Epoch: 2800, Loss= 0.6885, Training Accuracy= 0.504\n",
      "Epoch: 2810, Loss= 0.6884, Training Accuracy= 0.504\n",
      "Epoch: 2820, Loss= 0.6883, Training Accuracy= 0.504\n",
      "Epoch: 2830, Loss= 0.6881, Training Accuracy= 0.504\n",
      "Epoch: 2840, Loss= 0.6890, Training Accuracy= 0.504\n",
      "Epoch: 2850, Loss= 0.6849, Training Accuracy= 0.494\n",
      "Epoch: 2860, Loss= 0.6975, Training Accuracy= 0.496\n",
      "Epoch: 2870, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 2880, Loss= 0.6928, Training Accuracy= 0.500\n",
      "Epoch: 2890, Loss= 0.6923, Training Accuracy= 0.500\n",
      "Epoch: 2900, Loss= 0.6920, Training Accuracy= 0.500\n",
      "Epoch: 2910, Loss= 0.6917, Training Accuracy= 0.501\n",
      "Epoch: 2920, Loss= 0.6915, Training Accuracy= 0.503\n",
      "Epoch: 2930, Loss= 0.6911, Training Accuracy= 0.503\n",
      "Epoch: 2940, Loss= 0.6906, Training Accuracy= 0.501\n",
      "Epoch: 2950, Loss= 0.6891, Training Accuracy= 0.505\n",
      "Epoch: 2960, Loss= 0.6886, Training Accuracy= 0.504\n",
      "Epoch: 2970, Loss= 0.6884, Training Accuracy= 0.502\n",
      "Epoch: 2980, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 2990, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3000, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3010, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3020, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3030, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3040, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3050, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3060, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3070, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3080, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3090, Loss= 0.6956, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3100, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3110, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3120, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3130, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3140, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3150, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3160, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3170, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3180, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3190, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3200, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3210, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3220, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3230, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3240, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3250, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3260, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3270, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3280, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3290, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3300, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3310, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3320, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3330, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3340, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3350, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3360, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3370, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3380, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3390, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3400, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3410, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3420, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3430, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3440, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3450, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3460, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3470, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3480, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3490, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3500, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3510, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3520, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3530, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3540, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3550, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3560, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3570, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3580, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3590, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3600, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3610, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3620, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3630, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3640, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3650, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3660, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3670, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3680, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3690, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3700, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3710, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3720, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3730, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3740, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3750, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3760, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3770, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3780, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3790, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3800, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3810, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3820, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3830, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3840, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3850, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3860, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3870, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3880, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3890, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3900, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3910, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3920, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3930, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3940, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3950, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3960, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3970, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3980, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 3990, Loss= 0.6956, Training Accuracy= 0.496\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5005\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.7032, Training Accuracy= 0.496\n",
      "Epoch: 10, Loss= 0.6969, Training Accuracy= 0.492\n",
      "Epoch: 20, Loss= 0.6958, Training Accuracy= 0.492\n",
      "Epoch: 30, Loss= 0.6954, Training Accuracy= 0.492\n",
      "Epoch: 40, Loss= 0.6952, Training Accuracy= 0.492\n",
      "Epoch: 50, Loss= 0.6950, Training Accuracy= 0.492\n",
      "Epoch: 60, Loss= 0.6949, Training Accuracy= 0.492\n",
      "Epoch: 70, Loss= 0.6948, Training Accuracy= 0.492\n",
      "Epoch: 80, Loss= 0.6948, Training Accuracy= 0.492\n",
      "Epoch: 90, Loss= 0.6947, Training Accuracy= 0.492\n",
      "Epoch: 100, Loss= 0.6947, Training Accuracy= 0.492\n",
      "Epoch: 110, Loss= 0.6947, Training Accuracy= 0.492\n",
      "Epoch: 120, Loss= 0.6947, Training Accuracy= 0.492\n",
      "Epoch: 130, Loss= 0.6946, Training Accuracy= 0.492\n",
      "Epoch: 140, Loss= 0.6946, Training Accuracy= 0.492\n",
      "Epoch: 150, Loss= 0.6946, Training Accuracy= 0.492\n",
      "Epoch: 160, Loss= 0.6946, Training Accuracy= 0.492\n",
      "Epoch: 170, Loss= 0.6946, Training Accuracy= 0.492\n",
      "Epoch: 180, Loss= 0.6946, Training Accuracy= 0.492\n",
      "Epoch: 190, Loss= 0.6946, Training Accuracy= 0.492\n",
      "Epoch: 200, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 210, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 220, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 230, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 240, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 250, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 260, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 270, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 280, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 290, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 300, Loss= 0.6945, Training Accuracy= 0.492\n",
      "Epoch: 310, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 320, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 330, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 340, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 350, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 360, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 370, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 380, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 390, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 400, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 410, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 420, Loss= 0.6944, Training Accuracy= 0.492\n",
      "Epoch: 430, Loss= 0.6943, Training Accuracy= 0.492\n",
      "Epoch: 440, Loss= 0.6943, Training Accuracy= 0.492\n",
      "Epoch: 450, Loss= 0.6943, Training Accuracy= 0.492\n",
      "Epoch: 460, Loss= 0.6943, Training Accuracy= 0.492\n",
      "Epoch: 470, Loss= 0.6943, Training Accuracy= 0.492\n",
      "Epoch: 480, Loss= 0.6943, Training Accuracy= 0.492\n",
      "Epoch: 490, Loss= 0.6943, Training Accuracy= 0.492\n",
      "Epoch: 500, Loss= 0.6943, Training Accuracy= 0.492\n",
      "Epoch: 510, Loss= 0.6943, Training Accuracy= 0.492\n",
      "Epoch: 520, Loss= 0.6943, Training Accuracy= 0.492\n",
      "Epoch: 530, Loss= 0.6942, Training Accuracy= 0.492\n",
      "Epoch: 540, Loss= 0.6942, Training Accuracy= 0.492\n",
      "Epoch: 550, Loss= 0.6942, Training Accuracy= 0.492\n",
      "Epoch: 560, Loss= 0.6942, Training Accuracy= 0.492\n",
      "Epoch: 570, Loss= 0.6942, Training Accuracy= 0.492\n",
      "Epoch: 580, Loss= 0.6942, Training Accuracy= 0.492\n",
      "Epoch: 590, Loss= 0.6942, Training Accuracy= 0.492\n",
      "Epoch: 600, Loss= 0.6942, Training Accuracy= 0.492\n",
      "Epoch: 610, Loss= 0.6942, Training Accuracy= 0.492\n",
      "Epoch: 620, Loss= 0.6942, Training Accuracy= 0.492\n",
      "Epoch: 630, Loss= 0.6941, Training Accuracy= 0.492\n",
      "Epoch: 640, Loss= 0.6941, Training Accuracy= 0.492\n",
      "Epoch: 650, Loss= 0.6941, Training Accuracy= 0.492\n",
      "Epoch: 660, Loss= 0.6941, Training Accuracy= 0.492\n",
      "Epoch: 670, Loss= 0.6941, Training Accuracy= 0.492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 680, Loss= 0.6941, Training Accuracy= 0.492\n",
      "Epoch: 690, Loss= 0.6941, Training Accuracy= 0.492\n",
      "Epoch: 700, Loss= 0.6941, Training Accuracy= 0.492\n",
      "Epoch: 710, Loss= 0.6941, Training Accuracy= 0.492\n",
      "Epoch: 720, Loss= 0.6941, Training Accuracy= 0.492\n",
      "Epoch: 730, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 740, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 750, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 760, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 770, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 780, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 790, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 800, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 810, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 820, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 830, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 840, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 850, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 860, Loss= 0.6940, Training Accuracy= 0.492\n",
      "Epoch: 870, Loss= 0.6939, Training Accuracy= 0.492\n",
      "Epoch: 880, Loss= 0.6939, Training Accuracy= 0.492\n",
      "Epoch: 890, Loss= 0.6939, Training Accuracy= 0.492\n",
      "Epoch: 900, Loss= 0.6939, Training Accuracy= 0.492\n",
      "Epoch: 910, Loss= 0.6939, Training Accuracy= 0.492\n",
      "Epoch: 920, Loss= 0.6939, Training Accuracy= 0.492\n",
      "Epoch: 930, Loss= 0.6939, Training Accuracy= 0.491\n",
      "Epoch: 940, Loss= 0.6939, Training Accuracy= 0.491\n",
      "Epoch: 950, Loss= 0.6939, Training Accuracy= 0.491\n",
      "Epoch: 960, Loss= 0.6939, Training Accuracy= 0.492\n",
      "Epoch: 970, Loss= 0.6939, Training Accuracy= 0.493\n",
      "Epoch: 980, Loss= 0.6939, Training Accuracy= 0.493\n",
      "Epoch: 990, Loss= 0.6939, Training Accuracy= 0.493\n",
      "Epoch: 1000, Loss= 0.6939, Training Accuracy= 0.492\n",
      "Epoch: 1010, Loss= 0.6939, Training Accuracy= 0.493\n",
      "Epoch: 1020, Loss= 0.6939, Training Accuracy= 0.493\n",
      "Epoch: 1030, Loss= 0.6938, Training Accuracy= 0.494\n",
      "Epoch: 1040, Loss= 0.6938, Training Accuracy= 0.494\n",
      "Epoch: 1050, Loss= 0.6938, Training Accuracy= 0.492\n",
      "Epoch: 1060, Loss= 0.6938, Training Accuracy= 0.491\n",
      "Epoch: 1070, Loss= 0.6938, Training Accuracy= 0.489\n",
      "Epoch: 1080, Loss= 0.6938, Training Accuracy= 0.489\n",
      "Epoch: 1090, Loss= 0.6938, Training Accuracy= 0.488\n",
      "Epoch: 1100, Loss= 0.6938, Training Accuracy= 0.487\n",
      "Epoch: 1110, Loss= 0.6938, Training Accuracy= 0.486\n",
      "Epoch: 1120, Loss= 0.6938, Training Accuracy= 0.486\n",
      "Epoch: 1130, Loss= 0.6938, Training Accuracy= 0.487\n",
      "Epoch: 1140, Loss= 0.6938, Training Accuracy= 0.488\n",
      "Epoch: 1150, Loss= 0.6938, Training Accuracy= 0.488\n",
      "Epoch: 1160, Loss= 0.6938, Training Accuracy= 0.491\n",
      "Epoch: 1170, Loss= 0.6938, Training Accuracy= 0.490\n",
      "Epoch: 1180, Loss= 0.6938, Training Accuracy= 0.490\n",
      "Epoch: 1190, Loss= 0.6938, Training Accuracy= 0.491\n",
      "Epoch: 1200, Loss= 0.6938, Training Accuracy= 0.491\n",
      "Epoch: 1210, Loss= 0.6937, Training Accuracy= 0.495\n",
      "Epoch: 1220, Loss= 0.6937, Training Accuracy= 0.495\n",
      "Epoch: 1230, Loss= 0.6937, Training Accuracy= 0.494\n",
      "Epoch: 1240, Loss= 0.6937, Training Accuracy= 0.494\n",
      "Epoch: 1250, Loss= 0.6937, Training Accuracy= 0.495\n",
      "Epoch: 1260, Loss= 0.6937, Training Accuracy= 0.495\n",
      "Epoch: 1270, Loss= 0.6937, Training Accuracy= 0.493\n",
      "Epoch: 1280, Loss= 0.6937, Training Accuracy= 0.493\n",
      "Epoch: 1290, Loss= 0.6937, Training Accuracy= 0.493\n",
      "Epoch: 1300, Loss= 0.6937, Training Accuracy= 0.491\n",
      "Epoch: 1310, Loss= 0.6937, Training Accuracy= 0.492\n",
      "Epoch: 1320, Loss= 0.6937, Training Accuracy= 0.492\n",
      "Epoch: 1330, Loss= 0.6937, Training Accuracy= 0.494\n",
      "Epoch: 1340, Loss= 0.6937, Training Accuracy= 0.495\n",
      "Epoch: 1350, Loss= 0.6937, Training Accuracy= 0.495\n",
      "Epoch: 1360, Loss= 0.6937, Training Accuracy= 0.493\n",
      "Epoch: 1370, Loss= 0.6937, Training Accuracy= 0.493\n",
      "Epoch: 1380, Loss= 0.6937, Training Accuracy= 0.492\n",
      "Epoch: 1390, Loss= 0.6937, Training Accuracy= 0.492\n",
      "Epoch: 1400, Loss= 0.6936, Training Accuracy= 0.495\n",
      "Epoch: 1410, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 1420, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 1430, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 1440, Loss= 0.6936, Training Accuracy= 0.497\n",
      "Epoch: 1450, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 1460, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 1470, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 1480, Loss= 0.6936, Training Accuracy= 0.494\n",
      "Epoch: 1490, Loss= 0.6936, Training Accuracy= 0.494\n",
      "Epoch: 1500, Loss= 0.6936, Training Accuracy= 0.493\n",
      "Epoch: 1510, Loss= 0.6936, Training Accuracy= 0.497\n",
      "Epoch: 1520, Loss= 0.6936, Training Accuracy= 0.498\n",
      "Epoch: 1530, Loss= 0.6936, Training Accuracy= 0.497\n",
      "Epoch: 1540, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 1550, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 1560, Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 1570, Loss= 0.6936, Training Accuracy= 0.498\n",
      "Epoch: 1580, Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 1590, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 1600, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 1610, Loss= 0.6935, Training Accuracy= 0.504\n",
      "Epoch: 1620, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 1630, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 1640, Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 1650, Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 1660, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 1670, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 1680, Loss= 0.6935, Training Accuracy= 0.499\n",
      "Epoch: 1690, Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 1700, Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 1710, Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 1720, Loss= 0.6935, Training Accuracy= 0.499\n",
      "Epoch: 1730, Loss= 0.6935, Training Accuracy= 0.499\n",
      "Epoch: 1740, Loss= 0.6935, Training Accuracy= 0.499\n",
      "Epoch: 1750, Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 1760, Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 1770, Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 1780, Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1790, Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1800, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 1810, Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 1820, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1830, Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 1840, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1850, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1860, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1870, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 1880, Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 1890, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1900, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1910, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1920, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1930, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1940, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1950, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1960, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 1970, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 1980, Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 1990, Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 2000, Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 2010, Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 2020, Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 2030, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2040, Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 2050, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 2060, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 2070, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2080, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2090, Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 2100, Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 2110, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2120, Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 2130, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2140, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2150, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2160, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2170, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2180, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2190, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2200, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2210, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2220, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2230, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 2240, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 2250, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 2260, Loss= 0.6932, Training Accuracy= 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2270, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 2280, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 2290, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 2300, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 2310, Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 2320, Loss= 0.6931, Training Accuracy= 0.500\n",
      "Epoch: 2330, Loss= 0.6931, Training Accuracy= 0.496\n",
      "Epoch: 2340, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 2350, Loss= 0.6928, Training Accuracy= 0.506\n",
      "Epoch: 2360, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 2370, Loss= 0.6928, Training Accuracy= 0.505\n",
      "Epoch: 2380, Loss= 0.6928, Training Accuracy= 0.504\n",
      "Epoch: 2390, Loss= 0.6927, Training Accuracy= 0.506\n",
      "Epoch: 2400, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 2410, Loss= 0.6927, Training Accuracy= 0.506\n",
      "Epoch: 2420, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 2430, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 2440, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 2450, Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 2460, Loss= 0.6926, Training Accuracy= 0.506\n",
      "Epoch: 2470, Loss= 0.6926, Training Accuracy= 0.510\n",
      "Epoch: 2480, Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 2490, Loss= 0.6926, Training Accuracy= 0.510\n",
      "Epoch: 2500, Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 2510, Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 2520, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 2530, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 2540, Loss= 0.6924, Training Accuracy= 0.510\n",
      "Epoch: 2550, Loss= 0.6924, Training Accuracy= 0.505\n",
      "Epoch: 2560, Loss= 0.6924, Training Accuracy= 0.504\n",
      "Epoch: 2570, Loss= 0.6923, Training Accuracy= 0.504\n",
      "Epoch: 2580, Loss= 0.6922, Training Accuracy= 0.504\n",
      "Epoch: 2590, Loss= 0.6922, Training Accuracy= 0.505\n",
      "Epoch: 2600, Loss= 0.6921, Training Accuracy= 0.500\n",
      "Epoch: 2610, Loss= 0.6920, Training Accuracy= 0.498\n",
      "Epoch: 2620, Loss= 0.6918, Training Accuracy= 0.497\n",
      "Epoch: 2630, Loss= 0.6915, Training Accuracy= 0.500\n",
      "Epoch: 2640, Loss= 0.6899, Training Accuracy= 0.511\n",
      "Epoch: 2650, Loss= 0.6148, Training Accuracy= 0.584\n",
      "Epoch: 2660, Loss= 0.5871, Training Accuracy= 0.619\n",
      "Epoch: 2670, Loss= 0.5666, Training Accuracy= 0.607\n",
      "Epoch: 2680, Loss= 0.3130, Training Accuracy= 0.999\n",
      "Epoch: 2690, Loss= 0.0238, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0125, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0080, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0056, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0042, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0032, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 3000, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 3010, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 3020, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3030, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3040, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3050, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3060, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3070, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3080, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3090, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3100, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3110, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3120, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3130, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3140, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3150, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3160, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3170, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3180, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3190, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3200, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3210, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3220, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3230, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3240, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3250, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3260, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3270, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3280, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3290, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3300, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3310, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3320, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3330, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3340, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3350, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3360, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3370, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3380, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3390, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3700, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3710, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3720, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3730, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3740, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3750, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3760, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3770, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3780, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3840, Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 3990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.7007, Training Accuracy= 0.501\n",
      "Epoch: 10, Loss= 0.6960, Training Accuracy= 0.501\n",
      "Epoch: 20, Loss= 0.6950, Training Accuracy= 0.501\n",
      "Epoch: 30, Loss= 0.6945, Training Accuracy= 0.501\n",
      "Epoch: 40, Loss= 0.6943, Training Accuracy= 0.501\n",
      "Epoch: 50, Loss= 0.6941, Training Accuracy= 0.501\n",
      "Epoch: 60, Loss= 0.6939, Training Accuracy= 0.501\n",
      "Epoch: 70, Loss= 0.6938, Training Accuracy= 0.501\n",
      "Epoch: 80, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 90, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 100, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 110, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 120, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 130, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 140, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 150, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 160, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 170, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 180, Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 190, Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 200, Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 210, Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 220, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 230, Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 250, Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 260, Loss= 0.6932, Training Accuracy= 0.494\n",
      "Epoch: 270, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 280, Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 290, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 300, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 310, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 320, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 330, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 340, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 350, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 360, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 370, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 380, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 390, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 400, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 410, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 420, Loss= 0.6929, Training Accuracy= 0.515\n",
      "Epoch: 430, Loss= 0.6929, Training Accuracy= 0.518\n",
      "Epoch: 440, Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 450, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 460, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 470, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 480, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 490, Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 500, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 510, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 520, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 530, Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 540, Loss= 0.6926, Training Accuracy= 0.518\n",
      "Epoch: 550, Loss= 0.6925, Training Accuracy= 0.520\n",
      "Epoch: 560, Loss= 0.6887, Training Accuracy= 0.514\n",
      "Epoch: 570, Loss= 0.7102, Training Accuracy= 0.449\n",
      "Epoch: 580, Loss= 0.6407, Training Accuracy= 0.611\n",
      "Epoch: 590, Loss= 0.4893, Training Accuracy= 0.774\n",
      "Epoch: 600, Loss= 0.4388, Training Accuracy= 0.797\n",
      "Epoch: 610, Loss= 0.6638, Training Accuracy= 0.551\n",
      "Epoch: 620, Loss= 0.6136, Training Accuracy= 0.610\n",
      "Epoch: 630, Loss= 0.6029, Training Accuracy= 0.607\n",
      "Epoch: 640, Loss= 0.6807, Training Accuracy= 0.511\n",
      "Epoch: 650, Loss= 0.7184, Training Accuracy= 0.502\n",
      "Epoch: 660, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 670, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 680, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 690, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 700, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 710, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 720, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 730, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 740, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 750, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 760, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 770, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 780, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 790, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 800, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 810, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 820, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 830, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 840, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 850, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 860, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 870, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 880, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 890, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 900, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 910, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 920, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 930, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 940, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 950, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 960, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 970, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 980, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 990, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1000, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1010, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1020, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1030, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1040, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1050, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1060, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1070, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1080, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1090, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1100, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1110, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1120, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1130, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1140, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1150, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1160, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1170, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1180, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1190, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1200, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1210, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1220, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1230, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1240, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1250, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1260, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1270, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1280, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1290, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1300, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1310, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1320, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1330, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1340, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1350, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1360, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1370, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1380, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1390, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1400, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1410, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1420, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1430, Loss= 0.6935, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1440, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1450, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1460, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1470, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1480, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1490, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1500, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1510, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1520, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1530, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1540, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1550, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1560, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1570, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1580, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1590, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1600, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1610, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1620, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1630, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1640, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1650, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1660, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1670, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1680, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1690, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1700, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1710, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1720, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1730, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1740, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1750, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1760, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1770, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1780, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1790, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1800, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1810, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1820, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1830, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1840, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1850, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1860, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1870, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1880, Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1890, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1900, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1910, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1920, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1930, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1940, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1950, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1960, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1970, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1980, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 1990, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2000, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2010, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2020, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2030, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2040, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2050, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2060, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2070, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2080, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2090, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2100, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2110, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2120, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2130, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2140, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2150, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2160, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2170, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2180, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2190, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2200, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2210, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2220, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2230, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2240, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2250, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2260, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2270, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2280, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2290, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2300, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2310, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2320, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2330, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2340, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2350, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2360, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2370, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2380, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2390, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2400, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2410, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2420, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2430, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2440, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2450, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2460, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2470, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2480, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2490, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2500, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2510, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2520, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2530, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2540, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2550, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2560, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2570, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2580, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2590, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2600, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2610, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2620, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2630, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2640, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2650, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2660, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2670, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2680, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2690, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2700, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2710, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2720, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2730, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2740, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2750, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2760, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2770, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2780, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2790, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2800, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2810, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2820, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2830, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2840, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2850, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2860, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2870, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2880, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2890, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2900, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2910, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2920, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2930, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2940, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2950, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2960, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2970, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2980, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2990, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3000, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3010, Loss= 0.6935, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3020, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3030, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3040, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3050, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3060, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3070, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3080, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3090, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3100, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3110, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3120, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3130, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3140, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3150, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3160, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3170, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3180, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3190, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3200, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3210, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3220, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3230, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3240, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3250, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3260, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3270, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3280, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3290, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3300, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3310, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3320, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3330, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3340, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3350, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3360, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3370, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3380, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3390, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3400, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3410, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3420, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3430, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3440, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3450, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3460, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3470, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3480, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3490, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3500, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3510, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3520, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3530, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3540, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3550, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3560, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3570, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3580, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3590, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3600, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3610, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3620, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3630, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3640, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3650, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3660, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3670, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3680, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3690, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3700, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3710, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3720, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3730, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3740, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3750, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3760, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3770, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3780, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3790, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3800, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3810, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3820, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3830, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3840, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3850, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3860, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3870, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3880, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3890, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3900, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3910, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3920, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3930, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3940, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3950, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3960, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3970, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3980, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 3990, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4855\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 0.6941, Training Accuracy= 0.501\n",
      "Epoch: 10, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 20, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 30, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 40, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 50, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 60, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 70, Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 80, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 90, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 100, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 110, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 120, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 130, Loss= 0.6929, Training Accuracy= 0.501\n",
      "Epoch: 140, Loss= 0.6929, Training Accuracy= 0.499\n",
      "Epoch: 150, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 160, Loss= 0.6928, Training Accuracy= 0.505\n",
      "Epoch: 170, Loss= 0.6928, Training Accuracy= 0.507\n",
      "Epoch: 180, Loss= 0.6928, Training Accuracy= 0.506\n",
      "Epoch: 190, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 200, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 210, Loss= 0.6928, Training Accuracy= 0.505\n",
      "Epoch: 220, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 230, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 240, Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 250, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 260, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 270, Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 280, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 290, Loss= 0.6926, Training Accuracy= 0.518\n",
      "Epoch: 300, Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 310, Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 320, Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 330, Loss= 0.6925, Training Accuracy= 0.521\n",
      "Epoch: 340, Loss= 0.6925, Training Accuracy= 0.518\n",
      "Epoch: 350, Loss= 0.6924, Training Accuracy= 0.516\n",
      "Epoch: 360, Loss= 0.6924, Training Accuracy= 0.517\n",
      "Epoch: 370, Loss= 0.6923, Training Accuracy= 0.518\n",
      "Epoch: 380, Loss= 0.6923, Training Accuracy= 0.522\n",
      "Epoch: 390, Loss= 0.6922, Training Accuracy= 0.521\n",
      "Epoch: 400, Loss= 0.6922, Training Accuracy= 0.523\n",
      "Epoch: 410, Loss= 0.6921, Training Accuracy= 0.521\n",
      "Epoch: 420, Loss= 0.6921, Training Accuracy= 0.515\n",
      "Epoch: 430, Loss= 0.6921, Training Accuracy= 0.518\n",
      "Epoch: 440, Loss= 0.6920, Training Accuracy= 0.521\n",
      "Epoch: 450, Loss= 0.6920, Training Accuracy= 0.525\n",
      "Epoch: 460, Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 470, Loss= 0.6920, Training Accuracy= 0.518\n",
      "Epoch: 480, Loss= 0.6919, Training Accuracy= 0.523\n",
      "Epoch: 490, Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 500, Loss= 0.6919, Training Accuracy= 0.521\n",
      "Epoch: 510, Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 520, Loss= 0.6919, Training Accuracy= 0.523\n",
      "Epoch: 530, Loss= 0.6919, Training Accuracy= 0.526\n",
      "Epoch: 540, Loss= 0.6919, Training Accuracy= 0.525\n",
      "Epoch: 550, Loss= 0.6919, Training Accuracy= 0.525\n",
      "Epoch: 560, Loss= 0.6919, Training Accuracy= 0.525\n",
      "Epoch: 570, Loss= 0.6918, Training Accuracy= 0.525\n",
      "Epoch: 580, Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 590, Loss= 0.6918, Training Accuracy= 0.524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600, Loss= 0.6918, Training Accuracy= 0.524\n",
      "Epoch: 610, Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 620, Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 630, Loss= 0.6918, Training Accuracy= 0.525\n",
      "Epoch: 640, Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 650, Loss= 0.6918, Training Accuracy= 0.524\n",
      "Epoch: 660, Loss= 0.6918, Training Accuracy= 0.526\n",
      "Epoch: 670, Loss= 0.6918, Training Accuracy= 0.527\n",
      "Epoch: 680, Loss= 0.6918, Training Accuracy= 0.525\n",
      "Epoch: 690, Loss= 0.6918, Training Accuracy= 0.528\n",
      "Epoch: 700, Loss= 0.6918, Training Accuracy= 0.526\n",
      "Epoch: 710, Loss= 0.6917, Training Accuracy= 0.527\n",
      "Epoch: 720, Loss= 0.6917, Training Accuracy= 0.526\n",
      "Epoch: 730, Loss= 0.6917, Training Accuracy= 0.525\n",
      "Epoch: 740, Loss= 0.6917, Training Accuracy= 0.527\n",
      "Epoch: 750, Loss= 0.6917, Training Accuracy= 0.527\n",
      "Epoch: 760, Loss= 0.6917, Training Accuracy= 0.526\n",
      "Epoch: 770, Loss= 0.6917, Training Accuracy= 0.526\n",
      "Epoch: 780, Loss= 0.6917, Training Accuracy= 0.529\n",
      "Epoch: 790, Loss= 0.6917, Training Accuracy= 0.528\n",
      "Epoch: 800, Loss= 0.6917, Training Accuracy= 0.529\n",
      "Epoch: 810, Loss= 0.6917, Training Accuracy= 0.530\n",
      "Epoch: 820, Loss= 0.6916, Training Accuracy= 0.527\n",
      "Epoch: 830, Loss= 0.6916, Training Accuracy= 0.527\n",
      "Epoch: 840, Loss= 0.6916, Training Accuracy= 0.526\n",
      "Epoch: 850, Loss= 0.6916, Training Accuracy= 0.526\n",
      "Epoch: 860, Loss= 0.6916, Training Accuracy= 0.525\n",
      "Epoch: 870, Loss= 0.6916, Training Accuracy= 0.524\n",
      "Epoch: 880, Loss= 0.6916, Training Accuracy= 0.525\n",
      "Epoch: 890, Loss= 0.6916, Training Accuracy= 0.525\n",
      "Epoch: 900, Loss= 0.6916, Training Accuracy= 0.528\n",
      "Epoch: 910, Loss= 0.6915, Training Accuracy= 0.527\n",
      "Epoch: 920, Loss= 0.6915, Training Accuracy= 0.525\n",
      "Epoch: 930, Loss= 0.6915, Training Accuracy= 0.521\n",
      "Epoch: 940, Loss= 0.6915, Training Accuracy= 0.515\n",
      "Epoch: 950, Loss= 0.6915, Training Accuracy= 0.517\n",
      "Epoch: 960, Loss= 0.6915, Training Accuracy= 0.517\n",
      "Epoch: 970, Loss= 0.6914, Training Accuracy= 0.514\n",
      "Epoch: 980, Loss= 0.6914, Training Accuracy= 0.515\n",
      "Epoch: 990, Loss= 0.6914, Training Accuracy= 0.518\n",
      "Epoch: 1000, Loss= 0.6914, Training Accuracy= 0.517\n",
      "Epoch: 1010, Loss= 0.6913, Training Accuracy= 0.517\n",
      "Epoch: 1020, Loss= 0.6913, Training Accuracy= 0.518\n",
      "Epoch: 1030, Loss= 0.6913, Training Accuracy= 0.519\n",
      "Epoch: 1040, Loss= 0.6913, Training Accuracy= 0.521\n",
      "Epoch: 1050, Loss= 0.6912, Training Accuracy= 0.520\n",
      "Epoch: 1060, Loss= 0.6912, Training Accuracy= 0.521\n",
      "Epoch: 1070, Loss= 0.6911, Training Accuracy= 0.521\n",
      "Epoch: 1080, Loss= 0.6911, Training Accuracy= 0.522\n",
      "Epoch: 1090, Loss= 0.6910, Training Accuracy= 0.526\n",
      "Epoch: 1100, Loss= 0.6910, Training Accuracy= 0.525\n",
      "Epoch: 1110, Loss= 0.6910, Training Accuracy= 0.531\n",
      "Epoch: 1120, Loss= 0.6909, Training Accuracy= 0.531\n",
      "Epoch: 1130, Loss= 0.6909, Training Accuracy= 0.534\n",
      "Epoch: 1140, Loss= 0.6908, Training Accuracy= 0.534\n",
      "Epoch: 1150, Loss= 0.6908, Training Accuracy= 0.537\n",
      "Epoch: 1160, Loss= 0.6907, Training Accuracy= 0.537\n",
      "Epoch: 1170, Loss= 0.6907, Training Accuracy= 0.539\n",
      "Epoch: 1180, Loss= 0.6906, Training Accuracy= 0.536\n",
      "Epoch: 1190, Loss= 0.6906, Training Accuracy= 0.531\n",
      "Epoch: 1200, Loss= 0.6906, Training Accuracy= 0.533\n",
      "Epoch: 1210, Loss= 0.6906, Training Accuracy= 0.529\n",
      "Epoch: 1220, Loss= 0.6906, Training Accuracy= 0.531\n",
      "Epoch: 1230, Loss= 0.6905, Training Accuracy= 0.527\n",
      "Epoch: 1240, Loss= 0.6905, Training Accuracy= 0.526\n",
      "Epoch: 1250, Loss= 0.6905, Training Accuracy= 0.529\n",
      "Epoch: 1260, Loss= 0.6904, Training Accuracy= 0.525\n",
      "Epoch: 1270, Loss= 0.6904, Training Accuracy= 0.517\n",
      "Epoch: 1280, Loss= 0.6904, Training Accuracy= 0.520\n",
      "Epoch: 1290, Loss= 0.6903, Training Accuracy= 0.519\n",
      "Epoch: 1300, Loss= 0.6903, Training Accuracy= 0.521\n",
      "Epoch: 1310, Loss= 0.6902, Training Accuracy= 0.515\n",
      "Epoch: 1320, Loss= 0.6902, Training Accuracy= 0.515\n",
      "Epoch: 1330, Loss= 0.6901, Training Accuracy= 0.518\n",
      "Epoch: 1340, Loss= 0.6900, Training Accuracy= 0.516\n",
      "Epoch: 1350, Loss= 0.6899, Training Accuracy= 0.518\n",
      "Epoch: 1360, Loss= 0.6897, Training Accuracy= 0.515\n",
      "Epoch: 1370, Loss= 0.6893, Training Accuracy= 0.521\n",
      "Epoch: 1380, Loss= 0.6888, Training Accuracy= 0.530\n",
      "Epoch: 1390, Loss= 0.6884, Training Accuracy= 0.533\n",
      "Epoch: 1400, Loss= 0.6875, Training Accuracy= 0.544\n",
      "Epoch: 1410, Loss= 0.6848, Training Accuracy= 0.543\n",
      "Epoch: 1420, Loss= 0.6764, Training Accuracy= 0.535\n",
      "Epoch: 1430, Loss= 0.6648, Training Accuracy= 0.556\n",
      "Epoch: 1440, Loss= 0.6513, Training Accuracy= 0.564\n",
      "Epoch: 1450, Loss= 0.6781, Training Accuracy= 0.529\n",
      "Epoch: 1460, Loss= 0.6444, Training Accuracy= 0.591\n",
      "Epoch: 1470, Loss= 0.6465, Training Accuracy= 0.581\n",
      "Epoch: 1480, Loss= 0.6478, Training Accuracy= 0.580\n",
      "Epoch: 1490, Loss= 0.6793, Training Accuracy= 0.545\n",
      "Epoch: 1500, Loss= 0.7211, Training Accuracy= 0.516\n",
      "Epoch: 1510, Loss= 0.6753, Training Accuracy= 0.544\n",
      "Epoch: 1520, Loss= 0.6702, Training Accuracy= 0.531\n",
      "Epoch: 1530, Loss= 0.6861, Training Accuracy= 0.528\n",
      "Epoch: 1540, Loss= 0.6824, Training Accuracy= 0.536\n",
      "Epoch: 1550, Loss= 0.6792, Training Accuracy= 0.538\n",
      "Epoch: 1560, Loss= 0.6824, Training Accuracy= 0.533\n",
      "Epoch: 1570, Loss= 0.6728, Training Accuracy= 0.538\n",
      "Epoch: 1580, Loss= 0.6809, Training Accuracy= 0.514\n",
      "Epoch: 1590, Loss= 0.6776, Training Accuracy= 0.519\n",
      "Epoch: 1600, Loss= 0.6794, Training Accuracy= 0.521\n",
      "Epoch: 1610, Loss= 0.6909, Training Accuracy= 0.501\n",
      "Epoch: 1620, Loss= 0.6827, Training Accuracy= 0.515\n",
      "Epoch: 1630, Loss= 0.6803, Training Accuracy= 0.522\n",
      "Epoch: 1640, Loss= 0.6791, Training Accuracy= 0.534\n",
      "Epoch: 1650, Loss= 0.6773, Training Accuracy= 0.533\n",
      "Epoch: 1660, Loss= 0.6757, Training Accuracy= 0.530\n",
      "Epoch: 1670, Loss= 0.6930, Training Accuracy= 0.539\n",
      "Epoch: 1680, Loss= 0.6941, Training Accuracy= 0.514\n",
      "Epoch: 1690, Loss= 0.6749, Training Accuracy= 0.533\n",
      "Epoch: 1700, Loss= 0.6919, Training Accuracy= 0.512\n",
      "Epoch: 1710, Loss= 0.6917, Training Accuracy= 0.539\n",
      "Epoch: 1720, Loss= 0.6909, Training Accuracy= 0.522\n",
      "Epoch: 1730, Loss= 0.6929, Training Accuracy= 0.521\n",
      "Epoch: 1740, Loss= 0.6870, Training Accuracy= 0.548\n",
      "Epoch: 1750, Loss= 0.6921, Training Accuracy= 0.504\n",
      "Epoch: 1760, Loss= 0.6906, Training Accuracy= 0.518\n",
      "Epoch: 1770, Loss= 0.6896, Training Accuracy= 0.532\n",
      "Epoch: 1780, Loss= 0.6899, Training Accuracy= 0.527\n",
      "Epoch: 1790, Loss= 0.6872, Training Accuracy= 0.532\n",
      "Epoch: 1800, Loss= 0.6924, Training Accuracy= 0.537\n",
      "Epoch: 1810, Loss= 0.6880, Training Accuracy= 0.533\n",
      "Epoch: 1820, Loss= 0.7044, Training Accuracy= 0.506\n",
      "Epoch: 1830, Loss= 0.6887, Training Accuracy= 0.523\n",
      "Epoch: 1840, Loss= 0.6897, Training Accuracy= 0.529\n",
      "Epoch: 1850, Loss= 0.6964, Training Accuracy= 0.499\n",
      "Epoch: 1860, Loss= 0.6927, Training Accuracy= 0.522\n",
      "Epoch: 1870, Loss= 0.6879, Training Accuracy= 0.541\n",
      "Epoch: 1880, Loss= 0.6871, Training Accuracy= 0.556\n",
      "Epoch: 1890, Loss= 0.6814, Training Accuracy= 0.557\n",
      "Epoch: 1900, Loss= 0.6766, Training Accuracy= 0.583\n",
      "Epoch: 1910, Loss= 0.6557, Training Accuracy= 0.625\n",
      "Epoch: 1920, Loss= 0.6766, Training Accuracy= 0.581\n",
      "Epoch: 1930, Loss= 0.6953, Training Accuracy= 0.525\n",
      "Epoch: 1940, Loss= 0.6928, Training Accuracy= 0.503\n",
      "Epoch: 1950, Loss= 0.6918, Training Accuracy= 0.516\n",
      "Epoch: 1960, Loss= 0.6912, Training Accuracy= 0.515\n",
      "Epoch: 1970, Loss= 0.6910, Training Accuracy= 0.516\n",
      "Epoch: 1980, Loss= 0.6912, Training Accuracy= 0.517\n",
      "Epoch: 1990, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2000, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 2010, Loss= 0.6937, Training Accuracy= 0.507\n",
      "Epoch: 2020, Loss= 0.6935, Training Accuracy= 0.505\n",
      "Epoch: 2030, Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 2040, Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 2050, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 2060, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 2070, Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 2080, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 2090, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 2100, Loss= 0.6928, Training Accuracy= 0.504\n",
      "Epoch: 2110, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 2120, Loss= 0.6940, Training Accuracy= 0.498\n",
      "Epoch: 2130, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 2140, Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 2150, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 2160, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2170, Loss= 0.6923, Training Accuracy= 0.512\n",
      "Epoch: 2180, Loss= 0.6936, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2190, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 2200, Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 2210, Loss= 0.6927, Training Accuracy= 0.506\n",
      "Epoch: 2220, Loss= 0.6927, Training Accuracy= 0.506\n",
      "Epoch: 2230, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2240, Loss= 0.6923, Training Accuracy= 0.510\n",
      "Epoch: 2250, Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 2260, Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 2270, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2280, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 2290, Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 2300, Loss= 0.6925, Training Accuracy= 0.508\n",
      "Epoch: 2310, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2320, Loss= 0.6924, Training Accuracy= 0.507\n",
      "Epoch: 2330, Loss= 0.6924, Training Accuracy= 0.508\n",
      "Epoch: 2340, Loss= 0.6923, Training Accuracy= 0.510\n",
      "Epoch: 2350, Loss= 0.6924, Training Accuracy= 0.509\n",
      "Epoch: 2360, Loss= 0.6918, Training Accuracy= 0.513\n",
      "Epoch: 2370, Loss= 0.6917, Training Accuracy= 0.514\n",
      "Epoch: 2380, Loss= 0.6916, Training Accuracy= 0.514\n",
      "Epoch: 2390, Loss= 0.6915, Training Accuracy= 0.514\n",
      "Epoch: 2400, Loss= 0.6915, Training Accuracy= 0.512\n",
      "Epoch: 2410, Loss= 0.6913, Training Accuracy= 0.514\n",
      "Epoch: 2420, Loss= 0.6911, Training Accuracy= 0.516\n",
      "Epoch: 2430, Loss= 0.6909, Training Accuracy= 0.514\n",
      "Epoch: 2440, Loss= 0.6906, Training Accuracy= 0.512\n",
      "Epoch: 2450, Loss= 0.6904, Training Accuracy= 0.508\n",
      "Epoch: 2460, Loss= 0.6907, Training Accuracy= 0.513\n",
      "Epoch: 2470, Loss= 0.6907, Training Accuracy= 0.513\n",
      "Epoch: 2480, Loss= 0.6907, Training Accuracy= 0.510\n",
      "Epoch: 2490, Loss= 0.6907, Training Accuracy= 0.509\n",
      "Epoch: 2500, Loss= 0.6910, Training Accuracy= 0.512\n",
      "Epoch: 2510, Loss= 0.6906, Training Accuracy= 0.513\n",
      "Epoch: 2520, Loss= 0.6906, Training Accuracy= 0.509\n",
      "Epoch: 2530, Loss= 0.6904, Training Accuracy= 0.512\n",
      "Epoch: 2540, Loss= 0.6904, Training Accuracy= 0.512\n",
      "Epoch: 2550, Loss= 0.6902, Training Accuracy= 0.513\n",
      "Epoch: 2560, Loss= 0.6901, Training Accuracy= 0.512\n",
      "Epoch: 2570, Loss= 0.6902, Training Accuracy= 0.513\n",
      "Epoch: 2580, Loss= 0.6903, Training Accuracy= 0.513\n",
      "Epoch: 2590, Loss= 0.6905, Training Accuracy= 0.510\n",
      "Epoch: 2600, Loss= 0.6903, Training Accuracy= 0.515\n",
      "Epoch: 2610, Loss= 0.6904, Training Accuracy= 0.513\n",
      "Epoch: 2620, Loss= 0.6905, Training Accuracy= 0.512\n",
      "Epoch: 2630, Loss= 0.6902, Training Accuracy= 0.514\n",
      "Epoch: 2640, Loss= 0.6901, Training Accuracy= 0.513\n",
      "Epoch: 2650, Loss= 0.6901, Training Accuracy= 0.514\n",
      "Epoch: 2660, Loss= 0.6909, Training Accuracy= 0.509\n",
      "Epoch: 2670, Loss= 0.6899, Training Accuracy= 0.514\n",
      "Epoch: 2680, Loss= 0.6904, Training Accuracy= 0.512\n",
      "Epoch: 2690, Loss= 0.6903, Training Accuracy= 0.513\n",
      "Epoch: 2700, Loss= 0.6909, Training Accuracy= 0.511\n",
      "Epoch: 2710, Loss= 0.6923, Training Accuracy= 0.508\n",
      "Epoch: 2720, Loss= 0.6914, Training Accuracy= 0.515\n",
      "Epoch: 2730, Loss= 0.6911, Training Accuracy= 0.512\n",
      "Epoch: 2740, Loss= 0.6922, Training Accuracy= 0.510\n",
      "Epoch: 2750, Loss= 0.6915, Training Accuracy= 0.504\n",
      "Epoch: 2760, Loss= 0.6920, Training Accuracy= 0.502\n",
      "Epoch: 2770, Loss= 0.6919, Training Accuracy= 0.506\n",
      "Epoch: 2780, Loss= 0.6910, Training Accuracy= 0.506\n",
      "Epoch: 2790, Loss= 0.6908, Training Accuracy= 0.512\n",
      "Epoch: 2800, Loss= 0.6917, Training Accuracy= 0.504\n",
      "Epoch: 2810, Loss= 0.6923, Training Accuracy= 0.507\n",
      "Epoch: 2820, Loss= 0.6913, Training Accuracy= 0.510\n",
      "Epoch: 2830, Loss= 0.6911, Training Accuracy= 0.509\n",
      "Epoch: 2840, Loss= 0.6909, Training Accuracy= 0.511\n",
      "Epoch: 2850, Loss= 0.6910, Training Accuracy= 0.511\n",
      "Epoch: 2860, Loss= 0.6900, Training Accuracy= 0.512\n",
      "Epoch: 2870, Loss= 0.6884, Training Accuracy= 0.521\n",
      "Epoch: 2880, Loss= 0.6867, Training Accuracy= 0.528\n",
      "Epoch: 2890, Loss= 0.6863, Training Accuracy= 0.523\n",
      "Epoch: 2900, Loss= 0.6919, Training Accuracy= 0.512\n",
      "Epoch: 2910, Loss= 0.6883, Training Accuracy= 0.527\n",
      "Epoch: 2920, Loss= 0.6882, Training Accuracy= 0.528\n",
      "Epoch: 2930, Loss= 0.6935, Training Accuracy= 0.511\n",
      "Epoch: 2940, Loss= 0.6919, Training Accuracy= 0.510\n",
      "Epoch: 2950, Loss= 0.6897, Training Accuracy= 0.515\n",
      "Epoch: 2960, Loss= 0.6894, Training Accuracy= 0.510\n",
      "Epoch: 2970, Loss= 0.6891, Training Accuracy= 0.513\n",
      "Epoch: 2980, Loss= 0.6890, Training Accuracy= 0.513\n",
      "Epoch: 2990, Loss= 0.6901, Training Accuracy= 0.516\n",
      "Epoch: 3000, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 3010, Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 3020, Loss= 0.6924, Training Accuracy= 0.512\n",
      "Epoch: 3030, Loss= 0.6927, Training Accuracy= 0.515\n",
      "Epoch: 3040, Loss= 0.6921, Training Accuracy= 0.515\n",
      "Epoch: 3050, Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 3060, Loss= 0.6919, Training Accuracy= 0.517\n",
      "Epoch: 3070, Loss= 0.6919, Training Accuracy= 0.518\n",
      "Epoch: 3080, Loss= 0.6920, Training Accuracy= 0.515\n",
      "Epoch: 3090, Loss= 0.6918, Training Accuracy= 0.518\n",
      "Epoch: 3100, Loss= 0.6919, Training Accuracy= 0.517\n",
      "Epoch: 3110, Loss= 0.6919, Training Accuracy= 0.517\n",
      "Epoch: 3120, Loss= 0.6918, Training Accuracy= 0.516\n",
      "Epoch: 3130, Loss= 0.6919, Training Accuracy= 0.517\n",
      "Epoch: 3140, Loss= 0.6919, Training Accuracy= 0.519\n",
      "Epoch: 3150, Loss= 0.6918, Training Accuracy= 0.520\n",
      "Epoch: 3160, Loss= 0.6917, Training Accuracy= 0.521\n",
      "Epoch: 3170, Loss= 0.6918, Training Accuracy= 0.519\n",
      "Epoch: 3180, Loss= 0.6917, Training Accuracy= 0.516\n",
      "Epoch: 3190, Loss= 0.6932, Training Accuracy= 0.514\n",
      "Epoch: 3200, Loss= 0.6915, Training Accuracy= 0.517\n",
      "Epoch: 3210, Loss= 0.6917, Training Accuracy= 0.517\n",
      "Epoch: 3220, Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 3230, Loss= 0.6921, Training Accuracy= 0.511\n",
      "Epoch: 3240, Loss= 0.6921, Training Accuracy= 0.514\n",
      "Epoch: 3250, Loss= 0.6921, Training Accuracy= 0.517\n",
      "Epoch: 3260, Loss= 0.6920, Training Accuracy= 0.518\n",
      "Epoch: 3270, Loss= 0.6920, Training Accuracy= 0.518\n",
      "Epoch: 3280, Loss= 0.6920, Training Accuracy= 0.516\n",
      "Epoch: 3290, Loss= 0.6919, Training Accuracy= 0.518\n",
      "Epoch: 3300, Loss= 0.6906, Training Accuracy= 0.517\n",
      "Epoch: 3310, Loss= 0.6900, Training Accuracy= 0.521\n",
      "Epoch: 3320, Loss= 0.6902, Training Accuracy= 0.524\n",
      "Epoch: 3330, Loss= 0.6885, Training Accuracy= 0.532\n",
      "Epoch: 3340, Loss= 0.6885, Training Accuracy= 0.541\n",
      "Epoch: 3350, Loss= 0.6914, Training Accuracy= 0.518\n",
      "Epoch: 3360, Loss= 0.6914, Training Accuracy= 0.516\n",
      "Epoch: 3370, Loss= 0.6903, Training Accuracy= 0.525\n",
      "Epoch: 3380, Loss= 0.6988, Training Accuracy= 0.507\n",
      "Epoch: 3390, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 3400, Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 3410, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 3420, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 3430, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 3440, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 3450, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 3460, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 3470, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 3480, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 3490, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 3500, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 3510, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3520, Loss= 0.6930, Training Accuracy= 0.510\n",
      "Epoch: 3530, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3540, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3550, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3560, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3570, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3580, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3590, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3600, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3610, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3620, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3630, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3640, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3650, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3660, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3670, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 3680, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3690, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 3700, Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 3710, Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 3720, Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 3730, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3740, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3750, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3760, Loss= 0.6930, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3770, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3780, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3790, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3800, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3810, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3820, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3830, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3840, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 3850, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 3860, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 3870, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 3880, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 3890, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 3900, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 3910, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 3920, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 3930, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 3940, Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 3950, Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 3960, Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 3970, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 3980, Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 3990, Loss= 0.6927, Training Accuracy= 0.515\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5104\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.6938, Training Accuracy= 0.506\n",
      "Epoch: 10, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 20, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 30, Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 40, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 50, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 60, Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 70, Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 80, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 90, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 100, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 110, Loss= 0.6929, Training Accuracy= 0.503\n",
      "Epoch: 120, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 130, Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 140, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 150, Loss= 0.6929, Training Accuracy= 0.503\n",
      "Epoch: 160, Loss= 0.6929, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 0.6929, Training Accuracy= 0.503\n",
      "Epoch: 180, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 190, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 200, Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 210, Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 220, Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 230, Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 240, Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 250, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 260, Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 270, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 280, Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 290, Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 300, Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 310, Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 320, Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 330, Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 340, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 350, Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 360, Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 370, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 380, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 390, Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 400, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 410, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 420, Loss= 0.6927, Training Accuracy= 0.514\n",
      "Epoch: 430, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 440, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 450, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 460, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 470, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 480, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 490, Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 500, Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 510, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 520, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 530, Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 540, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 550, Loss= 0.6925, Training Accuracy= 0.507\n",
      "Epoch: 560, Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 570, Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 580, Loss= 0.6924, Training Accuracy= 0.508\n",
      "Epoch: 590, Loss= 0.6924, Training Accuracy= 0.510\n",
      "Epoch: 600, Loss= 0.6923, Training Accuracy= 0.505\n",
      "Epoch: 610, Loss= 0.6923, Training Accuracy= 0.506\n",
      "Epoch: 620, Loss= 0.6922, Training Accuracy= 0.507\n",
      "Epoch: 630, Loss= 0.6921, Training Accuracy= 0.509\n",
      "Epoch: 640, Loss= 0.6921, Training Accuracy= 0.515\n",
      "Epoch: 650, Loss= 0.6919, Training Accuracy= 0.510\n",
      "Epoch: 660, Loss= 0.6918, Training Accuracy= 0.510\n",
      "Epoch: 670, Loss= 0.6916, Training Accuracy= 0.519\n",
      "Epoch: 680, Loss= 0.6912, Training Accuracy= 0.523\n",
      "Epoch: 690, Loss= 0.6902, Training Accuracy= 0.529\n",
      "Epoch: 700, Loss= 0.6880, Training Accuracy= 0.526\n",
      "Epoch: 710, Loss= 0.6834, Training Accuracy= 0.555\n",
      "Epoch: 720, Loss= 0.6783, Training Accuracy= 0.567\n",
      "Epoch: 730, Loss= 0.6724, Training Accuracy= 0.592\n",
      "Epoch: 740, Loss= 0.6663, Training Accuracy= 0.616\n",
      "Epoch: 750, Loss= 0.6644, Training Accuracy= 0.612\n",
      "Epoch: 760, Loss= 0.6719, Training Accuracy= 0.574\n",
      "Epoch: 770, Loss= 0.6908, Training Accuracy= 0.569\n",
      "Epoch: 780, Loss= 0.7286, Training Accuracy= 0.536\n",
      "Epoch: 790, Loss= 0.7058, Training Accuracy= 0.494\n",
      "Epoch: 800, Loss= 0.6895, Training Accuracy= 0.545\n",
      "Epoch: 810, Loss= 0.6918, Training Accuracy= 0.524\n",
      "Epoch: 820, Loss= 0.5075, Training Accuracy= 0.762\n",
      "Epoch: 830, Loss= 0.2432, Training Accuracy= 0.920\n",
      "Epoch: 840, Loss= 0.0840, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0226, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0126, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0087, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0066, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0053, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0045, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0038, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0005, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1360, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2000, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2010, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2020, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2030, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2040, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2050, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2060, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2070, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2080, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2090, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2100, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2110, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2120, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2130, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2140, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2150, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2160, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2170, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2180, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2190, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2200, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2210, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2220, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2230, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2240, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2250, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2260, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2280, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3000, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3010, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3020, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3030, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3040, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3050, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3060, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3070, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3080, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3090, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3100, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3110, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3120, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3130, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3140, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3150, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3160, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3170, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3180, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3190, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3200, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3210, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3220, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3230, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3240, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3250, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3260, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3270, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3280, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3290, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3300, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3310, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3320, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3330, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3340, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3350, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3360, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3370, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3380, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3390, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 3990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 0.7161, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 0.7050, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.7019, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.7004, Training Accuracy= 0.501\n",
      "Epoch: 40, Loss= 0.6996, Training Accuracy= 0.502\n",
      "Epoch: 50, Loss= 0.6991, Training Accuracy= 0.499\n",
      "Epoch: 60, Loss= 0.6988, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.6985, Training Accuracy= 0.498\n",
      "Epoch: 80, Loss= 0.6983, Training Accuracy= 0.505\n",
      "Epoch: 90, Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.6977, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.6974, Training Accuracy= 0.501\n",
      "Epoch: 120, Loss= 0.6971, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 0.6969, Training Accuracy= 0.502\n",
      "Epoch: 140, Loss= 0.6966, Training Accuracy= 0.504\n",
      "Epoch: 150, Loss= 0.6963, Training Accuracy= 0.510\n",
      "Epoch: 160, Loss= 0.6961, Training Accuracy= 0.507\n",
      "Epoch: 170, Loss= 0.6958, Training Accuracy= 0.505\n",
      "Epoch: 180, Loss= 0.6956, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.6955, Training Accuracy= 0.506\n",
      "Epoch: 200, Loss= 0.6953, Training Accuracy= 0.501\n",
      "Epoch: 210, Loss= 0.6951, Training Accuracy= 0.499\n",
      "Epoch: 220, Loss= 0.6950, Training Accuracy= 0.499\n",
      "Epoch: 230, Loss= 0.6949, Training Accuracy= 0.499\n",
      "Epoch: 240, Loss= 0.6947, Training Accuracy= 0.500\n",
      "Epoch: 250, Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 260, Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 270, Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 280, Loss= 0.6944, Training Accuracy= 0.496\n",
      "Epoch: 290, Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 300, Loss= 0.6942, Training Accuracy= 0.501\n",
      "Epoch: 310, Loss= 0.6941, Training Accuracy= 0.503\n",
      "Epoch: 320, Loss= 0.6941, Training Accuracy= 0.507\n",
      "Epoch: 330, Loss= 0.6940, Training Accuracy= 0.506\n",
      "Epoch: 340, Loss= 0.6939, Training Accuracy= 0.506\n",
      "Epoch: 350, Loss= 0.6939, Training Accuracy= 0.501\n",
      "Epoch: 360, Loss= 0.6938, Training Accuracy= 0.499\n",
      "Epoch: 370, Loss= 0.6938, Training Accuracy= 0.503\n",
      "Epoch: 380, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 390, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 400, Loss= 0.6936, Training Accuracy= 0.505\n",
      "Epoch: 410, Loss= 0.6936, Training Accuracy= 0.508\n",
      "Epoch: 420, Loss= 0.6935, Training Accuracy= 0.503\n",
      "Epoch: 430, Loss= 0.6935, Training Accuracy= 0.504\n",
      "Epoch: 440, Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 450, Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 460, Loss= 0.6934, Training Accuracy= 0.506\n",
      "Epoch: 470, Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 480, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 490, Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 500, Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 510, Loss= 0.6932, Training Accuracy= 0.510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 520, Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 530, Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 540, Loss= 0.6931, Training Accuracy= 0.510\n",
      "Epoch: 550, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 560, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 570, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 580, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 590, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 600, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 610, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 620, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 630, Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 640, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 650, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 660, Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 670, Loss= 0.6929, Training Accuracy= 0.501\n",
      "Epoch: 680, Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 690, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 700, Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 710, Loss= 0.6928, Training Accuracy= 0.500\n",
      "Epoch: 720, Loss= 0.6928, Training Accuracy= 0.499\n",
      "Epoch: 730, Loss= 0.6928, Training Accuracy= 0.499\n",
      "Epoch: 740, Loss= 0.6928, Training Accuracy= 0.498\n",
      "Epoch: 750, Loss= 0.6928, Training Accuracy= 0.501\n",
      "Epoch: 760, Loss= 0.6928, Training Accuracy= 0.500\n",
      "Epoch: 770, Loss= 0.6927, Training Accuracy= 0.500\n",
      "Epoch: 780, Loss= 0.6927, Training Accuracy= 0.498\n",
      "Epoch: 790, Loss= 0.6927, Training Accuracy= 0.498\n",
      "Epoch: 800, Loss= 0.6927, Training Accuracy= 0.500\n",
      "Epoch: 810, Loss= 0.6927, Training Accuracy= 0.503\n",
      "Epoch: 820, Loss= 0.6927, Training Accuracy= 0.504\n",
      "Epoch: 830, Loss= 0.6926, Training Accuracy= 0.506\n",
      "Epoch: 840, Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 850, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 860, Loss= 0.6926, Training Accuracy= 0.506\n",
      "Epoch: 870, Loss= 0.6926, Training Accuracy= 0.505\n",
      "Epoch: 880, Loss= 0.6926, Training Accuracy= 0.502\n",
      "Epoch: 890, Loss= 0.6926, Training Accuracy= 0.501\n",
      "Epoch: 900, Loss= 0.6926, Training Accuracy= 0.503\n",
      "Epoch: 910, Loss= 0.6926, Training Accuracy= 0.504\n",
      "Epoch: 920, Loss= 0.6925, Training Accuracy= 0.504\n",
      "Epoch: 930, Loss= 0.6925, Training Accuracy= 0.502\n",
      "Epoch: 940, Loss= 0.6925, Training Accuracy= 0.503\n",
      "Epoch: 950, Loss= 0.6925, Training Accuracy= 0.501\n",
      "Epoch: 960, Loss= 0.6925, Training Accuracy= 0.500\n",
      "Epoch: 970, Loss= 0.6925, Training Accuracy= 0.500\n",
      "Epoch: 980, Loss= 0.6925, Training Accuracy= 0.499\n",
      "Epoch: 990, Loss= 0.6925, Training Accuracy= 0.500\n",
      "Epoch: 1000, Loss= 0.6925, Training Accuracy= 0.503\n",
      "Epoch: 1010, Loss= 0.6925, Training Accuracy= 0.502\n",
      "Epoch: 1020, Loss= 0.6925, Training Accuracy= 0.503\n",
      "Epoch: 1030, Loss= 0.6925, Training Accuracy= 0.505\n",
      "Epoch: 1040, Loss= 0.6924, Training Accuracy= 0.503\n",
      "Epoch: 1050, Loss= 0.6924, Training Accuracy= 0.505\n",
      "Epoch: 1060, Loss= 0.6924, Training Accuracy= 0.505\n",
      "Epoch: 1070, Loss= 0.6924, Training Accuracy= 0.507\n",
      "Epoch: 1080, Loss= 0.6924, Training Accuracy= 0.506\n",
      "Epoch: 1090, Loss= 0.6924, Training Accuracy= 0.511\n",
      "Epoch: 1100, Loss= 0.6924, Training Accuracy= 0.514\n",
      "Epoch: 1110, Loss= 0.6924, Training Accuracy= 0.514\n",
      "Epoch: 1120, Loss= 0.6924, Training Accuracy= 0.513\n",
      "Epoch: 1130, Loss= 0.6923, Training Accuracy= 0.514\n",
      "Epoch: 1140, Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 1150, Loss= 0.6923, Training Accuracy= 0.518\n",
      "Epoch: 1160, Loss= 0.6923, Training Accuracy= 0.519\n",
      "Epoch: 1170, Loss= 0.6923, Training Accuracy= 0.515\n",
      "Epoch: 1180, Loss= 0.6922, Training Accuracy= 0.518\n",
      "Epoch: 1190, Loss= 0.6922, Training Accuracy= 0.519\n",
      "Epoch: 1200, Loss= 0.6922, Training Accuracy= 0.517\n",
      "Epoch: 1210, Loss= 0.6921, Training Accuracy= 0.515\n",
      "Epoch: 1220, Loss= 0.6921, Training Accuracy= 0.517\n",
      "Epoch: 1230, Loss= 0.6920, Training Accuracy= 0.514\n",
      "Epoch: 1240, Loss= 0.6920, Training Accuracy= 0.516\n",
      "Epoch: 1250, Loss= 0.6919, Training Accuracy= 0.518\n",
      "Epoch: 1260, Loss= 0.6919, Training Accuracy= 0.518\n",
      "Epoch: 1270, Loss= 0.6918, Training Accuracy= 0.516\n",
      "Epoch: 1280, Loss= 0.6918, Training Accuracy= 0.515\n",
      "Epoch: 1290, Loss= 0.6917, Training Accuracy= 0.516\n",
      "Epoch: 1300, Loss= 0.6917, Training Accuracy= 0.518\n",
      "Epoch: 1310, Loss= 0.6916, Training Accuracy= 0.518\n",
      "Epoch: 1320, Loss= 0.6916, Training Accuracy= 0.513\n",
      "Epoch: 1330, Loss= 0.6915, Training Accuracy= 0.513\n",
      "Epoch: 1340, Loss= 0.6915, Training Accuracy= 0.513\n",
      "Epoch: 1350, Loss= 0.6914, Training Accuracy= 0.514\n",
      "Epoch: 1360, Loss= 0.6914, Training Accuracy= 0.518\n",
      "Epoch: 1370, Loss= 0.6913, Training Accuracy= 0.517\n",
      "Epoch: 1380, Loss= 0.6912, Training Accuracy= 0.520\n",
      "Epoch: 1390, Loss= 0.6912, Training Accuracy= 0.519\n",
      "Epoch: 1400, Loss= 0.6911, Training Accuracy= 0.528\n",
      "Epoch: 1410, Loss= 0.6910, Training Accuracy= 0.532\n",
      "Epoch: 1420, Loss= 0.6909, Training Accuracy= 0.535\n",
      "Epoch: 1430, Loss= 0.6907, Training Accuracy= 0.540\n",
      "Epoch: 1440, Loss= 0.6905, Training Accuracy= 0.537\n",
      "Epoch: 1450, Loss= 0.6899, Training Accuracy= 0.546\n",
      "Epoch: 1460, Loss= 0.6750, Training Accuracy= 0.561\n",
      "Epoch: 1470, Loss= 0.7004, Training Accuracy= 0.524\n",
      "Epoch: 1480, Loss= 0.6865, Training Accuracy= 0.588\n",
      "Epoch: 1490, Loss= 0.6309, Training Accuracy= 0.633\n",
      "Epoch: 1500, Loss= 0.5121, Training Accuracy= 0.759\n",
      "Epoch: 1510, Loss= 0.5571, Training Accuracy= 0.675\n",
      "Epoch: 1520, Loss= 0.6364, Training Accuracy= 0.551\n",
      "Epoch: 1530, Loss= 0.6290, Training Accuracy= 0.553\n",
      "Epoch: 1540, Loss= 0.6121, Training Accuracy= 0.579\n",
      "Epoch: 1550, Loss= 0.5890, Training Accuracy= 0.601\n",
      "Epoch: 1560, Loss= 0.6019, Training Accuracy= 0.595\n",
      "Epoch: 1570, Loss= 0.5691, Training Accuracy= 0.590\n",
      "Epoch: 1580, Loss= 0.6938, Training Accuracy= 0.503\n",
      "Epoch: 1590, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1600, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1610, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1620, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1630, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1640, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1650, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1660, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1670, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1680, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1690, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1700, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1710, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1720, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1730, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1740, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1750, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1760, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1770, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1780, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1790, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1800, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1810, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1820, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1830, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1840, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1850, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1860, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1870, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1880, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1890, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1900, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1910, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1920, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1930, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1940, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1950, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1960, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1970, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1980, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1990, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2000, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2010, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2020, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2030, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2040, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2050, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2060, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2070, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2080, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2090, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2100, Loss= 0.6937, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2110, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2120, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2130, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2140, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2150, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2160, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2170, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2180, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2190, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2200, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2210, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2220, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2230, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2240, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2250, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2260, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2270, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2280, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2290, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2300, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2310, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2320, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2330, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2340, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2350, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2360, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2370, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2380, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2390, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2400, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2410, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2420, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2430, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2440, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2450, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2460, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2470, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2480, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2490, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2500, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2510, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2520, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2530, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2540, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2550, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2560, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2570, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2580, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2590, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2600, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2610, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2620, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2630, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2640, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2650, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2660, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2670, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2680, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2690, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2700, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2710, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2720, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2730, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2740, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2750, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2760, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2770, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2780, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2790, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2800, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2810, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2820, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2830, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2840, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2850, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2860, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2870, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2880, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2890, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2900, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2910, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2920, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2930, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2940, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2950, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2960, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2970, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2980, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 2990, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3000, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3010, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3020, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3030, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3040, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3050, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3060, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3070, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3080, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3090, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3100, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3110, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3120, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3130, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3140, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3150, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3160, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3170, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3180, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3190, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3200, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3210, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3220, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3230, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3240, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3250, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3260, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3270, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3280, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3290, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3300, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3310, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3320, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3330, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3340, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3350, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3360, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3370, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3380, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3390, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3400, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3410, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3420, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3430, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3440, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3450, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3460, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3470, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3480, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3490, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3500, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3510, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3520, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3530, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3540, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3550, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3560, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3570, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3580, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3590, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3600, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3610, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3620, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3630, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3640, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3650, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3660, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3670, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3680, Loss= 0.6937, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3690, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3700, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3710, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3720, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3730, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3740, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3750, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3760, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3770, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3780, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3790, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3800, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3810, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3820, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3830, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3840, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3850, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3860, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3870, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3880, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3890, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3900, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3910, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3920, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3930, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3940, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3950, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3960, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3970, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3980, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 3990, Loss= 0.6937, Training Accuracy= 0.503\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5015\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 0.6953, Training Accuracy= 0.495\n",
      "Epoch: 10, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 20, Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 30, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 40, Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 50, Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 60, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 70, Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 80, Loss= 0.6927, Training Accuracy= 0.516\n",
      "Epoch: 90, Loss= 0.6927, Training Accuracy= 0.514\n",
      "Epoch: 100, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 110, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 120, Loss= 0.6926, Training Accuracy= 0.517\n",
      "Epoch: 130, Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 140, Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 150, Loss= 0.6925, Training Accuracy= 0.517\n",
      "Epoch: 160, Loss= 0.6924, Training Accuracy= 0.506\n",
      "Epoch: 170, Loss= 0.6924, Training Accuracy= 0.507\n",
      "Epoch: 180, Loss= 0.6924, Training Accuracy= 0.505\n",
      "Epoch: 190, Loss= 0.6923, Training Accuracy= 0.508\n",
      "Epoch: 200, Loss= 0.6923, Training Accuracy= 0.509\n",
      "Epoch: 210, Loss= 0.6923, Training Accuracy= 0.512\n",
      "Epoch: 220, Loss= 0.6923, Training Accuracy= 0.511\n",
      "Epoch: 230, Loss= 0.6923, Training Accuracy= 0.512\n",
      "Epoch: 240, Loss= 0.6923, Training Accuracy= 0.516\n",
      "Epoch: 250, Loss= 0.6922, Training Accuracy= 0.519\n",
      "Epoch: 260, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 270, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 280, Loss= 0.6922, Training Accuracy= 0.523\n",
      "Epoch: 290, Loss= 0.6922, Training Accuracy= 0.524\n",
      "Epoch: 300, Loss= 0.6922, Training Accuracy= 0.525\n",
      "Epoch: 310, Loss= 0.6922, Training Accuracy= 0.524\n",
      "Epoch: 320, Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 330, Loss= 0.6922, Training Accuracy= 0.523\n",
      "Epoch: 340, Loss= 0.6922, Training Accuracy= 0.527\n",
      "Epoch: 350, Loss= 0.6922, Training Accuracy= 0.526\n",
      "Epoch: 360, Loss= 0.6922, Training Accuracy= 0.525\n",
      "Epoch: 370, Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 380, Loss= 0.6921, Training Accuracy= 0.521\n",
      "Epoch: 390, Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 400, Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 410, Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 420, Loss= 0.6921, Training Accuracy= 0.519\n",
      "Epoch: 430, Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 440, Loss= 0.6921, Training Accuracy= 0.521\n",
      "Epoch: 450, Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 460, Loss= 0.6921, Training Accuracy= 0.516\n",
      "Epoch: 470, Loss= 0.6921, Training Accuracy= 0.521\n",
      "Epoch: 480, Loss= 0.6921, Training Accuracy= 0.523\n",
      "Epoch: 490, Loss= 0.6921, Training Accuracy= 0.523\n",
      "Epoch: 500, Loss= 0.6920, Training Accuracy= 0.523\n",
      "Epoch: 510, Loss= 0.6920, Training Accuracy= 0.521\n",
      "Epoch: 520, Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 530, Loss= 0.6920, Training Accuracy= 0.515\n",
      "Epoch: 540, Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 550, Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 560, Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 570, Loss= 0.6920, Training Accuracy= 0.523\n",
      "Epoch: 580, Loss= 0.6919, Training Accuracy= 0.521\n",
      "Epoch: 590, Loss= 0.6919, Training Accuracy= 0.523\n",
      "Epoch: 600, Loss= 0.6918, Training Accuracy= 0.515\n",
      "Epoch: 610, Loss= 0.6917, Training Accuracy= 0.520\n",
      "Epoch: 620, Loss= 0.6912, Training Accuracy= 0.528\n",
      "Epoch: 630, Loss= 0.6875, Training Accuracy= 0.546\n",
      "Epoch: 640, Loss= 0.6770, Training Accuracy= 0.529\n",
      "Epoch: 650, Loss= 0.6383, Training Accuracy= 0.593\n",
      "Epoch: 660, Loss= 0.5612, Training Accuracy= 0.675\n",
      "Epoch: 670, Loss= 0.5220, Training Accuracy= 0.678\n",
      "Epoch: 680, Loss= 0.5201, Training Accuracy= 0.689\n",
      "Epoch: 690, Loss= 0.5171, Training Accuracy= 0.709\n",
      "Epoch: 700, Loss= 0.5028, Training Accuracy= 0.710\n",
      "Epoch: 710, Loss= 0.4247, Training Accuracy= 0.790\n",
      "Epoch: 720, Loss= 0.4390, Training Accuracy= 0.802\n",
      "Epoch: 730, Loss= 0.3960, Training Accuracy= 0.799\n",
      "Epoch: 740, Loss= 0.3683, Training Accuracy= 0.795\n",
      "Epoch: 750, Loss= 0.3861, Training Accuracy= 0.819\n",
      "Epoch: 760, Loss= 0.3428, Training Accuracy= 0.820\n",
      "Epoch: 770, Loss= 0.6982, Training Accuracy= 0.501\n",
      "Epoch: 780, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 790, Loss= 0.6927, Training Accuracy= 0.503\n",
      "Epoch: 800, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 810, Loss= 0.6925, Training Accuracy= 0.508\n",
      "Epoch: 820, Loss= 0.6924, Training Accuracy= 0.510\n",
      "Epoch: 830, Loss= 0.6924, Training Accuracy= 0.508\n",
      "Epoch: 840, Loss= 0.6923, Training Accuracy= 0.504\n",
      "Epoch: 850, Loss= 0.6923, Training Accuracy= 0.507\n",
      "Epoch: 860, Loss= 0.6923, Training Accuracy= 0.508\n",
      "Epoch: 870, Loss= 0.6923, Training Accuracy= 0.503\n",
      "Epoch: 880, Loss= 0.6922, Training Accuracy= 0.502\n",
      "Epoch: 890, Loss= 0.6921, Training Accuracy= 0.502\n",
      "Epoch: 900, Loss= 0.6921, Training Accuracy= 0.503\n",
      "Epoch: 910, Loss= 0.6920, Training Accuracy= 0.505\n",
      "Epoch: 920, Loss= 0.6918, Training Accuracy= 0.504\n",
      "Epoch: 930, Loss= 0.6916, Training Accuracy= 0.512\n",
      "Epoch: 940, Loss= 0.6913, Training Accuracy= 0.513\n",
      "Epoch: 950, Loss= 0.6908, Training Accuracy= 0.511\n",
      "Epoch: 960, Loss= 0.6898, Training Accuracy= 0.513\n",
      "Epoch: 970, Loss= 0.6889, Training Accuracy= 0.514\n",
      "Epoch: 980, Loss= 0.6885, Training Accuracy= 0.510\n",
      "Epoch: 990, Loss= 0.6891, Training Accuracy= 0.517\n",
      "Epoch: 1000, Loss= 0.6925, Training Accuracy= 0.516\n",
      "Epoch: 1010, Loss= 0.6958, Training Accuracy= 0.507\n",
      "Epoch: 1020, Loss= 0.6934, Training Accuracy= 0.512\n",
      "Epoch: 1030, Loss= 0.6933, Training Accuracy= 0.513\n",
      "Epoch: 1040, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 1050, Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1060, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 1070, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 1080, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 1090, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1100, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1110, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1120, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1130, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1140, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1150, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1160, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1170, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1180, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1190, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1200, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1210, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1220, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1230, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1240, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1250, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1260, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1270, Loss= 0.6930, Training Accuracy= 0.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1280, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1290, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1300, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1310, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1320, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1330, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1340, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1350, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1360, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1370, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1380, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1390, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1400, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1410, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1420, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1430, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1440, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1450, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1460, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1470, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1480, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1490, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1500, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1510, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1520, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1530, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1540, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1550, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1560, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1570, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1580, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1590, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1600, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1610, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1620, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1630, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1640, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1650, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1660, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1670, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1680, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1690, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1700, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1710, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1720, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1730, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1740, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1750, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1760, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1770, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1780, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1790, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1800, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1810, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1820, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1830, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1840, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1850, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1860, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1870, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1880, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1890, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1900, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1910, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1920, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1930, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1940, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1950, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1960, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1970, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1980, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 1990, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2000, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2010, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2020, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2030, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2040, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2050, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2060, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2070, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2080, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2090, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2100, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2110, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2120, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2130, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2140, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2150, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2160, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2170, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2180, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2190, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2200, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2210, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 2220, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 2230, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2240, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2250, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2260, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2270, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2280, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2290, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2300, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2310, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2320, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2330, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2340, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2350, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2360, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2370, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2380, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2390, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2400, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2410, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2420, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2430, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2440, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2450, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2460, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2470, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2480, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2490, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2500, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2510, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2520, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2530, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2540, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2550, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2560, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2570, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2580, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2590, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2600, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2610, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2620, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2630, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2640, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2650, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2660, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2670, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 2680, Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 2690, Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 2700, Loss= 0.6929, Training Accuracy= 0.515\n",
      "Epoch: 2710, Loss= 0.6929, Training Accuracy= 0.515\n",
      "Epoch: 2720, Loss= 0.6929, Training Accuracy= 0.515\n",
      "Epoch: 2730, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2740, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2750, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2760, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2770, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2780, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2790, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2800, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2810, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2820, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2830, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2840, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2850, Loss= 0.6928, Training Accuracy= 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2860, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2870, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2880, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2890, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2900, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2910, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2920, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2930, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2940, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2950, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2960, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2970, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2980, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 2990, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3000, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3010, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3020, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3030, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3040, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3050, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3060, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3070, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3080, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3090, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3100, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3110, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3120, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3130, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3140, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3150, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3160, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3170, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3180, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3190, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3200, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3210, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3220, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3230, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3240, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3250, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3260, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3270, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3280, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3290, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3300, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3310, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3320, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3330, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3340, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3350, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3360, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3370, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3380, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3390, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3400, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3410, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3420, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3430, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3440, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3450, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3460, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3470, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3480, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 3490, Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 3500, Loss= 0.6928, Training Accuracy= 0.519\n",
      "Epoch: 3510, Loss= 0.6928, Training Accuracy= 0.519\n",
      "Epoch: 3520, Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 3530, Loss= 0.6928, Training Accuracy= 0.521\n",
      "Epoch: 3540, Loss= 0.6928, Training Accuracy= 0.520\n",
      "Epoch: 3550, Loss= 0.6928, Training Accuracy= 0.520\n",
      "Epoch: 3560, Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 3570, Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 3580, Loss= 0.6927, Training Accuracy= 0.515\n",
      "Epoch: 3590, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 3600, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 3610, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 3620, Loss= 0.6927, Training Accuracy= 0.515\n",
      "Epoch: 3630, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 3640, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 3650, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 3660, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 3670, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 3680, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 3690, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 3700, Loss= 0.6927, Training Accuracy= 0.506\n",
      "Epoch: 3710, Loss= 0.6927, Training Accuracy= 0.506\n",
      "Epoch: 3720, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 3730, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 3740, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 3750, Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 3760, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 3770, Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 3780, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 3790, Loss= 0.6926, Training Accuracy= 0.505\n",
      "Epoch: 3800, Loss= 0.6926, Training Accuracy= 0.503\n",
      "Epoch: 3810, Loss= 0.6926, Training Accuracy= 0.504\n",
      "Epoch: 3820, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 3830, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 3840, Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 3850, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 3860, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 3870, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 3880, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 3890, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 3900, Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 3910, Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 3920, Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 3930, Loss= 0.6926, Training Accuracy= 0.504\n",
      "Epoch: 3940, Loss= 0.6926, Training Accuracy= 0.506\n",
      "Epoch: 3950, Loss= 0.6926, Training Accuracy= 0.506\n",
      "Epoch: 3960, Loss= 0.6926, Training Accuracy= 0.502\n",
      "Epoch: 3970, Loss= 0.6926, Training Accuracy= 0.502\n",
      "Epoch: 3980, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 3990, Loss= 0.6926, Training Accuracy= 0.512\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5117\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.6946, Training Accuracy= 0.503\n",
      "Epoch: 10, Loss= 0.6932, Training Accuracy= 0.519\n",
      "Epoch: 20, Loss= 0.6932, Training Accuracy= 0.520\n",
      "Epoch: 30, Loss= 0.6932, Training Accuracy= 0.524\n",
      "Epoch: 40, Loss= 0.6932, Training Accuracy= 0.520\n",
      "Epoch: 50, Loss= 0.6932, Training Accuracy= 0.518\n",
      "Epoch: 60, Loss= 0.6932, Training Accuracy= 0.517\n",
      "Epoch: 70, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 80, Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 90, Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 100, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 110, Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 120, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 130, Loss= 0.6930, Training Accuracy= 0.500\n",
      "Epoch: 140, Loss= 0.6929, Training Accuracy= 0.499\n",
      "Epoch: 150, Loss= 0.6928, Training Accuracy= 0.494\n",
      "Epoch: 160, Loss= 0.6926, Training Accuracy= 0.497\n",
      "Epoch: 170, Loss= 0.6921, Training Accuracy= 0.512\n",
      "Epoch: 180, Loss= 0.6908, Training Accuracy= 0.526\n",
      "Epoch: 190, Loss= 0.6881, Training Accuracy= 0.553\n",
      "Epoch: 200, Loss= 0.6840, Training Accuracy= 0.565\n",
      "Epoch: 210, Loss= 0.6791, Training Accuracy= 0.568\n",
      "Epoch: 220, Loss= 0.6708, Training Accuracy= 0.598\n",
      "Epoch: 230, Loss= 0.6485, Training Accuracy= 0.619\n",
      "Epoch: 240, Loss= 0.6739, Training Accuracy= 0.555\n",
      "Epoch: 250, Loss= 0.7760, Training Accuracy= 0.461\n",
      "Epoch: 260, Loss= 0.6360, Training Accuracy= 0.594\n",
      "Epoch: 270, Loss= 0.6419, Training Accuracy= 0.614\n",
      "Epoch: 280, Loss= 0.7028, Training Accuracy= 0.531\n",
      "Epoch: 290, Loss= 0.6655, Training Accuracy= 0.587\n",
      "Epoch: 300, Loss= 0.7086, Training Accuracy= 0.501\n",
      "Epoch: 310, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 320, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 330, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 340, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 350, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 360, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 370, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 380, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 390, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 400, Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 410, Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 420, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 430, Loss= 0.6933, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 440, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 450, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 460, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 470, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 480, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 490, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 500, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 510, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 520, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 530, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 540, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 550, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 560, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 570, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 580, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 590, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 600, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 610, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 620, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 630, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 640, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 650, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 660, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 670, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 680, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 690, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 700, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 710, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 720, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 730, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 740, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 750, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 760, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 770, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 780, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 790, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 800, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 810, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 820, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 830, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 840, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 850, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 860, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 870, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 880, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 890, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 900, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 910, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 920, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 930, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 940, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 950, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 960, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 970, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 980, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 990, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 1000, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 1010, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 1020, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 1030, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 1040, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 1050, Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 1060, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1070, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1080, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1090, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 1100, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 1110, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 1120, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 1130, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1140, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1150, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1160, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1170, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1180, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1190, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1200, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1210, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1220, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1230, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1240, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1250, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1260, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1270, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1280, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1290, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1300, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1310, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1320, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1330, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1340, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1350, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1360, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1370, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1380, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1390, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1400, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1410, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1420, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1430, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1440, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1450, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1460, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1470, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1480, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1490, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1500, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1510, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1520, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1530, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1540, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 1550, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1560, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1570, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1580, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1590, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1600, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1610, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1620, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1630, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 1640, Loss= 0.6925, Training Accuracy= 0.508\n",
      "Epoch: 1650, Loss= 0.6924, Training Accuracy= 0.509\n",
      "Epoch: 1660, Loss= 0.6922, Training Accuracy= 0.509\n",
      "Epoch: 1670, Loss= 0.6921, Training Accuracy= 0.509\n",
      "Epoch: 1680, Loss= 0.6920, Training Accuracy= 0.509\n",
      "Epoch: 1690, Loss= 0.6920, Training Accuracy= 0.509\n",
      "Epoch: 1700, Loss= 0.6920, Training Accuracy= 0.509\n",
      "Epoch: 1710, Loss= 0.6920, Training Accuracy= 0.509\n",
      "Epoch: 1720, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1730, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1740, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1750, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1760, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1770, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1780, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1790, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1800, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1810, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1820, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1830, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1840, Loss= 0.6919, Training Accuracy= 0.509\n",
      "Epoch: 1850, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1860, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1870, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1880, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1890, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1900, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1910, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1920, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1930, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1940, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1950, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1960, Loss= 0.6918, Training Accuracy= 0.509\n",
      "Epoch: 1970, Loss= 0.6954, Training Accuracy= 0.498\n",
      "Epoch: 1980, Loss= 0.6950, Training Accuracy= 0.501\n",
      "Epoch: 1990, Loss= 0.6925, Training Accuracy= 0.503\n",
      "Epoch: 2000, Loss= 0.6923, Training Accuracy= 0.503\n",
      "Epoch: 2010, Loss= 0.6922, Training Accuracy= 0.507\n",
      "Epoch: 2020, Loss= 0.6922, Training Accuracy= 0.506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2030, Loss= 0.6921, Training Accuracy= 0.507\n",
      "Epoch: 2040, Loss= 0.6921, Training Accuracy= 0.507\n",
      "Epoch: 2050, Loss= 0.6920, Training Accuracy= 0.507\n",
      "Epoch: 2060, Loss= 0.6920, Training Accuracy= 0.507\n",
      "Epoch: 2070, Loss= 0.6919, Training Accuracy= 0.507\n",
      "Epoch: 2080, Loss= 0.6919, Training Accuracy= 0.507\n",
      "Epoch: 2090, Loss= 0.6919, Training Accuracy= 0.508\n",
      "Epoch: 2100, Loss= 0.6918, Training Accuracy= 0.508\n",
      "Epoch: 2110, Loss= 0.6918, Training Accuracy= 0.508\n",
      "Epoch: 2120, Loss= 0.6918, Training Accuracy= 0.508\n",
      "Epoch: 2130, Loss= 0.6917, Training Accuracy= 0.508\n",
      "Epoch: 2140, Loss= 0.6917, Training Accuracy= 0.508\n",
      "Epoch: 2150, Loss= 0.6935, Training Accuracy= 0.505\n",
      "Epoch: 2160, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 2170, Loss= 0.6928, Training Accuracy= 0.507\n",
      "Epoch: 2180, Loss= 0.6928, Training Accuracy= 0.507\n",
      "Epoch: 2190, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 2200, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 2210, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 2220, Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 2230, Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 2240, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2250, Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 2260, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2270, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2280, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2290, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2300, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2310, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2320, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2330, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2340, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2350, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2360, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2370, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2380, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2390, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2400, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2410, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2420, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2430, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2440, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2450, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2460, Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 2470, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2480, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2490, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2500, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2510, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2520, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2530, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2540, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2550, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2560, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2570, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2580, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2590, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2600, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2610, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2620, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2630, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2640, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2650, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 2660, Loss= 0.6924, Training Accuracy= 0.509\n",
      "Epoch: 2670, Loss= 0.6924, Training Accuracy= 0.509\n",
      "Epoch: 2680, Loss= 0.6923, Training Accuracy= 0.509\n",
      "Epoch: 2690, Loss= 0.6922, Training Accuracy= 0.510\n",
      "Epoch: 2700, Loss= 0.6922, Training Accuracy= 0.509\n",
      "Epoch: 2710, Loss= 0.6921, Training Accuracy= 0.509\n",
      "Epoch: 2720, Loss= 0.6912, Training Accuracy= 0.508\n",
      "Epoch: 2730, Loss= 0.6912, Training Accuracy= 0.506\n",
      "Epoch: 2740, Loss= 0.6912, Training Accuracy= 0.507\n",
      "Epoch: 2750, Loss= 0.6912, Training Accuracy= 0.508\n",
      "Epoch: 2760, Loss= 0.6912, Training Accuracy= 0.508\n",
      "Epoch: 2770, Loss= 0.6912, Training Accuracy= 0.507\n",
      "Epoch: 2780, Loss= 0.6912, Training Accuracy= 0.507\n",
      "Epoch: 2790, Loss= 0.6912, Training Accuracy= 0.507\n",
      "Epoch: 2800, Loss= 0.6912, Training Accuracy= 0.507\n",
      "Epoch: 2810, Loss= 0.6913, Training Accuracy= 0.507\n",
      "Epoch: 2820, Loss= 0.6912, Training Accuracy= 0.508\n",
      "Epoch: 2830, Loss= 0.6912, Training Accuracy= 0.508\n",
      "Epoch: 2840, Loss= 0.6912, Training Accuracy= 0.508\n",
      "Epoch: 2850, Loss= 0.6912, Training Accuracy= 0.508\n",
      "Epoch: 2860, Loss= 0.6912, Training Accuracy= 0.508\n",
      "Epoch: 2870, Loss= 0.6912, Training Accuracy= 0.508\n",
      "Epoch: 2880, Loss= 0.6912, Training Accuracy= 0.508\n",
      "Epoch: 2890, Loss= 0.6911, Training Accuracy= 0.508\n",
      "Epoch: 2900, Loss= 0.6911, Training Accuracy= 0.508\n",
      "Epoch: 2910, Loss= 0.6908, Training Accuracy= 0.507\n",
      "Epoch: 2920, Loss= 0.6907, Training Accuracy= 0.507\n",
      "Epoch: 2930, Loss= 0.6906, Training Accuracy= 0.507\n",
      "Epoch: 2940, Loss= 0.6905, Training Accuracy= 0.507\n",
      "Epoch: 2950, Loss= 0.6905, Training Accuracy= 0.507\n",
      "Epoch: 2960, Loss= 0.6905, Training Accuracy= 0.507\n",
      "Epoch: 2970, Loss= 0.6904, Training Accuracy= 0.507\n",
      "Epoch: 2980, Loss= 0.6904, Training Accuracy= 0.507\n",
      "Epoch: 2990, Loss= 0.6903, Training Accuracy= 0.507\n",
      "Epoch: 3000, Loss= 0.6902, Training Accuracy= 0.507\n",
      "Epoch: 3010, Loss= 0.6901, Training Accuracy= 0.507\n",
      "Epoch: 3020, Loss= 0.6900, Training Accuracy= 0.507\n",
      "Epoch: 3030, Loss= 0.6898, Training Accuracy= 0.508\n",
      "Epoch: 3040, Loss= 0.6896, Training Accuracy= 0.508\n",
      "Epoch: 3050, Loss= 0.6896, Training Accuracy= 0.510\n",
      "Epoch: 3060, Loss= 0.6895, Training Accuracy= 0.511\n",
      "Epoch: 3070, Loss= 0.6894, Training Accuracy= 0.510\n",
      "Epoch: 3080, Loss= 0.6893, Training Accuracy= 0.510\n",
      "Epoch: 3090, Loss= 0.6893, Training Accuracy= 0.509\n",
      "Epoch: 3100, Loss= 0.6892, Training Accuracy= 0.509\n",
      "Epoch: 3110, Loss= 0.6892, Training Accuracy= 0.509\n",
      "Epoch: 3120, Loss= 0.6892, Training Accuracy= 0.509\n",
      "Epoch: 3130, Loss= 0.6892, Training Accuracy= 0.508\n",
      "Epoch: 3140, Loss= 0.6892, Training Accuracy= 0.507\n",
      "Epoch: 3150, Loss= 0.6892, Training Accuracy= 0.507\n",
      "Epoch: 3160, Loss= 0.6892, Training Accuracy= 0.507\n",
      "Epoch: 3170, Loss= 0.6892, Training Accuracy= 0.507\n",
      "Epoch: 3180, Loss= 0.6892, Training Accuracy= 0.507\n",
      "Epoch: 3190, Loss= 0.6892, Training Accuracy= 0.507\n",
      "Epoch: 3200, Loss= 0.6891, Training Accuracy= 0.507\n",
      "Epoch: 3210, Loss= 0.6891, Training Accuracy= 0.507\n",
      "Epoch: 3220, Loss= 0.6891, Training Accuracy= 0.507\n",
      "Epoch: 3230, Loss= 0.6891, Training Accuracy= 0.507\n",
      "Epoch: 3240, Loss= 0.6891, Training Accuracy= 0.507\n",
      "Epoch: 3250, Loss= 0.6891, Training Accuracy= 0.507\n",
      "Epoch: 3260, Loss= 0.6891, Training Accuracy= 0.507\n",
      "Epoch: 3270, Loss= 0.6891, Training Accuracy= 0.507\n",
      "Epoch: 3280, Loss= 0.6890, Training Accuracy= 0.507\n",
      "Epoch: 3290, Loss= 0.6890, Training Accuracy= 0.507\n",
      "Epoch: 3300, Loss= 0.6890, Training Accuracy= 0.507\n",
      "Epoch: 3310, Loss= 0.6890, Training Accuracy= 0.507\n",
      "Epoch: 3320, Loss= 0.6890, Training Accuracy= 0.507\n",
      "Epoch: 3330, Loss= 0.6890, Training Accuracy= 0.507\n",
      "Epoch: 3340, Loss= 0.6890, Training Accuracy= 0.507\n",
      "Epoch: 3350, Loss= 0.6890, Training Accuracy= 0.507\n",
      "Epoch: 3360, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3370, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3380, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3390, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3400, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3410, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3420, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3430, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3440, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3450, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3460, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3470, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3480, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3490, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3500, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3510, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3520, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3530, Loss= 0.6889, Training Accuracy= 0.507\n",
      "Epoch: 3540, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3550, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3560, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3570, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3580, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3590, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3600, Loss= 0.6888, Training Accuracy= 0.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3610, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3620, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3630, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3640, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3650, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3660, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3670, Loss= 0.6888, Training Accuracy= 0.507\n",
      "Epoch: 3680, Loss= 0.6888, Training Accuracy= 0.509\n",
      "Epoch: 3690, Loss= 0.6888, Training Accuracy= 0.509\n",
      "Epoch: 3700, Loss= 0.6888, Training Accuracy= 0.508\n",
      "Epoch: 3710, Loss= 0.6888, Training Accuracy= 0.510\n",
      "Epoch: 3720, Loss= 0.6888, Training Accuracy= 0.509\n",
      "Epoch: 3730, Loss= 0.6888, Training Accuracy= 0.509\n",
      "Epoch: 3740, Loss= 0.6888, Training Accuracy= 0.509\n",
      "Epoch: 3750, Loss= 0.6888, Training Accuracy= 0.509\n",
      "Epoch: 3760, Loss= 0.6888, Training Accuracy= 0.508\n",
      "Epoch: 3770, Loss= 0.6888, Training Accuracy= 0.509\n",
      "Epoch: 3780, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3790, Loss= 0.6887, Training Accuracy= 0.507\n",
      "Epoch: 3800, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3810, Loss= 0.6887, Training Accuracy= 0.506\n",
      "Epoch: 3820, Loss= 0.6887, Training Accuracy= 0.507\n",
      "Epoch: 3830, Loss= 0.6887, Training Accuracy= 0.507\n",
      "Epoch: 3840, Loss= 0.6887, Training Accuracy= 0.507\n",
      "Epoch: 3850, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3860, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3870, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3880, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3890, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3900, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3910, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3920, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3930, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3940, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3950, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3960, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3970, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3980, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Epoch: 3990, Loss= 0.6887, Training Accuracy= 0.508\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5023\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.07\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 4000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a RNN cell with tensorflow\n",
    "    rnn_cell = rnn.BasicRNNCell(num_hidden)\n",
    "\n",
    "    # Get RNN cell output\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 0.4964, 0.50050002, 1.0, 0.48550001, 0.5104, 1.0, 0.50150001, 0.51169997, 0.50230002]\n",
      "mean of test_accuracies_10replications:  0.65083\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.00228687375784\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3VDXNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb1f460d210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
