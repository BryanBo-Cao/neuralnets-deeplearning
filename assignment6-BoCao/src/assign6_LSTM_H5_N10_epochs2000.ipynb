{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 10\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Minibatch Loss= 0.6941, Training Accuracy= 0.508\n",
      "Epoch: 10, Minibatch Loss= 0.6937, Training Accuracy= 0.500\n",
      "Epoch: 20, Minibatch Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 30, Minibatch Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 40, Minibatch Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 50, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 60, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 70, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 80, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 90, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 100, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 110, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 120, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 130, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 140, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 150, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 160, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 170, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 180, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 190, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 200, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 210, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 220, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 230, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 240, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 250, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 260, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 270, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 280, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 290, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 300, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 310, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 320, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 330, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 340, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 350, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 360, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 370, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 380, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 390, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 400, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 410, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 420, Minibatch Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 430, Minibatch Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 440, Minibatch Loss= 0.6934, Training Accuracy= 0.507\n",
      "Epoch: 450, Minibatch Loss= 0.6934, Training Accuracy= 0.506\n",
      "Epoch: 460, Minibatch Loss= 0.6934, Training Accuracy= 0.506\n",
      "Epoch: 470, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 480, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 490, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 500, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 510, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 520, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 530, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 540, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 550, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 560, Minibatch Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 570, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 580, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 590, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 600, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 610, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 620, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 630, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 640, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 650, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 660, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 670, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 680, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 690, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 700, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 710, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 720, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 730, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 740, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 750, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 760, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 770, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 780, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 790, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 800, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 810, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 820, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 830, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 840, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 850, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 860, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 870, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 880, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 890, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 900, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 910, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 920, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 930, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 940, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 950, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 960, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 970, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 980, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 990, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 1000, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 1010, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 1020, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 1030, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 1040, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 1050, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 1060, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 1070, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1080, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1090, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1100, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1110, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1120, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1130, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1140, Minibatch Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 1150, Minibatch Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 1160, Minibatch Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 1170, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1180, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1190, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1200, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1210, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1220, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1230, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1240, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1250, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1260, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1270, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1280, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 1290, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 1300, Minibatch Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 1310, Minibatch Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 1320, Minibatch Loss= 0.6933, Training Accuracy= 0.511\n",
      "Epoch: 1330, Minibatch Loss= 0.6933, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340, Minibatch Loss= 0.6933, Training Accuracy= 0.513\n",
      "Epoch: 1350, Minibatch Loss= 0.6933, Training Accuracy= 0.514\n",
      "Epoch: 1360, Minibatch Loss= 0.6932, Training Accuracy= 0.497\n",
      "Epoch: 1370, Minibatch Loss= 0.6923, Training Accuracy= 0.550\n",
      "Epoch: 1380, Minibatch Loss= 0.6874, Training Accuracy= 0.566\n",
      "Epoch: 1390, Minibatch Loss= 0.8440, Training Accuracy= 0.517\n",
      "Epoch: 1400, Minibatch Loss= 0.4047, Training Accuracy= 0.823\n",
      "Epoch: 1410, Minibatch Loss= 0.6923, Training Accuracy= 0.518\n",
      "Epoch: 1420, Minibatch Loss= 0.5314, Training Accuracy= 0.736\n",
      "Epoch: 1430, Minibatch Loss= 0.7231, Training Accuracy= 0.494\n",
      "Epoch: 1440, Minibatch Loss= 0.6921, Training Accuracy= 0.496\n",
      "Epoch: 1450, Minibatch Loss= 0.6764, Training Accuracy= 0.533\n",
      "Epoch: 1460, Minibatch Loss= 0.6847, Training Accuracy= 0.505\n",
      "Epoch: 1470, Minibatch Loss= 0.6492, Training Accuracy= 0.565\n",
      "Epoch: 1480, Minibatch Loss= 0.6579, Training Accuracy= 0.546\n",
      "Epoch: 1490, Minibatch Loss= 0.6478, Training Accuracy= 0.550\n",
      "Epoch: 1500, Minibatch Loss= 0.6370, Training Accuracy= 0.558\n",
      "Epoch: 1510, Minibatch Loss= 0.6821, Training Accuracy= 0.511\n",
      "Epoch: 1520, Minibatch Loss= 0.6742, Training Accuracy= 0.524\n",
      "Epoch: 1530, Minibatch Loss= 0.0133, Training Accuracy= 1.000\n",
      "Epoch: 1540, Minibatch Loss= 0.0058, Training Accuracy= 1.000\n",
      "Epoch: 1550, Minibatch Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 1560, Minibatch Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 1570, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1580, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1590, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1600, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1610, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1620, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1630, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1640, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1650, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1660, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1670, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1680, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1690, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1700, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1710, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1720, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1730, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1740, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1750, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1760, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1770, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1780, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1790, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1800, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1810, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1820, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1830, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1840, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1850, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1860, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1870, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1880, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1890, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1900, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1910, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1920, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1930, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1940, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1950, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1960, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1970, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1980, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1990, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Minibatch Loss= 0.7098, Training Accuracy= 0.510\n",
      "Epoch: 10, Minibatch Loss= 0.6981, Training Accuracy= 0.510\n",
      "Epoch: 20, Minibatch Loss= 0.6969, Training Accuracy= 0.510\n",
      "Epoch: 30, Minibatch Loss= 0.6963, Training Accuracy= 0.510\n",
      "Epoch: 40, Minibatch Loss= 0.6958, Training Accuracy= 0.510\n",
      "Epoch: 50, Minibatch Loss= 0.6955, Training Accuracy= 0.510\n",
      "Epoch: 60, Minibatch Loss= 0.6953, Training Accuracy= 0.510\n",
      "Epoch: 70, Minibatch Loss= 0.6951, Training Accuracy= 0.510\n",
      "Epoch: 80, Minibatch Loss= 0.6950, Training Accuracy= 0.510\n",
      "Epoch: 90, Minibatch Loss= 0.6949, Training Accuracy= 0.510\n",
      "Epoch: 100, Minibatch Loss= 0.6948, Training Accuracy= 0.510\n",
      "Epoch: 110, Minibatch Loss= 0.6947, Training Accuracy= 0.510\n",
      "Epoch: 120, Minibatch Loss= 0.6946, Training Accuracy= 0.510\n",
      "Epoch: 130, Minibatch Loss= 0.6946, Training Accuracy= 0.510\n",
      "Epoch: 140, Minibatch Loss= 0.6945, Training Accuracy= 0.510\n",
      "Epoch: 150, Minibatch Loss= 0.6945, Training Accuracy= 0.510\n",
      "Epoch: 160, Minibatch Loss= 0.6944, Training Accuracy= 0.510\n",
      "Epoch: 170, Minibatch Loss= 0.6944, Training Accuracy= 0.510\n",
      "Epoch: 180, Minibatch Loss= 0.6944, Training Accuracy= 0.510\n",
      "Epoch: 190, Minibatch Loss= 0.6943, Training Accuracy= 0.510\n",
      "Epoch: 200, Minibatch Loss= 0.6943, Training Accuracy= 0.510\n",
      "Epoch: 210, Minibatch Loss= 0.6943, Training Accuracy= 0.510\n",
      "Epoch: 220, Minibatch Loss= 0.6943, Training Accuracy= 0.510\n",
      "Epoch: 230, Minibatch Loss= 0.6942, Training Accuracy= 0.510\n",
      "Epoch: 240, Minibatch Loss= 0.6942, Training Accuracy= 0.510\n",
      "Epoch: 250, Minibatch Loss= 0.6942, Training Accuracy= 0.510\n",
      "Epoch: 260, Minibatch Loss= 0.6942, Training Accuracy= 0.510\n",
      "Epoch: 270, Minibatch Loss= 0.6942, Training Accuracy= 0.510\n",
      "Epoch: 280, Minibatch Loss= 0.6941, Training Accuracy= 0.510\n",
      "Epoch: 290, Minibatch Loss= 0.6941, Training Accuracy= 0.510\n",
      "Epoch: 300, Minibatch Loss= 0.6941, Training Accuracy= 0.510\n",
      "Epoch: 310, Minibatch Loss= 0.6941, Training Accuracy= 0.510\n",
      "Epoch: 320, Minibatch Loss= 0.6941, Training Accuracy= 0.510\n",
      "Epoch: 330, Minibatch Loss= 0.6941, Training Accuracy= 0.510\n",
      "Epoch: 340, Minibatch Loss= 0.6941, Training Accuracy= 0.510\n",
      "Epoch: 350, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 360, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 370, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 380, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 390, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 400, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 410, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 420, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 430, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 440, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 450, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 460, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 470, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 480, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 490, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 500, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 510, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 520, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 530, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 540, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 550, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 560, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 570, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 580, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 590, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 600, Minibatch Loss= 0.6939, Training Accuracy= 0.511\n",
      "Epoch: 610, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 620, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 630, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 640, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 650, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 660, Minibatch Loss= 0.6938, Training Accuracy= 0.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 670, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 680, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 690, Minibatch Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 700, Minibatch Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 710, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 720, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 730, Minibatch Loss= 0.6938, Training Accuracy= 0.512\n",
      "Epoch: 740, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 750, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 760, Minibatch Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 770, Minibatch Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 780, Minibatch Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 790, Minibatch Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 800, Minibatch Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 810, Minibatch Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 820, Minibatch Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 830, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 840, Minibatch Loss= 0.6938, Training Accuracy= 0.511\n",
      "Epoch: 850, Minibatch Loss= 0.6938, Training Accuracy= 0.512\n",
      "Epoch: 860, Minibatch Loss= 0.6938, Training Accuracy= 0.513\n",
      "Epoch: 870, Minibatch Loss= 0.6937, Training Accuracy= 0.513\n",
      "Epoch: 880, Minibatch Loss= 0.6937, Training Accuracy= 0.513\n",
      "Epoch: 890, Minibatch Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 900, Minibatch Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 910, Minibatch Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 920, Minibatch Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 930, Minibatch Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 940, Minibatch Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 950, Minibatch Loss= 0.6937, Training Accuracy= 0.513\n",
      "Epoch: 960, Minibatch Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 970, Minibatch Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 980, Minibatch Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 990, Minibatch Loss= 0.6937, Training Accuracy= 0.515\n",
      "Epoch: 1000, Minibatch Loss= 0.6937, Training Accuracy= 0.515\n",
      "Epoch: 1010, Minibatch Loss= 0.6937, Training Accuracy= 0.515\n",
      "Epoch: 1020, Minibatch Loss= 0.6937, Training Accuracy= 0.516\n",
      "Epoch: 1030, Minibatch Loss= 0.6937, Training Accuracy= 0.515\n",
      "Epoch: 1040, Minibatch Loss= 0.6937, Training Accuracy= 0.515\n",
      "Epoch: 1050, Minibatch Loss= 0.6937, Training Accuracy= 0.517\n",
      "Epoch: 1060, Minibatch Loss= 0.6936, Training Accuracy= 0.519\n",
      "Epoch: 1070, Minibatch Loss= 0.6936, Training Accuracy= 0.519\n",
      "Epoch: 1080, Minibatch Loss= 0.6932, Training Accuracy= 0.523\n",
      "Epoch: 1090, Minibatch Loss= 0.6604, Training Accuracy= 0.558\n",
      "Epoch: 1100, Minibatch Loss= 0.4315, Training Accuracy= 0.802\n",
      "Epoch: 1110, Minibatch Loss= 0.3600, Training Accuracy= 0.786\n",
      "Epoch: 1120, Minibatch Loss= 0.3237, Training Accuracy= 0.841\n",
      "Epoch: 1130, Minibatch Loss= 0.2625, Training Accuracy= 0.882\n",
      "Epoch: 1140, Minibatch Loss= 0.7215, Training Accuracy= 0.502\n",
      "Epoch: 1150, Minibatch Loss= 0.7104, Training Accuracy= 0.502\n",
      "Epoch: 1160, Minibatch Loss= 0.7077, Training Accuracy= 0.502\n",
      "Epoch: 1170, Minibatch Loss= 0.7060, Training Accuracy= 0.502\n",
      "Epoch: 1180, Minibatch Loss= 0.7048, Training Accuracy= 0.502\n",
      "Epoch: 1190, Minibatch Loss= 0.7038, Training Accuracy= 0.503\n",
      "Epoch: 1200, Minibatch Loss= 0.7034, Training Accuracy= 0.503\n",
      "Epoch: 1210, Minibatch Loss= 0.7031, Training Accuracy= 0.503\n",
      "Epoch: 1220, Minibatch Loss= 0.7028, Training Accuracy= 0.503\n",
      "Epoch: 1230, Minibatch Loss= 0.7025, Training Accuracy= 0.503\n",
      "Epoch: 1240, Minibatch Loss= 0.7023, Training Accuracy= 0.504\n",
      "Epoch: 1250, Minibatch Loss= 0.7021, Training Accuracy= 0.504\n",
      "Epoch: 1260, Minibatch Loss= 0.7019, Training Accuracy= 0.504\n",
      "Epoch: 1270, Minibatch Loss= 0.7017, Training Accuracy= 0.504\n",
      "Epoch: 1280, Minibatch Loss= 0.7016, Training Accuracy= 0.504\n",
      "Epoch: 1290, Minibatch Loss= 0.7015, Training Accuracy= 0.505\n",
      "Epoch: 1300, Minibatch Loss= 0.7014, Training Accuracy= 0.505\n",
      "Epoch: 1310, Minibatch Loss= 0.7013, Training Accuracy= 0.505\n",
      "Epoch: 1320, Minibatch Loss= 0.7012, Training Accuracy= 0.505\n",
      "Epoch: 1330, Minibatch Loss= 0.7011, Training Accuracy= 0.505\n",
      "Epoch: 1340, Minibatch Loss= 0.7010, Training Accuracy= 0.506\n",
      "Epoch: 1350, Minibatch Loss= 0.7009, Training Accuracy= 0.506\n",
      "Epoch: 1360, Minibatch Loss= 0.7008, Training Accuracy= 0.507\n",
      "Epoch: 1370, Minibatch Loss= 0.7007, Training Accuracy= 0.510\n",
      "Epoch: 1380, Minibatch Loss= 0.7006, Training Accuracy= 0.510\n",
      "Epoch: 1390, Minibatch Loss= 0.7005, Training Accuracy= 0.509\n",
      "Epoch: 1400, Minibatch Loss= 0.7005, Training Accuracy= 0.509\n",
      "Epoch: 1410, Minibatch Loss= 0.7004, Training Accuracy= 0.509\n",
      "Epoch: 1420, Minibatch Loss= 0.7003, Training Accuracy= 0.508\n",
      "Epoch: 1430, Minibatch Loss= 0.7003, Training Accuracy= 0.509\n",
      "Epoch: 1440, Minibatch Loss= 0.7003, Training Accuracy= 0.507\n",
      "Epoch: 1450, Minibatch Loss= 0.7003, Training Accuracy= 0.511\n",
      "Epoch: 1460, Minibatch Loss= 0.7102, Training Accuracy= 0.510\n",
      "Epoch: 1470, Minibatch Loss= 0.7099, Training Accuracy= 0.510\n",
      "Epoch: 1480, Minibatch Loss= 0.7095, Training Accuracy= 0.510\n",
      "Epoch: 1490, Minibatch Loss= 0.7092, Training Accuracy= 0.510\n",
      "Epoch: 1500, Minibatch Loss= 0.7090, Training Accuracy= 0.510\n",
      "Epoch: 1510, Minibatch Loss= 0.7087, Training Accuracy= 0.510\n",
      "Epoch: 1520, Minibatch Loss= 0.7085, Training Accuracy= 0.510\n",
      "Epoch: 1530, Minibatch Loss= 0.7083, Training Accuracy= 0.510\n",
      "Epoch: 1540, Minibatch Loss= 0.7081, Training Accuracy= 0.510\n",
      "Epoch: 1550, Minibatch Loss= 0.7079, Training Accuracy= 0.510\n",
      "Epoch: 1560, Minibatch Loss= 0.7077, Training Accuracy= 0.510\n",
      "Epoch: 1570, Minibatch Loss= 0.7075, Training Accuracy= 0.510\n",
      "Epoch: 1580, Minibatch Loss= 0.7073, Training Accuracy= 0.510\n",
      "Epoch: 1590, Minibatch Loss= 0.7071, Training Accuracy= 0.510\n",
      "Epoch: 1600, Minibatch Loss= 0.7070, Training Accuracy= 0.510\n",
      "Epoch: 1610, Minibatch Loss= 0.7068, Training Accuracy= 0.510\n",
      "Epoch: 1620, Minibatch Loss= 0.7066, Training Accuracy= 0.510\n",
      "Epoch: 1630, Minibatch Loss= 0.7065, Training Accuracy= 0.510\n",
      "Epoch: 1640, Minibatch Loss= 0.7063, Training Accuracy= 0.510\n",
      "Epoch: 1650, Minibatch Loss= 0.7061, Training Accuracy= 0.510\n",
      "Epoch: 1660, Minibatch Loss= 0.7060, Training Accuracy= 0.510\n",
      "Epoch: 1670, Minibatch Loss= 0.7058, Training Accuracy= 0.510\n",
      "Epoch: 1680, Minibatch Loss= 0.7057, Training Accuracy= 0.510\n",
      "Epoch: 1690, Minibatch Loss= 0.7055, Training Accuracy= 0.510\n",
      "Epoch: 1700, Minibatch Loss= 0.7054, Training Accuracy= 0.510\n",
      "Epoch: 1710, Minibatch Loss= 0.7052, Training Accuracy= 0.510\n",
      "Epoch: 1720, Minibatch Loss= 0.7050, Training Accuracy= 0.510\n",
      "Epoch: 1730, Minibatch Loss= 0.7049, Training Accuracy= 0.511\n",
      "Epoch: 1740, Minibatch Loss= 0.7047, Training Accuracy= 0.511\n",
      "Epoch: 1750, Minibatch Loss= 0.7046, Training Accuracy= 0.511\n",
      "Epoch: 1760, Minibatch Loss= 0.7044, Training Accuracy= 0.511\n",
      "Epoch: 1770, Minibatch Loss= 0.7042, Training Accuracy= 0.511\n",
      "Epoch: 1780, Minibatch Loss= 0.7041, Training Accuracy= 0.511\n",
      "Epoch: 1790, Minibatch Loss= 0.7039, Training Accuracy= 0.511\n",
      "Epoch: 1800, Minibatch Loss= 0.7037, Training Accuracy= 0.511\n",
      "Epoch: 1810, Minibatch Loss= 0.7035, Training Accuracy= 0.511\n",
      "Epoch: 1820, Minibatch Loss= 0.7033, Training Accuracy= 0.511\n",
      "Epoch: 1830, Minibatch Loss= 0.7031, Training Accuracy= 0.511\n",
      "Epoch: 1840, Minibatch Loss= 0.7030, Training Accuracy= 0.511\n",
      "Epoch: 1850, Minibatch Loss= 0.7028, Training Accuracy= 0.511\n",
      "Epoch: 1860, Minibatch Loss= 0.7026, Training Accuracy= 0.511\n",
      "Epoch: 1870, Minibatch Loss= 0.7024, Training Accuracy= 0.511\n",
      "Epoch: 1880, Minibatch Loss= 0.7022, Training Accuracy= 0.511\n",
      "Epoch: 1890, Minibatch Loss= 0.7020, Training Accuracy= 0.511\n",
      "Epoch: 1900, Minibatch Loss= 0.7018, Training Accuracy= 0.511\n",
      "Epoch: 1910, Minibatch Loss= 0.7016, Training Accuracy= 0.511\n",
      "Epoch: 1920, Minibatch Loss= 0.7014, Training Accuracy= 0.511\n",
      "Epoch: 1930, Minibatch Loss= 0.7012, Training Accuracy= 0.511\n",
      "Epoch: 1940, Minibatch Loss= 0.7009, Training Accuracy= 0.511\n",
      "Epoch: 1950, Minibatch Loss= 0.7006, Training Accuracy= 0.511\n",
      "Epoch: 1960, Minibatch Loss= 0.7000, Training Accuracy= 0.511\n",
      "Epoch: 1970, Minibatch Loss= 0.6989, Training Accuracy= 0.511\n",
      "Epoch: 1980, Minibatch Loss= 0.6957, Training Accuracy= 0.513\n",
      "Epoch: 1990, Minibatch Loss= 0.0312, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 2: \n",
      "Epoch: 0, Minibatch Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 10, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 20, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 30, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 40, Minibatch Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 50, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 60, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 70, Minibatch Loss= 0.6930, Training Accuracy= 0.510\n",
      "Epoch: 80, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 90, Minibatch Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 100, Minibatch Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 110, Minibatch Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 120, Minibatch Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 130, Minibatch Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 140, Minibatch Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 150, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 160, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 170, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 180, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 190, Minibatch Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 200, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 210, Minibatch Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 220, Minibatch Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 230, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 240, Minibatch Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 250, Minibatch Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 260, Minibatch Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 270, Minibatch Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 280, Minibatch Loss= 0.6927, Training Accuracy= 0.519\n",
      "Epoch: 290, Minibatch Loss= 0.6926, Training Accuracy= 0.519\n",
      "Epoch: 300, Minibatch Loss= 0.6926, Training Accuracy= 0.520\n",
      "Epoch: 310, Minibatch Loss= 0.6926, Training Accuracy= 0.518\n",
      "Epoch: 320, Minibatch Loss= 0.6926, Training Accuracy= 0.519\n",
      "Epoch: 330, Minibatch Loss= 0.6926, Training Accuracy= 0.520\n",
      "Epoch: 340, Minibatch Loss= 0.6926, Training Accuracy= 0.519\n",
      "Epoch: 350, Minibatch Loss= 0.6926, Training Accuracy= 0.517\n",
      "Epoch: 360, Minibatch Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 370, Minibatch Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 380, Minibatch Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 390, Minibatch Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 400, Minibatch Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 410, Minibatch Loss= 0.6926, Training Accuracy= 0.510\n",
      "Epoch: 420, Minibatch Loss= 0.6926, Training Accuracy= 0.510\n",
      "Epoch: 430, Minibatch Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 440, Minibatch Loss= 0.6925, Training Accuracy= 0.511\n",
      "Epoch: 450, Minibatch Loss= 0.6925, Training Accuracy= 0.513\n",
      "Epoch: 460, Minibatch Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 470, Minibatch Loss= 0.6925, Training Accuracy= 0.513\n",
      "Epoch: 480, Minibatch Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 490, Minibatch Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 500, Minibatch Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 510, Minibatch Loss= 0.6925, Training Accuracy= 0.511\n",
      "Epoch: 520, Minibatch Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 530, Minibatch Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 540, Minibatch Loss= 0.6924, Training Accuracy= 0.512\n",
      "Epoch: 550, Minibatch Loss= 0.6923, Training Accuracy= 0.509\n",
      "Epoch: 560, Minibatch Loss= 0.6904, Training Accuracy= 0.537\n",
      "Epoch: 570, Minibatch Loss= 0.4866, Training Accuracy= 0.793\n",
      "Epoch: 580, Minibatch Loss= 0.3507, Training Accuracy= 0.823\n",
      "Epoch: 590, Minibatch Loss= 0.2471, Training Accuracy= 0.902\n",
      "Epoch: 600, Minibatch Loss= 0.2125, Training Accuracy= 0.911\n",
      "Epoch: 610, Minibatch Loss= 0.6934, Training Accuracy= 0.508\n",
      "Epoch: 620, Minibatch Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 630, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 640, Minibatch Loss= 0.6933, Training Accuracy= 0.506\n",
      "Epoch: 650, Minibatch Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 660, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 670, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 680, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 690, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 700, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 710, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 720, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 730, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 740, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 750, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 760, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 770, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 780, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 790, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 800, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 810, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 820, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 830, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 840, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 850, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 860, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 870, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 880, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 890, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 900, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 910, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 920, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 930, Minibatch Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 940, Minibatch Loss= 0.6925, Training Accuracy= 0.513\n",
      "Epoch: 950, Minibatch Loss= 0.6919, Training Accuracy= 0.508\n",
      "Epoch: 960, Minibatch Loss= 0.6910, Training Accuracy= 0.516\n",
      "Epoch: 970, Minibatch Loss= 0.6876, Training Accuracy= 0.527\n",
      "Epoch: 980, Minibatch Loss= 0.0344, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0100, Training Accuracy= 1.000\n",
      "Epoch: 1000, Minibatch Loss= 0.0058, Training Accuracy= 1.000\n",
      "Epoch: 1010, Minibatch Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 1020, Minibatch Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 1030, Minibatch Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 1040, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1050, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1060, Minibatch Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1070, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1080, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1090, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1100, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1110, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1120, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1130, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1140, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1150, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1160, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1170, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1180, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1190, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1200, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1210, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1220, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1230, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1240, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1250, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1260, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1270, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1280, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1290, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1300, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1310, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1320, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1330, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1340, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1350, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1360, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1370, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1380, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1390, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1400, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1410, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1420, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1430, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1440, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1450, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1460, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1470, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1530, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1540, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1550, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1560, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1570, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1580, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1590, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1600, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1610, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1620, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1630, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1640, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1650, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1660, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1670, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1680, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1690, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1700, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1710, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1720, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1730, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1740, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1750, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1760, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1770, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1780, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Minibatch Loss= 0.7209, Training Accuracy= 0.505\n",
      "Epoch: 10, Minibatch Loss= 0.7037, Training Accuracy= 0.505\n",
      "Epoch: 20, Minibatch Loss= 0.7013, Training Accuracy= 0.505\n",
      "Epoch: 30, Minibatch Loss= 0.7001, Training Accuracy= 0.505\n",
      "Epoch: 40, Minibatch Loss= 0.6994, Training Accuracy= 0.505\n",
      "Epoch: 50, Minibatch Loss= 0.6989, Training Accuracy= 0.505\n",
      "Epoch: 60, Minibatch Loss= 0.6985, Training Accuracy= 0.505\n",
      "Epoch: 70, Minibatch Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 80, Minibatch Loss= 0.6979, Training Accuracy= 0.505\n",
      "Epoch: 90, Minibatch Loss= 0.6977, Training Accuracy= 0.505\n",
      "Epoch: 100, Minibatch Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 110, Minibatch Loss= 0.6973, Training Accuracy= 0.505\n",
      "Epoch: 120, Minibatch Loss= 0.6972, Training Accuracy= 0.505\n",
      "Epoch: 130, Minibatch Loss= 0.6971, Training Accuracy= 0.505\n",
      "Epoch: 140, Minibatch Loss= 0.6970, Training Accuracy= 0.505\n",
      "Epoch: 150, Minibatch Loss= 0.6969, Training Accuracy= 0.505\n",
      "Epoch: 160, Minibatch Loss= 0.6968, Training Accuracy= 0.505\n",
      "Epoch: 170, Minibatch Loss= 0.6967, Training Accuracy= 0.505\n",
      "Epoch: 180, Minibatch Loss= 0.6966, Training Accuracy= 0.505\n",
      "Epoch: 190, Minibatch Loss= 0.6965, Training Accuracy= 0.505\n",
      "Epoch: 200, Minibatch Loss= 0.6965, Training Accuracy= 0.505\n",
      "Epoch: 210, Minibatch Loss= 0.6964, Training Accuracy= 0.505\n",
      "Epoch: 220, Minibatch Loss= 0.6964, Training Accuracy= 0.505\n",
      "Epoch: 230, Minibatch Loss= 0.6963, Training Accuracy= 0.505\n",
      "Epoch: 240, Minibatch Loss= 0.6963, Training Accuracy= 0.505\n",
      "Epoch: 250, Minibatch Loss= 0.6962, Training Accuracy= 0.505\n",
      "Epoch: 260, Minibatch Loss= 0.6962, Training Accuracy= 0.505\n",
      "Epoch: 270, Minibatch Loss= 0.6961, Training Accuracy= 0.505\n",
      "Epoch: 280, Minibatch Loss= 0.6961, Training Accuracy= 0.505\n",
      "Epoch: 290, Minibatch Loss= 0.6961, Training Accuracy= 0.505\n",
      "Epoch: 300, Minibatch Loss= 0.6960, Training Accuracy= 0.505\n",
      "Epoch: 310, Minibatch Loss= 0.6960, Training Accuracy= 0.505\n",
      "Epoch: 320, Minibatch Loss= 0.6960, Training Accuracy= 0.505\n",
      "Epoch: 330, Minibatch Loss= 0.6960, Training Accuracy= 0.505\n",
      "Epoch: 340, Minibatch Loss= 0.6959, Training Accuracy= 0.505\n",
      "Epoch: 350, Minibatch Loss= 0.6959, Training Accuracy= 0.505\n",
      "Epoch: 360, Minibatch Loss= 0.6959, Training Accuracy= 0.505\n",
      "Epoch: 370, Minibatch Loss= 0.6959, Training Accuracy= 0.505\n",
      "Epoch: 380, Minibatch Loss= 0.6958, Training Accuracy= 0.505\n",
      "Epoch: 390, Minibatch Loss= 0.6958, Training Accuracy= 0.505\n",
      "Epoch: 400, Minibatch Loss= 0.6958, Training Accuracy= 0.505\n",
      "Epoch: 410, Minibatch Loss= 0.6958, Training Accuracy= 0.505\n",
      "Epoch: 420, Minibatch Loss= 0.6958, Training Accuracy= 0.505\n",
      "Epoch: 430, Minibatch Loss= 0.6957, Training Accuracy= 0.505\n",
      "Epoch: 440, Minibatch Loss= 0.6957, Training Accuracy= 0.505\n",
      "Epoch: 450, Minibatch Loss= 0.6957, Training Accuracy= 0.505\n",
      "Epoch: 460, Minibatch Loss= 0.6957, Training Accuracy= 0.505\n",
      "Epoch: 470, Minibatch Loss= 0.6957, Training Accuracy= 0.505\n",
      "Epoch: 480, Minibatch Loss= 0.6957, Training Accuracy= 0.505\n",
      "Epoch: 490, Minibatch Loss= 0.6956, Training Accuracy= 0.505\n",
      "Epoch: 500, Minibatch Loss= 0.6956, Training Accuracy= 0.505\n",
      "Epoch: 510, Minibatch Loss= 0.6956, Training Accuracy= 0.505\n",
      "Epoch: 520, Minibatch Loss= 0.6956, Training Accuracy= 0.505\n",
      "Epoch: 530, Minibatch Loss= 0.6956, Training Accuracy= 0.505\n",
      "Epoch: 540, Minibatch Loss= 0.6956, Training Accuracy= 0.505\n",
      "Epoch: 550, Minibatch Loss= 0.6956, Training Accuracy= 0.505\n",
      "Epoch: 560, Minibatch Loss= 0.6956, Training Accuracy= 0.505\n",
      "Epoch: 570, Minibatch Loss= 0.6956, Training Accuracy= 0.505\n",
      "Epoch: 580, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 590, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 600, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 610, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 620, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 630, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 640, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 650, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 660, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 670, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 680, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 690, Minibatch Loss= 0.6955, Training Accuracy= 0.505\n",
      "Epoch: 700, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 710, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 720, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 730, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 740, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 750, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 760, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 770, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 780, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 790, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 800, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 810, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 820, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 830, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 840, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 850, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 860, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 870, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 880, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 890, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 900, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 910, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 920, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 930, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 940, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 950, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 960, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 970, Minibatch Loss= 0.6954, Training Accuracy= 0.505\n",
      "Epoch: 980, Minibatch Loss= 0.6954, Training Accuracy= 0.504\n",
      "Epoch: 990, Minibatch Loss= 0.6954, Training Accuracy= 0.504\n",
      "Epoch: 1000, Minibatch Loss= 0.6954, Training Accuracy= 0.504\n",
      "Epoch: 1010, Minibatch Loss= 0.6954, Training Accuracy= 0.506\n",
      "Epoch: 1020, Minibatch Loss= 0.6954, Training Accuracy= 0.507\n",
      "Epoch: 1030, Minibatch Loss= 0.6954, Training Accuracy= 0.508\n",
      "Epoch: 1040, Minibatch Loss= 0.6946, Training Accuracy= 0.505\n",
      "Epoch: 1050, Minibatch Loss= 0.6876, Training Accuracy= 0.544\n",
      "Epoch: 1060, Minibatch Loss= 0.7113, Training Accuracy= 0.508\n",
      "Epoch: 1070, Minibatch Loss= 0.7005, Training Accuracy= 0.520\n",
      "Epoch: 1080, Minibatch Loss= 0.6985, Training Accuracy= 0.521\n",
      "Epoch: 1090, Minibatch Loss= 0.6967, Training Accuracy= 0.521\n",
      "Epoch: 1100, Minibatch Loss= 0.6946, Training Accuracy= 0.522\n",
      "Epoch: 1110, Minibatch Loss= 0.7095, Training Accuracy= 0.505\n",
      "Epoch: 1120, Minibatch Loss= 0.7085, Training Accuracy= 0.505\n",
      "Epoch: 1130, Minibatch Loss= 0.7077, Training Accuracy= 0.505\n",
      "Epoch: 1140, Minibatch Loss= 0.7069, Training Accuracy= 0.505\n",
      "Epoch: 1150, Minibatch Loss= 0.7062, Training Accuracy= 0.505\n",
      "Epoch: 1160, Minibatch Loss= 0.7056, Training Accuracy= 0.505\n",
      "Epoch: 1170, Minibatch Loss= 0.7050, Training Accuracy= 0.505\n",
      "Epoch: 1180, Minibatch Loss= 0.7045, Training Accuracy= 0.505\n",
      "Epoch: 1190, Minibatch Loss= 0.7040, Training Accuracy= 0.505\n",
      "Epoch: 1200, Minibatch Loss= 0.7035, Training Accuracy= 0.505\n",
      "Epoch: 1210, Minibatch Loss= 0.7030, Training Accuracy= 0.505\n",
      "Epoch: 1220, Minibatch Loss= 0.7026, Training Accuracy= 0.505\n",
      "Epoch: 1230, Minibatch Loss= 0.7022, Training Accuracy= 0.505\n",
      "Epoch: 1240, Minibatch Loss= 0.7019, Training Accuracy= 0.505\n",
      "Epoch: 1250, Minibatch Loss= 0.7016, Training Accuracy= 0.505\n",
      "Epoch: 1260, Minibatch Loss= 0.7013, Training Accuracy= 0.505\n",
      "Epoch: 1270, Minibatch Loss= 0.7011, Training Accuracy= 0.505\n",
      "Epoch: 1280, Minibatch Loss= 0.7010, Training Accuracy= 0.505\n",
      "Epoch: 1290, Minibatch Loss= 0.7009, Training Accuracy= 0.505\n",
      "Epoch: 1300, Minibatch Loss= 0.7008, Training Accuracy= 0.505\n",
      "Epoch: 1310, Minibatch Loss= 0.7007, Training Accuracy= 0.505\n",
      "Epoch: 1320, Minibatch Loss= 0.7007, Training Accuracy= 0.505\n",
      "Epoch: 1330, Minibatch Loss= 0.7006, Training Accuracy= 0.505\n",
      "Epoch: 1340, Minibatch Loss= 0.7005, Training Accuracy= 0.505\n",
      "Epoch: 1350, Minibatch Loss= 0.7004, Training Accuracy= 0.505\n",
      "Epoch: 1360, Minibatch Loss= 0.7003, Training Accuracy= 0.505\n",
      "Epoch: 1370, Minibatch Loss= 0.7002, Training Accuracy= 0.505\n",
      "Epoch: 1380, Minibatch Loss= 0.7001, Training Accuracy= 0.505\n",
      "Epoch: 1390, Minibatch Loss= 0.7000, Training Accuracy= 0.505\n",
      "Epoch: 1400, Minibatch Loss= 0.6999, Training Accuracy= 0.505\n",
      "Epoch: 1410, Minibatch Loss= 0.6998, Training Accuracy= 0.505\n",
      "Epoch: 1420, Minibatch Loss= 0.6997, Training Accuracy= 0.505\n",
      "Epoch: 1430, Minibatch Loss= 0.6996, Training Accuracy= 0.505\n",
      "Epoch: 1440, Minibatch Loss= 0.6995, Training Accuracy= 0.505\n",
      "Epoch: 1450, Minibatch Loss= 0.6994, Training Accuracy= 0.505\n",
      "Epoch: 1460, Minibatch Loss= 0.6994, Training Accuracy= 0.505\n",
      "Epoch: 1470, Minibatch Loss= 0.6993, Training Accuracy= 0.505\n",
      "Epoch: 1480, Minibatch Loss= 0.6992, Training Accuracy= 0.505\n",
      "Epoch: 1490, Minibatch Loss= 0.6991, Training Accuracy= 0.505\n",
      "Epoch: 1500, Minibatch Loss= 0.6990, Training Accuracy= 0.505\n",
      "Epoch: 1510, Minibatch Loss= 0.6989, Training Accuracy= 0.505\n",
      "Epoch: 1520, Minibatch Loss= 0.6988, Training Accuracy= 0.505\n",
      "Epoch: 1530, Minibatch Loss= 0.6987, Training Accuracy= 0.505\n",
      "Epoch: 1540, Minibatch Loss= 0.6986, Training Accuracy= 0.505\n",
      "Epoch: 1550, Minibatch Loss= 0.6985, Training Accuracy= 0.505\n",
      "Epoch: 1560, Minibatch Loss= 0.6984, Training Accuracy= 0.504\n",
      "Epoch: 1570, Minibatch Loss= 0.6983, Training Accuracy= 0.506\n",
      "Epoch: 1580, Minibatch Loss= 0.6982, Training Accuracy= 0.506\n",
      "Epoch: 1590, Minibatch Loss= 0.6981, Training Accuracy= 0.505\n",
      "Epoch: 1600, Minibatch Loss= 0.6980, Training Accuracy= 0.505\n",
      "Epoch: 1610, Minibatch Loss= 0.6979, Training Accuracy= 0.506\n",
      "Epoch: 1620, Minibatch Loss= 0.6978, Training Accuracy= 0.506\n",
      "Epoch: 1630, Minibatch Loss= 0.6977, Training Accuracy= 0.506\n",
      "Epoch: 1640, Minibatch Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 1650, Minibatch Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 1660, Minibatch Loss= 0.6974, Training Accuracy= 0.506\n",
      "Epoch: 1670, Minibatch Loss= 0.6973, Training Accuracy= 0.506\n",
      "Epoch: 1680, Minibatch Loss= 0.6971, Training Accuracy= 0.506\n",
      "Epoch: 1690, Minibatch Loss= 0.6970, Training Accuracy= 0.505\n",
      "Epoch: 1700, Minibatch Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 1710, Minibatch Loss= 0.6968, Training Accuracy= 0.510\n",
      "Epoch: 1720, Minibatch Loss= 0.6967, Training Accuracy= 0.511\n",
      "Epoch: 1730, Minibatch Loss= 0.6966, Training Accuracy= 0.511\n",
      "Epoch: 1740, Minibatch Loss= 0.6965, Training Accuracy= 0.511\n",
      "Epoch: 1750, Minibatch Loss= 0.6964, Training Accuracy= 0.512\n",
      "Epoch: 1760, Minibatch Loss= 0.6963, Training Accuracy= 0.512\n",
      "Epoch: 1770, Minibatch Loss= 0.6962, Training Accuracy= 0.511\n",
      "Epoch: 1780, Minibatch Loss= 0.6961, Training Accuracy= 0.513\n",
      "Epoch: 1790, Minibatch Loss= 0.6959, Training Accuracy= 0.513\n",
      "Epoch: 1800, Minibatch Loss= 0.6958, Training Accuracy= 0.512\n",
      "Epoch: 1810, Minibatch Loss= 0.6956, Training Accuracy= 0.511\n",
      "Epoch: 1820, Minibatch Loss= 0.6954, Training Accuracy= 0.510\n",
      "Epoch: 1830, Minibatch Loss= 0.6952, Training Accuracy= 0.509\n",
      "Epoch: 1840, Minibatch Loss= 0.6949, Training Accuracy= 0.507\n",
      "Epoch: 1850, Minibatch Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 1860, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 1870, Minibatch Loss= 0.6887, Training Accuracy= 0.525\n",
      "Epoch: 1880, Minibatch Loss= 0.6787, Training Accuracy= 0.545\n",
      "Epoch: 1890, Minibatch Loss= 0.5371, Training Accuracy= 0.707\n",
      "Epoch: 1900, Minibatch Loss= 0.7163, Training Accuracy= 0.508\n",
      "Epoch: 1910, Minibatch Loss= 0.7067, Training Accuracy= 0.515\n",
      "Epoch: 1920, Minibatch Loss= 0.7083, Training Accuracy= 0.505\n",
      "Epoch: 1930, Minibatch Loss= 0.7042, Training Accuracy= 0.492\n",
      "Epoch: 1940, Minibatch Loss= 0.6901, Training Accuracy= 0.485\n",
      "Epoch: 1950, Minibatch Loss= 0.6264, Training Accuracy= 0.596\n",
      "Epoch: 1960, Minibatch Loss= 0.6402, Training Accuracy= 0.630\n",
      "Epoch: 1970, Minibatch Loss= 0.6654, Training Accuracy= 0.585\n",
      "Epoch: 1980, Minibatch Loss= 0.6093, Training Accuracy= 0.644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1990, Minibatch Loss= 0.5399, Training Accuracy= 0.702\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5593\n",
      "Replication: 4: \n",
      "Epoch: 0, Minibatch Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 10, Minibatch Loss= 0.6933, Training Accuracy= 0.488\n",
      "Epoch: 20, Minibatch Loss= 0.6932, Training Accuracy= 0.485\n",
      "Epoch: 30, Minibatch Loss= 0.6931, Training Accuracy= 0.471\n",
      "Epoch: 40, Minibatch Loss= 0.6931, Training Accuracy= 0.478\n",
      "Epoch: 50, Minibatch Loss= 0.6931, Training Accuracy= 0.482\n",
      "Epoch: 60, Minibatch Loss= 0.6931, Training Accuracy= 0.481\n",
      "Epoch: 70, Minibatch Loss= 0.6930, Training Accuracy= 0.486\n",
      "Epoch: 80, Minibatch Loss= 0.6930, Training Accuracy= 0.489\n",
      "Epoch: 90, Minibatch Loss= 0.6930, Training Accuracy= 0.491\n",
      "Epoch: 100, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 110, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 120, Minibatch Loss= 0.6930, Training Accuracy= 0.510\n",
      "Epoch: 130, Minibatch Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 140, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 150, Minibatch Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 160, Minibatch Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 170, Minibatch Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 180, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 190, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 200, Minibatch Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 210, Minibatch Loss= 0.6930, Training Accuracy= 0.495\n",
      "Epoch: 220, Minibatch Loss= 0.6930, Training Accuracy= 0.492\n",
      "Epoch: 230, Minibatch Loss= 0.6930, Training Accuracy= 0.494\n",
      "Epoch: 240, Minibatch Loss= 0.6930, Training Accuracy= 0.493\n",
      "Epoch: 250, Minibatch Loss= 0.6930, Training Accuracy= 0.490\n",
      "Epoch: 260, Minibatch Loss= 0.6930, Training Accuracy= 0.486\n",
      "Epoch: 270, Minibatch Loss= 0.6930, Training Accuracy= 0.486\n",
      "Epoch: 280, Minibatch Loss= 0.6930, Training Accuracy= 0.486\n",
      "Epoch: 290, Minibatch Loss= 0.6930, Training Accuracy= 0.486\n",
      "Epoch: 300, Minibatch Loss= 0.6930, Training Accuracy= 0.485\n",
      "Epoch: 310, Minibatch Loss= 0.6930, Training Accuracy= 0.486\n",
      "Epoch: 320, Minibatch Loss= 0.6930, Training Accuracy= 0.488\n",
      "Epoch: 330, Minibatch Loss= 0.6930, Training Accuracy= 0.488\n",
      "Epoch: 340, Minibatch Loss= 0.6930, Training Accuracy= 0.488\n",
      "Epoch: 350, Minibatch Loss= 0.6930, Training Accuracy= 0.490\n",
      "Epoch: 360, Minibatch Loss= 0.6930, Training Accuracy= 0.489\n",
      "Epoch: 370, Minibatch Loss= 0.6930, Training Accuracy= 0.489\n",
      "Epoch: 380, Minibatch Loss= 0.6930, Training Accuracy= 0.488\n",
      "Epoch: 390, Minibatch Loss= 0.6930, Training Accuracy= 0.488\n",
      "Epoch: 400, Minibatch Loss= 0.6930, Training Accuracy= 0.488\n",
      "Epoch: 410, Minibatch Loss= 0.6930, Training Accuracy= 0.491\n",
      "Epoch: 420, Minibatch Loss= 0.6930, Training Accuracy= 0.491\n",
      "Epoch: 430, Minibatch Loss= 0.6930, Training Accuracy= 0.493\n",
      "Epoch: 440, Minibatch Loss= 0.6930, Training Accuracy= 0.493\n",
      "Epoch: 450, Minibatch Loss= 0.6930, Training Accuracy= 0.492\n",
      "Epoch: 460, Minibatch Loss= 0.6930, Training Accuracy= 0.494\n",
      "Epoch: 470, Minibatch Loss= 0.6930, Training Accuracy= 0.495\n",
      "Epoch: 480, Minibatch Loss= 0.6930, Training Accuracy= 0.493\n",
      "Epoch: 490, Minibatch Loss= 0.6930, Training Accuracy= 0.493\n",
      "Epoch: 500, Minibatch Loss= 0.6930, Training Accuracy= 0.496\n",
      "Epoch: 510, Minibatch Loss= 0.6930, Training Accuracy= 0.497\n",
      "Epoch: 520, Minibatch Loss= 0.6930, Training Accuracy= 0.496\n",
      "Epoch: 530, Minibatch Loss= 0.6930, Training Accuracy= 0.497\n",
      "Epoch: 540, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 550, Minibatch Loss= 0.6930, Training Accuracy= 0.500\n",
      "Epoch: 560, Minibatch Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 570, Minibatch Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 580, Minibatch Loss= 0.6929, Training Accuracy= 0.498\n",
      "Epoch: 590, Minibatch Loss= 0.6929, Training Accuracy= 0.497\n",
      "Epoch: 600, Minibatch Loss= 0.6929, Training Accuracy= 0.499\n",
      "Epoch: 610, Minibatch Loss= 0.6929, Training Accuracy= 0.500\n",
      "Epoch: 620, Minibatch Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 630, Minibatch Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 640, Minibatch Loss= 0.6929, Training Accuracy= 0.503\n",
      "Epoch: 650, Minibatch Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 660, Minibatch Loss= 0.6929, Training Accuracy= 0.503\n",
      "Epoch: 670, Minibatch Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 680, Minibatch Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 690, Minibatch Loss= 0.6929, Training Accuracy= 0.503\n",
      "Epoch: 700, Minibatch Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 710, Minibatch Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 720, Minibatch Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 730, Minibatch Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 740, Minibatch Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 750, Minibatch Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 760, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 770, Minibatch Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 780, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 790, Minibatch Loss= 0.6929, Training Accuracy= 0.515\n",
      "Epoch: 800, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 810, Minibatch Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 820, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 830, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 840, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 850, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 860, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 870, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 880, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 890, Minibatch Loss= 0.6929, Training Accuracy= 0.515\n",
      "Epoch: 900, Minibatch Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 910, Minibatch Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 920, Minibatch Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 930, Minibatch Loss= 0.6928, Training Accuracy= 0.522\n",
      "Epoch: 940, Minibatch Loss= 0.6928, Training Accuracy= 0.521\n",
      "Epoch: 950, Minibatch Loss= 0.6928, Training Accuracy= 0.526\n",
      "Epoch: 960, Minibatch Loss= 0.6928, Training Accuracy= 0.527\n",
      "Epoch: 970, Minibatch Loss= 0.6928, Training Accuracy= 0.522\n",
      "Epoch: 980, Minibatch Loss= 0.6928, Training Accuracy= 0.527\n",
      "Epoch: 990, Minibatch Loss= 0.6928, Training Accuracy= 0.529\n",
      "Epoch: 1000, Minibatch Loss= 0.6928, Training Accuracy= 0.526\n",
      "Epoch: 1010, Minibatch Loss= 0.6928, Training Accuracy= 0.525\n",
      "Epoch: 1020, Minibatch Loss= 0.6927, Training Accuracy= 0.527\n",
      "Epoch: 1030, Minibatch Loss= 0.6927, Training Accuracy= 0.528\n",
      "Epoch: 1040, Minibatch Loss= 0.6927, Training Accuracy= 0.528\n",
      "Epoch: 1050, Minibatch Loss= 0.6927, Training Accuracy= 0.526\n",
      "Epoch: 1060, Minibatch Loss= 0.6927, Training Accuracy= 0.524\n",
      "Epoch: 1070, Minibatch Loss= 0.6927, Training Accuracy= 0.521\n",
      "Epoch: 1080, Minibatch Loss= 0.6926, Training Accuracy= 0.518\n",
      "Epoch: 1090, Minibatch Loss= 0.6926, Training Accuracy= 0.517\n",
      "Epoch: 1100, Minibatch Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 1110, Minibatch Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 1120, Minibatch Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 1130, Minibatch Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 1140, Minibatch Loss= 0.6926, Training Accuracy= 0.517\n",
      "Epoch: 1150, Minibatch Loss= 0.6925, Training Accuracy= 0.518\n",
      "Epoch: 1160, Minibatch Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 1170, Minibatch Loss= 0.6925, Training Accuracy= 0.511\n",
      "Epoch: 1180, Minibatch Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 1190, Minibatch Loss= 0.6925, Training Accuracy= 0.511\n",
      "Epoch: 1200, Minibatch Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 1210, Minibatch Loss= 0.6924, Training Accuracy= 0.510\n",
      "Epoch: 1220, Minibatch Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 1230, Minibatch Loss= 0.6924, Training Accuracy= 0.523\n",
      "Epoch: 1240, Minibatch Loss= 0.6924, Training Accuracy= 0.525\n",
      "Epoch: 1250, Minibatch Loss= 0.6924, Training Accuracy= 0.527\n",
      "Epoch: 1260, Minibatch Loss= 0.6924, Training Accuracy= 0.525\n",
      "Epoch: 1270, Minibatch Loss= 0.6923, Training Accuracy= 0.522\n",
      "Epoch: 1280, Minibatch Loss= 0.6923, Training Accuracy= 0.522\n",
      "Epoch: 1290, Minibatch Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 1300, Minibatch Loss= 0.6919, Training Accuracy= 0.529\n",
      "Epoch: 1310, Minibatch Loss= 0.6784, Training Accuracy= 0.555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1320, Minibatch Loss= 0.4820, Training Accuracy= 0.772\n",
      "Epoch: 1330, Minibatch Loss= 0.3725, Training Accuracy= 0.814\n",
      "Epoch: 1340, Minibatch Loss= 0.2008, Training Accuracy= 0.939\n",
      "Epoch: 1350, Minibatch Loss= 0.1968, Training Accuracy= 0.924\n",
      "Epoch: 1360, Minibatch Loss= 0.0671, Training Accuracy= 0.982\n",
      "Epoch: 1370, Minibatch Loss= 0.1531, Training Accuracy= 0.924\n",
      "Epoch: 1380, Minibatch Loss= 0.1161, Training Accuracy= 0.952\n",
      "Epoch: 1390, Minibatch Loss= 0.0993, Training Accuracy= 0.964\n",
      "Epoch: 1400, Minibatch Loss= 0.0817, Training Accuracy= 0.966\n",
      "Epoch: 1410, Minibatch Loss= 0.0661, Training Accuracy= 0.973\n",
      "Epoch: 1420, Minibatch Loss= 0.0553, Training Accuracy= 0.982\n",
      "Epoch: 1430, Minibatch Loss= 0.0787, Training Accuracy= 0.970\n",
      "Epoch: 1440, Minibatch Loss= 0.6931, Training Accuracy= 0.523\n",
      "Epoch: 1450, Minibatch Loss= 0.6930, Training Accuracy= 0.479\n",
      "Epoch: 1460, Minibatch Loss= 0.6930, Training Accuracy= 0.474\n",
      "Epoch: 1470, Minibatch Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 1480, Minibatch Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 1490, Minibatch Loss= 0.6929, Training Accuracy= 0.521\n",
      "Epoch: 1500, Minibatch Loss= 0.6929, Training Accuracy= 0.534\n",
      "Epoch: 1510, Minibatch Loss= 0.6929, Training Accuracy= 0.539\n",
      "Epoch: 1520, Minibatch Loss= 0.6929, Training Accuracy= 0.544\n",
      "Epoch: 1530, Minibatch Loss= 0.6929, Training Accuracy= 0.530\n",
      "Epoch: 1540, Minibatch Loss= 0.6929, Training Accuracy= 0.525\n",
      "Epoch: 1550, Minibatch Loss= 0.6928, Training Accuracy= 0.526\n",
      "Epoch: 1560, Minibatch Loss= 0.6928, Training Accuracy= 0.526\n",
      "Epoch: 1570, Minibatch Loss= 0.6928, Training Accuracy= 0.524\n",
      "Epoch: 1580, Minibatch Loss= 0.6928, Training Accuracy= 0.523\n",
      "Epoch: 1590, Minibatch Loss= 0.6928, Training Accuracy= 0.522\n",
      "Epoch: 1600, Minibatch Loss= 0.6928, Training Accuracy= 0.521\n",
      "Epoch: 1610, Minibatch Loss= 0.6928, Training Accuracy= 0.521\n",
      "Epoch: 1620, Minibatch Loss= 0.6928, Training Accuracy= 0.524\n",
      "Epoch: 1630, Minibatch Loss= 0.6928, Training Accuracy= 0.526\n",
      "Epoch: 1640, Minibatch Loss= 0.6928, Training Accuracy= 0.530\n",
      "Epoch: 1650, Minibatch Loss= 0.6928, Training Accuracy= 0.535\n",
      "Epoch: 1660, Minibatch Loss= 0.6928, Training Accuracy= 0.540\n",
      "Epoch: 1670, Minibatch Loss= 0.6928, Training Accuracy= 0.546\n",
      "Epoch: 1680, Minibatch Loss= 0.6928, Training Accuracy= 0.546\n",
      "Epoch: 1690, Minibatch Loss= 0.6928, Training Accuracy= 0.543\n",
      "Epoch: 1700, Minibatch Loss= 0.6928, Training Accuracy= 0.544\n",
      "Epoch: 1710, Minibatch Loss= 0.6927, Training Accuracy= 0.543\n",
      "Epoch: 1720, Minibatch Loss= 0.6927, Training Accuracy= 0.543\n",
      "Epoch: 1730, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1740, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1750, Minibatch Loss= 0.6927, Training Accuracy= 0.540\n",
      "Epoch: 1760, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1770, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1780, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1790, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1800, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1810, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1820, Minibatch Loss= 0.6927, Training Accuracy= 0.540\n",
      "Epoch: 1830, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1840, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1850, Minibatch Loss= 0.6927, Training Accuracy= 0.540\n",
      "Epoch: 1860, Minibatch Loss= 0.6927, Training Accuracy= 0.540\n",
      "Epoch: 1870, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1880, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1890, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1900, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1910, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1920, Minibatch Loss= 0.6927, Training Accuracy= 0.541\n",
      "Epoch: 1930, Minibatch Loss= 0.6927, Training Accuracy= 0.543\n",
      "Epoch: 1940, Minibatch Loss= 0.6927, Training Accuracy= 0.544\n",
      "Epoch: 1950, Minibatch Loss= 0.6926, Training Accuracy= 0.546\n",
      "Epoch: 1960, Minibatch Loss= 0.6926, Training Accuracy= 0.546\n",
      "Epoch: 1970, Minibatch Loss= 0.6926, Training Accuracy= 0.549\n",
      "Epoch: 1980, Minibatch Loss= 0.6926, Training Accuracy= 0.551\n",
      "Epoch: 1990, Minibatch Loss= 0.6926, Training Accuracy= 0.553\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5438\n",
      "Replication: 5: \n",
      "Epoch: 0, Minibatch Loss= 0.7507, Training Accuracy= 0.500\n",
      "Epoch: 10, Minibatch Loss= 0.7082, Training Accuracy= 0.500\n",
      "Epoch: 20, Minibatch Loss= 0.7042, Training Accuracy= 0.500\n",
      "Epoch: 30, Minibatch Loss= 0.7025, Training Accuracy= 0.500\n",
      "Epoch: 40, Minibatch Loss= 0.7014, Training Accuracy= 0.500\n",
      "Epoch: 50, Minibatch Loss= 0.7007, Training Accuracy= 0.500\n",
      "Epoch: 60, Minibatch Loss= 0.7001, Training Accuracy= 0.500\n",
      "Epoch: 70, Minibatch Loss= 0.6996, Training Accuracy= 0.500\n",
      "Epoch: 80, Minibatch Loss= 0.6993, Training Accuracy= 0.500\n",
      "Epoch: 90, Minibatch Loss= 0.6989, Training Accuracy= 0.500\n",
      "Epoch: 100, Minibatch Loss= 0.6987, Training Accuracy= 0.500\n",
      "Epoch: 110, Minibatch Loss= 0.6984, Training Accuracy= 0.500\n",
      "Epoch: 120, Minibatch Loss= 0.6982, Training Accuracy= 0.500\n",
      "Epoch: 130, Minibatch Loss= 0.6980, Training Accuracy= 0.500\n",
      "Epoch: 140, Minibatch Loss= 0.6979, Training Accuracy= 0.500\n",
      "Epoch: 150, Minibatch Loss= 0.6977, Training Accuracy= 0.500\n",
      "Epoch: 160, Minibatch Loss= 0.6976, Training Accuracy= 0.500\n",
      "Epoch: 170, Minibatch Loss= 0.6975, Training Accuracy= 0.500\n",
      "Epoch: 180, Minibatch Loss= 0.6974, Training Accuracy= 0.500\n",
      "Epoch: 190, Minibatch Loss= 0.6973, Training Accuracy= 0.500\n",
      "Epoch: 200, Minibatch Loss= 0.6972, Training Accuracy= 0.500\n",
      "Epoch: 210, Minibatch Loss= 0.6972, Training Accuracy= 0.500\n",
      "Epoch: 220, Minibatch Loss= 0.6971, Training Accuracy= 0.500\n",
      "Epoch: 230, Minibatch Loss= 0.6971, Training Accuracy= 0.500\n",
      "Epoch: 240, Minibatch Loss= 0.6970, Training Accuracy= 0.500\n",
      "Epoch: 250, Minibatch Loss= 0.6970, Training Accuracy= 0.500\n",
      "Epoch: 260, Minibatch Loss= 0.6969, Training Accuracy= 0.500\n",
      "Epoch: 270, Minibatch Loss= 0.6969, Training Accuracy= 0.500\n",
      "Epoch: 280, Minibatch Loss= 0.6969, Training Accuracy= 0.500\n",
      "Epoch: 290, Minibatch Loss= 0.6968, Training Accuracy= 0.500\n",
      "Epoch: 300, Minibatch Loss= 0.6968, Training Accuracy= 0.500\n",
      "Epoch: 310, Minibatch Loss= 0.6968, Training Accuracy= 0.500\n",
      "Epoch: 320, Minibatch Loss= 0.6968, Training Accuracy= 0.500\n",
      "Epoch: 330, Minibatch Loss= 0.6967, Training Accuracy= 0.500\n",
      "Epoch: 340, Minibatch Loss= 0.6967, Training Accuracy= 0.500\n",
      "Epoch: 350, Minibatch Loss= 0.6967, Training Accuracy= 0.500\n",
      "Epoch: 360, Minibatch Loss= 0.6967, Training Accuracy= 0.500\n",
      "Epoch: 370, Minibatch Loss= 0.6967, Training Accuracy= 0.500\n",
      "Epoch: 380, Minibatch Loss= 0.6967, Training Accuracy= 0.500\n",
      "Epoch: 390, Minibatch Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 400, Minibatch Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 410, Minibatch Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 420, Minibatch Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 430, Minibatch Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 440, Minibatch Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 450, Minibatch Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 460, Minibatch Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 470, Minibatch Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 480, Minibatch Loss= 0.6966, Training Accuracy= 0.500\n",
      "Epoch: 490, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 500, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 510, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 520, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 530, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 540, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 550, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 560, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 570, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 580, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 590, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 600, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 610, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 620, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 630, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 640, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 650, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 660, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 670, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 680, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 690, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 700, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 710, Minibatch Loss= 0.6965, Training Accuracy= 0.500\n",
      "Epoch: 720, Minibatch Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 730, Minibatch Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 740, Minibatch Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 750, Minibatch Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 760, Minibatch Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 770, Minibatch Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 780, Minibatch Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 790, Minibatch Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 800, Minibatch Loss= 0.6969, Training Accuracy= 0.500\n",
      "Epoch: 810, Minibatch Loss= 0.7059, Training Accuracy= 0.545\n",
      "Epoch: 820, Minibatch Loss= 0.7145, Training Accuracy= 0.510\n",
      "Epoch: 830, Minibatch Loss= 0.3100, Training Accuracy= 0.821\n",
      "Epoch: 840, Minibatch Loss= 0.2399, Training Accuracy= 0.864\n",
      "Epoch: 850, Minibatch Loss= 0.1661, Training Accuracy= 0.924\n",
      "Epoch: 860, Minibatch Loss= 0.1216, Training Accuracy= 0.946\n",
      "Epoch: 870, Minibatch Loss= 0.1034, Training Accuracy= 0.953\n",
      "Epoch: 880, Minibatch Loss= 0.1012, Training Accuracy= 0.952\n",
      "Epoch: 890, Minibatch Loss= 0.1016, Training Accuracy= 0.942\n",
      "Epoch: 900, Minibatch Loss= 0.1012, Training Accuracy= 0.944\n",
      "Epoch: 910, Minibatch Loss= 0.0982, Training Accuracy= 0.948\n",
      "Epoch: 920, Minibatch Loss= 0.0916, Training Accuracy= 0.960\n",
      "Epoch: 930, Minibatch Loss= 0.0826, Training Accuracy= 0.967\n",
      "Epoch: 940, Minibatch Loss= 0.0728, Training Accuracy= 0.975\n",
      "Epoch: 950, Minibatch Loss= 0.0624, Training Accuracy= 0.976\n",
      "Epoch: 960, Minibatch Loss= 0.0508, Training Accuracy= 0.984\n",
      "Epoch: 970, Minibatch Loss= 0.0388, Training Accuracy= 0.987\n",
      "Epoch: 980, Minibatch Loss= 0.0296, Training Accuracy= 0.988\n",
      "Epoch: 990, Minibatch Loss= 0.0240, Training Accuracy= 0.995\n",
      "Epoch: 1000, Minibatch Loss= 0.0204, Training Accuracy= 0.997\n",
      "Epoch: 1010, Minibatch Loss= 0.0179, Training Accuracy= 0.997\n",
      "Epoch: 1020, Minibatch Loss= 0.0163, Training Accuracy= 0.997\n",
      "Epoch: 1030, Minibatch Loss= 0.0157, Training Accuracy= 0.997\n",
      "Epoch: 1040, Minibatch Loss= 0.0143, Training Accuracy= 0.997\n",
      "Epoch: 1050, Minibatch Loss= 0.0132, Training Accuracy= 0.997\n",
      "Epoch: 1060, Minibatch Loss= 0.0123, Training Accuracy= 0.997\n",
      "Epoch: 1070, Minibatch Loss= 0.0115, Training Accuracy= 0.997\n",
      "Epoch: 1080, Minibatch Loss= 0.0109, Training Accuracy= 0.997\n",
      "Epoch: 1090, Minibatch Loss= 0.0103, Training Accuracy= 0.997\n",
      "Epoch: 1100, Minibatch Loss= 0.0099, Training Accuracy= 0.997\n",
      "Epoch: 1110, Minibatch Loss= 0.0094, Training Accuracy= 0.997\n",
      "Epoch: 1120, Minibatch Loss= 0.0090, Training Accuracy= 0.998\n",
      "Epoch: 1130, Minibatch Loss= 0.0086, Training Accuracy= 0.998\n",
      "Epoch: 1140, Minibatch Loss= 0.0083, Training Accuracy= 0.998\n",
      "Epoch: 1150, Minibatch Loss= 0.0080, Training Accuracy= 0.998\n",
      "Epoch: 1160, Minibatch Loss= 0.0077, Training Accuracy= 0.998\n",
      "Epoch: 1170, Minibatch Loss= 0.0075, Training Accuracy= 0.998\n",
      "Epoch: 1180, Minibatch Loss= 0.0072, Training Accuracy= 0.999\n",
      "Epoch: 1190, Minibatch Loss= 0.0070, Training Accuracy= 0.999\n",
      "Epoch: 1200, Minibatch Loss= 0.0067, Training Accuracy= 0.999\n",
      "Epoch: 1210, Minibatch Loss= 0.0065, Training Accuracy= 0.999\n",
      "Epoch: 1220, Minibatch Loss= 0.0063, Training Accuracy= 0.999\n",
      "Epoch: 1230, Minibatch Loss= 0.0060, Training Accuracy= 0.999\n",
      "Epoch: 1240, Minibatch Loss= 0.0058, Training Accuracy= 0.999\n",
      "Epoch: 1250, Minibatch Loss= 0.0055, Training Accuracy= 0.999\n",
      "Epoch: 1260, Minibatch Loss= 0.0053, Training Accuracy= 0.999\n",
      "Epoch: 1270, Minibatch Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 1280, Minibatch Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 1290, Minibatch Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 1300, Minibatch Loss= 0.0041, Training Accuracy= 0.999\n",
      "Epoch: 1310, Minibatch Loss= 0.0039, Training Accuracy= 0.999\n",
      "Epoch: 1320, Minibatch Loss= 0.0036, Training Accuracy= 0.999\n",
      "Epoch: 1330, Minibatch Loss= 0.0034, Training Accuracy= 0.999\n",
      "Epoch: 1340, Minibatch Loss= 0.0031, Training Accuracy= 0.999\n",
      "Epoch: 1350, Minibatch Loss= 0.0029, Training Accuracy= 0.999\n",
      "Epoch: 1360, Minibatch Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 1370, Minibatch Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 1380, Minibatch Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 1390, Minibatch Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 1400, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1410, Minibatch Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 1420, Minibatch Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 1430, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1440, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1450, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1460, Minibatch Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1470, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1480, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1490, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1500, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1510, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1520, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1530, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1540, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1550, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1560, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1570, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1580, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1590, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1600, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1610, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1620, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1630, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1640, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1650, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1660, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1670, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1680, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1690, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1700, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1710, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1720, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1730, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1740, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1750, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1760, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1770, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1780, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1790, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1800, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1810, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1820, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1830, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1840, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1850, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1860, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1870, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1880, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1890, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1900, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1910, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1920, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1930, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1940, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1950, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1960, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1970, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1980, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1990, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Minibatch Loss= 0.7148, Training Accuracy= 0.503\n",
      "Epoch: 10, Minibatch Loss= 0.7032, Training Accuracy= 0.503\n",
      "Epoch: 20, Minibatch Loss= 0.7009, Training Accuracy= 0.503\n",
      "Epoch: 30, Minibatch Loss= 0.6998, Training Accuracy= 0.503\n",
      "Epoch: 40, Minibatch Loss= 0.6992, Training Accuracy= 0.503\n",
      "Epoch: 50, Minibatch Loss= 0.6987, Training Accuracy= 0.503\n",
      "Epoch: 60, Minibatch Loss= 0.6984, Training Accuracy= 0.503\n",
      "Epoch: 70, Minibatch Loss= 0.6981, Training Accuracy= 0.503\n",
      "Epoch: 80, Minibatch Loss= 0.6979, Training Accuracy= 0.503\n",
      "Epoch: 90, Minibatch Loss= 0.6977, Training Accuracy= 0.503\n",
      "Epoch: 100, Minibatch Loss= 0.6975, Training Accuracy= 0.503\n",
      "Epoch: 110, Minibatch Loss= 0.6974, Training Accuracy= 0.503\n",
      "Epoch: 120, Minibatch Loss= 0.6973, Training Accuracy= 0.503\n",
      "Epoch: 130, Minibatch Loss= 0.6972, Training Accuracy= 0.503\n",
      "Epoch: 140, Minibatch Loss= 0.6971, Training Accuracy= 0.503\n",
      "Epoch: 150, Minibatch Loss= 0.6970, Training Accuracy= 0.503\n",
      "Epoch: 160, Minibatch Loss= 0.6970, Training Accuracy= 0.503\n",
      "Epoch: 170, Minibatch Loss= 0.6969, Training Accuracy= 0.503\n",
      "Epoch: 180, Minibatch Loss= 0.6969, Training Accuracy= 0.503\n",
      "Epoch: 190, Minibatch Loss= 0.6968, Training Accuracy= 0.503\n",
      "Epoch: 200, Minibatch Loss= 0.6968, Training Accuracy= 0.503\n",
      "Epoch: 210, Minibatch Loss= 0.6967, Training Accuracy= 0.503\n",
      "Epoch: 220, Minibatch Loss= 0.6967, Training Accuracy= 0.503\n",
      "Epoch: 230, Minibatch Loss= 0.6967, Training Accuracy= 0.503\n",
      "Epoch: 240, Minibatch Loss= 0.6967, Training Accuracy= 0.503\n",
      "Epoch: 250, Minibatch Loss= 0.6966, Training Accuracy= 0.503\n",
      "Epoch: 260, Minibatch Loss= 0.6966, Training Accuracy= 0.503\n",
      "Epoch: 270, Minibatch Loss= 0.6966, Training Accuracy= 0.503\n",
      "Epoch: 280, Minibatch Loss= 0.6966, Training Accuracy= 0.503\n",
      "Epoch: 290, Minibatch Loss= 0.6966, Training Accuracy= 0.503\n",
      "Epoch: 300, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 310, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 320, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 330, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 340, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 350, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 360, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 370, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 380, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 390, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 400, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 410, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 420, Minibatch Loss= 0.6965, Training Accuracy= 0.503\n",
      "Epoch: 430, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 440, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 450, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 460, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 470, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 480, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 490, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 500, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 510, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 520, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 530, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 540, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 550, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 560, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 570, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 580, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 590, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 600, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 610, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 620, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 630, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 640, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 650, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 660, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 670, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 680, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 690, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 700, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 710, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 720, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 730, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 740, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 750, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 760, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 770, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 780, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 790, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 800, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 810, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 820, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 830, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 840, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 850, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 860, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 870, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 880, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 890, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 900, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 910, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 920, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 930, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 940, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 950, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 960, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 970, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 980, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 990, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1000, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1010, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1020, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1030, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1040, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1050, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1060, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1070, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1080, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1090, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1100, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1110, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1120, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1130, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1140, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1150, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1160, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1170, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1180, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1190, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1200, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1210, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1220, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1230, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1240, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1250, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1260, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1270, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1280, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1290, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1300, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1310, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1320, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1330, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1340, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1350, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1360, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1370, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1380, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1390, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1400, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1410, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1420, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1430, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1440, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1450, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1460, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1470, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1480, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1490, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1500, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1510, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1520, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1530, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1540, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1550, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1560, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1570, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1580, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1590, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1600, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1610, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1620, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1630, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1640, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1650, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1660, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1670, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1680, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1690, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1700, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1710, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1720, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1730, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1740, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1750, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1760, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1770, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1780, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1790, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1800, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1810, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1820, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1830, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1840, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1850, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1860, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1870, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1880, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1890, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1900, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1910, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1920, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1930, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1940, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1950, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1960, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1970, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1980, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 1990, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5075\n",
      "Replication: 7: \n",
      "Epoch: 0, Minibatch Loss= 0.6935, Training Accuracy= 0.495\n",
      "Epoch: 10, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 20, Minibatch Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 30, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 40, Minibatch Loss= 0.6929, Training Accuracy= 0.503\n",
      "Epoch: 50, Minibatch Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 60, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 70, Minibatch Loss= 0.6929, Training Accuracy= 0.521\n",
      "Epoch: 80, Minibatch Loss= 0.6929, Training Accuracy= 0.525\n",
      "Epoch: 90, Minibatch Loss= 0.6928, Training Accuracy= 0.522\n",
      "Epoch: 100, Minibatch Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 110, Minibatch Loss= 0.6928, Training Accuracy= 0.520\n",
      "Epoch: 120, Minibatch Loss= 0.6928, Training Accuracy= 0.520\n",
      "Epoch: 130, Minibatch Loss= 0.6928, Training Accuracy= 0.519\n",
      "Epoch: 140, Minibatch Loss= 0.6928, Training Accuracy= 0.520\n",
      "Epoch: 150, Minibatch Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 160, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 170, Minibatch Loss= 0.6927, Training Accuracy= 0.507\n",
      "Epoch: 180, Minibatch Loss= 0.6927, Training Accuracy= 0.504\n",
      "Epoch: 190, Minibatch Loss= 0.6927, Training Accuracy= 0.492\n",
      "Epoch: 200, Minibatch Loss= 0.6927, Training Accuracy= 0.488\n",
      "Epoch: 210, Minibatch Loss= 0.6927, Training Accuracy= 0.489\n",
      "Epoch: 220, Minibatch Loss= 0.6927, Training Accuracy= 0.495\n",
      "Epoch: 230, Minibatch Loss= 0.6927, Training Accuracy= 0.493\n",
      "Epoch: 240, Minibatch Loss= 0.6927, Training Accuracy= 0.495\n",
      "Epoch: 250, Minibatch Loss= 0.6927, Training Accuracy= 0.498\n",
      "Epoch: 260, Minibatch Loss= 0.6927, Training Accuracy= 0.497\n",
      "Epoch: 270, Minibatch Loss= 0.6926, Training Accuracy= 0.495\n",
      "Epoch: 280, Minibatch Loss= 0.6926, Training Accuracy= 0.497\n",
      "Epoch: 290, Minibatch Loss= 0.6926, Training Accuracy= 0.496\n",
      "Epoch: 300, Minibatch Loss= 0.6926, Training Accuracy= 0.499\n",
      "Epoch: 310, Minibatch Loss= 0.6926, Training Accuracy= 0.498\n",
      "Epoch: 320, Minibatch Loss= 0.6926, Training Accuracy= 0.498\n",
      "Epoch: 330, Minibatch Loss= 0.6926, Training Accuracy= 0.497\n",
      "Epoch: 340, Minibatch Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 350, Minibatch Loss= 0.6926, Training Accuracy= 0.517\n",
      "Epoch: 360, Minibatch Loss= 0.6925, Training Accuracy= 0.531\n",
      "Epoch: 370, Minibatch Loss= 0.6908, Training Accuracy= 0.442\n",
      "Epoch: 380, Minibatch Loss= 0.3987, Training Accuracy= 0.703\n",
      "Epoch: 390, Minibatch Loss= 0.9437, Training Accuracy= 0.518\n",
      "Epoch: 400, Minibatch Loss= 0.0766, Training Accuracy= 0.979\n",
      "Epoch: 410, Minibatch Loss= 0.0175, Training Accuracy= 0.998\n",
      "Epoch: 420, Minibatch Loss= 0.0097, Training Accuracy= 0.999\n",
      "Epoch: 430, Minibatch Loss= 0.0067, Training Accuracy= 0.999\n",
      "Epoch: 440, Minibatch Loss= 0.0051, Training Accuracy= 0.999\n",
      "Epoch: 450, Minibatch Loss= 0.0041, Training Accuracy= 0.999\n",
      "Epoch: 460, Minibatch Loss= 0.0034, Training Accuracy= 0.999\n",
      "Epoch: 470, Minibatch Loss= 0.0029, Training Accuracy= 0.999\n",
      "Epoch: 480, Minibatch Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 640, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.5063, Training Accuracy= 0.797\n",
      "Epoch: 720, Minibatch Loss= 0.3993, Training Accuracy= 0.786\n",
      "Epoch: 730, Minibatch Loss= 0.2316, Training Accuracy= 0.904\n",
      "Epoch: 740, Minibatch Loss= 1.6391, Training Accuracy= 0.636\n",
      "Epoch: 750, Minibatch Loss= 0.1999, Training Accuracy= 0.933\n",
      "Epoch: 760, Minibatch Loss= 0.1729, Training Accuracy= 0.945\n",
      "Epoch: 770, Minibatch Loss= 0.1628, Training Accuracy= 0.950\n",
      "Epoch: 780, Minibatch Loss= 0.1717, Training Accuracy= 0.953\n",
      "Epoch: 790, Minibatch Loss= 0.1757, Training Accuracy= 0.952\n",
      "Epoch: 800, Minibatch Loss= 0.1515, Training Accuracy= 0.959\n",
      "Epoch: 810, Minibatch Loss= 0.1326, Training Accuracy= 0.964\n",
      "Epoch: 820, Minibatch Loss= 0.1265, Training Accuracy= 0.966\n",
      "Epoch: 830, Minibatch Loss= 0.1220, Training Accuracy= 0.966\n",
      "Epoch: 840, Minibatch Loss= 0.1229, Training Accuracy= 0.968\n",
      "Epoch: 850, Minibatch Loss= 0.1178, Training Accuracy= 0.969\n",
      "Epoch: 860, Minibatch Loss= 0.1265, Training Accuracy= 0.964\n",
      "Epoch: 870, Minibatch Loss= 0.1280, Training Accuracy= 0.963\n",
      "Epoch: 880, Minibatch Loss= 0.1202, Training Accuracy= 0.967\n",
      "Epoch: 890, Minibatch Loss= 0.1111, Training Accuracy= 0.970\n",
      "Epoch: 900, Minibatch Loss= 0.1081, Training Accuracy= 0.970\n",
      "Epoch: 910, Minibatch Loss= 0.1061, Training Accuracy= 0.970\n",
      "Epoch: 920, Minibatch Loss= 0.1113, Training Accuracy= 0.967\n",
      "Epoch: 930, Minibatch Loss= 0.1156, Training Accuracy= 0.968\n",
      "Epoch: 940, Minibatch Loss= 0.1098, Training Accuracy= 0.968\n",
      "Epoch: 950, Minibatch Loss= 0.1124, Training Accuracy= 0.969\n",
      "Epoch: 960, Minibatch Loss= 0.1038, Training Accuracy= 0.970\n",
      "Epoch: 970, Minibatch Loss= 0.1133, Training Accuracy= 0.969\n",
      "Epoch: 980, Minibatch Loss= 0.4712, Training Accuracy= 0.742\n",
      "Epoch: 990, Minibatch Loss= 0.4602, Training Accuracy= 0.747\n",
      "Epoch: 1000, Minibatch Loss= 0.4502, Training Accuracy= 0.758\n",
      "Epoch: 1010, Minibatch Loss= 0.4427, Training Accuracy= 0.762\n",
      "Epoch: 1020, Minibatch Loss= 0.4307, Training Accuracy= 0.760\n",
      "Epoch: 1030, Minibatch Loss= 0.4143, Training Accuracy= 0.765\n",
      "Epoch: 1040, Minibatch Loss= 0.3986, Training Accuracy= 0.773\n",
      "Epoch: 1050, Minibatch Loss= 0.3884, Training Accuracy= 0.780\n",
      "Epoch: 1060, Minibatch Loss= 0.3794, Training Accuracy= 0.784\n",
      "Epoch: 1070, Minibatch Loss= 0.3811, Training Accuracy= 0.777\n",
      "Epoch: 1080, Minibatch Loss= 0.3735, Training Accuracy= 0.807\n",
      "Epoch: 1090, Minibatch Loss= 0.3526, Training Accuracy= 0.820\n",
      "Epoch: 1100, Minibatch Loss= 0.3411, Training Accuracy= 0.825\n",
      "Epoch: 1110, Minibatch Loss= 0.3321, Training Accuracy= 0.826\n",
      "Epoch: 1120, Minibatch Loss= 0.3245, Training Accuracy= 0.827\n",
      "Epoch: 1130, Minibatch Loss= 0.3168, Training Accuracy= 0.833\n",
      "Epoch: 1140, Minibatch Loss= 0.3005, Training Accuracy= 0.837\n",
      "Epoch: 1150, Minibatch Loss= 0.2612, Training Accuracy= 0.871\n",
      "Epoch: 1160, Minibatch Loss= 0.2483, Training Accuracy= 0.895\n",
      "Epoch: 1170, Minibatch Loss= 0.2317, Training Accuracy= 0.902\n",
      "Epoch: 1180, Minibatch Loss= 0.2201, Training Accuracy= 0.906\n",
      "Epoch: 1190, Minibatch Loss= 0.2327, Training Accuracy= 0.900\n",
      "Epoch: 1200, Minibatch Loss= 0.2457, Training Accuracy= 0.894\n",
      "Epoch: 1210, Minibatch Loss= 0.2369, Training Accuracy= 0.894\n",
      "Epoch: 1220, Minibatch Loss= 0.2368, Training Accuracy= 0.897\n",
      "Epoch: 1230, Minibatch Loss= 0.2399, Training Accuracy= 0.894\n",
      "Epoch: 1240, Minibatch Loss= 0.2429, Training Accuracy= 0.889\n",
      "Epoch: 1250, Minibatch Loss= 0.2399, Training Accuracy= 0.892\n",
      "Epoch: 1260, Minibatch Loss= 0.2040, Training Accuracy= 0.913\n",
      "Epoch: 1270, Minibatch Loss= 0.2183, Training Accuracy= 0.910\n",
      "Epoch: 1280, Minibatch Loss= 0.2464, Training Accuracy= 0.898\n",
      "Epoch: 1290, Minibatch Loss= 0.1975, Training Accuracy= 0.919\n",
      "Epoch: 1300, Minibatch Loss= 0.1827, Training Accuracy= 0.922\n",
      "Epoch: 1310, Minibatch Loss= 0.2365, Training Accuracy= 0.900\n",
      "Epoch: 1320, Minibatch Loss= 0.1569, Training Accuracy= 0.939\n",
      "Epoch: 1330, Minibatch Loss= 0.1554, Training Accuracy= 0.940\n",
      "Epoch: 1340, Minibatch Loss= 0.1436, Training Accuracy= 0.941\n",
      "Epoch: 1350, Minibatch Loss= 0.1311, Training Accuracy= 0.947\n",
      "Epoch: 1360, Minibatch Loss= 0.1237, Training Accuracy= 0.954\n",
      "Epoch: 1370, Minibatch Loss= 0.1183, Training Accuracy= 0.957\n",
      "Epoch: 1380, Minibatch Loss= 0.1136, Training Accuracy= 0.956\n",
      "Epoch: 1390, Minibatch Loss= 0.1086, Training Accuracy= 0.958\n",
      "Epoch: 1400, Minibatch Loss= 0.1424, Training Accuracy= 0.984\n",
      "Epoch: 1410, Minibatch Loss= 0.0652, Training Accuracy= 0.999\n",
      "Epoch: 1420, Minibatch Loss= 0.0478, Training Accuracy= 0.999\n",
      "Epoch: 1430, Minibatch Loss= 0.0374, Training Accuracy= 1.000\n",
      "Epoch: 1440, Minibatch Loss= 0.0316, Training Accuracy= 1.000\n",
      "Epoch: 1450, Minibatch Loss= 0.0276, Training Accuracy= 1.000\n",
      "Epoch: 1460, Minibatch Loss= 0.0246, Training Accuracy= 1.000\n",
      "Epoch: 1470, Minibatch Loss= 0.0221, Training Accuracy= 1.000\n",
      "Epoch: 1480, Minibatch Loss= 0.0201, Training Accuracy= 1.000\n",
      "Epoch: 1490, Minibatch Loss= 0.0185, Training Accuracy= 1.000\n",
      "Epoch: 1500, Minibatch Loss= 0.0171, Training Accuracy= 1.000\n",
      "Epoch: 1510, Minibatch Loss= 0.0159, Training Accuracy= 1.000\n",
      "Epoch: 1520, Minibatch Loss= 0.0148, Training Accuracy= 1.000\n",
      "Epoch: 1530, Minibatch Loss= 0.0139, Training Accuracy= 1.000\n",
      "Epoch: 1540, Minibatch Loss= 0.0131, Training Accuracy= 1.000\n",
      "Epoch: 1550, Minibatch Loss= 0.0124, Training Accuracy= 1.000\n",
      "Epoch: 1560, Minibatch Loss= 0.0117, Training Accuracy= 1.000\n",
      "Epoch: 1570, Minibatch Loss= 0.0111, Training Accuracy= 1.000\n",
      "Epoch: 1580, Minibatch Loss= 0.0106, Training Accuracy= 1.000\n",
      "Epoch: 1590, Minibatch Loss= 0.0101, Training Accuracy= 1.000\n",
      "Epoch: 1600, Minibatch Loss= 0.0097, Training Accuracy= 1.000\n",
      "Epoch: 1610, Minibatch Loss= 0.0093, Training Accuracy= 1.000\n",
      "Epoch: 1620, Minibatch Loss= 0.0089, Training Accuracy= 1.000\n",
      "Epoch: 1630, Minibatch Loss= 0.0086, Training Accuracy= 1.000\n",
      "Epoch: 1640, Minibatch Loss= 0.0083, Training Accuracy= 1.000\n",
      "Epoch: 1650, Minibatch Loss= 0.0080, Training Accuracy= 1.000\n",
      "Epoch: 1660, Minibatch Loss= 0.0077, Training Accuracy= 1.000\n",
      "Epoch: 1670, Minibatch Loss= 0.0074, Training Accuracy= 1.000\n",
      "Epoch: 1680, Minibatch Loss= 0.0072, Training Accuracy= 1.000\n",
      "Epoch: 1690, Minibatch Loss= 0.0070, Training Accuracy= 1.000\n",
      "Epoch: 1700, Minibatch Loss= 0.0068, Training Accuracy= 1.000\n",
      "Epoch: 1710, Minibatch Loss= 0.0066, Training Accuracy= 1.000\n",
      "Epoch: 1720, Minibatch Loss= 0.0064, Training Accuracy= 1.000\n",
      "Epoch: 1730, Minibatch Loss= 0.0062, Training Accuracy= 1.000\n",
      "Epoch: 1740, Minibatch Loss= 0.0060, Training Accuracy= 1.000\n",
      "Epoch: 1750, Minibatch Loss= 0.0059, Training Accuracy= 1.000\n",
      "Epoch: 1760, Minibatch Loss= 0.0057, Training Accuracy= 1.000\n",
      "Epoch: 1770, Minibatch Loss= 0.0056, Training Accuracy= 1.000\n",
      "Epoch: 1780, Minibatch Loss= 0.0054, Training Accuracy= 1.000\n",
      "Epoch: 1790, Minibatch Loss= 0.0053, Training Accuracy= 1.000\n",
      "Epoch: 1800, Minibatch Loss= 0.0052, Training Accuracy= 1.000\n",
      "Epoch: 1810, Minibatch Loss= 0.0051, Training Accuracy= 1.000\n",
      "Epoch: 1820, Minibatch Loss= 0.0050, Training Accuracy= 1.000\n",
      "Epoch: 1830, Minibatch Loss= 0.0049, Training Accuracy= 1.000\n",
      "Epoch: 1840, Minibatch Loss= 0.0048, Training Accuracy= 1.000\n",
      "Epoch: 1850, Minibatch Loss= 0.0047, Training Accuracy= 1.000\n",
      "Epoch: 1860, Minibatch Loss= 0.0046, Training Accuracy= 1.000\n",
      "Epoch: 1870, Minibatch Loss= 0.0045, Training Accuracy= 1.000\n",
      "Epoch: 1880, Minibatch Loss= 0.0044, Training Accuracy= 1.000\n",
      "Epoch: 1890, Minibatch Loss= 0.0043, Training Accuracy= 1.000\n",
      "Epoch: 1900, Minibatch Loss= 0.0042, Training Accuracy= 1.000\n",
      "Epoch: 1910, Minibatch Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 1920, Minibatch Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 1930, Minibatch Loss= 0.0040, Training Accuracy= 1.000\n",
      "Epoch: 1940, Minibatch Loss= 0.0039, Training Accuracy= 1.000\n",
      "Epoch: 1950, Minibatch Loss= 0.0039, Training Accuracy= 1.000\n",
      "Epoch: 1960, Minibatch Loss= 0.0038, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1970, Minibatch Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 1980, Minibatch Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 1990, Minibatch Loss= 0.0036, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 8: \n",
      "Epoch: 0, Minibatch Loss= 0.7076, Training Accuracy= 0.499\n",
      "Epoch: 10, Minibatch Loss= 0.6951, Training Accuracy= 0.499\n",
      "Epoch: 20, Minibatch Loss= 0.6941, Training Accuracy= 0.499\n",
      "Epoch: 30, Minibatch Loss= 0.6937, Training Accuracy= 0.499\n",
      "Epoch: 40, Minibatch Loss= 0.6935, Training Accuracy= 0.499\n",
      "Epoch: 50, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 60, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 70, Minibatch Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 80, Minibatch Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 90, Minibatch Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 100, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 110, Minibatch Loss= 0.6932, Training Accuracy= 0.498\n",
      "Epoch: 120, Minibatch Loss= 0.6932, Training Accuracy= 0.495\n",
      "Epoch: 130, Minibatch Loss= 0.6932, Training Accuracy= 0.495\n",
      "Epoch: 140, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 150, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 160, Minibatch Loss= 0.6932, Training Accuracy= 0.498\n",
      "Epoch: 170, Minibatch Loss= 0.6932, Training Accuracy= 0.493\n",
      "Epoch: 180, Minibatch Loss= 0.6932, Training Accuracy= 0.492\n",
      "Epoch: 190, Minibatch Loss= 0.6932, Training Accuracy= 0.496\n",
      "Epoch: 200, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 210, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 220, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 230, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 240, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 250, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 260, Minibatch Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 270, Minibatch Loss= 0.6931, Training Accuracy= 0.510\n",
      "Epoch: 280, Minibatch Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 290, Minibatch Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 300, Minibatch Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 310, Minibatch Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 320, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 330, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 340, Minibatch Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 350, Minibatch Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 360, Minibatch Loss= 0.6931, Training Accuracy= 0.516\n",
      "Epoch: 370, Minibatch Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 380, Minibatch Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 390, Minibatch Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 400, Minibatch Loss= 0.6931, Training Accuracy= 0.516\n",
      "Epoch: 410, Minibatch Loss= 0.6931, Training Accuracy= 0.517\n",
      "Epoch: 420, Minibatch Loss= 0.6931, Training Accuracy= 0.521\n",
      "Epoch: 430, Minibatch Loss= 0.6931, Training Accuracy= 0.522\n",
      "Epoch: 440, Minibatch Loss= 0.6931, Training Accuracy= 0.517\n",
      "Epoch: 450, Minibatch Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 460, Minibatch Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 470, Minibatch Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 480, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 490, Minibatch Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 500, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 510, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 520, Minibatch Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 530, Minibatch Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 540, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 550, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 560, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 570, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 580, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 590, Minibatch Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 600, Minibatch Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 610, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 620, Minibatch Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 630, Minibatch Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 640, Minibatch Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 650, Minibatch Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 660, Minibatch Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 670, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 680, Minibatch Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 690, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 700, Minibatch Loss= 0.6929, Training Accuracy= 0.501\n",
      "Epoch: 710, Minibatch Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 720, Minibatch Loss= 0.6929, Training Accuracy= 0.503\n",
      "Epoch: 730, Minibatch Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 740, Minibatch Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 750, Minibatch Loss= 0.6929, Training Accuracy= 0.499\n",
      "Epoch: 760, Minibatch Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 770, Minibatch Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 780, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 790, Minibatch Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 800, Minibatch Loss= 0.6928, Training Accuracy= 0.519\n",
      "Epoch: 810, Minibatch Loss= 0.6927, Training Accuracy= 0.520\n",
      "Epoch: 820, Minibatch Loss= 0.6923, Training Accuracy= 0.514\n",
      "Epoch: 830, Minibatch Loss= 0.6402, Training Accuracy= 0.574\n",
      "Epoch: 840, Minibatch Loss= 0.4274, Training Accuracy= 0.822\n",
      "Epoch: 850, Minibatch Loss= 0.7270, Training Accuracy= 0.499\n",
      "Epoch: 860, Minibatch Loss= 0.7215, Training Accuracy= 0.499\n",
      "Epoch: 870, Minibatch Loss= 0.7176, Training Accuracy= 0.499\n",
      "Epoch: 880, Minibatch Loss= 0.7147, Training Accuracy= 0.499\n",
      "Epoch: 890, Minibatch Loss= 0.7125, Training Accuracy= 0.499\n",
      "Epoch: 900, Minibatch Loss= 0.7109, Training Accuracy= 0.499\n",
      "Epoch: 910, Minibatch Loss= 0.7097, Training Accuracy= 0.499\n",
      "Epoch: 920, Minibatch Loss= 0.7088, Training Accuracy= 0.499\n",
      "Epoch: 930, Minibatch Loss= 0.7082, Training Accuracy= 0.499\n",
      "Epoch: 940, Minibatch Loss= 0.7077, Training Accuracy= 0.499\n",
      "Epoch: 950, Minibatch Loss= 0.7073, Training Accuracy= 0.499\n",
      "Epoch: 960, Minibatch Loss= 0.7070, Training Accuracy= 0.499\n",
      "Epoch: 970, Minibatch Loss= 0.7068, Training Accuracy= 0.499\n",
      "Epoch: 980, Minibatch Loss= 0.7066, Training Accuracy= 0.499\n",
      "Epoch: 990, Minibatch Loss= 0.7064, Training Accuracy= 0.499\n",
      "Epoch: 1000, Minibatch Loss= 0.7063, Training Accuracy= 0.499\n",
      "Epoch: 1010, Minibatch Loss= 0.7062, Training Accuracy= 0.499\n",
      "Epoch: 1020, Minibatch Loss= 0.7061, Training Accuracy= 0.499\n",
      "Epoch: 1030, Minibatch Loss= 0.7060, Training Accuracy= 0.499\n",
      "Epoch: 1040, Minibatch Loss= 0.7059, Training Accuracy= 0.499\n",
      "Epoch: 1050, Minibatch Loss= 0.7058, Training Accuracy= 0.499\n",
      "Epoch: 1060, Minibatch Loss= 0.7058, Training Accuracy= 0.499\n",
      "Epoch: 1070, Minibatch Loss= 0.7057, Training Accuracy= 0.499\n",
      "Epoch: 1080, Minibatch Loss= 0.7057, Training Accuracy= 0.499\n",
      "Epoch: 1090, Minibatch Loss= 0.7056, Training Accuracy= 0.499\n",
      "Epoch: 1100, Minibatch Loss= 0.7056, Training Accuracy= 0.499\n",
      "Epoch: 1110, Minibatch Loss= 0.7055, Training Accuracy= 0.499\n",
      "Epoch: 1120, Minibatch Loss= 0.7055, Training Accuracy= 0.499\n",
      "Epoch: 1130, Minibatch Loss= 0.7055, Training Accuracy= 0.499\n",
      "Epoch: 1140, Minibatch Loss= 0.7054, Training Accuracy= 0.499\n",
      "Epoch: 1150, Minibatch Loss= 0.7054, Training Accuracy= 0.499\n",
      "Epoch: 1160, Minibatch Loss= 0.7054, Training Accuracy= 0.499\n",
      "Epoch: 1170, Minibatch Loss= 0.7053, Training Accuracy= 0.499\n",
      "Epoch: 1180, Minibatch Loss= 0.7053, Training Accuracy= 0.499\n",
      "Epoch: 1190, Minibatch Loss= 0.7053, Training Accuracy= 0.499\n",
      "Epoch: 1200, Minibatch Loss= 0.7053, Training Accuracy= 0.499\n",
      "Epoch: 1210, Minibatch Loss= 0.7052, Training Accuracy= 0.499\n",
      "Epoch: 1220, Minibatch Loss= 0.7052, Training Accuracy= 0.499\n",
      "Epoch: 1230, Minibatch Loss= 0.7052, Training Accuracy= 0.499\n",
      "Epoch: 1240, Minibatch Loss= 0.7052, Training Accuracy= 0.499\n",
      "Epoch: 1250, Minibatch Loss= 0.7052, Training Accuracy= 0.499\n",
      "Epoch: 1260, Minibatch Loss= 0.7052, Training Accuracy= 0.499\n",
      "Epoch: 1270, Minibatch Loss= 0.7051, Training Accuracy= 0.499\n",
      "Epoch: 1280, Minibatch Loss= 0.7051, Training Accuracy= 0.499\n",
      "Epoch: 1290, Minibatch Loss= 0.7051, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1300, Minibatch Loss= 0.7051, Training Accuracy= 0.499\n",
      "Epoch: 1310, Minibatch Loss= 0.7051, Training Accuracy= 0.499\n",
      "Epoch: 1320, Minibatch Loss= 0.7051, Training Accuracy= 0.499\n",
      "Epoch: 1330, Minibatch Loss= 0.7051, Training Accuracy= 0.499\n",
      "Epoch: 1340, Minibatch Loss= 0.7050, Training Accuracy= 0.499\n",
      "Epoch: 1350, Minibatch Loss= 0.7050, Training Accuracy= 0.499\n",
      "Epoch: 1360, Minibatch Loss= 0.7050, Training Accuracy= 0.499\n",
      "Epoch: 1370, Minibatch Loss= 0.7050, Training Accuracy= 0.499\n",
      "Epoch: 1380, Minibatch Loss= 0.7050, Training Accuracy= 0.499\n",
      "Epoch: 1390, Minibatch Loss= 0.7050, Training Accuracy= 0.499\n",
      "Epoch: 1400, Minibatch Loss= 0.7050, Training Accuracy= 0.499\n",
      "Epoch: 1410, Minibatch Loss= 0.7050, Training Accuracy= 0.499\n",
      "Epoch: 1420, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1430, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1440, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1450, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1460, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1470, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1480, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1490, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1500, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1510, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1520, Minibatch Loss= 0.7049, Training Accuracy= 0.499\n",
      "Epoch: 1530, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1540, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1550, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1560, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1570, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1580, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1590, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1600, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1610, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1620, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1630, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1640, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1650, Minibatch Loss= 0.7048, Training Accuracy= 0.499\n",
      "Epoch: 1660, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1670, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1680, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1690, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1700, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1710, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1720, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1730, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1740, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1750, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1760, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1770, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1780, Minibatch Loss= 0.7047, Training Accuracy= 0.499\n",
      "Epoch: 1790, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1800, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1810, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1820, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1830, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1840, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1850, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1860, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1870, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1880, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1890, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1900, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1910, Minibatch Loss= 0.7046, Training Accuracy= 0.499\n",
      "Epoch: 1920, Minibatch Loss= 0.7045, Training Accuracy= 0.499\n",
      "Epoch: 1930, Minibatch Loss= 0.7045, Training Accuracy= 0.499\n",
      "Epoch: 1940, Minibatch Loss= 0.7045, Training Accuracy= 0.499\n",
      "Epoch: 1950, Minibatch Loss= 0.7045, Training Accuracy= 0.499\n",
      "Epoch: 1960, Minibatch Loss= 0.7045, Training Accuracy= 0.499\n",
      "Epoch: 1970, Minibatch Loss= 0.7045, Training Accuracy= 0.499\n",
      "Epoch: 1980, Minibatch Loss= 0.7045, Training Accuracy= 0.499\n",
      "Epoch: 1990, Minibatch Loss= 0.7045, Training Accuracy= 0.499\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4917\n",
      "Replication: 9: \n",
      "Epoch: 0, Minibatch Loss= 0.6958, Training Accuracy= 0.491\n",
      "Epoch: 10, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 20, Minibatch Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 30, Minibatch Loss= 0.6929, Training Accuracy= 0.523\n",
      "Epoch: 40, Minibatch Loss= 0.6929, Training Accuracy= 0.531\n",
      "Epoch: 50, Minibatch Loss= 0.6928, Training Accuracy= 0.535\n",
      "Epoch: 60, Minibatch Loss= 0.6928, Training Accuracy= 0.534\n",
      "Epoch: 70, Minibatch Loss= 0.6928, Training Accuracy= 0.535\n",
      "Epoch: 80, Minibatch Loss= 0.6928, Training Accuracy= 0.536\n",
      "Epoch: 90, Minibatch Loss= 0.6928, Training Accuracy= 0.538\n",
      "Epoch: 100, Minibatch Loss= 0.6928, Training Accuracy= 0.536\n",
      "Epoch: 110, Minibatch Loss= 0.6928, Training Accuracy= 0.533\n",
      "Epoch: 120, Minibatch Loss= 0.6928, Training Accuracy= 0.533\n",
      "Epoch: 130, Minibatch Loss= 0.6928, Training Accuracy= 0.531\n",
      "Epoch: 140, Minibatch Loss= 0.6928, Training Accuracy= 0.534\n",
      "Epoch: 150, Minibatch Loss= 0.6928, Training Accuracy= 0.532\n",
      "Epoch: 160, Minibatch Loss= 0.6928, Training Accuracy= 0.530\n",
      "Epoch: 170, Minibatch Loss= 0.6928, Training Accuracy= 0.529\n",
      "Epoch: 180, Minibatch Loss= 0.6928, Training Accuracy= 0.528\n",
      "Epoch: 190, Minibatch Loss= 0.6928, Training Accuracy= 0.526\n",
      "Epoch: 200, Minibatch Loss= 0.6928, Training Accuracy= 0.524\n",
      "Epoch: 210, Minibatch Loss= 0.6928, Training Accuracy= 0.523\n",
      "Epoch: 220, Minibatch Loss= 0.6928, Training Accuracy= 0.518\n",
      "Epoch: 230, Minibatch Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 240, Minibatch Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 250, Minibatch Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 260, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 270, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 280, Minibatch Loss= 0.6928, Training Accuracy= 0.507\n",
      "Epoch: 290, Minibatch Loss= 0.6928, Training Accuracy= 0.507\n",
      "Epoch: 300, Minibatch Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 310, Minibatch Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 320, Minibatch Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 330, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 340, Minibatch Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 350, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 360, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 370, Minibatch Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 380, Minibatch Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 390, Minibatch Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 400, Minibatch Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 410, Minibatch Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 420, Minibatch Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 430, Minibatch Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 440, Minibatch Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 450, Minibatch Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 460, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 470, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 480, Minibatch Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 490, Minibatch Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 500, Minibatch Loss= 0.6914, Training Accuracy= 0.540\n",
      "Epoch: 510, Minibatch Loss= 0.5685, Training Accuracy= 0.731\n",
      "Epoch: 520, Minibatch Loss= 0.2838, Training Accuracy= 0.845\n",
      "Epoch: 530, Minibatch Loss= 0.1933, Training Accuracy= 0.921\n",
      "Epoch: 540, Minibatch Loss= 0.1480, Training Accuracy= 0.945\n",
      "Epoch: 550, Minibatch Loss= 0.1115, Training Accuracy= 0.965\n",
      "Epoch: 560, Minibatch Loss= 0.0953, Training Accuracy= 0.970\n",
      "Epoch: 570, Minibatch Loss= 0.0827, Training Accuracy= 0.973\n",
      "Epoch: 580, Minibatch Loss= 0.0724, Training Accuracy= 0.974\n",
      "Epoch: 590, Minibatch Loss= 0.0627, Training Accuracy= 0.981\n",
      "Epoch: 600, Minibatch Loss= 0.1613, Training Accuracy= 0.936\n",
      "Epoch: 610, Minibatch Loss= 0.7001, Training Accuracy= 0.490\n",
      "Epoch: 620, Minibatch Loss= 0.6993, Training Accuracy= 0.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 630, Minibatch Loss= 0.6993, Training Accuracy= 0.491\n",
      "Epoch: 640, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 650, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 660, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 670, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 680, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 690, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 700, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 710, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 720, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 730, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 740, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 750, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 760, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 770, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 780, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 790, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 800, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 810, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 820, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 830, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 840, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 850, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 860, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 870, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 880, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 890, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 900, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 910, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 920, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 930, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 940, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 950, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 960, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 970, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 980, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 990, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1000, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1010, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1020, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1030, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1040, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1050, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1060, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1070, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1080, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1090, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1100, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1110, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1120, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1130, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1140, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1150, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1160, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1170, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1180, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1190, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1200, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1210, Minibatch Loss= 0.6992, Training Accuracy= 0.491\n",
      "Epoch: 1220, Minibatch Loss= 0.6991, Training Accuracy= 0.491\n",
      "Epoch: 1230, Minibatch Loss= 0.6991, Training Accuracy= 0.491\n",
      "Epoch: 1240, Minibatch Loss= 0.6991, Training Accuracy= 0.491\n",
      "Epoch: 1250, Minibatch Loss= 0.6991, Training Accuracy= 0.491\n",
      "Epoch: 1260, Minibatch Loss= 0.6991, Training Accuracy= 0.491\n",
      "Epoch: 1270, Minibatch Loss= 0.6991, Training Accuracy= 0.491\n",
      "Epoch: 1280, Minibatch Loss= 0.6991, Training Accuracy= 0.491\n",
      "Epoch: 1290, Minibatch Loss= 0.6991, Training Accuracy= 0.491\n",
      "Epoch: 1300, Minibatch Loss= 0.6991, Training Accuracy= 0.491\n",
      "Epoch: 1310, Minibatch Loss= 0.6991, Training Accuracy= 0.491\n",
      "Epoch: 1320, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1330, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1340, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1350, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1360, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1370, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1380, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1390, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1400, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1410, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1420, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1430, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1440, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1450, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1460, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1470, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1480, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1490, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1500, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1510, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1520, Minibatch Loss= 0.6990, Training Accuracy= 0.491\n",
      "Epoch: 1530, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1540, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1550, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1560, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1570, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1580, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1590, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1600, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1610, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1620, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1630, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1640, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1650, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1660, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1670, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1680, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1690, Minibatch Loss= 0.6989, Training Accuracy= 0.491\n",
      "Epoch: 1700, Minibatch Loss= 0.6988, Training Accuracy= 0.491\n",
      "Epoch: 1710, Minibatch Loss= 0.6988, Training Accuracy= 0.491\n",
      "Epoch: 1720, Minibatch Loss= 0.6988, Training Accuracy= 0.491\n",
      "Epoch: 1730, Minibatch Loss= 0.6987, Training Accuracy= 0.491\n",
      "Epoch: 1740, Minibatch Loss= 0.6986, Training Accuracy= 0.491\n",
      "Epoch: 1750, Minibatch Loss= 0.6985, Training Accuracy= 0.491\n",
      "Epoch: 1760, Minibatch Loss= 0.6985, Training Accuracy= 0.491\n",
      "Epoch: 1770, Minibatch Loss= 0.6984, Training Accuracy= 0.491\n",
      "Epoch: 1780, Minibatch Loss= 0.6984, Training Accuracy= 0.491\n",
      "Epoch: 1790, Minibatch Loss= 0.6983, Training Accuracy= 0.491\n",
      "Epoch: 1800, Minibatch Loss= 0.6983, Training Accuracy= 0.491\n",
      "Epoch: 1810, Minibatch Loss= 0.6983, Training Accuracy= 0.491\n",
      "Epoch: 1820, Minibatch Loss= 0.6983, Training Accuracy= 0.491\n",
      "Epoch: 1830, Minibatch Loss= 0.6983, Training Accuracy= 0.491\n",
      "Epoch: 1840, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1850, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1860, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1870, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1880, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1890, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1900, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1910, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1920, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1930, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1940, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1950, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1960, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1970, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1980, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Epoch: 1990, Minibatch Loss= 0.6982, Training Accuracy= 0.491\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4997\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.35\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 2000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "minibatch_losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                minibatch_losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 1.0, 1.0, 0.55930001, 0.5438, 1.0, 0.50749999, 1.0, 0.49169999, 0.49970001]\n",
      "mean of test_accuracies_10replications:  0.7602\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.00240524366498\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEoCAYAAABPQRaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZlYVJw4zM6uKE4eZmVXl/wP02FSyXwafSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc6280f8350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minibatch_losses_1st_replication\n",
    "plt.plot(minibatch_losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, minibacth loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
