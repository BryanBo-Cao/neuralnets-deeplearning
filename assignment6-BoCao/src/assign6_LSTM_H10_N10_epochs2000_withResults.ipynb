{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 10\n",
    "N = 10\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.8184, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 0.7231, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.7134, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.7094, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.7071, Training Accuracy= 0.497\n",
      "Epoch: 50, Loss= 0.7056, Training Accuracy= 0.497\n",
      "Epoch: 60, Loss= 0.7046, Training Accuracy= 0.497\n",
      "Epoch: 70, Loss= 0.7038, Training Accuracy= 0.497\n",
      "Epoch: 80, Loss= 0.7033, Training Accuracy= 0.497\n",
      "Epoch: 90, Loss= 0.7028, Training Accuracy= 0.497\n",
      "Epoch: 100, Loss= 0.7024, Training Accuracy= 0.497\n",
      "Epoch: 110, Loss= 0.7021, Training Accuracy= 0.497\n",
      "Epoch: 120, Loss= 0.7019, Training Accuracy= 0.497\n",
      "Epoch: 130, Loss= 0.7017, Training Accuracy= 0.497\n",
      "Epoch: 140, Loss= 0.7015, Training Accuracy= 0.497\n",
      "Epoch: 150, Loss= 0.7013, Training Accuracy= 0.497\n",
      "Epoch: 160, Loss= 0.7012, Training Accuracy= 0.497\n",
      "Epoch: 170, Loss= 0.7011, Training Accuracy= 0.497\n",
      "Epoch: 180, Loss= 0.7009, Training Accuracy= 0.497\n",
      "Epoch: 190, Loss= 0.7008, Training Accuracy= 0.497\n",
      "Epoch: 200, Loss= 0.7007, Training Accuracy= 0.497\n",
      "Epoch: 210, Loss= 0.7006, Training Accuracy= 0.497\n",
      "Epoch: 220, Loss= 0.7006, Training Accuracy= 0.497\n",
      "Epoch: 230, Loss= 0.6979, Training Accuracy= 0.501\n",
      "Epoch: 240, Loss= 0.3698, Training Accuracy= 0.856\n",
      "Epoch: 250, Loss= 0.1208, Training Accuracy= 0.956\n",
      "Epoch: 260, Loss= 0.0788, Training Accuracy= 0.977\n",
      "Epoch: 270, Loss= 0.9231, Training Accuracy= 0.498\n",
      "Epoch: 280, Loss= 0.8646, Training Accuracy= 0.498\n",
      "Epoch: 290, Loss= 0.8393, Training Accuracy= 0.498\n",
      "Epoch: 300, Loss= 0.8196, Training Accuracy= 0.498\n",
      "Epoch: 310, Loss= 0.8063, Training Accuracy= 0.499\n",
      "Epoch: 320, Loss= 0.7986, Training Accuracy= 0.499\n",
      "Epoch: 330, Loss= 0.7942, Training Accuracy= 0.499\n",
      "Epoch: 340, Loss= 0.7914, Training Accuracy= 0.499\n",
      "Epoch: 350, Loss= 0.7891, Training Accuracy= 0.499\n",
      "Epoch: 360, Loss= 0.7863, Training Accuracy= 0.499\n",
      "Epoch: 370, Loss= 0.7764, Training Accuracy= 0.502\n",
      "Epoch: 380, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 390, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 400, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 410, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 420, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 430, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 440, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 450, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 460, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.6999, Training Accuracy= 0.507\n",
      "Epoch: 10, Loss= 0.6943, Training Accuracy= 0.507\n",
      "Epoch: 20, Loss= 0.6940, Training Accuracy= 0.507\n",
      "Epoch: 30, Loss= 0.6938, Training Accuracy= 0.507\n",
      "Epoch: 40, Loss= 0.6938, Training Accuracy= 0.507\n",
      "Epoch: 50, Loss= 0.6937, Training Accuracy= 0.507\n",
      "Epoch: 60, Loss= 0.6937, Training Accuracy= 0.507\n",
      "Epoch: 70, Loss= 0.6936, Training Accuracy= 0.507\n",
      "Epoch: 80, Loss= 0.6936, Training Accuracy= 0.507\n",
      "Epoch: 90, Loss= 0.6936, Training Accuracy= 0.507\n",
      "Epoch: 100, Loss= 0.6935, Training Accuracy= 0.507\n",
      "Epoch: 110, Loss= 0.6935, Training Accuracy= 0.507\n",
      "Epoch: 120, Loss= 0.6935, Training Accuracy= 0.507\n",
      "Epoch: 130, Loss= 0.6935, Training Accuracy= 0.507\n",
      "Epoch: 140, Loss= 0.6935, Training Accuracy= 0.506\n",
      "Epoch: 150, Loss= 0.6934, Training Accuracy= 0.506\n",
      "Epoch: 160, Loss= 0.6934, Training Accuracy= 0.508\n",
      "Epoch: 170, Loss= 0.6934, Training Accuracy= 0.514\n",
      "Epoch: 180, Loss= 0.6933, Training Accuracy= 0.513\n",
      "Epoch: 190, Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 200, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 210, Loss= 0.6932, Training Accuracy= 0.498\n",
      "Epoch: 220, Loss= 0.6932, Training Accuracy= 0.496\n",
      "Epoch: 230, Loss= 0.6931, Training Accuracy= 0.491\n",
      "Epoch: 240, Loss= 0.6931, Training Accuracy= 0.487\n",
      "Epoch: 250, Loss= 0.6930, Training Accuracy= 0.487\n",
      "Epoch: 260, Loss= 0.6930, Training Accuracy= 0.490\n",
      "Epoch: 270, Loss= 0.6929, Training Accuracy= 0.498\n",
      "Epoch: 280, Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 290, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 300, Loss= 0.6928, Training Accuracy= 0.520\n",
      "Epoch: 310, Loss= 0.6927, Training Accuracy= 0.529\n",
      "Epoch: 320, Loss= 0.6925, Training Accuracy= 0.535\n",
      "Epoch: 330, Loss= 0.6817, Training Accuracy= 0.534\n",
      "Epoch: 340, Loss= 0.3734, Training Accuracy= 0.814\n",
      "Epoch: 350, Loss= 0.3105, Training Accuracy= 0.871\n",
      "Epoch: 360, Loss= 0.1654, Training Accuracy= 0.952\n",
      "Epoch: 370, Loss= 0.0649, Training Accuracy= 0.982\n",
      "Epoch: 380, Loss= 0.0459, Training Accuracy= 0.989\n",
      "Epoch: 390, Loss= 0.0395, Training Accuracy= 0.990\n",
      "Epoch: 400, Loss= 0.0357, Training Accuracy= 0.990\n",
      "Epoch: 410, Loss= 0.0330, Training Accuracy= 0.990\n",
      "Epoch: 420, Loss= 0.0303, Training Accuracy= 0.990\n",
      "Epoch: 430, Loss= 0.0251, Training Accuracy= 0.990\n",
      "Epoch: 440, Loss= 0.0190, Training Accuracy= 0.991\n",
      "Epoch: 450, Loss= 0.0141, Training Accuracy= 0.997\n",
      "Epoch: 460, Loss= 0.0115, Training Accuracy= 0.997\n",
      "Epoch: 470, Loss= 0.0099, Training Accuracy= 0.997\n",
      "Epoch: 480, Loss= 0.0088, Training Accuracy= 0.998\n",
      "Epoch: 490, Loss= 0.0080, Training Accuracy= 0.998\n",
      "Epoch: 500, Loss= 0.0075, Training Accuracy= 0.999\n",
      "Epoch: 510, Loss= 0.0070, Training Accuracy= 0.999\n",
      "Epoch: 520, Loss= 0.0067, Training Accuracy= 0.999\n",
      "Epoch: 530, Loss= 0.0064, Training Accuracy= 0.999\n",
      "Epoch: 540, Loss= 0.0061, Training Accuracy= 0.999\n",
      "Epoch: 550, Loss= 0.0059, Training Accuracy= 0.999\n",
      "Epoch: 560, Loss= 0.0057, Training Accuracy= 0.999\n",
      "Epoch: 570, Loss= 0.0056, Training Accuracy= 0.999\n",
      "Epoch: 580, Loss= 0.0054, Training Accuracy= 0.999\n",
      "Epoch: 590, Loss= 0.0053, Training Accuracy= 0.999\n",
      "Epoch: 600, Loss= 0.0052, Training Accuracy= 0.999\n",
      "Epoch: 610, Loss= 0.0051, Training Accuracy= 0.999\n",
      "Epoch: 620, Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 630, Loss= 0.0049, Training Accuracy= 0.999\n",
      "Epoch: 640, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 650, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 660, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 670, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 680, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 690, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 700, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 710, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 720, Loss= 0.0042, Training Accuracy= 0.999\n",
      "Epoch: 730, Loss= 0.0042, Training Accuracy= 0.999\n",
      "Epoch: 740, Loss= 0.0041, Training Accuracy= 0.999\n",
      "Epoch: 750, Loss= 0.0040, Training Accuracy= 0.999\n",
      "Epoch: 760, Loss= 0.0039, Training Accuracy= 0.999\n",
      "Epoch: 770, Loss= 0.0038, Training Accuracy= 0.999\n",
      "Epoch: 780, Loss= 0.0037, Training Accuracy= 0.999\n",
      "Epoch: 790, Loss= 0.0036, Training Accuracy= 0.999\n",
      "Epoch: 800, Loss= 0.0035, Training Accuracy= 0.999\n",
      "Epoch: 810, Loss= 0.0033, Training Accuracy= 0.999\n",
      "Epoch: 820, Loss= 0.0032, Training Accuracy= 0.999\n",
      "Epoch: 830, Loss= 0.0030, Training Accuracy= 0.999\n",
      "Epoch: 840, Loss= 0.0029, Training Accuracy= 0.999\n",
      "Epoch: 850, Loss= 0.0027, Training Accuracy= 0.999\n",
      "Epoch: 860, Loss= 0.0025, Training Accuracy= 0.999\n",
      "Epoch: 870, Loss= 0.0024, Training Accuracy= 0.999\n",
      "Epoch: 880, Loss= 0.0022, Training Accuracy= 0.999\n",
      "Epoch: 890, Loss= 0.0020, Training Accuracy= 0.999\n",
      "Epoch: 900, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0004, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1190, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.7365, Training Accuracy= 0.500\n",
      "Epoch: 10, Loss= 0.7095, Training Accuracy= 0.500\n",
      "Epoch: 20, Loss= 0.7046, Training Accuracy= 0.500\n",
      "Epoch: 30, Loss= 0.7024, Training Accuracy= 0.500\n",
      "Epoch: 40, Loss= 0.7011, Training Accuracy= 0.500\n",
      "Epoch: 50, Loss= 0.7003, Training Accuracy= 0.500\n",
      "Epoch: 60, Loss= 0.6997, Training Accuracy= 0.500\n",
      "Epoch: 70, Loss= 0.6992, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.6988, Training Accuracy= 0.500\n",
      "Epoch: 90, Loss= 0.6985, Training Accuracy= 0.500\n",
      "Epoch: 100, Loss= 0.6983, Training Accuracy= 0.500\n",
      "Epoch: 110, Loss= 0.6980, Training Accuracy= 0.500\n",
      "Epoch: 120, Loss= 0.6979, Training Accuracy= 0.500\n",
      "Epoch: 130, Loss= 0.6977, Training Accuracy= 0.500\n",
      "Epoch: 140, Loss= 0.6976, Training Accuracy= 0.500\n",
      "Epoch: 150, Loss= 0.6975, Training Accuracy= 0.500\n",
      "Epoch: 160, Loss= 0.6974, Training Accuracy= 0.500\n",
      "Epoch: 170, Loss= 0.6973, Training Accuracy= 0.500\n",
      "Epoch: 180, Loss= 0.6972, Training Accuracy= 0.500\n",
      "Epoch: 190, Loss= 0.6972, Training Accuracy= 0.500\n",
      "Epoch: 200, Loss= 0.6971, Training Accuracy= 0.500\n",
      "Epoch: 210, Loss= 0.6970, Training Accuracy= 0.500\n",
      "Epoch: 220, Loss= 0.6970, Training Accuracy= 0.500\n",
      "Epoch: 230, Loss= 0.6969, Training Accuracy= 0.500\n",
      "Epoch: 240, Loss= 0.6968, Training Accuracy= 0.500\n",
      "Epoch: 250, Loss= 0.6968, Training Accuracy= 0.500\n",
      "Epoch: 260, Loss= 0.6964, Training Accuracy= 0.500\n",
      "Epoch: 270, Loss= 0.6947, Training Accuracy= 0.500\n",
      "Epoch: 280, Loss= 0.6918, Training Accuracy= 0.539\n",
      "Epoch: 290, Loss= 0.7050, Training Accuracy= 0.507\n",
      "Epoch: 300, Loss= 0.5649, Training Accuracy= 0.611\n",
      "Epoch: 310, Loss= 0.5917, Training Accuracy= 0.609\n",
      "Epoch: 320, Loss= 0.5867, Training Accuracy= 0.610\n",
      "Epoch: 330, Loss= 0.1898, Training Accuracy= 0.951\n",
      "Epoch: 340, Loss= 0.0538, Training Accuracy= 0.995\n",
      "Epoch: 350, Loss= 0.0231, Training Accuracy= 0.995\n",
      "Epoch: 360, Loss= 0.0176, Training Accuracy= 0.996\n",
      "Epoch: 370, Loss= 0.0147, Training Accuracy= 0.996\n",
      "Epoch: 380, Loss= 0.0130, Training Accuracy= 0.997\n",
      "Epoch: 390, Loss= 0.0117, Training Accuracy= 0.997\n",
      "Epoch: 400, Loss= 0.0107, Training Accuracy= 0.997\n",
      "Epoch: 410, Loss= 0.0100, Training Accuracy= 0.997\n",
      "Epoch: 420, Loss= 0.0093, Training Accuracy= 0.997\n",
      "Epoch: 430, Loss= 0.0088, Training Accuracy= 0.997\n",
      "Epoch: 440, Loss= 0.0083, Training Accuracy= 0.998\n",
      "Epoch: 450, Loss= 0.0079, Training Accuracy= 0.998\n",
      "Epoch: 460, Loss= 0.0076, Training Accuracy= 0.998\n",
      "Epoch: 470, Loss= 0.0073, Training Accuracy= 0.998\n",
      "Epoch: 480, Loss= 0.0069, Training Accuracy= 0.998\n",
      "Epoch: 490, Loss= 0.0064, Training Accuracy= 0.998\n",
      "Epoch: 500, Loss= 0.0057, Training Accuracy= 0.998\n",
      "Epoch: 510, Loss= 0.0047, Training Accuracy= 0.998\n",
      "Epoch: 520, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 530, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 540, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 550, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 560, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 570, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 580, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 590, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 600, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 610, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 620, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 630, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 640, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 650, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 660, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 670, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 680, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 690, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0004, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 780, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 10, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 20, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 30, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 40, Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 50, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 80, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 90, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 100, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 110, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 120, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 130, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 140, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 150, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 160, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 170, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 180, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 190, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 200, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 210, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 220, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 230, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 240, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 250, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 260, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 270, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 280, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 290, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 300, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 310, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 320, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 330, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 340, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 350, Loss= 0.6930, Training Accuracy= 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 370, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 380, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 390, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 400, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 410, Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 420, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 430, Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 440, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 450, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 460, Loss= 0.6930, Training Accuracy= 0.497\n",
      "Epoch: 470, Loss= 0.6930, Training Accuracy= 0.488\n",
      "Epoch: 480, Loss= 0.6930, Training Accuracy= 0.482\n",
      "Epoch: 490, Loss= 0.6930, Training Accuracy= 0.479\n",
      "Epoch: 500, Loss= 0.6930, Training Accuracy= 0.481\n",
      "Epoch: 510, Loss= 0.6930, Training Accuracy= 0.481\n",
      "Epoch: 520, Loss= 0.6930, Training Accuracy= 0.484\n",
      "Epoch: 530, Loss= 0.6929, Training Accuracy= 0.485\n",
      "Epoch: 540, Loss= 0.6929, Training Accuracy= 0.488\n",
      "Epoch: 550, Loss= 0.6929, Training Accuracy= 0.495\n",
      "Epoch: 560, Loss= 0.6929, Training Accuracy= 0.498\n",
      "Epoch: 570, Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 580, Loss= 0.6928, Training Accuracy= 0.506\n",
      "Epoch: 590, Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 600, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 610, Loss= 0.6924, Training Accuracy= 0.522\n",
      "Epoch: 620, Loss= 0.6877, Training Accuracy= 0.576\n",
      "Epoch: 630, Loss= 0.5222, Training Accuracy= 0.710\n",
      "Epoch: 640, Loss= 0.7696, Training Accuracy= 0.493\n",
      "Epoch: 650, Loss= 0.1275, Training Accuracy= 0.943\n",
      "Epoch: 660, Loss= 0.0437, Training Accuracy= 0.986\n",
      "Epoch: 670, Loss= 0.0173, Training Accuracy= 0.998\n",
      "Epoch: 680, Loss= 0.0122, Training Accuracy= 0.998\n",
      "Epoch: 690, Loss= 0.0101, Training Accuracy= 0.998\n",
      "Epoch: 700, Loss= 0.0088, Training Accuracy= 0.998\n",
      "Epoch: 710, Loss= 0.0072, Training Accuracy= 0.998\n",
      "Epoch: 720, Loss= 0.0054, Training Accuracy= 0.999\n",
      "Epoch: 730, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 740, Loss= 0.0033, Training Accuracy= 0.999\n",
      "Epoch: 750, Loss= 0.0026, Training Accuracy= 0.999\n",
      "Epoch: 760, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.7651, Training Accuracy= 0.497\n",
      "Epoch: 10, Loss= 0.7066, Training Accuracy= 0.497\n",
      "Epoch: 20, Loss= 0.7019, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.6999, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.6989, Training Accuracy= 0.497\n",
      "Epoch: 50, Loss= 0.6982, Training Accuracy= 0.497\n",
      "Epoch: 60, Loss= 0.6977, Training Accuracy= 0.497\n",
      "Epoch: 70, Loss= 0.6973, Training Accuracy= 0.497\n",
      "Epoch: 80, Loss= 0.6970, Training Accuracy= 0.497\n",
      "Epoch: 90, Loss= 0.6968, Training Accuracy= 0.497\n",
      "Epoch: 100, Loss= 0.6966, Training Accuracy= 0.497\n",
      "Epoch: 110, Loss= 0.6964, Training Accuracy= 0.497\n",
      "Epoch: 120, Loss= 0.6963, Training Accuracy= 0.497\n",
      "Epoch: 130, Loss= 0.6961, Training Accuracy= 0.497\n",
      "Epoch: 140, Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 150, Loss= 0.6959, Training Accuracy= 0.497\n",
      "Epoch: 160, Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 170, Loss= 0.6958, Training Accuracy= 0.497\n",
      "Epoch: 180, Loss= 0.6957, Training Accuracy= 0.497\n",
      "Epoch: 190, Loss= 0.6956, Training Accuracy= 0.497\n",
      "Epoch: 200, Loss= 0.6956, Training Accuracy= 0.497\n",
      "Epoch: 210, Loss= 0.6955, Training Accuracy= 0.497\n",
      "Epoch: 220, Loss= 0.6955, Training Accuracy= 0.497\n",
      "Epoch: 230, Loss= 0.6954, Training Accuracy= 0.497\n",
      "Epoch: 240, Loss= 0.6954, Training Accuracy= 0.497\n",
      "Epoch: 250, Loss= 0.6953, Training Accuracy= 0.497\n",
      "Epoch: 260, Loss= 0.6953, Training Accuracy= 0.497\n",
      "Epoch: 270, Loss= 0.6953, Training Accuracy= 0.497\n",
      "Epoch: 280, Loss= 0.6952, Training Accuracy= 0.497\n",
      "Epoch: 290, Loss= 0.6952, Training Accuracy= 0.497\n",
      "Epoch: 300, Loss= 0.6952, Training Accuracy= 0.497\n",
      "Epoch: 310, Loss= 0.6951, Training Accuracy= 0.497\n",
      "Epoch: 320, Loss= 0.6951, Training Accuracy= 0.497\n",
      "Epoch: 330, Loss= 0.6951, Training Accuracy= 0.497\n",
      "Epoch: 340, Loss= 0.6951, Training Accuracy= 0.497\n",
      "Epoch: 350, Loss= 0.6950, Training Accuracy= 0.497\n",
      "Epoch: 360, Loss= 0.6950, Training Accuracy= 0.497\n",
      "Epoch: 370, Loss= 0.6950, Training Accuracy= 0.497\n",
      "Epoch: 380, Loss= 0.6950, Training Accuracy= 0.497\n",
      "Epoch: 390, Loss= 0.6950, Training Accuracy= 0.497\n",
      "Epoch: 400, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 410, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 420, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 430, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 440, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 450, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 460, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 470, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 480, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 490, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 500, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 510, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 520, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 530, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 540, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 550, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 560, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 570, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 580, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 590, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 600, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 610, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 620, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 630, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 640, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 650, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 660, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 670, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 680, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 690, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 700, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 710, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 720, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 730, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 740, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 750, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 760, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 770, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 780, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 790, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 800, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 810, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 820, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 830, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 840, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 850, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 860, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 870, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 880, Loss= 0.6947, Training Accuracy= 0.497\n",
      "Epoch: 890, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 900, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 910, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 920, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 930, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 940, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 950, Loss= 0.6948, Training Accuracy= 0.497\n",
      "Epoch: 960, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 970, Loss= 0.6949, Training Accuracy= 0.497\n",
      "Epoch: 980, Loss= 0.6950, Training Accuracy= 0.497\n",
      "Epoch: 990, Loss= 0.6951, Training Accuracy= 0.496\n",
      "Epoch: 1000, Loss= 0.6947, Training Accuracy= 0.514\n",
      "Epoch: 1010, Loss= 0.6732, Training Accuracy= 0.571\n",
      "Epoch: 1020, Loss= 0.2986, Training Accuracy= 0.836\n",
      "Epoch: 1030, Loss= 0.2034, Training Accuracy= 0.898\n",
      "Epoch: 1040, Loss= 0.2385, Training Accuracy= 0.880\n",
      "Epoch: 1050, Loss= 0.1145, Training Accuracy= 0.962\n",
      "Epoch: 1060, Loss= 0.0699, Training Accuracy= 0.983\n",
      "Epoch: 1070, Loss= 0.0409, Training Accuracy= 0.989\n",
      "Epoch: 1080, Loss= 0.0257, Training Accuracy= 0.991\n",
      "Epoch: 1090, Loss= 0.0196, Training Accuracy= 0.996\n",
      "Epoch: 1100, Loss= 0.0158, Training Accuracy= 0.997\n",
      "Epoch: 1110, Loss= 0.0137, Training Accuracy= 0.997\n",
      "Epoch: 1120, Loss= 0.0125, Training Accuracy= 0.997\n",
      "Epoch: 1130, Loss= 0.0117, Training Accuracy= 0.997\n",
      "Epoch: 1140, Loss= 0.0111, Training Accuracy= 0.997\n",
      "Epoch: 1150, Loss= 0.0107, Training Accuracy= 0.997\n",
      "Epoch: 1160, Loss= 0.0103, Training Accuracy= 0.997\n",
      "Epoch: 1170, Loss= 0.0100, Training Accuracy= 0.998\n",
      "Epoch: 1180, Loss= 0.0097, Training Accuracy= 0.998\n",
      "Epoch: 1190, Loss= 0.0094, Training Accuracy= 0.998\n",
      "Epoch: 1200, Loss= 0.0091, Training Accuracy= 0.998\n",
      "Epoch: 1210, Loss= 0.0087, Training Accuracy= 0.998\n",
      "Epoch: 1220, Loss= 0.0081, Training Accuracy= 0.998\n",
      "Epoch: 1230, Loss= 0.0070, Training Accuracy= 0.998\n",
      "Epoch: 1240, Loss= 0.0056, Training Accuracy= 0.998\n",
      "Epoch: 1250, Loss= 0.0044, Training Accuracy= 0.998\n",
      "Epoch: 1260, Loss= 0.0034, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0004, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1540, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 0.7459, Training Accuracy= 0.495\n",
      "Epoch: 10, Loss= 0.7085, Training Accuracy= 0.495\n",
      "Epoch: 20, Loss= 0.7048, Training Accuracy= 0.495\n",
      "Epoch: 30, Loss= 0.7030, Training Accuracy= 0.495\n",
      "Epoch: 40, Loss= 0.7018, Training Accuracy= 0.495\n",
      "Epoch: 50, Loss= 0.7010, Training Accuracy= 0.495\n",
      "Epoch: 60, Loss= 0.7004, Training Accuracy= 0.495\n",
      "Epoch: 70, Loss= 0.6999, Training Accuracy= 0.495\n",
      "Epoch: 80, Loss= 0.6995, Training Accuracy= 0.495\n",
      "Epoch: 90, Loss= 0.6992, Training Accuracy= 0.495\n",
      "Epoch: 100, Loss= 0.6989, Training Accuracy= 0.495\n",
      "Epoch: 110, Loss= 0.6987, Training Accuracy= 0.495\n",
      "Epoch: 120, Loss= 0.6985, Training Accuracy= 0.495\n",
      "Epoch: 130, Loss= 0.6983, Training Accuracy= 0.495\n",
      "Epoch: 140, Loss= 0.6982, Training Accuracy= 0.495\n",
      "Epoch: 150, Loss= 0.6981, Training Accuracy= 0.495\n",
      "Epoch: 160, Loss= 0.6980, Training Accuracy= 0.495\n",
      "Epoch: 170, Loss= 0.6979, Training Accuracy= 0.495\n",
      "Epoch: 180, Loss= 0.6978, Training Accuracy= 0.495\n",
      "Epoch: 190, Loss= 0.6977, Training Accuracy= 0.495\n",
      "Epoch: 200, Loss= 0.6976, Training Accuracy= 0.495\n",
      "Epoch: 210, Loss= 0.6976, Training Accuracy= 0.495\n",
      "Epoch: 220, Loss= 0.6975, Training Accuracy= 0.495\n",
      "Epoch: 230, Loss= 0.6974, Training Accuracy= 0.495\n",
      "Epoch: 240, Loss= 0.6974, Training Accuracy= 0.495\n",
      "Epoch: 250, Loss= 0.6974, Training Accuracy= 0.495\n",
      "Epoch: 260, Loss= 0.6973, Training Accuracy= 0.495\n",
      "Epoch: 270, Loss= 0.6973, Training Accuracy= 0.495\n",
      "Epoch: 280, Loss= 0.6972, Training Accuracy= 0.495\n",
      "Epoch: 290, Loss= 0.6972, Training Accuracy= 0.495\n",
      "Epoch: 300, Loss= 0.6972, Training Accuracy= 0.495\n",
      "Epoch: 310, Loss= 0.6971, Training Accuracy= 0.495\n",
      "Epoch: 320, Loss= 0.6971, Training Accuracy= 0.495\n",
      "Epoch: 330, Loss= 0.6971, Training Accuracy= 0.495\n",
      "Epoch: 340, Loss= 0.6971, Training Accuracy= 0.495\n",
      "Epoch: 350, Loss= 0.6971, Training Accuracy= 0.495\n",
      "Epoch: 360, Loss= 0.6970, Training Accuracy= 0.495\n",
      "Epoch: 370, Loss= 0.6970, Training Accuracy= 0.495\n",
      "Epoch: 380, Loss= 0.6970, Training Accuracy= 0.495\n",
      "Epoch: 390, Loss= 0.6970, Training Accuracy= 0.495\n",
      "Epoch: 400, Loss= 0.6970, Training Accuracy= 0.495\n",
      "Epoch: 410, Loss= 0.6970, Training Accuracy= 0.495\n",
      "Epoch: 420, Loss= 0.6969, Training Accuracy= 0.495\n",
      "Epoch: 430, Loss= 0.6969, Training Accuracy= 0.495\n",
      "Epoch: 440, Loss= 0.6969, Training Accuracy= 0.495\n",
      "Epoch: 450, Loss= 0.6969, Training Accuracy= 0.495\n",
      "Epoch: 460, Loss= 0.6969, Training Accuracy= 0.495\n",
      "Epoch: 470, Loss= 0.6969, Training Accuracy= 0.495\n",
      "Epoch: 480, Loss= 0.6969, Training Accuracy= 0.495\n",
      "Epoch: 490, Loss= 0.6969, Training Accuracy= 0.495\n",
      "Epoch: 500, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 510, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 520, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 530, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 540, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 550, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 560, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 570, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 580, Loss= 0.6968, Training Accuracy= 0.495\n",
      "Epoch: 590, Loss= 0.6967, Training Accuracy= 0.495\n",
      "Epoch: 600, Loss= 0.6967, Training Accuracy= 0.495\n",
      "Epoch: 610, Loss= 0.6967, Training Accuracy= 0.495\n",
      "Epoch: 620, Loss= 0.6967, Training Accuracy= 0.495\n",
      "Epoch: 630, Loss= 0.6966, Training Accuracy= 0.495\n",
      "Epoch: 640, Loss= 0.6828, Training Accuracy= 0.573\n",
      "Epoch: 650, Loss= 0.3627, Training Accuracy= 0.843\n",
      "Epoch: 660, Loss= 0.1249, Training Accuracy= 0.961\n",
      "Epoch: 670, Loss= 0.2452, Training Accuracy= 0.876\n",
      "Epoch: 680, Loss= 0.1034, Training Accuracy= 0.957\n",
      "Epoch: 690, Loss= 0.0111, Training Accuracy= 1.000\n",
      "Epoch: 700, Loss= 0.0060, Training Accuracy= 1.000\n",
      "Epoch: 710, Loss= 0.0042, Training Accuracy= 1.000\n",
      "Epoch: 720, Loss= 0.0032, Training Accuracy= 1.000\n",
      "Epoch: 730, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 740, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 750, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 760, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 770, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 780, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0002, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1130, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.7720, Training Accuracy= 0.496\n",
      "Epoch: 10, Loss= 0.7215, Training Accuracy= 0.496\n",
      "Epoch: 20, Loss= 0.7149, Training Accuracy= 0.496\n",
      "Epoch: 30, Loss= 0.7116, Training Accuracy= 0.496\n",
      "Epoch: 40, Loss= 0.7095, Training Accuracy= 0.496\n",
      "Epoch: 50, Loss= 0.7079, Training Accuracy= 0.496\n",
      "Epoch: 60, Loss= 0.7067, Training Accuracy= 0.496\n",
      "Epoch: 70, Loss= 0.7058, Training Accuracy= 0.496\n",
      "Epoch: 80, Loss= 0.7050, Training Accuracy= 0.496\n",
      "Epoch: 90, Loss= 0.7043, Training Accuracy= 0.496\n",
      "Epoch: 100, Loss= 0.7038, Training Accuracy= 0.496\n",
      "Epoch: 110, Loss= 0.7033, Training Accuracy= 0.496\n",
      "Epoch: 120, Loss= 0.7029, Training Accuracy= 0.496\n",
      "Epoch: 130, Loss= 0.7025, Training Accuracy= 0.496\n",
      "Epoch: 140, Loss= 0.7022, Training Accuracy= 0.496\n",
      "Epoch: 150, Loss= 0.7019, Training Accuracy= 0.496\n",
      "Epoch: 160, Loss= 0.7017, Training Accuracy= 0.496\n",
      "Epoch: 170, Loss= 0.7014, Training Accuracy= 0.496\n",
      "Epoch: 180, Loss= 0.7012, Training Accuracy= 0.496\n",
      "Epoch: 190, Loss= 0.7010, Training Accuracy= 0.496\n",
      "Epoch: 200, Loss= 0.7009, Training Accuracy= 0.496\n",
      "Epoch: 210, Loss= 0.7007, Training Accuracy= 0.496\n",
      "Epoch: 220, Loss= 0.7006, Training Accuracy= 0.496\n",
      "Epoch: 230, Loss= 0.7004, Training Accuracy= 0.496\n",
      "Epoch: 240, Loss= 0.7003, Training Accuracy= 0.496\n",
      "Epoch: 250, Loss= 0.7002, Training Accuracy= 0.496\n",
      "Epoch: 260, Loss= 0.7001, Training Accuracy= 0.496\n",
      "Epoch: 270, Loss= 0.7000, Training Accuracy= 0.496\n",
      "Epoch: 280, Loss= 0.6999, Training Accuracy= 0.496\n",
      "Epoch: 290, Loss= 0.6998, Training Accuracy= 0.496\n",
      "Epoch: 300, Loss= 0.6997, Training Accuracy= 0.496\n",
      "Epoch: 310, Loss= 0.6996, Training Accuracy= 0.496\n",
      "Epoch: 320, Loss= 0.6996, Training Accuracy= 0.496\n",
      "Epoch: 330, Loss= 0.6995, Training Accuracy= 0.496\n",
      "Epoch: 340, Loss= 0.6994, Training Accuracy= 0.496\n",
      "Epoch: 350, Loss= 0.6994, Training Accuracy= 0.496\n",
      "Epoch: 360, Loss= 0.6993, Training Accuracy= 0.496\n",
      "Epoch: 370, Loss= 0.6993, Training Accuracy= 0.496\n",
      "Epoch: 380, Loss= 0.6992, Training Accuracy= 0.496\n",
      "Epoch: 390, Loss= 0.6992, Training Accuracy= 0.496\n",
      "Epoch: 400, Loss= 0.6991, Training Accuracy= 0.496\n",
      "Epoch: 410, Loss= 0.6991, Training Accuracy= 0.496\n",
      "Epoch: 420, Loss= 0.6990, Training Accuracy= 0.496\n",
      "Epoch: 430, Loss= 0.6990, Training Accuracy= 0.496\n",
      "Epoch: 440, Loss= 0.6989, Training Accuracy= 0.496\n",
      "Epoch: 450, Loss= 0.6989, Training Accuracy= 0.496\n",
      "Epoch: 460, Loss= 0.6989, Training Accuracy= 0.496\n",
      "Epoch: 470, Loss= 0.6988, Training Accuracy= 0.496\n",
      "Epoch: 480, Loss= 0.6988, Training Accuracy= 0.496\n",
      "Epoch: 490, Loss= 0.6988, Training Accuracy= 0.496\n",
      "Epoch: 500, Loss= 0.6987, Training Accuracy= 0.496\n",
      "Epoch: 510, Loss= 0.6987, Training Accuracy= 0.496\n",
      "Epoch: 520, Loss= 0.6987, Training Accuracy= 0.496\n",
      "Epoch: 530, Loss= 0.6987, Training Accuracy= 0.496\n",
      "Epoch: 540, Loss= 0.6986, Training Accuracy= 0.496\n",
      "Epoch: 550, Loss= 0.6986, Training Accuracy= 0.496\n",
      "Epoch: 560, Loss= 0.6986, Training Accuracy= 0.496\n",
      "Epoch: 570, Loss= 0.6986, Training Accuracy= 0.496\n",
      "Epoch: 580, Loss= 0.6986, Training Accuracy= 0.496\n",
      "Epoch: 590, Loss= 0.6985, Training Accuracy= 0.496\n",
      "Epoch: 600, Loss= 0.6985, Training Accuracy= 0.496\n",
      "Epoch: 610, Loss= 0.6985, Training Accuracy= 0.496\n",
      "Epoch: 620, Loss= 0.6985, Training Accuracy= 0.496\n",
      "Epoch: 630, Loss= 0.6985, Training Accuracy= 0.496\n",
      "Epoch: 640, Loss= 0.6984, Training Accuracy= 0.496\n",
      "Epoch: 650, Loss= 0.6984, Training Accuracy= 0.496\n",
      "Epoch: 660, Loss= 0.6984, Training Accuracy= 0.496\n",
      "Epoch: 670, Loss= 0.6984, Training Accuracy= 0.496\n",
      "Epoch: 680, Loss= 0.6984, Training Accuracy= 0.496\n",
      "Epoch: 690, Loss= 0.6984, Training Accuracy= 0.496\n",
      "Epoch: 700, Loss= 0.6984, Training Accuracy= 0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 710, Loss= 0.6984, Training Accuracy= 0.496\n",
      "Epoch: 720, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 730, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 740, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 750, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 760, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 770, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 780, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 790, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 800, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 810, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 820, Loss= 0.6983, Training Accuracy= 0.496\n",
      "Epoch: 830, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 840, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 850, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 860, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 870, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 880, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 890, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 900, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 910, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 920, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 930, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 940, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 950, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 960, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 970, Loss= 0.6982, Training Accuracy= 0.496\n",
      "Epoch: 980, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 990, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1000, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1010, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1020, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1030, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1040, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1050, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1060, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1070, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1080, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1090, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1100, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1110, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1120, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1130, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1140, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1150, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1160, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1170, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1180, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1190, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1200, Loss= 0.6981, Training Accuracy= 0.496\n",
      "Epoch: 1210, Loss= 0.6869, Training Accuracy= 0.514\n",
      "Epoch: 1220, Loss= 0.3415, Training Accuracy= 0.837\n",
      "Epoch: 1230, Loss= 0.2228, Training Accuracy= 0.911\n",
      "Epoch: 1240, Loss= 0.1095, Training Accuracy= 0.958\n",
      "Epoch: 1250, Loss= 0.0690, Training Accuracy= 0.980\n",
      "Epoch: 1260, Loss= 0.0555, Training Accuracy= 0.982\n",
      "Epoch: 1270, Loss= 0.8785, Training Accuracy= 0.496\n",
      "Epoch: 1280, Loss= 0.8627, Training Accuracy= 0.496\n",
      "Epoch: 1290, Loss= 0.8551, Training Accuracy= 0.496\n",
      "Epoch: 1300, Loss= 0.8467, Training Accuracy= 0.496\n",
      "Epoch: 1310, Loss= 0.8352, Training Accuracy= 0.496\n",
      "Epoch: 1320, Loss= 0.8212, Training Accuracy= 0.496\n",
      "Epoch: 1330, Loss= 0.8073, Training Accuracy= 0.496\n",
      "Epoch: 1340, Loss= 0.7954, Training Accuracy= 0.496\n",
      "Epoch: 1350, Loss= 0.7867, Training Accuracy= 0.496\n",
      "Epoch: 1360, Loss= 0.7809, Training Accuracy= 0.496\n",
      "Epoch: 1370, Loss= 0.7767, Training Accuracy= 0.496\n",
      "Epoch: 1380, Loss= 0.7736, Training Accuracy= 0.496\n",
      "Epoch: 1390, Loss= 0.7711, Training Accuracy= 0.496\n",
      "Epoch: 1400, Loss= 0.7690, Training Accuracy= 0.496\n",
      "Epoch: 1410, Loss= 0.7672, Training Accuracy= 0.496\n",
      "Epoch: 1420, Loss= 0.7656, Training Accuracy= 0.496\n",
      "Epoch: 1430, Loss= 0.7640, Training Accuracy= 0.496\n",
      "Epoch: 1440, Loss= 0.7623, Training Accuracy= 0.496\n",
      "Epoch: 1450, Loss= 0.7606, Training Accuracy= 0.496\n",
      "Epoch: 1460, Loss= 0.7588, Training Accuracy= 0.496\n",
      "Epoch: 1470, Loss= 0.7569, Training Accuracy= 0.496\n",
      "Epoch: 1480, Loss= 0.7554, Training Accuracy= 0.496\n",
      "Epoch: 1490, Loss= 0.7541, Training Accuracy= 0.496\n",
      "Epoch: 1500, Loss= 0.7530, Training Accuracy= 0.496\n",
      "Epoch: 1510, Loss= 0.7520, Training Accuracy= 0.496\n",
      "Epoch: 1520, Loss= 0.7512, Training Accuracy= 0.496\n",
      "Epoch: 1530, Loss= 0.7505, Training Accuracy= 0.496\n",
      "Epoch: 1540, Loss= 0.7499, Training Accuracy= 0.496\n",
      "Epoch: 1550, Loss= 0.7494, Training Accuracy= 0.496\n",
      "Epoch: 1560, Loss= 0.7489, Training Accuracy= 0.496\n",
      "Epoch: 1570, Loss= 0.7485, Training Accuracy= 0.496\n",
      "Epoch: 1580, Loss= 0.7481, Training Accuracy= 0.496\n",
      "Epoch: 1590, Loss= 0.7478, Training Accuracy= 0.496\n",
      "Epoch: 1600, Loss= 0.7474, Training Accuracy= 0.496\n",
      "Epoch: 1610, Loss= 0.7472, Training Accuracy= 0.496\n",
      "Epoch: 1620, Loss= 0.7469, Training Accuracy= 0.496\n",
      "Epoch: 1630, Loss= 0.7467, Training Accuracy= 0.496\n",
      "Epoch: 1640, Loss= 0.7465, Training Accuracy= 0.496\n",
      "Epoch: 1650, Loss= 0.7463, Training Accuracy= 0.496\n",
      "Epoch: 1660, Loss= 0.7461, Training Accuracy= 0.496\n",
      "Epoch: 1670, Loss= 0.7459, Training Accuracy= 0.496\n",
      "Epoch: 1680, Loss= 0.7458, Training Accuracy= 0.496\n",
      "Epoch: 1690, Loss= 0.7457, Training Accuracy= 0.496\n",
      "Epoch: 1700, Loss= 0.7455, Training Accuracy= 0.496\n",
      "Epoch: 1710, Loss= 0.7454, Training Accuracy= 0.496\n",
      "Epoch: 1720, Loss= 0.7453, Training Accuracy= 0.496\n",
      "Epoch: 1730, Loss= 0.7452, Training Accuracy= 0.496\n",
      "Epoch: 1740, Loss= 0.7451, Training Accuracy= 0.496\n",
      "Epoch: 1750, Loss= 0.7450, Training Accuracy= 0.496\n",
      "Epoch: 1760, Loss= 0.7449, Training Accuracy= 0.496\n",
      "Epoch: 1770, Loss= 0.7449, Training Accuracy= 0.496\n",
      "Epoch: 1780, Loss= 0.7448, Training Accuracy= 0.496\n",
      "Epoch: 1790, Loss= 0.7448, Training Accuracy= 0.496\n",
      "Epoch: 1800, Loss= 0.7447, Training Accuracy= 0.496\n",
      "Epoch: 1810, Loss= 0.7447, Training Accuracy= 0.496\n",
      "Epoch: 1820, Loss= 0.7446, Training Accuracy= 0.496\n",
      "Epoch: 1830, Loss= 0.7446, Training Accuracy= 0.496\n",
      "Epoch: 1840, Loss= 0.7445, Training Accuracy= 0.496\n",
      "Epoch: 1850, Loss= 0.7445, Training Accuracy= 0.496\n",
      "Epoch: 1860, Loss= 0.7445, Training Accuracy= 0.496\n",
      "Epoch: 1870, Loss= 0.7445, Training Accuracy= 0.496\n",
      "Epoch: 1880, Loss= 0.7446, Training Accuracy= 0.496\n",
      "Epoch: 1890, Loss= 0.7449, Training Accuracy= 0.496\n",
      "Epoch: 1900, Loss= 0.7453, Training Accuracy= 0.496\n",
      "Epoch: 1910, Loss= 0.7460, Training Accuracy= 0.496\n",
      "Epoch: 1920, Loss= 0.7470, Training Accuracy= 0.496\n",
      "Epoch: 1930, Loss= 0.7482, Training Accuracy= 0.497\n",
      "Epoch: 1940, Loss= 0.7497, Training Accuracy= 0.500\n",
      "Epoch: 1950, Loss= 0.7516, Training Accuracy= 0.500\n",
      "Epoch: 1960, Loss= 0.7516, Training Accuracy= 0.500\n",
      "Epoch: 1970, Loss= 0.7519, Training Accuracy= 0.500\n",
      "Epoch: 1980, Loss= 0.7519, Training Accuracy= 0.500\n",
      "Epoch: 1990, Loss= 0.7520, Training Accuracy= 0.500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4958\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 0.7283, Training Accuracy= 0.503\n",
      "Epoch: 10, Loss= 0.7014, Training Accuracy= 0.503\n",
      "Epoch: 20, Loss= 0.6989, Training Accuracy= 0.503\n",
      "Epoch: 30, Loss= 0.6978, Training Accuracy= 0.503\n",
      "Epoch: 40, Loss= 0.6971, Training Accuracy= 0.503\n",
      "Epoch: 50, Loss= 0.6966, Training Accuracy= 0.503\n",
      "Epoch: 60, Loss= 0.6963, Training Accuracy= 0.503\n",
      "Epoch: 70, Loss= 0.6961, Training Accuracy= 0.503\n",
      "Epoch: 80, Loss= 0.6959, Training Accuracy= 0.503\n",
      "Epoch: 90, Loss= 0.6957, Training Accuracy= 0.503\n",
      "Epoch: 100, Loss= 0.6956, Training Accuracy= 0.503\n",
      "Epoch: 110, Loss= 0.6955, Training Accuracy= 0.503\n",
      "Epoch: 120, Loss= 0.6954, Training Accuracy= 0.503\n",
      "Epoch: 130, Loss= 0.6953, Training Accuracy= 0.503\n",
      "Epoch: 140, Loss= 0.6952, Training Accuracy= 0.503\n",
      "Epoch: 150, Loss= 0.6952, Training Accuracy= 0.503\n",
      "Epoch: 160, Loss= 0.6951, Training Accuracy= 0.503\n",
      "Epoch: 170, Loss= 0.6951, Training Accuracy= 0.503\n",
      "Epoch: 180, Loss= 0.6951, Training Accuracy= 0.503\n",
      "Epoch: 190, Loss= 0.6950, Training Accuracy= 0.503\n",
      "Epoch: 200, Loss= 0.6950, Training Accuracy= 0.503\n",
      "Epoch: 210, Loss= 0.6950, Training Accuracy= 0.503\n",
      "Epoch: 220, Loss= 0.6949, Training Accuracy= 0.503\n",
      "Epoch: 230, Loss= 0.6949, Training Accuracy= 0.503\n",
      "Epoch: 240, Loss= 0.6949, Training Accuracy= 0.503\n",
      "Epoch: 250, Loss= 0.6949, Training Accuracy= 0.503\n",
      "Epoch: 260, Loss= 0.6949, Training Accuracy= 0.503\n",
      "Epoch: 270, Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 280, Loss= 0.6948, Training Accuracy= 0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 290, Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 300, Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 310, Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 320, Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 330, Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 340, Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 350, Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 360, Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 370, Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 380, Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 390, Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 400, Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 410, Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 420, Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 430, Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 440, Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 450, Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 460, Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 470, Loss= 0.6946, Training Accuracy= 0.503\n",
      "Epoch: 480, Loss= 0.6946, Training Accuracy= 0.503\n",
      "Epoch: 490, Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 500, Loss= 0.6892, Training Accuracy= 0.482\n",
      "Epoch: 510, Loss= 0.3611, Training Accuracy= 0.828\n",
      "Epoch: 520, Loss= 0.1369, Training Accuracy= 0.964\n",
      "Epoch: 530, Loss= 0.0891, Training Accuracy= 0.974\n",
      "Epoch: 540, Loss= 0.0684, Training Accuracy= 0.986\n",
      "Epoch: 550, Loss= 0.0535, Training Accuracy= 0.987\n",
      "Epoch: 560, Loss= 0.0336, Training Accuracy= 0.989\n",
      "Epoch: 570, Loss= 0.0198, Training Accuracy= 0.996\n",
      "Epoch: 580, Loss= 0.0139, Training Accuracy= 0.998\n",
      "Epoch: 590, Loss= 0.0115, Training Accuracy= 0.999\n",
      "Epoch: 600, Loss= 0.0101, Training Accuracy= 0.999\n",
      "Epoch: 610, Loss= 0.0091, Training Accuracy= 0.999\n",
      "Epoch: 620, Loss= 0.0083, Training Accuracy= 0.999\n",
      "Epoch: 630, Loss= 0.0076, Training Accuracy= 0.999\n",
      "Epoch: 640, Loss= 0.0071, Training Accuracy= 0.999\n",
      "Epoch: 650, Loss= 0.0066, Training Accuracy= 0.999\n",
      "Epoch: 660, Loss= 0.0062, Training Accuracy= 0.999\n",
      "Epoch: 670, Loss= 0.0058, Training Accuracy= 0.999\n",
      "Epoch: 680, Loss= 0.0055, Training Accuracy= 0.999\n",
      "Epoch: 690, Loss= 0.0051, Training Accuracy= 0.999\n",
      "Epoch: 700, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 710, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 720, Loss= 0.0041, Training Accuracy= 0.999\n",
      "Epoch: 730, Loss= 0.0037, Training Accuracy= 0.999\n",
      "Epoch: 740, Loss= 0.0034, Training Accuracy= 0.999\n",
      "Epoch: 750, Loss= 0.0031, Training Accuracy= 0.999\n",
      "Epoch: 760, Loss= 0.0028, Training Accuracy= 0.999\n",
      "Epoch: 770, Loss= 0.0025, Training Accuracy= 0.999\n",
      "Epoch: 780, Loss= 0.0023, Training Accuracy= 0.999\n",
      "Epoch: 790, Loss= 0.0021, Training Accuracy= 0.999\n",
      "Epoch: 800, Loss= 0.0019, Training Accuracy= 0.999\n",
      "Epoch: 810, Loss= 0.0017, Training Accuracy= 0.999\n",
      "Epoch: 820, Loss= 0.0016, Training Accuracy= 0.999\n",
      "Epoch: 830, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 0.7191, Training Accuracy= 0.501\n",
      "Epoch: 10, Loss= 0.7063, Training Accuracy= 0.501\n",
      "Epoch: 20, Loss= 0.7031, Training Accuracy= 0.501\n",
      "Epoch: 30, Loss= 0.7015, Training Accuracy= 0.501\n",
      "Epoch: 40, Loss= 0.7004, Training Accuracy= 0.501\n",
      "Epoch: 50, Loss= 0.6998, Training Accuracy= 0.501\n",
      "Epoch: 60, Loss= 0.6993, Training Accuracy= 0.501\n",
      "Epoch: 70, Loss= 0.6989, Training Accuracy= 0.501\n",
      "Epoch: 80, Loss= 0.6986, Training Accuracy= 0.501\n",
      "Epoch: 90, Loss= 0.6984, Training Accuracy= 0.501\n",
      "Epoch: 100, Loss= 0.6982, Training Accuracy= 0.501\n",
      "Epoch: 110, Loss= 0.6980, Training Accuracy= 0.501\n",
      "Epoch: 120, Loss= 0.6979, Training Accuracy= 0.501\n",
      "Epoch: 130, Loss= 0.6977, Training Accuracy= 0.501\n",
      "Epoch: 140, Loss= 0.6976, Training Accuracy= 0.501\n",
      "Epoch: 150, Loss= 0.6976, Training Accuracy= 0.501\n",
      "Epoch: 160, Loss= 0.6975, Training Accuracy= 0.501\n",
      "Epoch: 170, Loss= 0.6974, Training Accuracy= 0.501\n",
      "Epoch: 180, Loss= 0.6974, Training Accuracy= 0.501\n",
      "Epoch: 190, Loss= 0.6973, Training Accuracy= 0.501\n",
      "Epoch: 200, Loss= 0.6973, Training Accuracy= 0.501\n",
      "Epoch: 210, Loss= 0.6973, Training Accuracy= 0.501\n",
      "Epoch: 220, Loss= 0.6973, Training Accuracy= 0.501\n",
      "Epoch: 230, Loss= 0.6973, Training Accuracy= 0.501\n",
      "Epoch: 240, Loss= 0.6973, Training Accuracy= 0.501\n",
      "Epoch: 250, Loss= 0.6973, Training Accuracy= 0.501\n",
      "Epoch: 260, Loss= 0.6973, Training Accuracy= 0.501\n",
      "Epoch: 270, Loss= 0.6974, Training Accuracy= 0.501\n",
      "Epoch: 280, Loss= 0.6975, Training Accuracy= 0.501\n",
      "Epoch: 290, Loss= 0.6975, Training Accuracy= 0.501\n",
      "Epoch: 300, Loss= 0.6976, Training Accuracy= 0.501\n",
      "Epoch: 310, Loss= 0.6977, Training Accuracy= 0.501\n",
      "Epoch: 320, Loss= 0.6977, Training Accuracy= 0.501\n",
      "Epoch: 330, Loss= 0.6976, Training Accuracy= 0.501\n",
      "Epoch: 340, Loss= 0.6975, Training Accuracy= 0.501\n",
      "Epoch: 350, Loss= 0.6974, Training Accuracy= 0.501\n",
      "Epoch: 360, Loss= 0.6968, Training Accuracy= 0.502\n",
      "Epoch: 370, Loss= 0.6654, Training Accuracy= 0.674\n",
      "Epoch: 380, Loss= 0.3160, Training Accuracy= 0.817\n",
      "Epoch: 390, Loss= 0.2821, Training Accuracy= 0.867\n",
      "Epoch: 400, Loss= 0.1581, Training Accuracy= 0.937\n",
      "Epoch: 410, Loss= 0.1463, Training Accuracy= 0.942\n",
      "Epoch: 420, Loss= 0.8500, Training Accuracy= 0.501\n",
      "Epoch: 430, Loss= 0.8362, Training Accuracy= 0.501\n",
      "Epoch: 440, Loss= 0.8325, Training Accuracy= 0.501\n",
      "Epoch: 450, Loss= 0.8306, Training Accuracy= 0.501\n",
      "Epoch: 460, Loss= 0.8294, Training Accuracy= 0.501\n",
      "Epoch: 470, Loss= 0.8285, Training Accuracy= 0.501\n",
      "Epoch: 480, Loss= 0.8278, Training Accuracy= 0.501\n",
      "Epoch: 490, Loss= 0.8272, Training Accuracy= 0.501\n",
      "Epoch: 500, Loss= 0.8266, Training Accuracy= 0.501\n",
      "Epoch: 510, Loss= 0.8260, Training Accuracy= 0.501\n",
      "Epoch: 520, Loss= 0.8254, Training Accuracy= 0.501\n",
      "Epoch: 530, Loss= 0.8248, Training Accuracy= 0.501\n",
      "Epoch: 540, Loss= 0.8242, Training Accuracy= 0.501\n",
      "Epoch: 550, Loss= 0.8236, Training Accuracy= 0.501\n",
      "Epoch: 560, Loss= 0.8229, Training Accuracy= 0.501\n",
      "Epoch: 570, Loss= 0.8222, Training Accuracy= 0.501\n",
      "Epoch: 580, Loss= 0.8214, Training Accuracy= 0.501\n",
      "Epoch: 590, Loss= 0.8204, Training Accuracy= 0.501\n",
      "Epoch: 600, Loss= 0.8190, Training Accuracy= 0.501\n",
      "Epoch: 610, Loss= 0.8171, Training Accuracy= 0.501\n",
      "Epoch: 620, Loss= 0.8142, Training Accuracy= 0.501\n",
      "Epoch: 630, Loss= 0.8099, Training Accuracy= 0.501\n",
      "Epoch: 640, Loss= 0.8042, Training Accuracy= 0.501\n",
      "Epoch: 650, Loss= 0.7990, Training Accuracy= 0.501\n",
      "Epoch: 660, Loss= 0.7954, Training Accuracy= 0.501\n",
      "Epoch: 670, Loss= 0.7932, Training Accuracy= 0.501\n",
      "Epoch: 680, Loss= 0.7918, Training Accuracy= 0.501\n",
      "Epoch: 690, Loss= 0.7908, Training Accuracy= 0.501\n",
      "Epoch: 700, Loss= 0.7900, Training Accuracy= 0.501\n",
      "Epoch: 710, Loss= 0.7893, Training Accuracy= 0.501\n",
      "Epoch: 720, Loss= 0.7888, Training Accuracy= 0.501\n",
      "Epoch: 730, Loss= 0.7882, Training Accuracy= 0.501\n",
      "Epoch: 740, Loss= 0.7877, Training Accuracy= 0.501\n",
      "Epoch: 750, Loss= 0.7873, Training Accuracy= 0.501\n",
      "Epoch: 760, Loss= 0.7868, Training Accuracy= 0.501\n",
      "Epoch: 770, Loss= 0.7864, Training Accuracy= 0.501\n",
      "Epoch: 780, Loss= 0.7860, Training Accuracy= 0.501\n",
      "Epoch: 790, Loss= 0.7855, Training Accuracy= 0.501\n",
      "Epoch: 800, Loss= 0.7851, Training Accuracy= 0.501\n",
      "Epoch: 810, Loss= 0.7846, Training Accuracy= 0.501\n",
      "Epoch: 820, Loss= 0.7842, Training Accuracy= 0.501\n",
      "Epoch: 830, Loss= 0.7837, Training Accuracy= 0.501\n",
      "Epoch: 840, Loss= 0.7831, Training Accuracy= 0.501\n",
      "Epoch: 850, Loss= 0.7826, Training Accuracy= 0.501\n",
      "Epoch: 860, Loss= 0.7820, Training Accuracy= 0.501\n",
      "Epoch: 870, Loss= 0.7813, Training Accuracy= 0.501\n",
      "Epoch: 880, Loss= 0.7806, Training Accuracy= 0.501\n",
      "Epoch: 890, Loss= 0.7797, Training Accuracy= 0.501\n",
      "Epoch: 900, Loss= 0.7786, Training Accuracy= 0.501\n",
      "Epoch: 910, Loss= 0.7772, Training Accuracy= 0.501\n",
      "Epoch: 920, Loss= 0.7753, Training Accuracy= 0.501\n",
      "Epoch: 930, Loss= 0.7725, Training Accuracy= 0.501\n",
      "Epoch: 940, Loss= 0.7688, Training Accuracy= 0.501\n",
      "Epoch: 950, Loss= 0.7650, Training Accuracy= 0.501\n",
      "Epoch: 960, Loss= 0.7622, Training Accuracy= 0.501\n",
      "Epoch: 970, Loss= 0.7604, Training Accuracy= 0.501\n",
      "Epoch: 980, Loss= 0.7593, Training Accuracy= 0.501\n",
      "Epoch: 990, Loss= 0.7586, Training Accuracy= 0.501\n",
      "Epoch: 1000, Loss= 0.7583, Training Accuracy= 0.501\n",
      "Epoch: 1010, Loss= 0.7585, Training Accuracy= 0.501\n",
      "Epoch: 1020, Loss= 0.7595, Training Accuracy= 0.501\n",
      "Epoch: 1030, Loss= 0.7614, Training Accuracy= 0.501\n",
      "Epoch: 1040, Loss= 0.7597, Training Accuracy= 0.501\n",
      "Epoch: 1050, Loss= 0.7582, Training Accuracy= 0.501\n",
      "Epoch: 1060, Loss= 0.7169, Training Accuracy= 0.533\n",
      "Epoch: 1070, Loss= 0.7593, Training Accuracy= 0.501\n",
      "Epoch: 1080, Loss= 0.7558, Training Accuracy= 0.501\n",
      "Epoch: 1090, Loss= 0.7489, Training Accuracy= 0.509\n",
      "Epoch: 1100, Loss= 0.7418, Training Accuracy= 0.515\n",
      "Epoch: 1110, Loss= 0.7343, Training Accuracy= 0.520\n",
      "Epoch: 1120, Loss= 0.7579, Training Accuracy= 0.501\n",
      "Epoch: 1130, Loss= 0.7548, Training Accuracy= 0.501\n",
      "Epoch: 1140, Loss= 0.7524, Training Accuracy= 0.501\n",
      "Epoch: 1150, Loss= 0.7501, Training Accuracy= 0.501\n",
      "Epoch: 1160, Loss= 0.7484, Training Accuracy= 0.501\n",
      "Epoch: 1170, Loss= 0.7393, Training Accuracy= 0.508\n",
      "Epoch: 1180, Loss= 0.7472, Training Accuracy= 0.501\n",
      "Epoch: 1190, Loss= 0.7414, Training Accuracy= 0.506\n",
      "Epoch: 1200, Loss= 0.7202, Training Accuracy= 0.523\n",
      "Epoch: 1210, Loss= 0.7524, Training Accuracy= 0.501\n",
      "Epoch: 1220, Loss= 0.7506, Training Accuracy= 0.501\n",
      "Epoch: 1230, Loss= 0.7491, Training Accuracy= 0.501\n",
      "Epoch: 1240, Loss= 0.7478, Training Accuracy= 0.501\n",
      "Epoch: 1250, Loss= 0.7466, Training Accuracy= 0.501\n",
      "Epoch: 1260, Loss= 0.7456, Training Accuracy= 0.501\n",
      "Epoch: 1270, Loss= 0.7447, Training Accuracy= 0.501\n",
      "Epoch: 1280, Loss= 0.7439, Training Accuracy= 0.501\n",
      "Epoch: 1290, Loss= 0.7433, Training Accuracy= 0.501\n",
      "Epoch: 1300, Loss= 0.7427, Training Accuracy= 0.501\n",
      "Epoch: 1310, Loss= 0.7421, Training Accuracy= 0.501\n",
      "Epoch: 1320, Loss= 0.7252, Training Accuracy= 0.515\n",
      "Epoch: 1330, Loss= 0.6648, Training Accuracy= 0.543\n",
      "Epoch: 1340, Loss= 0.7078, Training Accuracy= 0.535\n",
      "Epoch: 1350, Loss= 0.3631, Training Accuracy= 0.836\n",
      "Epoch: 1360, Loss= 0.7631, Training Accuracy= 0.502\n",
      "Epoch: 1370, Loss= 0.0086, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0002, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1470, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 10, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 20, Loss= 0.6930, Training Accuracy= 0.510\n",
      "Epoch: 30, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 40, Loss= 0.6930, Training Accuracy= 0.514\n",
      "Epoch: 50, Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 60, Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 70, Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 80, Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 90, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 100, Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 110, Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 120, Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 130, Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 140, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 150, Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 160, Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 170, Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 180, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 190, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 200, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 210, Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 220, Loss= 0.6927, Training Accuracy= 0.509\n",
      "Epoch: 230, Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 240, Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 250, Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 260, Loss= 0.6925, Training Accuracy= 0.508\n",
      "Epoch: 270, Loss= 0.6925, Training Accuracy= 0.513\n",
      "Epoch: 280, Loss= 0.6925, Training Accuracy= 0.511\n",
      "Epoch: 290, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 300, Loss= 0.6924, Training Accuracy= 0.508\n",
      "Epoch: 310, Loss= 0.6924, Training Accuracy= 0.511\n",
      "Epoch: 320, Loss= 0.6924, Training Accuracy= 0.511\n",
      "Epoch: 330, Loss= 0.6924, Training Accuracy= 0.509\n",
      "Epoch: 340, Loss= 0.6924, Training Accuracy= 0.508\n",
      "Epoch: 350, Loss= 0.6924, Training Accuracy= 0.511\n",
      "Epoch: 360, Loss= 0.6923, Training Accuracy= 0.505\n",
      "Epoch: 370, Loss= 0.6923, Training Accuracy= 0.508\n",
      "Epoch: 380, Loss= 0.6923, Training Accuracy= 0.511\n",
      "Epoch: 390, Loss= 0.6923, Training Accuracy= 0.507\n",
      "Epoch: 400, Loss= 0.6923, Training Accuracy= 0.507\n",
      "Epoch: 410, Loss= 0.6923, Training Accuracy= 0.503\n",
      "Epoch: 420, Loss= 0.6922, Training Accuracy= 0.503\n",
      "Epoch: 430, Loss= 0.6922, Training Accuracy= 0.503\n",
      "Epoch: 440, Loss= 0.6922, Training Accuracy= 0.502\n",
      "Epoch: 450, Loss= 0.6922, Training Accuracy= 0.504\n",
      "Epoch: 460, Loss= 0.6922, Training Accuracy= 0.508\n",
      "Epoch: 470, Loss= 0.6921, Training Accuracy= 0.509\n",
      "Epoch: 480, Loss= 0.6921, Training Accuracy= 0.512\n",
      "Epoch: 490, Loss= 0.6921, Training Accuracy= 0.512\n",
      "Epoch: 500, Loss= 0.6921, Training Accuracy= 0.514\n",
      "Epoch: 510, Loss= 0.6920, Training Accuracy= 0.517\n",
      "Epoch: 520, Loss= 0.6920, Training Accuracy= 0.515\n",
      "Epoch: 530, Loss= 0.6920, Training Accuracy= 0.522\n",
      "Epoch: 540, Loss= 0.6919, Training Accuracy= 0.524\n",
      "Epoch: 550, Loss= 0.6919, Training Accuracy= 0.521\n",
      "Epoch: 560, Loss= 0.6918, Training Accuracy= 0.522\n",
      "Epoch: 570, Loss= 0.6917, Training Accuracy= 0.520\n",
      "Epoch: 580, Loss= 0.6917, Training Accuracy= 0.517\n",
      "Epoch: 590, Loss= 0.6916, Training Accuracy= 0.516\n",
      "Epoch: 600, Loss= 0.6915, Training Accuracy= 0.513\n",
      "Epoch: 610, Loss= 0.6914, Training Accuracy= 0.514\n",
      "Epoch: 620, Loss= 0.6913, Training Accuracy= 0.520\n",
      "Epoch: 630, Loss= 0.6912, Training Accuracy= 0.521\n",
      "Epoch: 640, Loss= 0.6911, Training Accuracy= 0.517\n",
      "Epoch: 650, Loss= 0.6910, Training Accuracy= 0.524\n",
      "Epoch: 660, Loss= 0.6909, Training Accuracy= 0.525\n",
      "Epoch: 670, Loss= 0.6906, Training Accuracy= 0.516\n",
      "Epoch: 680, Loss= 0.6900, Training Accuracy= 0.515\n",
      "Epoch: 690, Loss= 0.6743, Training Accuracy= 0.558\n",
      "Epoch: 700, Loss= 0.3398, Training Accuracy= 0.821\n",
      "Epoch: 710, Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 720, Loss= 0.6924, Training Accuracy= 0.517\n",
      "Epoch: 730, Loss= 0.6640, Training Accuracy= 0.514\n",
      "Epoch: 740, Loss= 0.6414, Training Accuracy= 0.534\n",
      "Epoch: 750, Loss= 0.5267, Training Accuracy= 0.740\n",
      "Epoch: 760, Loss= 0.3794, Training Accuracy= 0.814\n",
      "Epoch: 770, Loss= 0.2821, Training Accuracy= 0.860\n",
      "Epoch: 780, Loss= 0.1900, Training Accuracy= 0.930\n",
      "Epoch: 790, Loss= 0.1310, Training Accuracy= 0.945\n",
      "Epoch: 800, Loss= 0.0760, Training Accuracy= 0.982\n",
      "Epoch: 810, Loss= 0.0534, Training Accuracy= 0.984\n",
      "Epoch: 820, Loss= 0.6794, Training Accuracy= 0.836\n",
      "Epoch: 830, Loss= 0.1245, Training Accuracy= 0.941\n",
      "Epoch: 840, Loss= 0.0494, Training Accuracy= 0.990\n",
      "Epoch: 850, Loss= 0.0365, Training Accuracy= 0.995\n",
      "Epoch: 860, Loss= 0.0297, Training Accuracy= 0.996\n",
      "Epoch: 870, Loss= 0.0249, Training Accuracy= 0.996\n",
      "Epoch: 880, Loss= 0.0211, Training Accuracy= 0.997\n",
      "Epoch: 890, Loss= 0.0182, Training Accuracy= 0.997\n",
      "Epoch: 900, Loss= 0.0159, Training Accuracy= 0.997\n",
      "Epoch: 910, Loss= 0.0138, Training Accuracy= 0.997\n",
      "Epoch: 920, Loss= 0.0122, Training Accuracy= 0.997\n",
      "Epoch: 930, Loss= 0.0110, Training Accuracy= 0.997\n",
      "Epoch: 940, Loss= 0.6501, Training Accuracy= 0.757\n",
      "Epoch: 950, Loss= 0.1129, Training Accuracy= 0.967\n",
      "Epoch: 960, Loss= 0.0628, Training Accuracy= 0.984\n",
      "Epoch: 970, Loss= 0.0377, Training Accuracy= 0.992\n",
      "Epoch: 980, Loss= 0.0244, Training Accuracy= 0.997\n",
      "Epoch: 990, Loss= 0.0208, Training Accuracy= 0.998\n",
      "Epoch: 1000, Loss= 0.0179, Training Accuracy= 0.998\n",
      "Epoch: 1010, Loss= 0.0151, Training Accuracy= 0.998\n",
      "Epoch: 1020, Loss= 0.0129, Training Accuracy= 0.998\n",
      "Epoch: 1030, Loss= 0.0114, Training Accuracy= 0.998\n",
      "Epoch: 1040, Loss= 0.0103, Training Accuracy= 0.998\n",
      "Epoch: 1050, Loss= 0.0095, Training Accuracy= 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1060, Loss= 0.0088, Training Accuracy= 0.999\n",
      "Epoch: 1070, Loss= 0.0083, Training Accuracy= 0.999\n",
      "Epoch: 1080, Loss= 0.0078, Training Accuracy= 0.999\n",
      "Epoch: 1090, Loss= 0.0074, Training Accuracy= 0.999\n",
      "Epoch: 1100, Loss= 0.0071, Training Accuracy= 0.999\n",
      "Epoch: 1110, Loss= 0.0068, Training Accuracy= 0.999\n",
      "Epoch: 1120, Loss= 0.0065, Training Accuracy= 0.999\n",
      "Epoch: 1130, Loss= 0.0062, Training Accuracy= 0.999\n",
      "Epoch: 1140, Loss= 0.0060, Training Accuracy= 0.999\n",
      "Epoch: 1150, Loss= 0.0058, Training Accuracy= 0.999\n",
      "Epoch: 1160, Loss= 0.0056, Training Accuracy= 0.999\n",
      "Epoch: 1170, Loss= 0.0055, Training Accuracy= 0.999\n",
      "Epoch: 1180, Loss= 0.0053, Training Accuracy= 0.999\n",
      "Epoch: 1190, Loss= 0.0052, Training Accuracy= 0.999\n",
      "Epoch: 1200, Loss= 0.0051, Training Accuracy= 0.999\n",
      "Epoch: 1210, Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 1220, Loss= 0.0049, Training Accuracy= 0.999\n",
      "Epoch: 1230, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 1240, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 1250, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 1260, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 1270, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 1280, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 1290, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 1300, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 1310, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 1320, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 1330, Loss= 0.0042, Training Accuracy= 0.999\n",
      "Epoch: 1340, Loss= 0.0042, Training Accuracy= 0.999\n",
      "Epoch: 1350, Loss= 0.0041, Training Accuracy= 0.999\n",
      "Epoch: 1360, Loss= 0.0041, Training Accuracy= 0.999\n",
      "Epoch: 1370, Loss= 0.0041, Training Accuracy= 0.999\n",
      "Epoch: 1380, Loss= 0.0040, Training Accuracy= 0.999\n",
      "Epoch: 1390, Loss= 0.0040, Training Accuracy= 0.999\n",
      "Epoch: 1400, Loss= 0.0040, Training Accuracy= 0.999\n",
      "Epoch: 1410, Loss= 0.0039, Training Accuracy= 0.999\n",
      "Epoch: 1420, Loss= 0.0039, Training Accuracy= 0.999\n",
      "Epoch: 1430, Loss= 0.0039, Training Accuracy= 0.999\n",
      "Epoch: 1440, Loss= 0.0038, Training Accuracy= 0.999\n",
      "Epoch: 1450, Loss= 0.0038, Training Accuracy= 0.999\n",
      "Epoch: 1460, Loss= 0.0038, Training Accuracy= 0.999\n",
      "Epoch: 1470, Loss= 0.0037, Training Accuracy= 0.999\n",
      "Epoch: 1480, Loss= 0.0037, Training Accuracy= 0.999\n",
      "Epoch: 1490, Loss= 0.0037, Training Accuracy= 0.999\n",
      "Epoch: 1500, Loss= 0.0036, Training Accuracy= 0.999\n",
      "Epoch: 1510, Loss= 0.0036, Training Accuracy= 0.999\n",
      "Epoch: 1520, Loss= 0.0036, Training Accuracy= 0.999\n",
      "Epoch: 1530, Loss= 0.0035, Training Accuracy= 0.999\n",
      "Epoch: 1540, Loss= 0.0035, Training Accuracy= 0.999\n",
      "Epoch: 1550, Loss= 0.0034, Training Accuracy= 0.999\n",
      "Epoch: 1560, Loss= 0.0034, Training Accuracy= 0.999\n",
      "Epoch: 1570, Loss= 0.0033, Training Accuracy= 0.999\n",
      "Epoch: 1580, Loss= 0.0030, Training Accuracy= 0.999\n",
      "Epoch: 1590, Loss= 0.0026, Training Accuracy= 0.999\n",
      "Epoch: 1600, Loss= 0.0021, Training Accuracy= 0.999\n",
      "Epoch: 1610, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.35\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 2000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49579999, 1.0, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  0.94958\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.00151260003448\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x9bc273F3TefAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7733108650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
