{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 4\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Minibatch Loss= 0.6935, Training Accuracy= 0.376\n",
      "Epoch: 10, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 20, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 30, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 40, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 50, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 60, Minibatch Loss= 0.6930, Training Accuracy= 0.447\n",
      "Epoch: 70, Minibatch Loss= 0.6930, Training Accuracy= 0.447\n",
      "Epoch: 80, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 90, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 100, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 110, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 120, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 130, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 140, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 150, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 160, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 170, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 180, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 190, Minibatch Loss= 0.6930, Training Accuracy= 0.574\n",
      "Epoch: 200, Minibatch Loss= 0.6929, Training Accuracy= 0.574\n",
      "Epoch: 210, Minibatch Loss= 0.6929, Training Accuracy= 0.574\n",
      "Epoch: 220, Minibatch Loss= 0.6929, Training Accuracy= 0.574\n",
      "Epoch: 230, Minibatch Loss= 0.6929, Training Accuracy= 0.574\n",
      "Epoch: 240, Minibatch Loss= 0.6928, Training Accuracy= 0.574\n",
      "Epoch: 250, Minibatch Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 260, Minibatch Loss= 0.6907, Training Accuracy= 0.633\n",
      "Epoch: 270, Minibatch Loss= 0.1109, Training Accuracy= 0.939\n",
      "Epoch: 280, Minibatch Loss= 0.0117, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0049, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Minibatch Loss= 0.6995, Training Accuracy= 0.502\n",
      "Epoch: 10, Minibatch Loss= 0.6983, Training Accuracy= 0.502\n",
      "Epoch: 20, Minibatch Loss= 0.6977, Training Accuracy= 0.502\n",
      "Epoch: 30, Minibatch Loss= 0.6973, Training Accuracy= 0.502\n",
      "Epoch: 40, Minibatch Loss= 0.6970, Training Accuracy= 0.502\n",
      "Epoch: 50, Minibatch Loss= 0.6968, Training Accuracy= 0.502\n",
      "Epoch: 60, Minibatch Loss= 0.6966, Training Accuracy= 0.502\n",
      "Epoch: 70, Minibatch Loss= 0.6958, Training Accuracy= 0.502\n",
      "Epoch: 80, Minibatch Loss= 0.1468, Training Accuracy= 0.936\n",
      "Epoch: 90, Minibatch Loss= 0.0121, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0053, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 2: \n",
      "Epoch: 0, Minibatch Loss= 0.7326, Training Accuracy= 0.508\n",
      "Epoch: 10, Minibatch Loss= 0.7026, Training Accuracy= 0.508\n",
      "Epoch: 20, Minibatch Loss= 0.6995, Training Accuracy= 0.508\n",
      "Epoch: 30, Minibatch Loss= 0.6982, Training Accuracy= 0.508\n",
      "Epoch: 40, Minibatch Loss= 0.6975, Training Accuracy= 0.508\n",
      "Epoch: 50, Minibatch Loss= 0.6970, Training Accuracy= 0.508\n",
      "Epoch: 60, Minibatch Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 70, Minibatch Loss= 0.6964, Training Accuracy= 0.508\n",
      "Epoch: 80, Minibatch Loss= 0.6962, Training Accuracy= 0.508\n",
      "Epoch: 90, Minibatch Loss= 0.6960, Training Accuracy= 0.508\n",
      "Epoch: 100, Minibatch Loss= 0.6959, Training Accuracy= 0.508\n",
      "Epoch: 110, Minibatch Loss= 0.6953, Training Accuracy= 0.508\n",
      "Epoch: 120, Minibatch Loss= 0.2453, Training Accuracy= 0.938\n",
      "Epoch: 130, Minibatch Loss= 0.0308, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0101, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0056, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0038, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 680, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Minibatch Loss= 0.7057, Training Accuracy= 0.502\n",
      "Epoch: 10, Minibatch Loss= 0.6961, Training Accuracy= 0.502\n",
      "Epoch: 20, Minibatch Loss= 0.6949, Training Accuracy= 0.502\n",
      "Epoch: 30, Minibatch Loss= 0.6944, Training Accuracy= 0.502\n",
      "Epoch: 40, Minibatch Loss= 0.6941, Training Accuracy= 0.502\n",
      "Epoch: 50, Minibatch Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 60, Minibatch Loss= 0.6938, Training Accuracy= 0.502\n",
      "Epoch: 70, Minibatch Loss= 0.6938, Training Accuracy= 0.502\n",
      "Epoch: 80, Minibatch Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 90, Minibatch Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 100, Minibatch Loss= 0.6936, Training Accuracy= 0.502\n",
      "Epoch: 110, Minibatch Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 120, Minibatch Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 130, Minibatch Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 140, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 150, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 160, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 170, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 180, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 190, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 200, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 210, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 220, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 230, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 240, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 250, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 260, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 270, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 280, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 290, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 300, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 310, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 320, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 330, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 340, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 350, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 360, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 370, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 380, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 390, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 400, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 410, Minibatch Loss= 0.6932, Training Accuracy= 0.441\n",
      "Epoch: 420, Minibatch Loss= 0.6932, Training Accuracy= 0.441\n",
      "Epoch: 430, Minibatch Loss= 0.6932, Training Accuracy= 0.441\n",
      "Epoch: 440, Minibatch Loss= 0.6932, Training Accuracy= 0.441\n",
      "Epoch: 450, Minibatch Loss= 0.6932, Training Accuracy= 0.441\n",
      "Epoch: 460, Minibatch Loss= 0.6932, Training Accuracy= 0.441\n",
      "Epoch: 470, Minibatch Loss= 0.6932, Training Accuracy= 0.441\n",
      "Epoch: 480, Minibatch Loss= 0.6932, Training Accuracy= 0.441\n",
      "Epoch: 490, Minibatch Loss= 0.6931, Training Accuracy= 0.441\n",
      "Epoch: 500, Minibatch Loss= 0.6931, Training Accuracy= 0.441\n",
      "Epoch: 510, Minibatch Loss= 0.6931, Training Accuracy= 0.441\n",
      "Epoch: 520, Minibatch Loss= 0.6931, Training Accuracy= 0.441\n",
      "Epoch: 530, Minibatch Loss= 0.6931, Training Accuracy= 0.441\n",
      "Epoch: 540, Minibatch Loss= 0.6931, Training Accuracy= 0.441\n",
      "Epoch: 550, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 560, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 570, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 580, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 590, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 600, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 610, Minibatch Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 620, Minibatch Loss= 0.6928, Training Accuracy= 0.504\n",
      "Epoch: 630, Minibatch Loss= 0.6921, Training Accuracy= 0.569\n",
      "Epoch: 640, Minibatch Loss= 0.3810, Training Accuracy= 0.871\n",
      "Epoch: 650, Minibatch Loss= 0.0296, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0054, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Minibatch Loss= 0.6964, Training Accuracy= 0.493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Minibatch Loss= 0.6930, Training Accuracy= 0.445\n",
      "Epoch: 20, Minibatch Loss= 0.6927, Training Accuracy= 0.572\n",
      "Epoch: 30, Minibatch Loss= 0.6905, Training Accuracy= 0.449\n",
      "Epoch: 40, Minibatch Loss= 0.0732, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0043, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Minibatch Loss= 0.6990, Training Accuracy= 0.499\n",
      "Epoch: 10, Minibatch Loss= 0.6982, Training Accuracy= 0.499\n",
      "Epoch: 20, Minibatch Loss= 0.6978, Training Accuracy= 0.499\n",
      "Epoch: 30, Minibatch Loss= 0.6975, Training Accuracy= 0.499\n",
      "Epoch: 40, Minibatch Loss= 0.6973, Training Accuracy= 0.499\n",
      "Epoch: 50, Minibatch Loss= 0.6972, Training Accuracy= 0.499\n",
      "Epoch: 60, Minibatch Loss= 0.6970, Training Accuracy= 0.499\n",
      "Epoch: 70, Minibatch Loss= 0.6969, Training Accuracy= 0.499\n",
      "Epoch: 80, Minibatch Loss= 0.6968, Training Accuracy= 0.499\n",
      "Epoch: 90, Minibatch Loss= 0.6966, Training Accuracy= 0.499\n",
      "Epoch: 100, Minibatch Loss= 0.6964, Training Accuracy= 0.499\n",
      "Epoch: 110, Minibatch Loss= 0.6531, Training Accuracy= 0.636\n",
      "Epoch: 120, Minibatch Loss= 0.0183, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0052, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Minibatch Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 10, Minibatch Loss= 0.6935, Training Accuracy= 0.444\n",
      "Epoch: 20, Minibatch Loss= 0.6934, Training Accuracy= 0.444\n",
      "Epoch: 30, Minibatch Loss= 0.6933, Training Accuracy= 0.444\n",
      "Epoch: 40, Minibatch Loss= 0.6933, Training Accuracy= 0.444\n",
      "Epoch: 50, Minibatch Loss= 0.6932, Training Accuracy= 0.444\n",
      "Epoch: 60, Minibatch Loss= 0.6931, Training Accuracy= 0.444\n",
      "Epoch: 70, Minibatch Loss= 0.6929, Training Accuracy= 0.444\n",
      "Epoch: 80, Minibatch Loss= 0.6824, Training Accuracy= 0.634\n",
      "Epoch: 90, Minibatch Loss= 0.0456, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0069, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Minibatch Loss= 0.6999, Training Accuracy= 0.494\n",
      "Epoch: 10, Minibatch Loss= 0.6965, Training Accuracy= 0.494\n",
      "Epoch: 20, Minibatch Loss= 0.6956, Training Accuracy= 0.494\n",
      "Epoch: 30, Minibatch Loss= 0.6952, Training Accuracy= 0.494\n",
      "Epoch: 40, Minibatch Loss= 0.6950, Training Accuracy= 0.494\n",
      "Epoch: 50, Minibatch Loss= 0.6949, Training Accuracy= 0.494\n",
      "Epoch: 60, Minibatch Loss= 0.6948, Training Accuracy= 0.494\n",
      "Epoch: 70, Minibatch Loss= 0.6948, Training Accuracy= 0.494\n",
      "Epoch: 80, Minibatch Loss= 0.6948, Training Accuracy= 0.494\n",
      "Epoch: 90, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 100, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 110, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 120, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 130, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 140, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 150, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 160, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 170, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 180, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 190, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 200, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 210, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 220, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 230, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 240, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 250, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 260, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 270, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 280, Minibatch Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 290, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 300, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 310, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 320, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 330, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 340, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 350, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 360, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 370, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 380, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 390, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 400, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 410, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 420, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 430, Minibatch Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 440, Minibatch Loss= 0.6944, Training Accuracy= 0.494\n",
      "Epoch: 450, Minibatch Loss= 0.6563, Training Accuracy= 0.568\n",
      "Epoch: 460, Minibatch Loss= 0.0243, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0063, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0034, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 8: \n",
      "Epoch: 0, Minibatch Loss= 0.7020, Training Accuracy= 0.499\n",
      "Epoch: 10, Minibatch Loss= 0.6997, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Minibatch Loss= 0.6987, Training Accuracy= 0.499\n",
      "Epoch: 30, Minibatch Loss= 0.6981, Training Accuracy= 0.499\n",
      "Epoch: 40, Minibatch Loss= 0.6977, Training Accuracy= 0.499\n",
      "Epoch: 50, Minibatch Loss= 0.6975, Training Accuracy= 0.499\n",
      "Epoch: 60, Minibatch Loss= 0.6973, Training Accuracy= 0.499\n",
      "Epoch: 70, Minibatch Loss= 0.6972, Training Accuracy= 0.499\n",
      "Epoch: 80, Minibatch Loss= 0.6971, Training Accuracy= 0.499\n",
      "Epoch: 90, Minibatch Loss= 0.6969, Training Accuracy= 0.499\n",
      "Epoch: 100, Minibatch Loss= 0.4950, Training Accuracy= 0.625\n",
      "Epoch: 110, Minibatch Loss= 0.0154, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0046, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 360, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Minibatch Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 10, Minibatch Loss= 0.6964, Training Accuracy= 0.508\n",
      "Epoch: 20, Minibatch Loss= 0.6951, Training Accuracy= 0.508\n",
      "Epoch: 30, Minibatch Loss= 0.2237, Training Accuracy= 0.938\n",
      "Epoch: 40, Minibatch Loss= 0.0197, Training Accuracy= 1.000\n",
      "Epoch: 50, Minibatch Loss= 0.0053, Training Accuracy= 1.000\n",
      "Epoch: 60, Minibatch Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 70, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 80, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 90, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 100, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 110, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 120, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 130, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 140, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 150, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 160, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 170, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 180, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 190, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 200, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 210, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 220, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 230, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 240, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 250, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 260, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 270, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 280, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 290, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 300, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 310, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 320, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 330, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 340, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 350, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 370, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 380, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 390, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.35\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 1000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "minibatch_losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                minibatch_losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  1.0\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.0\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEoCAYAAABPQRaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ec7f15850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minibatch_losses_1st_replication\n",
    "plt.plot(minibatch_losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, minibacth loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
