{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 10\n",
    "N = 10\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Loss= 0.6974, Training Accuracy= 0.509\n",
      "Epoch: 10, Loss= 0.6940, Training Accuracy= 0.506\n",
      "Epoch: 20, Loss= 0.6939, Training Accuracy= 0.504\n",
      "Epoch: 30, Loss= 0.6938, Training Accuracy= 0.504\n",
      "Epoch: 40, Loss= 0.6938, Training Accuracy= 0.506\n",
      "Epoch: 50, Loss= 0.6937, Training Accuracy= 0.506\n",
      "Epoch: 60, Loss= 0.6937, Training Accuracy= 0.506\n",
      "Epoch: 70, Loss= 0.6936, Training Accuracy= 0.507\n",
      "Epoch: 80, Loss= 0.6936, Training Accuracy= 0.507\n",
      "Epoch: 90, Loss= 0.6936, Training Accuracy= 0.506\n",
      "Epoch: 100, Loss= 0.6935, Training Accuracy= 0.507\n",
      "Epoch: 110, Loss= 0.6935, Training Accuracy= 0.506\n",
      "Epoch: 120, Loss= 0.6935, Training Accuracy= 0.509\n",
      "Epoch: 130, Loss= 0.6934, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.6934, Training Accuracy= 0.507\n",
      "Epoch: 150, Loss= 0.6934, Training Accuracy= 0.510\n",
      "Epoch: 160, Loss= 0.6934, Training Accuracy= 0.512\n",
      "Epoch: 170, Loss= 0.6933, Training Accuracy= 0.511\n",
      "Epoch: 180, Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 190, Loss= 0.6933, Training Accuracy= 0.507\n",
      "Epoch: 200, Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 210, Loss= 0.6932, Training Accuracy= 0.514\n",
      "Epoch: 220, Loss= 0.6932, Training Accuracy= 0.516\n",
      "Epoch: 230, Loss= 0.6932, Training Accuracy= 0.516\n",
      "Epoch: 240, Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 250, Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 260, Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 270, Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 280, Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 290, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 300, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 310, Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 320, Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 330, Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 340, Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 350, Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 360, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 370, Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 380, Loss= 0.6927, Training Accuracy= 0.515\n",
      "Epoch: 390, Loss= 0.6927, Training Accuracy= 0.516\n",
      "Epoch: 400, Loss= 0.6927, Training Accuracy= 0.517\n",
      "Epoch: 410, Loss= 0.6927, Training Accuracy= 0.517\n",
      "Epoch: 420, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 430, Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 440, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 450, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 460, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 470, Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 480, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 490, Loss= 0.6925, Training Accuracy= 0.511\n",
      "Epoch: 500, Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 510, Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 520, Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 530, Loss= 0.6924, Training Accuracy= 0.517\n",
      "Epoch: 540, Loss= 0.6924, Training Accuracy= 0.517\n",
      "Epoch: 550, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 560, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 570, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 580, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 590, Loss= 0.6923, Training Accuracy= 0.522\n",
      "Epoch: 600, Loss= 0.6923, Training Accuracy= 0.522\n",
      "Epoch: 610, Loss= 0.6923, Training Accuracy= 0.523\n",
      "Epoch: 620, Loss= 0.6923, Training Accuracy= 0.526\n",
      "Epoch: 630, Loss= 0.6923, Training Accuracy= 0.526\n",
      "Epoch: 640, Loss= 0.6922, Training Accuracy= 0.527\n",
      "Epoch: 650, Loss= 0.6922, Training Accuracy= 0.527\n",
      "Epoch: 660, Loss= 0.6922, Training Accuracy= 0.524\n",
      "Epoch: 670, Loss= 0.6922, Training Accuracy= 0.527\n",
      "Epoch: 680, Loss= 0.6922, Training Accuracy= 0.527\n",
      "Epoch: 690, Loss= 0.6922, Training Accuracy= 0.526\n",
      "Epoch: 700, Loss= 0.6921, Training Accuracy= 0.527\n",
      "Epoch: 710, Loss= 0.6921, Training Accuracy= 0.527\n",
      "Epoch: 720, Loss= 0.6921, Training Accuracy= 0.526\n",
      "Epoch: 730, Loss= 0.6921, Training Accuracy= 0.525\n",
      "Epoch: 740, Loss= 0.6921, Training Accuracy= 0.524\n",
      "Epoch: 750, Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 760, Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 770, Loss= 0.6920, Training Accuracy= 0.523\n",
      "Epoch: 780, Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 790, Loss= 0.6920, Training Accuracy= 0.525\n",
      "Epoch: 800, Loss= 0.6919, Training Accuracy= 0.524\n",
      "Epoch: 810, Loss= 0.6919, Training Accuracy= 0.525\n",
      "Epoch: 820, Loss= 0.6919, Training Accuracy= 0.525\n",
      "Epoch: 830, Loss= 0.6919, Training Accuracy= 0.527\n",
      "Epoch: 840, Loss= 0.6918, Training Accuracy= 0.529\n",
      "Epoch: 850, Loss= 0.6918, Training Accuracy= 0.530\n",
      "Epoch: 860, Loss= 0.6918, Training Accuracy= 0.529\n",
      "Epoch: 870, Loss= 0.6917, Training Accuracy= 0.531\n",
      "Epoch: 880, Loss= 0.6917, Training Accuracy= 0.529\n",
      "Epoch: 890, Loss= 0.6917, Training Accuracy= 0.529\n",
      "Epoch: 900, Loss= 0.6916, Training Accuracy= 0.528\n",
      "Epoch: 910, Loss= 0.6916, Training Accuracy= 0.528\n",
      "Epoch: 920, Loss= 0.6915, Training Accuracy= 0.529\n",
      "Epoch: 930, Loss= 0.6915, Training Accuracy= 0.527\n",
      "Epoch: 940, Loss= 0.6914, Training Accuracy= 0.528\n",
      "Epoch: 950, Loss= 0.6914, Training Accuracy= 0.527\n",
      "Epoch: 960, Loss= 0.6913, Training Accuracy= 0.526\n",
      "Epoch: 970, Loss= 0.6913, Training Accuracy= 0.528\n",
      "Epoch: 980, Loss= 0.6912, Training Accuracy= 0.528\n",
      "Epoch: 990, Loss= 0.6912, Training Accuracy= 0.526\n",
      "Epoch: 1000, Loss= 0.6911, Training Accuracy= 0.526\n",
      "Epoch: 1010, Loss= 0.6910, Training Accuracy= 0.525\n",
      "Epoch: 1020, Loss= 0.6910, Training Accuracy= 0.524\n",
      "Epoch: 1030, Loss= 0.6909, Training Accuracy= 0.525\n",
      "Epoch: 1040, Loss= 0.6908, Training Accuracy= 0.524\n",
      "Epoch: 1050, Loss= 0.6908, Training Accuracy= 0.525\n",
      "Epoch: 1060, Loss= 0.6907, Training Accuracy= 0.528\n",
      "Epoch: 1070, Loss= 0.6906, Training Accuracy= 0.529\n",
      "Epoch: 1080, Loss= 0.6906, Training Accuracy= 0.530\n",
      "Epoch: 1090, Loss= 0.6905, Training Accuracy= 0.530\n",
      "Epoch: 1100, Loss= 0.6905, Training Accuracy= 0.530\n",
      "Epoch: 1110, Loss= 0.6904, Training Accuracy= 0.532\n",
      "Epoch: 1120, Loss= 0.6904, Training Accuracy= 0.533\n",
      "Epoch: 1130, Loss= 0.6903, Training Accuracy= 0.533\n",
      "Epoch: 1140, Loss= 0.6902, Training Accuracy= 0.532\n",
      "Epoch: 1150, Loss= 0.6902, Training Accuracy= 0.532\n",
      "Epoch: 1160, Loss= 0.6901, Training Accuracy= 0.536\n",
      "Epoch: 1170, Loss= 0.6901, Training Accuracy= 0.532\n",
      "Epoch: 1180, Loss= 0.6900, Training Accuracy= 0.532\n",
      "Epoch: 1190, Loss= 0.6900, Training Accuracy= 0.532\n",
      "Epoch: 1200, Loss= 0.6899, Training Accuracy= 0.534\n",
      "Epoch: 1210, Loss= 0.6899, Training Accuracy= 0.532\n",
      "Epoch: 1220, Loss= 0.6898, Training Accuracy= 0.533\n",
      "Epoch: 1230, Loss= 0.6898, Training Accuracy= 0.533\n",
      "Epoch: 1240, Loss= 0.6897, Training Accuracy= 0.532\n",
      "Epoch: 1250, Loss= 0.6897, Training Accuracy= 0.532\n",
      "Epoch: 1260, Loss= 0.6896, Training Accuracy= 0.531\n",
      "Epoch: 1270, Loss= 0.6896, Training Accuracy= 0.527\n",
      "Epoch: 1280, Loss= 0.6895, Training Accuracy= 0.524\n",
      "Epoch: 1290, Loss= 0.6895, Training Accuracy= 0.521\n",
      "Epoch: 1300, Loss= 0.6894, Training Accuracy= 0.523\n",
      "Epoch: 1310, Loss= 0.6894, Training Accuracy= 0.525\n",
      "Epoch: 1320, Loss= 0.6893, Training Accuracy= 0.525\n",
      "Epoch: 1330, Loss= 0.6893, Training Accuracy= 0.524\n",
      "Epoch: 1340, Loss= 0.6892, Training Accuracy= 0.526\n",
      "Epoch: 1350, Loss= 0.6892, Training Accuracy= 0.525\n",
      "Epoch: 1360, Loss= 0.6891, Training Accuracy= 0.529\n",
      "Epoch: 1370, Loss= 0.6891, Training Accuracy= 0.527\n",
      "Epoch: 1380, Loss= 0.6890, Training Accuracy= 0.530\n",
      "Epoch: 1390, Loss= 0.6890, Training Accuracy= 0.531\n",
      "Epoch: 1400, Loss= 0.6889, Training Accuracy= 0.532\n",
      "Epoch: 1410, Loss= 0.6889, Training Accuracy= 0.532\n",
      "Epoch: 1420, Loss= 0.6888, Training Accuracy= 0.530\n",
      "Epoch: 1430, Loss= 0.6888, Training Accuracy= 0.532\n",
      "Epoch: 1440, Loss= 0.6887, Training Accuracy= 0.532\n",
      "Epoch: 1450, Loss= 0.6887, Training Accuracy= 0.532\n",
      "Epoch: 1460, Loss= 0.6886, Training Accuracy= 0.530\n",
      "Epoch: 1470, Loss= 0.6886, Training Accuracy= 0.530\n",
      "Epoch: 1480, Loss= 0.6885, Training Accuracy= 0.529\n",
      "Epoch: 1490, Loss= 0.6884, Training Accuracy= 0.528\n",
      "Epoch: 1500, Loss= 0.6884, Training Accuracy= 0.528\n",
      "Epoch: 1510, Loss= 0.6883, Training Accuracy= 0.529\n",
      "Epoch: 1520, Loss= 0.6882, Training Accuracy= 0.529\n",
      "Epoch: 1530, Loss= 0.6882, Training Accuracy= 0.529\n",
      "Epoch: 1540, Loss= 0.6881, Training Accuracy= 0.532\n",
      "Epoch: 1550, Loss= 0.6880, Training Accuracy= 0.534\n",
      "Epoch: 1560, Loss= 0.6879, Training Accuracy= 0.532\n",
      "Epoch: 1570, Loss= 0.6878, Training Accuracy= 0.534\n",
      "Epoch: 1580, Loss= 0.6878, Training Accuracy= 0.534\n",
      "Epoch: 1590, Loss= 0.6877, Training Accuracy= 0.534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600, Loss= 0.6876, Training Accuracy= 0.535\n",
      "Epoch: 1610, Loss= 0.6875, Training Accuracy= 0.537\n",
      "Epoch: 1620, Loss= 0.6874, Training Accuracy= 0.539\n",
      "Epoch: 1630, Loss= 0.6873, Training Accuracy= 0.540\n",
      "Epoch: 1640, Loss= 0.6872, Training Accuracy= 0.540\n",
      "Epoch: 1650, Loss= 0.6871, Training Accuracy= 0.538\n",
      "Epoch: 1660, Loss= 0.6869, Training Accuracy= 0.538\n",
      "Epoch: 1670, Loss= 0.6868, Training Accuracy= 0.538\n",
      "Epoch: 1680, Loss= 0.6867, Training Accuracy= 0.538\n",
      "Epoch: 1690, Loss= 0.6865, Training Accuracy= 0.538\n",
      "Epoch: 1700, Loss= 0.6864, Training Accuracy= 0.539\n",
      "Epoch: 1710, Loss= 0.6862, Training Accuracy= 0.534\n",
      "Epoch: 1720, Loss= 0.6861, Training Accuracy= 0.537\n",
      "Epoch: 1730, Loss= 0.6859, Training Accuracy= 0.540\n",
      "Epoch: 1740, Loss= 0.6857, Training Accuracy= 0.539\n",
      "Epoch: 1750, Loss= 0.6856, Training Accuracy= 0.538\n",
      "Epoch: 1760, Loss= 0.6854, Training Accuracy= 0.537\n",
      "Epoch: 1770, Loss= 0.6852, Training Accuracy= 0.541\n",
      "Epoch: 1780, Loss= 0.6849, Training Accuracy= 0.543\n",
      "Epoch: 1790, Loss= 0.6847, Training Accuracy= 0.546\n",
      "Epoch: 1800, Loss= 0.6845, Training Accuracy= 0.544\n",
      "Epoch: 1810, Loss= 0.6842, Training Accuracy= 0.546\n",
      "Epoch: 1820, Loss= 0.6839, Training Accuracy= 0.543\n",
      "Epoch: 1830, Loss= 0.6836, Training Accuracy= 0.549\n",
      "Epoch: 1840, Loss= 0.6833, Training Accuracy= 0.545\n",
      "Epoch: 1850, Loss= 0.6829, Training Accuracy= 0.547\n",
      "Epoch: 1860, Loss= 0.6824, Training Accuracy= 0.551\n",
      "Epoch: 1870, Loss= 0.6818, Training Accuracy= 0.548\n",
      "Epoch: 1880, Loss= 0.6810, Training Accuracy= 0.549\n",
      "Epoch: 1890, Loss= 0.6799, Training Accuracy= 0.554\n",
      "Epoch: 1900, Loss= 0.6778, Training Accuracy= 0.570\n",
      "Epoch: 1910, Loss= 0.6735, Training Accuracy= 0.592\n",
      "Epoch: 1920, Loss= 0.6563, Training Accuracy= 0.637\n",
      "Epoch: 1930, Loss= 0.5624, Training Accuracy= 0.783\n",
      "Epoch: 1940, Loss= 0.4271, Training Accuracy= 0.875\n",
      "Epoch: 1950, Loss= 0.3510, Training Accuracy= 0.889\n",
      "Epoch: 1960, Loss= 0.2727, Training Accuracy= 0.926\n",
      "Epoch: 1970, Loss= 0.2615, Training Accuracy= 0.923\n",
      "Epoch: 1980, Loss= 0.2613, Training Accuracy= 0.919\n",
      "Epoch: 1990, Loss= 0.2743, Training Accuracy= 0.909\n",
      "Epoch: 2000, Loss= 0.3028, Training Accuracy= 0.892\n",
      "Epoch: 2010, Loss= 0.3513, Training Accuracy= 0.870\n",
      "Epoch: 2020, Loss= 0.1963, Training Accuracy= 0.933\n",
      "Epoch: 2030, Loss= 0.1762, Training Accuracy= 0.938\n",
      "Epoch: 2040, Loss= 0.2384, Training Accuracy= 0.910\n",
      "Epoch: 2050, Loss= 0.1821, Training Accuracy= 0.931\n",
      "Epoch: 2060, Loss= 0.1429, Training Accuracy= 0.955\n",
      "Epoch: 2070, Loss= 0.1058, Training Accuracy= 0.976\n",
      "Epoch: 2080, Loss= 0.0956, Training Accuracy= 0.977\n",
      "Epoch: 2090, Loss= 0.0880, Training Accuracy= 0.978\n",
      "Epoch: 2100, Loss= 0.0838, Training Accuracy= 0.978\n",
      "Epoch: 2110, Loss= 0.0836, Training Accuracy= 0.973\n",
      "Epoch: 2120, Loss= 0.0594, Training Accuracy= 0.986\n",
      "Epoch: 2130, Loss= 0.0515, Training Accuracy= 0.989\n",
      "Epoch: 2140, Loss= 0.1345, Training Accuracy= 0.971\n",
      "Epoch: 2150, Loss= 0.0235, Training Accuracy= 0.999\n",
      "Epoch: 2160, Loss= 0.0189, Training Accuracy= 0.999\n",
      "Epoch: 2170, Loss= 0.0162, Training Accuracy= 0.999\n",
      "Epoch: 2180, Loss= 0.0141, Training Accuracy= 0.999\n",
      "Epoch: 2190, Loss= 0.0121, Training Accuracy= 0.999\n",
      "Epoch: 2200, Loss= 0.0106, Training Accuracy= 0.999\n",
      "Epoch: 2210, Loss= 0.0095, Training Accuracy= 1.000\n",
      "Epoch: 2220, Loss= 0.0087, Training Accuracy= 1.000\n",
      "Epoch: 2230, Loss= 0.0081, Training Accuracy= 1.000\n",
      "Epoch: 2240, Loss= 0.0076, Training Accuracy= 1.000\n",
      "Epoch: 2250, Loss= 0.0071, Training Accuracy= 1.000\n",
      "Epoch: 2260, Loss= 0.0068, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0064, Training Accuracy= 1.000\n",
      "Epoch: 2280, Loss= 0.0061, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0058, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0056, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0054, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0052, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0050, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0048, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0047, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0045, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0044, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0042, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0040, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0039, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0038, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0036, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0034, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0032, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0032, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Loss= 0.6993, Training Accuracy= 0.525\n",
      "Epoch: 10, Loss= 0.6922, Training Accuracy= 0.545\n",
      "Epoch: 20, Loss= 0.6859, Training Accuracy= 0.565\n",
      "Epoch: 30, Loss= 0.6347, Training Accuracy= 0.654\n",
      "Epoch: 40, Loss= 0.5367, Training Accuracy= 0.725\n",
      "Epoch: 50, Loss= 0.4054, Training Accuracy= 0.871\n",
      "Epoch: 60, Loss= 0.3176, Training Accuracy= 0.889\n",
      "Epoch: 70, Loss= 0.2691, Training Accuracy= 0.901\n",
      "Epoch: 80, Loss= 0.2368, Training Accuracy= 0.901\n",
      "Epoch: 90, Loss= 0.2122, Training Accuracy= 0.906\n",
      "Epoch: 100, Loss= 0.1907, Training Accuracy= 0.908\n",
      "Epoch: 110, Loss= 0.1700, Training Accuracy= 0.921\n",
      "Epoch: 120, Loss= 0.1519, Training Accuracy= 0.924\n",
      "Epoch: 130, Loss= 0.1369, Training Accuracy= 0.933\n",
      "Epoch: 140, Loss= 0.1248, Training Accuracy= 0.955\n",
      "Epoch: 150, Loss= 0.1150, Training Accuracy= 0.967\n",
      "Epoch: 160, Loss= 0.1073, Training Accuracy= 0.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170, Loss= 0.1010, Training Accuracy= 0.970\n",
      "Epoch: 180, Loss= 0.0952, Training Accuracy= 0.969\n",
      "Epoch: 190, Loss= 0.0892, Training Accuracy= 0.978\n",
      "Epoch: 200, Loss= 0.0828, Training Accuracy= 0.977\n",
      "Epoch: 210, Loss= 0.0777, Training Accuracy= 0.977\n",
      "Epoch: 220, Loss= 0.0737, Training Accuracy= 0.977\n",
      "Epoch: 230, Loss= 0.0705, Training Accuracy= 0.976\n",
      "Epoch: 240, Loss= 0.0677, Training Accuracy= 0.977\n",
      "Epoch: 250, Loss= 0.0653, Training Accuracy= 0.979\n",
      "Epoch: 260, Loss= 0.0632, Training Accuracy= 0.985\n",
      "Epoch: 270, Loss= 0.0613, Training Accuracy= 0.985\n",
      "Epoch: 280, Loss= 0.0597, Training Accuracy= 0.985\n",
      "Epoch: 290, Loss= 0.0582, Training Accuracy= 0.985\n",
      "Epoch: 300, Loss= 0.0569, Training Accuracy= 0.985\n",
      "Epoch: 310, Loss= 0.0556, Training Accuracy= 0.985\n",
      "Epoch: 320, Loss= 0.0545, Training Accuracy= 0.985\n",
      "Epoch: 330, Loss= 0.0535, Training Accuracy= 0.985\n",
      "Epoch: 340, Loss= 0.0526, Training Accuracy= 0.985\n",
      "Epoch: 350, Loss= 0.0517, Training Accuracy= 0.985\n",
      "Epoch: 360, Loss= 0.0509, Training Accuracy= 0.985\n",
      "Epoch: 370, Loss= 0.0502, Training Accuracy= 0.985\n",
      "Epoch: 380, Loss= 0.0495, Training Accuracy= 0.985\n",
      "Epoch: 390, Loss= 0.0489, Training Accuracy= 0.985\n",
      "Epoch: 400, Loss= 0.0482, Training Accuracy= 0.985\n",
      "Epoch: 410, Loss= 0.0476, Training Accuracy= 0.985\n",
      "Epoch: 420, Loss= 0.0470, Training Accuracy= 0.985\n",
      "Epoch: 430, Loss= 0.0465, Training Accuracy= 0.985\n",
      "Epoch: 440, Loss= 0.0459, Training Accuracy= 0.985\n",
      "Epoch: 450, Loss= 0.0454, Training Accuracy= 0.985\n",
      "Epoch: 460, Loss= 0.0448, Training Accuracy= 0.985\n",
      "Epoch: 470, Loss= 0.0441, Training Accuracy= 0.985\n",
      "Epoch: 480, Loss= 0.0434, Training Accuracy= 0.985\n",
      "Epoch: 490, Loss= 0.0426, Training Accuracy= 0.985\n",
      "Epoch: 500, Loss= 0.0416, Training Accuracy= 0.985\n",
      "Epoch: 510, Loss= 0.0404, Training Accuracy= 0.985\n",
      "Epoch: 520, Loss= 0.0390, Training Accuracy= 0.985\n",
      "Epoch: 530, Loss= 0.0376, Training Accuracy= 0.987\n",
      "Epoch: 540, Loss= 0.0362, Training Accuracy= 0.987\n",
      "Epoch: 550, Loss= 0.0348, Training Accuracy= 0.987\n",
      "Epoch: 560, Loss= 0.0334, Training Accuracy= 0.987\n",
      "Epoch: 570, Loss= 0.0321, Training Accuracy= 0.987\n",
      "Epoch: 580, Loss= 0.0307, Training Accuracy= 0.987\n",
      "Epoch: 590, Loss= 0.0294, Training Accuracy= 0.987\n",
      "Epoch: 600, Loss= 0.0282, Training Accuracy= 0.995\n",
      "Epoch: 610, Loss= 0.0270, Training Accuracy= 0.995\n",
      "Epoch: 620, Loss= 0.0258, Training Accuracy= 0.995\n",
      "Epoch: 630, Loss= 0.0248, Training Accuracy= 0.995\n",
      "Epoch: 640, Loss= 0.0237, Training Accuracy= 0.995\n",
      "Epoch: 650, Loss= 0.0228, Training Accuracy= 0.996\n",
      "Epoch: 660, Loss= 0.0219, Training Accuracy= 0.996\n",
      "Epoch: 670, Loss= 0.0210, Training Accuracy= 0.996\n",
      "Epoch: 680, Loss= 0.0202, Training Accuracy= 0.996\n",
      "Epoch: 690, Loss= 0.0195, Training Accuracy= 0.996\n",
      "Epoch: 700, Loss= 0.0188, Training Accuracy= 0.996\n",
      "Epoch: 710, Loss= 0.0182, Training Accuracy= 0.996\n",
      "Epoch: 720, Loss= 0.0176, Training Accuracy= 0.996\n",
      "Epoch: 730, Loss= 0.0171, Training Accuracy= 0.996\n",
      "Epoch: 740, Loss= 0.0166, Training Accuracy= 0.996\n",
      "Epoch: 750, Loss= 0.0161, Training Accuracy= 0.996\n",
      "Epoch: 760, Loss= 0.0157, Training Accuracy= 0.996\n",
      "Epoch: 770, Loss= 0.0152, Training Accuracy= 0.996\n",
      "Epoch: 780, Loss= 0.0149, Training Accuracy= 0.997\n",
      "Epoch: 790, Loss= 0.0145, Training Accuracy= 0.997\n",
      "Epoch: 800, Loss= 0.0142, Training Accuracy= 0.997\n",
      "Epoch: 810, Loss= 0.0139, Training Accuracy= 0.998\n",
      "Epoch: 820, Loss= 0.0136, Training Accuracy= 0.998\n",
      "Epoch: 830, Loss= 0.0133, Training Accuracy= 0.998\n",
      "Epoch: 840, Loss= 0.0130, Training Accuracy= 0.998\n",
      "Epoch: 850, Loss= 0.0128, Training Accuracy= 0.998\n",
      "Epoch: 860, Loss= 0.0125, Training Accuracy= 0.998\n",
      "Epoch: 870, Loss= 0.0123, Training Accuracy= 0.998\n",
      "Epoch: 880, Loss= 0.0121, Training Accuracy= 0.998\n",
      "Epoch: 890, Loss= 0.0119, Training Accuracy= 0.998\n",
      "Epoch: 900, Loss= 0.0117, Training Accuracy= 0.998\n",
      "Epoch: 910, Loss= 0.0115, Training Accuracy= 0.998\n",
      "Epoch: 920, Loss= 0.0114, Training Accuracy= 0.998\n",
      "Epoch: 930, Loss= 0.0112, Training Accuracy= 0.998\n",
      "Epoch: 940, Loss= 0.0110, Training Accuracy= 0.998\n",
      "Epoch: 950, Loss= 0.0109, Training Accuracy= 0.998\n",
      "Epoch: 960, Loss= 0.0107, Training Accuracy= 0.998\n",
      "Epoch: 970, Loss= 0.0106, Training Accuracy= 0.998\n",
      "Epoch: 980, Loss= 0.0105, Training Accuracy= 0.998\n",
      "Epoch: 990, Loss= 0.0103, Training Accuracy= 0.998\n",
      "Epoch: 1000, Loss= 0.0102, Training Accuracy= 0.998\n",
      "Epoch: 1010, Loss= 0.0101, Training Accuracy= 0.998\n",
      "Epoch: 1020, Loss= 0.0100, Training Accuracy= 0.998\n",
      "Epoch: 1030, Loss= 0.0099, Training Accuracy= 0.998\n",
      "Epoch: 1040, Loss= 0.0097, Training Accuracy= 0.998\n",
      "Epoch: 1050, Loss= 0.0096, Training Accuracy= 0.998\n",
      "Epoch: 1060, Loss= 0.0095, Training Accuracy= 0.998\n",
      "Epoch: 1070, Loss= 0.0094, Training Accuracy= 0.998\n",
      "Epoch: 1080, Loss= 0.0093, Training Accuracy= 0.998\n",
      "Epoch: 1090, Loss= 0.0093, Training Accuracy= 0.998\n",
      "Epoch: 1100, Loss= 0.0092, Training Accuracy= 0.998\n",
      "Epoch: 1110, Loss= 0.0091, Training Accuracy= 0.998\n",
      "Epoch: 1120, Loss= 0.0090, Training Accuracy= 0.998\n",
      "Epoch: 1130, Loss= 0.0089, Training Accuracy= 0.998\n",
      "Epoch: 1140, Loss= 0.0088, Training Accuracy= 0.998\n",
      "Epoch: 1150, Loss= 0.0087, Training Accuracy= 0.998\n",
      "Epoch: 1160, Loss= 0.0087, Training Accuracy= 0.998\n",
      "Epoch: 1170, Loss= 0.0086, Training Accuracy= 0.998\n",
      "Epoch: 1180, Loss= 0.0085, Training Accuracy= 0.998\n",
      "Epoch: 1190, Loss= 0.0085, Training Accuracy= 0.998\n",
      "Epoch: 1200, Loss= 0.0084, Training Accuracy= 0.998\n",
      "Epoch: 1210, Loss= 0.0083, Training Accuracy= 0.998\n",
      "Epoch: 1220, Loss= 0.0082, Training Accuracy= 0.998\n",
      "Epoch: 1230, Loss= 0.0082, Training Accuracy= 0.998\n",
      "Epoch: 1240, Loss= 0.0081, Training Accuracy= 0.998\n",
      "Epoch: 1250, Loss= 0.0081, Training Accuracy= 0.998\n",
      "Epoch: 1260, Loss= 0.0080, Training Accuracy= 0.998\n",
      "Epoch: 1270, Loss= 0.0079, Training Accuracy= 0.998\n",
      "Epoch: 1280, Loss= 0.0079, Training Accuracy= 0.998\n",
      "Epoch: 1290, Loss= 0.0078, Training Accuracy= 0.998\n",
      "Epoch: 1300, Loss= 0.0078, Training Accuracy= 0.998\n",
      "Epoch: 1310, Loss= 0.0077, Training Accuracy= 0.998\n",
      "Epoch: 1320, Loss= 0.0077, Training Accuracy= 0.998\n",
      "Epoch: 1330, Loss= 0.0076, Training Accuracy= 0.998\n",
      "Epoch: 1340, Loss= 0.0076, Training Accuracy= 0.998\n",
      "Epoch: 1350, Loss= 0.0075, Training Accuracy= 0.998\n",
      "Epoch: 1360, Loss= 0.0075, Training Accuracy= 0.998\n",
      "Epoch: 1370, Loss= 0.0074, Training Accuracy= 0.998\n",
      "Epoch: 1380, Loss= 0.0074, Training Accuracy= 0.998\n",
      "Epoch: 1390, Loss= 0.0073, Training Accuracy= 0.998\n",
      "Epoch: 1400, Loss= 0.0073, Training Accuracy= 0.998\n",
      "Epoch: 1410, Loss= 0.0072, Training Accuracy= 0.998\n",
      "Epoch: 1420, Loss= 0.0072, Training Accuracy= 0.998\n",
      "Epoch: 1430, Loss= 0.0071, Training Accuracy= 0.998\n",
      "Epoch: 1440, Loss= 0.0071, Training Accuracy= 0.998\n",
      "Epoch: 1450, Loss= 0.0070, Training Accuracy= 0.998\n",
      "Epoch: 1460, Loss= 0.0070, Training Accuracy= 0.998\n",
      "Epoch: 1470, Loss= 0.0070, Training Accuracy= 0.998\n",
      "Epoch: 1480, Loss= 0.0069, Training Accuracy= 0.998\n",
      "Epoch: 1490, Loss= 0.0069, Training Accuracy= 0.998\n",
      "Epoch: 1500, Loss= 0.0068, Training Accuracy= 0.998\n",
      "Epoch: 1510, Loss= 0.0068, Training Accuracy= 0.998\n",
      "Epoch: 1520, Loss= 0.0068, Training Accuracy= 0.998\n",
      "Epoch: 1530, Loss= 0.0067, Training Accuracy= 0.998\n",
      "Epoch: 1540, Loss= 0.0067, Training Accuracy= 0.998\n",
      "Epoch: 1550, Loss= 0.0067, Training Accuracy= 0.998\n",
      "Epoch: 1560, Loss= 0.0066, Training Accuracy= 0.998\n",
      "Epoch: 1570, Loss= 0.0066, Training Accuracy= 0.998\n",
      "Epoch: 1580, Loss= 0.0065, Training Accuracy= 0.998\n",
      "Epoch: 1590, Loss= 0.0065, Training Accuracy= 0.998\n",
      "Epoch: 1600, Loss= 0.0065, Training Accuracy= 0.998\n",
      "Epoch: 1610, Loss= 0.0064, Training Accuracy= 0.998\n",
      "Epoch: 1620, Loss= 0.0064, Training Accuracy= 0.998\n",
      "Epoch: 1630, Loss= 0.0064, Training Accuracy= 0.998\n",
      "Epoch: 1640, Loss= 0.0064, Training Accuracy= 0.998\n",
      "Epoch: 1650, Loss= 0.0063, Training Accuracy= 0.998\n",
      "Epoch: 1660, Loss= 0.0063, Training Accuracy= 0.999\n",
      "Epoch: 1670, Loss= 0.0063, Training Accuracy= 0.999\n",
      "Epoch: 1680, Loss= 0.0062, Training Accuracy= 0.999\n",
      "Epoch: 1690, Loss= 0.0062, Training Accuracy= 0.999\n",
      "Epoch: 1700, Loss= 0.0062, Training Accuracy= 0.999\n",
      "Epoch: 1710, Loss= 0.0061, Training Accuracy= 0.999\n",
      "Epoch: 1720, Loss= 0.0061, Training Accuracy= 0.999\n",
      "Epoch: 1730, Loss= 0.0061, Training Accuracy= 0.999\n",
      "Epoch: 1740, Loss= 0.0061, Training Accuracy= 0.999\n",
      "Epoch: 1750, Loss= 0.0060, Training Accuracy= 0.999\n",
      "Epoch: 1760, Loss= 0.0060, Training Accuracy= 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1770, Loss= 0.0060, Training Accuracy= 0.999\n",
      "Epoch: 1780, Loss= 0.0059, Training Accuracy= 0.999\n",
      "Epoch: 1790, Loss= 0.0059, Training Accuracy= 0.999\n",
      "Epoch: 1800, Loss= 0.0059, Training Accuracy= 0.999\n",
      "Epoch: 1810, Loss= 0.0059, Training Accuracy= 0.999\n",
      "Epoch: 1820, Loss= 0.0058, Training Accuracy= 0.999\n",
      "Epoch: 1830, Loss= 0.0058, Training Accuracy= 0.999\n",
      "Epoch: 1840, Loss= 0.0058, Training Accuracy= 0.999\n",
      "Epoch: 1850, Loss= 0.0058, Training Accuracy= 0.999\n",
      "Epoch: 1860, Loss= 0.0057, Training Accuracy= 0.999\n",
      "Epoch: 1870, Loss= 0.0057, Training Accuracy= 0.999\n",
      "Epoch: 1880, Loss= 0.0057, Training Accuracy= 0.999\n",
      "Epoch: 1890, Loss= 0.0057, Training Accuracy= 0.999\n",
      "Epoch: 1900, Loss= 0.0057, Training Accuracy= 0.999\n",
      "Epoch: 1910, Loss= 0.0056, Training Accuracy= 0.999\n",
      "Epoch: 1920, Loss= 0.0056, Training Accuracy= 0.999\n",
      "Epoch: 1930, Loss= 0.0056, Training Accuracy= 0.999\n",
      "Epoch: 1940, Loss= 0.0056, Training Accuracy= 0.999\n",
      "Epoch: 1950, Loss= 0.0055, Training Accuracy= 0.999\n",
      "Epoch: 1960, Loss= 0.0055, Training Accuracy= 0.999\n",
      "Epoch: 1970, Loss= 0.0055, Training Accuracy= 0.999\n",
      "Epoch: 1980, Loss= 0.0055, Training Accuracy= 0.999\n",
      "Epoch: 1990, Loss= 0.0055, Training Accuracy= 0.999\n",
      "Epoch: 2000, Loss= 0.0054, Training Accuracy= 0.999\n",
      "Epoch: 2010, Loss= 0.0054, Training Accuracy= 0.999\n",
      "Epoch: 2020, Loss= 0.0054, Training Accuracy= 0.999\n",
      "Epoch: 2030, Loss= 0.0054, Training Accuracy= 0.999\n",
      "Epoch: 2040, Loss= 0.0054, Training Accuracy= 0.999\n",
      "Epoch: 2050, Loss= 0.0053, Training Accuracy= 0.999\n",
      "Epoch: 2060, Loss= 0.0053, Training Accuracy= 0.999\n",
      "Epoch: 2070, Loss= 0.0053, Training Accuracy= 0.999\n",
      "Epoch: 2080, Loss= 0.0053, Training Accuracy= 0.999\n",
      "Epoch: 2090, Loss= 0.0053, Training Accuracy= 0.999\n",
      "Epoch: 2100, Loss= 0.0053, Training Accuracy= 0.999\n",
      "Epoch: 2110, Loss= 0.0052, Training Accuracy= 0.999\n",
      "Epoch: 2120, Loss= 0.0052, Training Accuracy= 0.999\n",
      "Epoch: 2130, Loss= 0.0052, Training Accuracy= 0.999\n",
      "Epoch: 2140, Loss= 0.0052, Training Accuracy= 0.999\n",
      "Epoch: 2150, Loss= 0.0052, Training Accuracy= 0.999\n",
      "Epoch: 2160, Loss= 0.0051, Training Accuracy= 0.999\n",
      "Epoch: 2170, Loss= 0.0051, Training Accuracy= 0.999\n",
      "Epoch: 2180, Loss= 0.0051, Training Accuracy= 0.999\n",
      "Epoch: 2190, Loss= 0.0051, Training Accuracy= 0.999\n",
      "Epoch: 2200, Loss= 0.0051, Training Accuracy= 0.999\n",
      "Epoch: 2210, Loss= 0.0051, Training Accuracy= 0.999\n",
      "Epoch: 2220, Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 2230, Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 2240, Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 2250, Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 2260, Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 2270, Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 2280, Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 2290, Loss= 0.0049, Training Accuracy= 0.999\n",
      "Epoch: 2300, Loss= 0.0049, Training Accuracy= 0.999\n",
      "Epoch: 2310, Loss= 0.0049, Training Accuracy= 0.999\n",
      "Epoch: 2320, Loss= 0.0049, Training Accuracy= 0.999\n",
      "Epoch: 2330, Loss= 0.0049, Training Accuracy= 0.999\n",
      "Epoch: 2340, Loss= 0.0049, Training Accuracy= 0.999\n",
      "Epoch: 2350, Loss= 0.0049, Training Accuracy= 0.999\n",
      "Epoch: 2360, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 2370, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 2380, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 2390, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 2400, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 2410, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 2420, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 2430, Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 2440, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 2450, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 2460, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 2470, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 2480, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 2490, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 2500, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 2510, Loss= 0.0047, Training Accuracy= 0.999\n",
      "Epoch: 2520, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 2530, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 2540, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 2550, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 2560, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 2570, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 2580, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 2590, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 2600, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 2610, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 2620, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 2630, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 2640, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 2650, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 2660, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 2670, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 2680, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 2690, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 2700, Loss= 0.0045, Training Accuracy= 0.999\n",
      "Epoch: 2710, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2720, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2730, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2740, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2750, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2760, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2770, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2780, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2790, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2800, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2810, Loss= 0.0044, Training Accuracy= 0.999\n",
      "Epoch: 2820, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2830, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2840, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2850, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2860, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2870, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2880, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2890, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2900, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2910, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2920, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2930, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2940, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 2950, Loss= 0.0042, Training Accuracy= 0.999\n",
      "Epoch: 2960, Loss= 0.0042, Training Accuracy= 0.999\n",
      "Epoch: 2970, Loss= 0.0042, Training Accuracy= 0.999\n",
      "Epoch: 2980, Loss= 0.0042, Training Accuracy= 0.999\n",
      "Epoch: 2990, Loss= 0.0042, Training Accuracy= 0.999\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.9993\n",
      "Replication: 2: \n",
      "Epoch: 0, Loss= 0.7108, Training Accuracy= 0.509\n",
      "Epoch: 10, Loss= 0.6930, Training Accuracy= 0.510\n",
      "Epoch: 20, Loss= 0.6927, Training Accuracy= 0.514\n",
      "Epoch: 30, Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 40, Loss= 0.6926, Training Accuracy= 0.518\n",
      "Epoch: 50, Loss= 0.6925, Training Accuracy= 0.518\n",
      "Epoch: 60, Loss= 0.6925, Training Accuracy= 0.519\n",
      "Epoch: 70, Loss= 0.6925, Training Accuracy= 0.522\n",
      "Epoch: 80, Loss= 0.6925, Training Accuracy= 0.517\n",
      "Epoch: 90, Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 100, Loss= 0.6925, Training Accuracy= 0.513\n",
      "Epoch: 110, Loss= 0.6925, Training Accuracy= 0.509\n",
      "Epoch: 120, Loss= 0.6924, Training Accuracy= 0.513\n",
      "Epoch: 130, Loss= 0.6924, Training Accuracy= 0.513\n",
      "Epoch: 140, Loss= 0.6924, Training Accuracy= 0.516\n",
      "Epoch: 150, Loss= 0.6924, Training Accuracy= 0.516\n",
      "Epoch: 160, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 170, Loss= 0.6924, Training Accuracy= 0.517\n",
      "Epoch: 180, Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 190, Loss= 0.6923, Training Accuracy= 0.516\n",
      "Epoch: 200, Loss= 0.6923, Training Accuracy= 0.513\n",
      "Epoch: 210, Loss= 0.6922, Training Accuracy= 0.512\n",
      "Epoch: 220, Loss= 0.6922, Training Accuracy= 0.514\n",
      "Epoch: 230, Loss= 0.6922, Training Accuracy= 0.516\n",
      "Epoch: 240, Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 250, Loss= 0.6920, Training Accuracy= 0.517\n",
      "Epoch: 260, Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 270, Loss= 0.6919, Training Accuracy= 0.520\n",
      "Epoch: 280, Loss= 0.6918, Training Accuracy= 0.521\n",
      "Epoch: 290, Loss= 0.6917, Training Accuracy= 0.523\n",
      "Epoch: 300, Loss= 0.6916, Training Accuracy= 0.518\n",
      "Epoch: 310, Loss= 0.6915, Training Accuracy= 0.516\n",
      "Epoch: 320, Loss= 0.6914, Training Accuracy= 0.513\n",
      "Epoch: 330, Loss= 0.6914, Training Accuracy= 0.503\n",
      "Epoch: 340, Loss= 0.6913, Training Accuracy= 0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, Loss= 0.6912, Training Accuracy= 0.520\n",
      "Epoch: 360, Loss= 0.6912, Training Accuracy= 0.525\n",
      "Epoch: 370, Loss= 0.6911, Training Accuracy= 0.527\n",
      "Epoch: 380, Loss= 0.6911, Training Accuracy= 0.528\n",
      "Epoch: 390, Loss= 0.6911, Training Accuracy= 0.534\n",
      "Epoch: 400, Loss= 0.6910, Training Accuracy= 0.533\n",
      "Epoch: 410, Loss= 0.6910, Training Accuracy= 0.536\n",
      "Epoch: 420, Loss= 0.6909, Training Accuracy= 0.535\n",
      "Epoch: 430, Loss= 0.6909, Training Accuracy= 0.533\n",
      "Epoch: 440, Loss= 0.6907, Training Accuracy= 0.543\n",
      "Epoch: 450, Loss= 0.6904, Training Accuracy= 0.545\n",
      "Epoch: 460, Loss= 0.6897, Training Accuracy= 0.557\n",
      "Epoch: 470, Loss= 0.6874, Training Accuracy= 0.554\n",
      "Epoch: 480, Loss= 0.6799, Training Accuracy= 0.549\n",
      "Epoch: 490, Loss= 0.6598, Training Accuracy= 0.603\n",
      "Epoch: 500, Loss= 0.6151, Training Accuracy= 0.672\n",
      "Epoch: 510, Loss= 0.5379, Training Accuracy= 0.730\n",
      "Epoch: 520, Loss= 0.4754, Training Accuracy= 0.741\n",
      "Epoch: 530, Loss= 0.4100, Training Accuracy= 0.771\n",
      "Epoch: 540, Loss= 0.3504, Training Accuracy= 0.784\n",
      "Epoch: 550, Loss= 0.2961, Training Accuracy= 0.882\n",
      "Epoch: 560, Loss= 0.2425, Training Accuracy= 0.899\n",
      "Epoch: 570, Loss= 0.1945, Training Accuracy= 0.940\n",
      "Epoch: 580, Loss= 0.1593, Training Accuracy= 0.953\n",
      "Epoch: 590, Loss= 0.1331, Training Accuracy= 0.956\n",
      "Epoch: 600, Loss= 0.1148, Training Accuracy= 0.962\n",
      "Epoch: 610, Loss= 0.1022, Training Accuracy= 0.963\n",
      "Epoch: 620, Loss= 0.0923, Training Accuracy= 0.963\n",
      "Epoch: 630, Loss= 0.0824, Training Accuracy= 0.966\n",
      "Epoch: 640, Loss= 0.0725, Training Accuracy= 0.972\n",
      "Epoch: 650, Loss= 0.0615, Training Accuracy= 0.978\n",
      "Epoch: 660, Loss= 0.0502, Training Accuracy= 0.980\n",
      "Epoch: 670, Loss= 0.0393, Training Accuracy= 0.987\n",
      "Epoch: 680, Loss= 0.0319, Training Accuracy= 0.989\n",
      "Epoch: 690, Loss= 0.0271, Training Accuracy= 0.996\n",
      "Epoch: 700, Loss= 0.0237, Training Accuracy= 0.997\n",
      "Epoch: 710, Loss= 0.0211, Training Accuracy= 0.998\n",
      "Epoch: 720, Loss= 0.0190, Training Accuracy= 0.998\n",
      "Epoch: 730, Loss= 0.0172, Training Accuracy= 0.998\n",
      "Epoch: 740, Loss= 0.0155, Training Accuracy= 0.998\n",
      "Epoch: 750, Loss= 0.0138, Training Accuracy= 0.998\n",
      "Epoch: 760, Loss= 0.0122, Training Accuracy= 0.999\n",
      "Epoch: 770, Loss= 0.0109, Training Accuracy= 0.999\n",
      "Epoch: 780, Loss= 0.0099, Training Accuracy= 1.000\n",
      "Epoch: 790, Loss= 0.0090, Training Accuracy= 1.000\n",
      "Epoch: 800, Loss= 0.0083, Training Accuracy= 1.000\n",
      "Epoch: 810, Loss= 0.0076, Training Accuracy= 1.000\n",
      "Epoch: 820, Loss= 0.0071, Training Accuracy= 1.000\n",
      "Epoch: 830, Loss= 0.0066, Training Accuracy= 1.000\n",
      "Epoch: 840, Loss= 0.0061, Training Accuracy= 1.000\n",
      "Epoch: 850, Loss= 0.0057, Training Accuracy= 1.000\n",
      "Epoch: 860, Loss= 0.0054, Training Accuracy= 1.000\n",
      "Epoch: 870, Loss= 0.0050, Training Accuracy= 1.000\n",
      "Epoch: 880, Loss= 0.0048, Training Accuracy= 1.000\n",
      "Epoch: 890, Loss= 0.0045, Training Accuracy= 1.000\n",
      "Epoch: 900, Loss= 0.0043, Training Accuracy= 1.000\n",
      "Epoch: 910, Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 920, Loss= 0.0039, Training Accuracy= 1.000\n",
      "Epoch: 930, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 940, Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 950, Loss= 0.0034, Training Accuracy= 1.000\n",
      "Epoch: 960, Loss= 0.0032, Training Accuracy= 1.000\n",
      "Epoch: 970, Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 980, Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0006, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1940, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2000, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2010, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2020, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2030, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2040, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2050, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2060, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2070, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2080, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2090, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2100, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2110, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2120, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2130, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2140, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2150, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2160, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2170, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2180, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2190, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2200, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2210, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2220, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2230, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2240, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2250, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2260, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2280, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 3: \n",
      "Epoch: 0, Loss= 0.6977, Training Accuracy= 0.504\n",
      "Epoch: 10, Loss= 0.6955, Training Accuracy= 0.502\n",
      "Epoch: 20, Loss= 0.6951, Training Accuracy= 0.506\n",
      "Epoch: 30, Loss= 0.6949, Training Accuracy= 0.501\n",
      "Epoch: 40, Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 50, Loss= 0.6946, Training Accuracy= 0.503\n",
      "Epoch: 60, Loss= 0.6945, Training Accuracy= 0.503\n",
      "Epoch: 70, Loss= 0.6944, Training Accuracy= 0.510\n",
      "Epoch: 80, Loss= 0.6943, Training Accuracy= 0.506\n",
      "Epoch: 90, Loss= 0.6943, Training Accuracy= 0.508\n",
      "Epoch: 100, Loss= 0.6942, Training Accuracy= 0.513\n",
      "Epoch: 110, Loss= 0.6941, Training Accuracy= 0.506\n",
      "Epoch: 120, Loss= 0.6941, Training Accuracy= 0.507\n",
      "Epoch: 130, Loss= 0.6940, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.6939, Training Accuracy= 0.508\n",
      "Epoch: 150, Loss= 0.6939, Training Accuracy= 0.508\n",
      "Epoch: 160, Loss= 0.6938, Training Accuracy= 0.512\n",
      "Epoch: 170, Loss= 0.6938, Training Accuracy= 0.513\n",
      "Epoch: 180, Loss= 0.6937, Training Accuracy= 0.514\n",
      "Epoch: 190, Loss= 0.6937, Training Accuracy= 0.509\n",
      "Epoch: 200, Loss= 0.6936, Training Accuracy= 0.507\n",
      "Epoch: 210, Loss= 0.6936, Training Accuracy= 0.513\n",
      "Epoch: 220, Loss= 0.6935, Training Accuracy= 0.514\n",
      "Epoch: 230, Loss= 0.6935, Training Accuracy= 0.518\n",
      "Epoch: 240, Loss= 0.6935, Training Accuracy= 0.517\n",
      "Epoch: 250, Loss= 0.6934, Training Accuracy= 0.517\n",
      "Epoch: 260, Loss= 0.6934, Training Accuracy= 0.520\n",
      "Epoch: 270, Loss= 0.6933, Training Accuracy= 0.523\n",
      "Epoch: 280, Loss= 0.6933, Training Accuracy= 0.518\n",
      "Epoch: 290, Loss= 0.6933, Training Accuracy= 0.518\n",
      "Epoch: 300, Loss= 0.6932, Training Accuracy= 0.516\n",
      "Epoch: 310, Loss= 0.6932, Training Accuracy= 0.513\n",
      "Epoch: 320, Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 330, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 340, Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 350, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 360, Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 370, Loss= 0.6930, Training Accuracy= 0.510\n",
      "Epoch: 380, Loss= 0.6930, Training Accuracy= 0.517\n",
      "Epoch: 390, Loss= 0.6929, Training Accuracy= 0.518\n",
      "Epoch: 400, Loss= 0.6929, Training Accuracy= 0.519\n",
      "Epoch: 410, Loss= 0.6929, Training Accuracy= 0.521\n",
      "Epoch: 420, Loss= 0.6929, Training Accuracy= 0.523\n",
      "Epoch: 430, Loss= 0.6928, Training Accuracy= 0.523\n",
      "Epoch: 440, Loss= 0.6928, Training Accuracy= 0.524\n",
      "Epoch: 450, Loss= 0.6928, Training Accuracy= 0.527\n",
      "Epoch: 460, Loss= 0.6927, Training Accuracy= 0.531\n",
      "Epoch: 470, Loss= 0.6927, Training Accuracy= 0.531\n",
      "Epoch: 480, Loss= 0.6927, Training Accuracy= 0.535\n",
      "Epoch: 490, Loss= 0.6926, Training Accuracy= 0.534\n",
      "Epoch: 500, Loss= 0.6926, Training Accuracy= 0.534\n",
      "Epoch: 510, Loss= 0.6926, Training Accuracy= 0.532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 520, Loss= 0.6925, Training Accuracy= 0.531\n",
      "Epoch: 530, Loss= 0.6925, Training Accuracy= 0.530\n",
      "Epoch: 540, Loss= 0.6925, Training Accuracy= 0.528\n",
      "Epoch: 550, Loss= 0.6924, Training Accuracy= 0.534\n",
      "Epoch: 560, Loss= 0.6924, Training Accuracy= 0.535\n",
      "Epoch: 570, Loss= 0.6924, Training Accuracy= 0.537\n",
      "Epoch: 580, Loss= 0.6924, Training Accuracy= 0.537\n",
      "Epoch: 590, Loss= 0.6923, Training Accuracy= 0.535\n",
      "Epoch: 600, Loss= 0.6923, Training Accuracy= 0.533\n",
      "Epoch: 610, Loss= 0.6923, Training Accuracy= 0.536\n",
      "Epoch: 620, Loss= 0.6923, Training Accuracy= 0.537\n",
      "Epoch: 630, Loss= 0.6922, Training Accuracy= 0.535\n",
      "Epoch: 640, Loss= 0.6922, Training Accuracy= 0.534\n",
      "Epoch: 650, Loss= 0.6922, Training Accuracy= 0.529\n",
      "Epoch: 660, Loss= 0.6922, Training Accuracy= 0.533\n",
      "Epoch: 670, Loss= 0.6922, Training Accuracy= 0.530\n",
      "Epoch: 680, Loss= 0.6921, Training Accuracy= 0.529\n",
      "Epoch: 690, Loss= 0.6921, Training Accuracy= 0.527\n",
      "Epoch: 700, Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 710, Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 720, Loss= 0.6921, Training Accuracy= 0.518\n",
      "Epoch: 730, Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 740, Loss= 0.6920, Training Accuracy= 0.521\n",
      "Epoch: 750, Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 760, Loss= 0.6920, Training Accuracy= 0.518\n",
      "Epoch: 770, Loss= 0.6920, Training Accuracy= 0.514\n",
      "Epoch: 780, Loss= 0.6920, Training Accuracy= 0.514\n",
      "Epoch: 790, Loss= 0.6920, Training Accuracy= 0.515\n",
      "Epoch: 800, Loss= 0.6920, Training Accuracy= 0.515\n",
      "Epoch: 810, Loss= 0.6919, Training Accuracy= 0.517\n",
      "Epoch: 820, Loss= 0.6919, Training Accuracy= 0.518\n",
      "Epoch: 830, Loss= 0.6919, Training Accuracy= 0.519\n",
      "Epoch: 840, Loss= 0.6919, Training Accuracy= 0.519\n",
      "Epoch: 850, Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 860, Loss= 0.6919, Training Accuracy= 0.523\n",
      "Epoch: 870, Loss= 0.6919, Training Accuracy= 0.524\n",
      "Epoch: 880, Loss= 0.6918, Training Accuracy= 0.525\n",
      "Epoch: 890, Loss= 0.6918, Training Accuracy= 0.527\n",
      "Epoch: 900, Loss= 0.6918, Training Accuracy= 0.526\n",
      "Epoch: 910, Loss= 0.6918, Training Accuracy= 0.527\n",
      "Epoch: 920, Loss= 0.6918, Training Accuracy= 0.527\n",
      "Epoch: 930, Loss= 0.6917, Training Accuracy= 0.530\n",
      "Epoch: 940, Loss= 0.6917, Training Accuracy= 0.531\n",
      "Epoch: 950, Loss= 0.6917, Training Accuracy= 0.531\n",
      "Epoch: 960, Loss= 0.6917, Training Accuracy= 0.531\n",
      "Epoch: 970, Loss= 0.6916, Training Accuracy= 0.531\n",
      "Epoch: 980, Loss= 0.6916, Training Accuracy= 0.527\n",
      "Epoch: 990, Loss= 0.6916, Training Accuracy= 0.529\n",
      "Epoch: 1000, Loss= 0.6915, Training Accuracy= 0.528\n",
      "Epoch: 1010, Loss= 0.6915, Training Accuracy= 0.527\n",
      "Epoch: 1020, Loss= 0.6915, Training Accuracy= 0.525\n",
      "Epoch: 1030, Loss= 0.6914, Training Accuracy= 0.525\n",
      "Epoch: 1040, Loss= 0.6914, Training Accuracy= 0.525\n",
      "Epoch: 1050, Loss= 0.6913, Training Accuracy= 0.525\n",
      "Epoch: 1060, Loss= 0.6913, Training Accuracy= 0.527\n",
      "Epoch: 1070, Loss= 0.6913, Training Accuracy= 0.529\n",
      "Epoch: 1080, Loss= 0.6912, Training Accuracy= 0.529\n",
      "Epoch: 1090, Loss= 0.6912, Training Accuracy= 0.526\n",
      "Epoch: 1100, Loss= 0.6911, Training Accuracy= 0.523\n",
      "Epoch: 1110, Loss= 0.6911, Training Accuracy= 0.521\n",
      "Epoch: 1120, Loss= 0.6910, Training Accuracy= 0.520\n",
      "Epoch: 1130, Loss= 0.6910, Training Accuracy= 0.520\n",
      "Epoch: 1140, Loss= 0.6909, Training Accuracy= 0.521\n",
      "Epoch: 1150, Loss= 0.6909, Training Accuracy= 0.519\n",
      "Epoch: 1160, Loss= 0.6908, Training Accuracy= 0.520\n",
      "Epoch: 1170, Loss= 0.6907, Training Accuracy= 0.525\n",
      "Epoch: 1180, Loss= 0.6907, Training Accuracy= 0.525\n",
      "Epoch: 1190, Loss= 0.6906, Training Accuracy= 0.528\n",
      "Epoch: 1200, Loss= 0.6905, Training Accuracy= 0.528\n",
      "Epoch: 1210, Loss= 0.6904, Training Accuracy= 0.531\n",
      "Epoch: 1220, Loss= 0.6903, Training Accuracy= 0.525\n",
      "Epoch: 1230, Loss= 0.6902, Training Accuracy= 0.521\n",
      "Epoch: 1240, Loss= 0.6901, Training Accuracy= 0.519\n",
      "Epoch: 1250, Loss= 0.6898, Training Accuracy= 0.522\n",
      "Epoch: 1260, Loss= 0.6892, Training Accuracy= 0.517\n",
      "Epoch: 1270, Loss= 0.6873, Training Accuracy= 0.534\n",
      "Epoch: 1280, Loss= 0.6820, Training Accuracy= 0.545\n",
      "Epoch: 1290, Loss= 0.6708, Training Accuracy= 0.566\n",
      "Epoch: 1300, Loss= 0.6450, Training Accuracy= 0.605\n",
      "Epoch: 1310, Loss= 0.5999, Training Accuracy= 0.646\n",
      "Epoch: 1320, Loss= 0.5424, Training Accuracy= 0.682\n",
      "Epoch: 1330, Loss= 0.4805, Training Accuracy= 0.718\n",
      "Epoch: 1340, Loss= 0.4250, Training Accuracy= 0.777\n",
      "Epoch: 1350, Loss= 0.3801, Training Accuracy= 0.817\n",
      "Epoch: 1360, Loss= 0.3385, Training Accuracy= 0.829\n",
      "Epoch: 1370, Loss= 0.2967, Training Accuracy= 0.872\n",
      "Epoch: 1380, Loss= 0.2595, Training Accuracy= 0.871\n",
      "Epoch: 1390, Loss= 0.2350, Training Accuracy= 0.893\n",
      "Epoch: 1400, Loss= 0.2190, Training Accuracy= 0.912\n",
      "Epoch: 1410, Loss= 0.2062, Training Accuracy= 0.914\n",
      "Epoch: 1420, Loss= 0.1937, Training Accuracy= 0.915\n",
      "Epoch: 1430, Loss= 0.1806, Training Accuracy= 0.914\n",
      "Epoch: 1440, Loss= 0.1678, Training Accuracy= 0.922\n",
      "Epoch: 1450, Loss= 0.1569, Training Accuracy= 0.938\n",
      "Epoch: 1460, Loss= 0.1485, Training Accuracy= 0.949\n",
      "Epoch: 1470, Loss= 0.1420, Training Accuracy= 0.950\n",
      "Epoch: 1480, Loss= 0.1361, Training Accuracy= 0.958\n",
      "Epoch: 1490, Loss= 0.1373, Training Accuracy= 0.959\n",
      "Epoch: 1500, Loss= 0.8196, Training Accuracy= 0.590\n",
      "Epoch: 1510, Loss= 0.6996, Training Accuracy= 0.496\n",
      "Epoch: 1520, Loss= 0.6955, Training Accuracy= 0.495\n",
      "Epoch: 1530, Loss= 0.6947, Training Accuracy= 0.502\n",
      "Epoch: 1540, Loss= 0.6947, Training Accuracy= 0.494\n",
      "Epoch: 1550, Loss= 0.6946, Training Accuracy= 0.494\n",
      "Epoch: 1560, Loss= 0.6946, Training Accuracy= 0.495\n",
      "Epoch: 1570, Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1580, Loss= 0.6945, Training Accuracy= 0.495\n",
      "Epoch: 1590, Loss= 0.6941, Training Accuracy= 0.500\n",
      "Epoch: 1600, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 1610, Loss= 0.6939, Training Accuracy= 0.506\n",
      "Epoch: 1620, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 1630, Loss= 0.6938, Training Accuracy= 0.504\n",
      "Epoch: 1640, Loss= 0.6938, Training Accuracy= 0.502\n",
      "Epoch: 1650, Loss= 0.6938, Training Accuracy= 0.504\n",
      "Epoch: 1660, Loss= 0.6938, Training Accuracy= 0.503\n",
      "Epoch: 1670, Loss= 0.6938, Training Accuracy= 0.507\n",
      "Epoch: 1680, Loss= 0.6938, Training Accuracy= 0.506\n",
      "Epoch: 1690, Loss= 0.6938, Training Accuracy= 0.505\n",
      "Epoch: 1700, Loss= 0.6938, Training Accuracy= 0.505\n",
      "Epoch: 1710, Loss= 0.6938, Training Accuracy= 0.505\n",
      "Epoch: 1720, Loss= 0.6938, Training Accuracy= 0.506\n",
      "Epoch: 1730, Loss= 0.6938, Training Accuracy= 0.506\n",
      "Epoch: 1740, Loss= 0.6939, Training Accuracy= 0.506\n",
      "Epoch: 1750, Loss= 0.6939, Training Accuracy= 0.506\n",
      "Epoch: 1760, Loss= 0.6939, Training Accuracy= 0.504\n",
      "Epoch: 1770, Loss= 0.6939, Training Accuracy= 0.504\n",
      "Epoch: 1780, Loss= 0.6939, Training Accuracy= 0.503\n",
      "Epoch: 1790, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 1800, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 1810, Loss= 0.6940, Training Accuracy= 0.501\n",
      "Epoch: 1820, Loss= 0.6940, Training Accuracy= 0.500\n",
      "Epoch: 1830, Loss= 0.6940, Training Accuracy= 0.500\n",
      "Epoch: 1840, Loss= 0.6940, Training Accuracy= 0.500\n",
      "Epoch: 1850, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 1860, Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 1870, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 1880, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 1890, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 1900, Loss= 0.6939, Training Accuracy= 0.502\n",
      "Epoch: 1910, Loss= 0.6939, Training Accuracy= 0.501\n",
      "Epoch: 1920, Loss= 0.6939, Training Accuracy= 0.501\n",
      "Epoch: 1930, Loss= 0.6939, Training Accuracy= 0.501\n",
      "Epoch: 1940, Loss= 0.6939, Training Accuracy= 0.500\n",
      "Epoch: 1950, Loss= 0.6939, Training Accuracy= 0.500\n",
      "Epoch: 1960, Loss= 0.6938, Training Accuracy= 0.500\n",
      "Epoch: 1970, Loss= 0.6938, Training Accuracy= 0.500\n",
      "Epoch: 1980, Loss= 0.6938, Training Accuracy= 0.501\n",
      "Epoch: 1990, Loss= 0.6938, Training Accuracy= 0.501\n",
      "Epoch: 2000, Loss= 0.6938, Training Accuracy= 0.501\n",
      "Epoch: 2010, Loss= 0.6938, Training Accuracy= 0.501\n",
      "Epoch: 2020, Loss= 0.6938, Training Accuracy= 0.501\n",
      "Epoch: 2030, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 2040, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 2050, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 2060, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 2070, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 2080, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 2090, Loss= 0.6937, Training Accuracy= 0.501\n",
      "Epoch: 2100, Loss= 0.6936, Training Accuracy= 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2110, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 2120, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 2130, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 2140, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 2150, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 2160, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 2170, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2180, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2190, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2200, Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 2210, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 2220, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 2230, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 2240, Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 2250, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 2260, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 2270, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 2280, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 2290, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 2300, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 2310, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 2320, Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 2330, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 2340, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 2350, Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 2360, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2370, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2380, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2390, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2400, Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2410, Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 2420, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2430, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2440, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2450, Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2460, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2470, Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 2480, Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 2490, Loss= 0.6931, Training Accuracy= 0.500\n",
      "Epoch: 2500, Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 2510, Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 2520, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 2530, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 2540, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 2550, Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 2560, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 2570, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 2580, Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 2590, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 2600, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 2610, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 2620, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 2630, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 2640, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 2650, Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 2660, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 2670, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2680, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2690, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2700, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 2710, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 2720, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 2730, Loss= 0.6929, Training Accuracy= 0.504\n",
      "Epoch: 2740, Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 2750, Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 2760, Loss= 0.6929, Training Accuracy= 0.501\n",
      "Epoch: 2770, Loss= 0.6929, Training Accuracy= 0.500\n",
      "Epoch: 2780, Loss= 0.6929, Training Accuracy= 0.500\n",
      "Epoch: 2790, Loss= 0.6929, Training Accuracy= 0.499\n",
      "Epoch: 2800, Loss= 0.6929, Training Accuracy= 0.500\n",
      "Epoch: 2810, Loss= 0.6929, Training Accuracy= 0.500\n",
      "Epoch: 2820, Loss= 0.6929, Training Accuracy= 0.500\n",
      "Epoch: 2830, Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 2840, Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 2850, Loss= 0.6928, Training Accuracy= 0.501\n",
      "Epoch: 2860, Loss= 0.6928, Training Accuracy= 0.501\n",
      "Epoch: 2870, Loss= 0.6928, Training Accuracy= 0.502\n",
      "Epoch: 2880, Loss= 0.6928, Training Accuracy= 0.503\n",
      "Epoch: 2890, Loss= 0.6928, Training Accuracy= 0.503\n",
      "Epoch: 2900, Loss= 0.6928, Training Accuracy= 0.503\n",
      "Epoch: 2910, Loss= 0.6928, Training Accuracy= 0.502\n",
      "Epoch: 2920, Loss= 0.6928, Training Accuracy= 0.502\n",
      "Epoch: 2930, Loss= 0.6928, Training Accuracy= 0.503\n",
      "Epoch: 2940, Loss= 0.6928, Training Accuracy= 0.503\n",
      "Epoch: 2950, Loss= 0.6928, Training Accuracy= 0.505\n",
      "Epoch: 2960, Loss= 0.6928, Training Accuracy= 0.505\n",
      "Epoch: 2970, Loss= 0.6928, Training Accuracy= 0.505\n",
      "Epoch: 2980, Loss= 0.6928, Training Accuracy= 0.505\n",
      "Epoch: 2990, Loss= 0.6928, Training Accuracy= 0.505\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5092\n",
      "Replication: 4: \n",
      "Epoch: 0, Loss= 0.7051, Training Accuracy= 0.504\n",
      "Epoch: 10, Loss= 0.6938, Training Accuracy= 0.491\n",
      "Epoch: 20, Loss= 0.6934, Training Accuracy= 0.507\n",
      "Epoch: 30, Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 40, Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 50, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 60, Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 70, Loss= 0.6929, Training Accuracy= 0.500\n",
      "Epoch: 80, Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 90, Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 100, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 110, Loss= 0.6927, Training Accuracy= 0.519\n",
      "Epoch: 120, Loss= 0.6927, Training Accuracy= 0.516\n",
      "Epoch: 130, Loss= 0.6926, Training Accuracy= 0.506\n",
      "Epoch: 140, Loss= 0.6926, Training Accuracy= 0.505\n",
      "Epoch: 150, Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 160, Loss= 0.6925, Training Accuracy= 0.504\n",
      "Epoch: 170, Loss= 0.6925, Training Accuracy= 0.507\n",
      "Epoch: 180, Loss= 0.6924, Training Accuracy= 0.513\n",
      "Epoch: 190, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 200, Loss= 0.6924, Training Accuracy= 0.516\n",
      "Epoch: 210, Loss= 0.6923, Training Accuracy= 0.514\n",
      "Epoch: 220, Loss= 0.6923, Training Accuracy= 0.518\n",
      "Epoch: 230, Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 240, Loss= 0.6922, Training Accuracy= 0.513\n",
      "Epoch: 250, Loss= 0.6922, Training Accuracy= 0.514\n",
      "Epoch: 260, Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 270, Loss= 0.6921, Training Accuracy= 0.518\n",
      "Epoch: 280, Loss= 0.6921, Training Accuracy= 0.519\n",
      "Epoch: 290, Loss= 0.6921, Training Accuracy= 0.525\n",
      "Epoch: 300, Loss= 0.6920, Training Accuracy= 0.526\n",
      "Epoch: 310, Loss= 0.6920, Training Accuracy= 0.530\n",
      "Epoch: 320, Loss= 0.6920, Training Accuracy= 0.532\n",
      "Epoch: 330, Loss= 0.6920, Training Accuracy= 0.532\n",
      "Epoch: 340, Loss= 0.6919, Training Accuracy= 0.534\n",
      "Epoch: 350, Loss= 0.6919, Training Accuracy= 0.535\n",
      "Epoch: 360, Loss= 0.6919, Training Accuracy= 0.533\n",
      "Epoch: 370, Loss= 0.6919, Training Accuracy= 0.535\n",
      "Epoch: 380, Loss= 0.6918, Training Accuracy= 0.536\n",
      "Epoch: 390, Loss= 0.6918, Training Accuracy= 0.535\n",
      "Epoch: 400, Loss= 0.6918, Training Accuracy= 0.534\n",
      "Epoch: 410, Loss= 0.6918, Training Accuracy= 0.535\n",
      "Epoch: 420, Loss= 0.6918, Training Accuracy= 0.530\n",
      "Epoch: 430, Loss= 0.6917, Training Accuracy= 0.529\n",
      "Epoch: 440, Loss= 0.6917, Training Accuracy= 0.524\n",
      "Epoch: 450, Loss= 0.6917, Training Accuracy= 0.525\n",
      "Epoch: 460, Loss= 0.6917, Training Accuracy= 0.524\n",
      "Epoch: 470, Loss= 0.6917, Training Accuracy= 0.524\n",
      "Epoch: 480, Loss= 0.6916, Training Accuracy= 0.523\n",
      "Epoch: 490, Loss= 0.6916, Training Accuracy= 0.522\n",
      "Epoch: 500, Loss= 0.6916, Training Accuracy= 0.524\n",
      "Epoch: 510, Loss= 0.6916, Training Accuracy= 0.527\n",
      "Epoch: 520, Loss= 0.6916, Training Accuracy= 0.529\n",
      "Epoch: 530, Loss= 0.6915, Training Accuracy= 0.527\n",
      "Epoch: 540, Loss= 0.6915, Training Accuracy= 0.528\n",
      "Epoch: 550, Loss= 0.6915, Training Accuracy= 0.528\n",
      "Epoch: 560, Loss= 0.6915, Training Accuracy= 0.530\n",
      "Epoch: 570, Loss= 0.6915, Training Accuracy= 0.532\n",
      "Epoch: 580, Loss= 0.6915, Training Accuracy= 0.529\n",
      "Epoch: 590, Loss= 0.6914, Training Accuracy= 0.531\n",
      "Epoch: 600, Loss= 0.6914, Training Accuracy= 0.532\n",
      "Epoch: 610, Loss= 0.6914, Training Accuracy= 0.531\n",
      "Epoch: 620, Loss= 0.6914, Training Accuracy= 0.529\n",
      "Epoch: 630, Loss= 0.6914, Training Accuracy= 0.530\n",
      "Epoch: 640, Loss= 0.6914, Training Accuracy= 0.530\n",
      "Epoch: 650, Loss= 0.6913, Training Accuracy= 0.530\n",
      "Epoch: 660, Loss= 0.6913, Training Accuracy= 0.531\n",
      "Epoch: 670, Loss= 0.6913, Training Accuracy= 0.527\n",
      "Epoch: 680, Loss= 0.6913, Training Accuracy= 0.529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 690, Loss= 0.6913, Training Accuracy= 0.529\n",
      "Epoch: 700, Loss= 0.6912, Training Accuracy= 0.526\n",
      "Epoch: 710, Loss= 0.6912, Training Accuracy= 0.524\n",
      "Epoch: 720, Loss= 0.6912, Training Accuracy= 0.522\n",
      "Epoch: 730, Loss= 0.6912, Training Accuracy= 0.524\n",
      "Epoch: 740, Loss= 0.6911, Training Accuracy= 0.527\n",
      "Epoch: 750, Loss= 0.6911, Training Accuracy= 0.525\n",
      "Epoch: 760, Loss= 0.6911, Training Accuracy= 0.521\n",
      "Epoch: 770, Loss= 0.6911, Training Accuracy= 0.522\n",
      "Epoch: 780, Loss= 0.6910, Training Accuracy= 0.524\n",
      "Epoch: 790, Loss= 0.6909, Training Accuracy= 0.528\n",
      "Epoch: 800, Loss= 0.6908, Training Accuracy= 0.525\n",
      "Epoch: 810, Loss= 0.6905, Training Accuracy= 0.525\n",
      "Epoch: 820, Loss= 0.6887, Training Accuracy= 0.514\n",
      "Epoch: 830, Loss= 0.6774, Training Accuracy= 0.586\n",
      "Epoch: 840, Loss= 0.6294, Training Accuracy= 0.656\n",
      "Epoch: 850, Loss= 0.5697, Training Accuracy= 0.695\n",
      "Epoch: 860, Loss= 0.4860, Training Accuracy= 0.760\n",
      "Epoch: 870, Loss= 0.3957, Training Accuracy= 0.784\n",
      "Epoch: 880, Loss= 0.3564, Training Accuracy= 0.805\n",
      "Epoch: 890, Loss= 0.3630, Training Accuracy= 0.791\n",
      "Epoch: 900, Loss= 0.3771, Training Accuracy= 0.784\n",
      "Epoch: 910, Loss= 0.3309, Training Accuracy= 0.797\n",
      "Epoch: 920, Loss= 0.2902, Training Accuracy= 0.817\n",
      "Epoch: 930, Loss= 0.2425, Training Accuracy= 0.873\n",
      "Epoch: 940, Loss= 0.1925, Training Accuracy= 0.921\n",
      "Epoch: 950, Loss= 0.1694, Training Accuracy= 0.952\n",
      "Epoch: 960, Loss= 0.1505, Training Accuracy= 0.958\n",
      "Epoch: 970, Loss= 0.1253, Training Accuracy= 0.961\n",
      "Epoch: 980, Loss= 0.0871, Training Accuracy= 0.991\n",
      "Epoch: 990, Loss= 0.0611, Training Accuracy= 0.998\n",
      "Epoch: 1000, Loss= 0.0458, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0363, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0300, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0255, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0221, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0194, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0173, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0155, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0140, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0128, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0117, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0108, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0100, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0094, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0087, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0082, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0077, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0073, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0069, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0065, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0062, Training Accuracy= 1.000\n",
      "Epoch: 1210, Loss= 0.0059, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0056, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0054, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0052, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0050, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0048, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0046, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0044, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0042, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0040, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0038, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0036, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0034, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0032, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2000, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2010, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2020, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2030, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2040, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2050, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2060, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2070, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2080, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2090, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2100, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2110, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2120, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2130, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2140, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2150, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2160, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2170, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2180, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2190, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2200, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2210, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2220, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2230, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2240, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2250, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2260, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0008, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2280, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Loss= 0.7133, Training Accuracy= 0.496\n",
      "Epoch: 10, Loss= 0.6985, Training Accuracy= 0.495\n",
      "Epoch: 20, Loss= 0.6965, Training Accuracy= 0.495\n",
      "Epoch: 30, Loss= 0.6956, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.6950, Training Accuracy= 0.494\n",
      "Epoch: 50, Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 60, Loss= 0.6944, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6941, Training Accuracy= 0.509\n",
      "Epoch: 80, Loss= 0.6940, Training Accuracy= 0.506\n",
      "Epoch: 90, Loss= 0.6938, Training Accuracy= 0.503\n",
      "Epoch: 100, Loss= 0.6937, Training Accuracy= 0.502\n",
      "Epoch: 110, Loss= 0.6936, Training Accuracy= 0.501\n",
      "Epoch: 120, Loss= 0.6935, Training Accuracy= 0.509\n",
      "Epoch: 130, Loss= 0.6934, Training Accuracy= 0.514\n",
      "Epoch: 140, Loss= 0.6933, Training Accuracy= 0.517\n",
      "Epoch: 150, Loss= 0.6932, Training Accuracy= 0.519\n",
      "Epoch: 160, Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 170, Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 180, Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 190, Loss= 0.6929, Training Accuracy= 0.515\n",
      "Epoch: 200, Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 210, Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 220, Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 230, Loss= 0.6927, Training Accuracy= 0.516\n",
      "Epoch: 240, Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 250, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 260, Loss= 0.6925, Training Accuracy= 0.517\n",
      "Epoch: 270, Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 280, Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 290, Loss= 0.6924, Training Accuracy= 0.521\n",
      "Epoch: 300, Loss= 0.6923, Training Accuracy= 0.521\n",
      "Epoch: 310, Loss= 0.6923, Training Accuracy= 0.521\n",
      "Epoch: 320, Loss= 0.6923, Training Accuracy= 0.519\n",
      "Epoch: 330, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 340, Loss= 0.6922, Training Accuracy= 0.525\n",
      "Epoch: 350, Loss= 0.6921, Training Accuracy= 0.523\n",
      "Epoch: 360, Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 370, Loss= 0.6921, Training Accuracy= 0.516\n",
      "Epoch: 380, Loss= 0.6920, Training Accuracy= 0.514\n",
      "Epoch: 390, Loss= 0.6920, Training Accuracy= 0.517\n",
      "Epoch: 400, Loss= 0.6920, Training Accuracy= 0.514\n",
      "Epoch: 410, Loss= 0.6919, Training Accuracy= 0.516\n",
      "Epoch: 420, Loss= 0.6919, Training Accuracy= 0.518\n",
      "Epoch: 430, Loss= 0.6919, Training Accuracy= 0.519\n",
      "Epoch: 440, Loss= 0.6918, Training Accuracy= 0.515\n",
      "Epoch: 450, Loss= 0.6918, Training Accuracy= 0.514\n",
      "Epoch: 460, Loss= 0.6918, Training Accuracy= 0.513\n",
      "Epoch: 470, Loss= 0.6917, Training Accuracy= 0.516\n",
      "Epoch: 480, Loss= 0.6917, Training Accuracy= 0.520\n",
      "Epoch: 490, Loss= 0.6916, Training Accuracy= 0.519\n",
      "Epoch: 500, Loss= 0.6916, Training Accuracy= 0.520\n",
      "Epoch: 510, Loss= 0.6915, Training Accuracy= 0.523\n",
      "Epoch: 520, Loss= 0.6915, Training Accuracy= 0.520\n",
      "Epoch: 530, Loss= 0.6914, Training Accuracy= 0.526\n",
      "Epoch: 540, Loss= 0.6914, Training Accuracy= 0.519\n",
      "Epoch: 550, Loss= 0.6913, Training Accuracy= 0.522\n",
      "Epoch: 560, Loss= 0.6913, Training Accuracy= 0.519\n",
      "Epoch: 570, Loss= 0.6912, Training Accuracy= 0.516\n",
      "Epoch: 580, Loss= 0.6911, Training Accuracy= 0.516\n",
      "Epoch: 590, Loss= 0.6911, Training Accuracy= 0.520\n",
      "Epoch: 600, Loss= 0.6910, Training Accuracy= 0.518\n",
      "Epoch: 610, Loss= 0.6909, Training Accuracy= 0.515\n",
      "Epoch: 620, Loss= 0.6908, Training Accuracy= 0.512\n",
      "Epoch: 630, Loss= 0.6908, Training Accuracy= 0.515\n",
      "Epoch: 640, Loss= 0.6907, Training Accuracy= 0.522\n",
      "Epoch: 650, Loss= 0.6906, Training Accuracy= 0.522\n",
      "Epoch: 660, Loss= 0.6905, Training Accuracy= 0.518\n",
      "Epoch: 670, Loss= 0.6904, Training Accuracy= 0.522\n",
      "Epoch: 680, Loss= 0.6904, Training Accuracy= 0.519\n",
      "Epoch: 690, Loss= 0.6903, Training Accuracy= 0.524\n",
      "Epoch: 700, Loss= 0.6902, Training Accuracy= 0.527\n",
      "Epoch: 710, Loss= 0.6902, Training Accuracy= 0.527\n",
      "Epoch: 720, Loss= 0.6901, Training Accuracy= 0.525\n",
      "Epoch: 730, Loss= 0.6901, Training Accuracy= 0.520\n",
      "Epoch: 740, Loss= 0.6900, Training Accuracy= 0.521\n",
      "Epoch: 750, Loss= 0.6900, Training Accuracy= 0.523\n",
      "Epoch: 760, Loss= 0.6899, Training Accuracy= 0.528\n",
      "Epoch: 770, Loss= 0.6899, Training Accuracy= 0.527\n",
      "Epoch: 780, Loss= 0.6899, Training Accuracy= 0.528\n",
      "Epoch: 790, Loss= 0.6898, Training Accuracy= 0.526\n",
      "Epoch: 800, Loss= 0.6898, Training Accuracy= 0.528\n",
      "Epoch: 810, Loss= 0.6897, Training Accuracy= 0.527\n",
      "Epoch: 820, Loss= 0.6897, Training Accuracy= 0.528\n",
      "Epoch: 830, Loss= 0.6897, Training Accuracy= 0.530\n",
      "Epoch: 840, Loss= 0.6896, Training Accuracy= 0.530\n",
      "Epoch: 850, Loss= 0.6896, Training Accuracy= 0.531\n",
      "Epoch: 860, Loss= 0.6895, Training Accuracy= 0.532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 870, Loss= 0.6895, Training Accuracy= 0.535\n",
      "Epoch: 880, Loss= 0.6895, Training Accuracy= 0.536\n",
      "Epoch: 890, Loss= 0.6894, Training Accuracy= 0.541\n",
      "Epoch: 900, Loss= 0.6894, Training Accuracy= 0.542\n",
      "Epoch: 910, Loss= 0.6893, Training Accuracy= 0.545\n",
      "Epoch: 920, Loss= 0.6893, Training Accuracy= 0.539\n",
      "Epoch: 930, Loss= 0.6892, Training Accuracy= 0.542\n",
      "Epoch: 940, Loss= 0.6891, Training Accuracy= 0.541\n",
      "Epoch: 950, Loss= 0.6891, Training Accuracy= 0.547\n",
      "Epoch: 960, Loss= 0.6890, Training Accuracy= 0.547\n",
      "Epoch: 970, Loss= 0.6890, Training Accuracy= 0.545\n",
      "Epoch: 980, Loss= 0.6889, Training Accuracy= 0.547\n",
      "Epoch: 990, Loss= 0.6889, Training Accuracy= 0.547\n",
      "Epoch: 1000, Loss= 0.6888, Training Accuracy= 0.549\n",
      "Epoch: 1010, Loss= 0.6888, Training Accuracy= 0.549\n",
      "Epoch: 1020, Loss= 0.6887, Training Accuracy= 0.547\n",
      "Epoch: 1030, Loss= 0.6887, Training Accuracy= 0.546\n",
      "Epoch: 1040, Loss= 0.6886, Training Accuracy= 0.549\n",
      "Epoch: 1050, Loss= 0.6886, Training Accuracy= 0.551\n",
      "Epoch: 1060, Loss= 0.6885, Training Accuracy= 0.552\n",
      "Epoch: 1070, Loss= 0.6885, Training Accuracy= 0.556\n",
      "Epoch: 1080, Loss= 0.6884, Training Accuracy= 0.558\n",
      "Epoch: 1090, Loss= 0.6884, Training Accuracy= 0.557\n",
      "Epoch: 1100, Loss= 0.6883, Training Accuracy= 0.555\n",
      "Epoch: 1110, Loss= 0.6883, Training Accuracy= 0.556\n",
      "Epoch: 1120, Loss= 0.6882, Training Accuracy= 0.552\n",
      "Epoch: 1130, Loss= 0.6882, Training Accuracy= 0.557\n",
      "Epoch: 1140, Loss= 0.6881, Training Accuracy= 0.555\n",
      "Epoch: 1150, Loss= 0.6881, Training Accuracy= 0.557\n",
      "Epoch: 1160, Loss= 0.6880, Training Accuracy= 0.554\n",
      "Epoch: 1170, Loss= 0.6880, Training Accuracy= 0.554\n",
      "Epoch: 1180, Loss= 0.6879, Training Accuracy= 0.552\n",
      "Epoch: 1190, Loss= 0.6878, Training Accuracy= 0.554\n",
      "Epoch: 1200, Loss= 0.6878, Training Accuracy= 0.553\n",
      "Epoch: 1210, Loss= 0.6877, Training Accuracy= 0.550\n",
      "Epoch: 1220, Loss= 0.6876, Training Accuracy= 0.551\n",
      "Epoch: 1230, Loss= 0.6876, Training Accuracy= 0.552\n",
      "Epoch: 1240, Loss= 0.6875, Training Accuracy= 0.550\n",
      "Epoch: 1250, Loss= 0.6874, Training Accuracy= 0.546\n",
      "Epoch: 1260, Loss= 0.6873, Training Accuracy= 0.545\n",
      "Epoch: 1270, Loss= 0.6872, Training Accuracy= 0.544\n",
      "Epoch: 1280, Loss= 0.6871, Training Accuracy= 0.552\n",
      "Epoch: 1290, Loss= 0.6870, Training Accuracy= 0.555\n",
      "Epoch: 1300, Loss= 0.6868, Training Accuracy= 0.556\n",
      "Epoch: 1310, Loss= 0.6866, Training Accuracy= 0.548\n",
      "Epoch: 1320, Loss= 0.6863, Training Accuracy= 0.553\n",
      "Epoch: 1330, Loss= 0.6857, Training Accuracy= 0.557\n",
      "Epoch: 1340, Loss= 0.6847, Training Accuracy= 0.558\n",
      "Epoch: 1350, Loss= 0.6828, Training Accuracy= 0.564\n",
      "Epoch: 1360, Loss= 0.6800, Training Accuracy= 0.577\n",
      "Epoch: 1370, Loss= 0.6765, Training Accuracy= 0.565\n",
      "Epoch: 1380, Loss= 0.6724, Training Accuracy= 0.572\n",
      "Epoch: 1390, Loss= 0.6675, Training Accuracy= 0.585\n",
      "Epoch: 1400, Loss= 0.6608, Training Accuracy= 0.594\n",
      "Epoch: 1410, Loss= 0.6499, Training Accuracy= 0.622\n",
      "Epoch: 1420, Loss= 0.6299, Training Accuracy= 0.655\n",
      "Epoch: 1430, Loss= 0.5785, Training Accuracy= 0.724\n",
      "Epoch: 1440, Loss= 0.3090, Training Accuracy= 0.916\n",
      "Epoch: 1450, Loss= 0.2116, Training Accuracy= 0.938\n",
      "Epoch: 1460, Loss= 0.1697, Training Accuracy= 0.950\n",
      "Epoch: 1470, Loss= 0.1467, Training Accuracy= 0.957\n",
      "Epoch: 1480, Loss= 0.1248, Training Accuracy= 0.965\n",
      "Epoch: 1490, Loss= 0.1136, Training Accuracy= 0.968\n",
      "Epoch: 1500, Loss= 0.1041, Training Accuracy= 0.972\n",
      "Epoch: 1510, Loss= 0.0960, Training Accuracy= 0.975\n",
      "Epoch: 1520, Loss= 0.0893, Training Accuracy= 0.977\n",
      "Epoch: 1530, Loss= 0.0835, Training Accuracy= 0.976\n",
      "Epoch: 1540, Loss= 0.0787, Training Accuracy= 0.977\n",
      "Epoch: 1550, Loss= 0.0747, Training Accuracy= 0.979\n",
      "Epoch: 1560, Loss= 0.0710, Training Accuracy= 0.980\n",
      "Epoch: 1570, Loss= 0.0677, Training Accuracy= 0.981\n",
      "Epoch: 1580, Loss= 0.0647, Training Accuracy= 0.981\n",
      "Epoch: 1590, Loss= 0.0622, Training Accuracy= 0.984\n",
      "Epoch: 1600, Loss= 0.0601, Training Accuracy= 0.985\n",
      "Epoch: 1610, Loss= 0.0105, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0079, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0067, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0059, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0054, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0050, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0046, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0043, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0039, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0032, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2000, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2010, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2020, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2030, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2040, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2050, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2060, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2070, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2080, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2090, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2100, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2110, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2120, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2130, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2140, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2150, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2160, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2170, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2180, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2190, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2200, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2210, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2220, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2230, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2240, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2250, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2260, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2280, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0008, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2450, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 6: \n",
      "Epoch: 0, Loss= 0.6982, Training Accuracy= 0.502\n",
      "Epoch: 10, Loss= 0.6935, Training Accuracy= 0.496\n",
      "Epoch: 20, Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 30, Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 40, Loss= 0.6929, Training Accuracy= 0.498\n",
      "Epoch: 50, Loss= 0.6928, Training Accuracy= 0.498\n",
      "Epoch: 60, Loss= 0.6928, Training Accuracy= 0.497\n",
      "Epoch: 70, Loss= 0.6927, Training Accuracy= 0.495\n",
      "Epoch: 80, Loss= 0.6926, Training Accuracy= 0.490\n",
      "Epoch: 90, Loss= 0.6926, Training Accuracy= 0.499\n",
      "Epoch: 100, Loss= 0.6925, Training Accuracy= 0.496\n",
      "Epoch: 110, Loss= 0.6925, Training Accuracy= 0.496\n",
      "Epoch: 120, Loss= 0.6924, Training Accuracy= 0.498\n",
      "Epoch: 130, Loss= 0.6924, Training Accuracy= 0.503\n",
      "Epoch: 140, Loss= 0.6923, Training Accuracy= 0.509\n",
      "Epoch: 150, Loss= 0.6923, Training Accuracy= 0.519\n",
      "Epoch: 160, Loss= 0.6922, Training Accuracy= 0.527\n",
      "Epoch: 170, Loss= 0.6922, Training Accuracy= 0.528\n",
      "Epoch: 180, Loss= 0.6921, Training Accuracy= 0.526\n",
      "Epoch: 190, Loss= 0.6921, Training Accuracy= 0.534\n",
      "Epoch: 200, Loss= 0.6921, Training Accuracy= 0.531\n",
      "Epoch: 210, Loss= 0.6920, Training Accuracy= 0.531\n",
      "Epoch: 220, Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 230, Loss= 0.6919, Training Accuracy= 0.519\n",
      "Epoch: 240, Loss= 0.6919, Training Accuracy= 0.517\n",
      "Epoch: 250, Loss= 0.6918, Training Accuracy= 0.514\n",
      "Epoch: 260, Loss= 0.6918, Training Accuracy= 0.514\n",
      "Epoch: 270, Loss= 0.6918, Training Accuracy= 0.515\n",
      "Epoch: 280, Loss= 0.6917, Training Accuracy= 0.520\n",
      "Epoch: 290, Loss= 0.6917, Training Accuracy= 0.517\n",
      "Epoch: 300, Loss= 0.6916, Training Accuracy= 0.522\n",
      "Epoch: 310, Loss= 0.6916, Training Accuracy= 0.520\n",
      "Epoch: 320, Loss= 0.6915, Training Accuracy= 0.521\n",
      "Epoch: 330, Loss= 0.6915, Training Accuracy= 0.521\n",
      "Epoch: 340, Loss= 0.6914, Training Accuracy= 0.518\n",
      "Epoch: 350, Loss= 0.6914, Training Accuracy= 0.520\n",
      "Epoch: 360, Loss= 0.6913, Training Accuracy= 0.518\n",
      "Epoch: 370, Loss= 0.6913, Training Accuracy= 0.516\n",
      "Epoch: 380, Loss= 0.6913, Training Accuracy= 0.519\n",
      "Epoch: 390, Loss= 0.6912, Training Accuracy= 0.510\n",
      "Epoch: 400, Loss= 0.6912, Training Accuracy= 0.512\n",
      "Epoch: 410, Loss= 0.6911, Training Accuracy= 0.515\n",
      "Epoch: 420, Loss= 0.6911, Training Accuracy= 0.512\n",
      "Epoch: 430, Loss= 0.6911, Training Accuracy= 0.510\n",
      "Epoch: 440, Loss= 0.6910, Training Accuracy= 0.509\n",
      "Epoch: 450, Loss= 0.6910, Training Accuracy= 0.510\n",
      "Epoch: 460, Loss= 0.6909, Training Accuracy= 0.509\n",
      "Epoch: 470, Loss= 0.6909, Training Accuracy= 0.510\n",
      "Epoch: 480, Loss= 0.6909, Training Accuracy= 0.509\n",
      "Epoch: 490, Loss= 0.6908, Training Accuracy= 0.508\n",
      "Epoch: 500, Loss= 0.6908, Training Accuracy= 0.509\n",
      "Epoch: 510, Loss= 0.6907, Training Accuracy= 0.505\n",
      "Epoch: 520, Loss= 0.6907, Training Accuracy= 0.510\n",
      "Epoch: 530, Loss= 0.6907, Training Accuracy= 0.508\n",
      "Epoch: 540, Loss= 0.6906, Training Accuracy= 0.509\n",
      "Epoch: 550, Loss= 0.6906, Training Accuracy= 0.510\n",
      "Epoch: 560, Loss= 0.6905, Training Accuracy= 0.510\n",
      "Epoch: 570, Loss= 0.6905, Training Accuracy= 0.512\n",
      "Epoch: 580, Loss= 0.6904, Training Accuracy= 0.513\n",
      "Epoch: 590, Loss= 0.6904, Training Accuracy= 0.517\n",
      "Epoch: 600, Loss= 0.6903, Training Accuracy= 0.518\n",
      "Epoch: 610, Loss= 0.6902, Training Accuracy= 0.521\n",
      "Epoch: 620, Loss= 0.6901, Training Accuracy= 0.526\n",
      "Epoch: 630, Loss= 0.6899, Training Accuracy= 0.530\n",
      "Epoch: 640, Loss= 0.6897, Training Accuracy= 0.531\n",
      "Epoch: 650, Loss= 0.6892, Training Accuracy= 0.531\n",
      "Epoch: 660, Loss= 0.6882, Training Accuracy= 0.541\n",
      "Epoch: 670, Loss= 0.6862, Training Accuracy= 0.552\n",
      "Epoch: 680, Loss= 0.6808, Training Accuracy= 0.547\n",
      "Epoch: 690, Loss= 0.6611, Training Accuracy= 0.617\n",
      "Epoch: 700, Loss= 0.6075, Training Accuracy= 0.701\n",
      "Epoch: 710, Loss= 0.5470, Training Accuracy= 0.742\n",
      "Epoch: 720, Loss= 0.4957, Training Accuracy= 0.779\n",
      "Epoch: 730, Loss= 0.4436, Training Accuracy= 0.803\n",
      "Epoch: 740, Loss= 0.3951, Training Accuracy= 0.843\n",
      "Epoch: 750, Loss= 0.3589, Training Accuracy= 0.862\n",
      "Epoch: 760, Loss= 0.3262, Training Accuracy= 0.890\n",
      "Epoch: 770, Loss= 0.2925, Training Accuracy= 0.902\n",
      "Epoch: 780, Loss= 0.2508, Training Accuracy= 0.922\n",
      "Epoch: 790, Loss= 0.2121, Training Accuracy= 0.949\n",
      "Epoch: 800, Loss= 0.1768, Training Accuracy= 0.958\n",
      "Epoch: 810, Loss= 0.1465, Training Accuracy= 0.969\n",
      "Epoch: 820, Loss= 0.8303, Training Accuracy= 0.547\n",
      "Epoch: 830, Loss= 0.6853, Training Accuracy= 0.519\n",
      "Epoch: 840, Loss= 0.6834, Training Accuracy= 0.522\n",
      "Epoch: 850, Loss= 0.6820, Training Accuracy= 0.516\n",
      "Epoch: 860, Loss= 0.6811, Training Accuracy= 0.519\n",
      "Epoch: 870, Loss= 0.6803, Training Accuracy= 0.514\n",
      "Epoch: 880, Loss= 0.6796, Training Accuracy= 0.519\n",
      "Epoch: 890, Loss= 0.6790, Training Accuracy= 0.519\n",
      "Epoch: 900, Loss= 0.6786, Training Accuracy= 0.520\n",
      "Epoch: 910, Loss= 0.6781, Training Accuracy= 0.520\n",
      "Epoch: 920, Loss= 0.6777, Training Accuracy= 0.517\n",
      "Epoch: 930, Loss= 0.6773, Training Accuracy= 0.514\n",
      "Epoch: 940, Loss= 0.6770, Training Accuracy= 0.517\n",
      "Epoch: 950, Loss= 0.6767, Training Accuracy= 0.516\n",
      "Epoch: 960, Loss= 0.6764, Training Accuracy= 0.514\n",
      "Epoch: 970, Loss= 0.6762, Training Accuracy= 0.512\n",
      "Epoch: 980, Loss= 0.6760, Training Accuracy= 0.519\n",
      "Epoch: 990, Loss= 0.6757, Training Accuracy= 0.517\n",
      "Epoch: 1000, Loss= 0.6754, Training Accuracy= 0.511\n",
      "Epoch: 1010, Loss= 0.6750, Training Accuracy= 0.512\n",
      "Epoch: 1020, Loss= 0.6747, Training Accuracy= 0.519\n",
      "Epoch: 1030, Loss= 0.6744, Training Accuracy= 0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1040, Loss= 0.6741, Training Accuracy= 0.521\n",
      "Epoch: 1050, Loss= 0.6737, Training Accuracy= 0.519\n",
      "Epoch: 1060, Loss= 0.6731, Training Accuracy= 0.518\n",
      "Epoch: 1070, Loss= 0.6724, Training Accuracy= 0.519\n",
      "Epoch: 1080, Loss= 0.6718, Training Accuracy= 0.517\n",
      "Epoch: 1090, Loss= 0.6713, Training Accuracy= 0.524\n",
      "Epoch: 1100, Loss= 0.6708, Training Accuracy= 0.518\n",
      "Epoch: 1110, Loss= 0.6703, Training Accuracy= 0.519\n",
      "Epoch: 1120, Loss= 0.6697, Training Accuracy= 0.522\n",
      "Epoch: 1130, Loss= 0.6693, Training Accuracy= 0.525\n",
      "Epoch: 1140, Loss= 0.6689, Training Accuracy= 0.528\n",
      "Epoch: 1150, Loss= 0.6686, Training Accuracy= 0.532\n",
      "Epoch: 1160, Loss= 0.6683, Training Accuracy= 0.531\n",
      "Epoch: 1170, Loss= 0.6680, Training Accuracy= 0.534\n",
      "Epoch: 1180, Loss= 0.6678, Training Accuracy= 0.534\n",
      "Epoch: 1190, Loss= 0.6672, Training Accuracy= 0.532\n",
      "Epoch: 1200, Loss= 0.6664, Training Accuracy= 0.529\n",
      "Epoch: 1210, Loss= 0.6660, Training Accuracy= 0.529\n",
      "Epoch: 1220, Loss= 0.6657, Training Accuracy= 0.526\n",
      "Epoch: 1230, Loss= 0.6653, Training Accuracy= 0.526\n",
      "Epoch: 1240, Loss= 0.6650, Training Accuracy= 0.525\n",
      "Epoch: 1250, Loss= 0.6647, Training Accuracy= 0.525\n",
      "Epoch: 1260, Loss= 0.6644, Training Accuracy= 0.524\n",
      "Epoch: 1270, Loss= 0.6642, Training Accuracy= 0.523\n",
      "Epoch: 1280, Loss= 0.6640, Training Accuracy= 0.522\n",
      "Epoch: 1290, Loss= 0.6638, Training Accuracy= 0.522\n",
      "Epoch: 1300, Loss= 0.6637, Training Accuracy= 0.526\n",
      "Epoch: 1310, Loss= 0.6635, Training Accuracy= 0.524\n",
      "Epoch: 1320, Loss= 0.6633, Training Accuracy= 0.529\n",
      "Epoch: 1330, Loss= 0.6632, Training Accuracy= 0.524\n",
      "Epoch: 1340, Loss= 0.6629, Training Accuracy= 0.522\n",
      "Epoch: 1350, Loss= 0.6627, Training Accuracy= 0.520\n",
      "Epoch: 1360, Loss= 0.6624, Training Accuracy= 0.520\n",
      "Epoch: 1370, Loss= 0.6622, Training Accuracy= 0.518\n",
      "Epoch: 1380, Loss= 0.6620, Training Accuracy= 0.519\n",
      "Epoch: 1390, Loss= 0.6618, Training Accuracy= 0.520\n",
      "Epoch: 1400, Loss= 0.6617, Training Accuracy= 0.518\n",
      "Epoch: 1410, Loss= 0.6616, Training Accuracy= 0.518\n",
      "Epoch: 1420, Loss= 0.6614, Training Accuracy= 0.518\n",
      "Epoch: 1430, Loss= 0.6612, Training Accuracy= 0.518\n",
      "Epoch: 1440, Loss= 0.6611, Training Accuracy= 0.519\n",
      "Epoch: 1450, Loss= 0.6610, Training Accuracy= 0.519\n",
      "Epoch: 1460, Loss= 0.6609, Training Accuracy= 0.518\n",
      "Epoch: 1470, Loss= 0.6610, Training Accuracy= 0.517\n",
      "Epoch: 1480, Loss= 0.6609, Training Accuracy= 0.514\n",
      "Epoch: 1490, Loss= 0.6607, Training Accuracy= 0.514\n",
      "Epoch: 1500, Loss= 0.6603, Training Accuracy= 0.512\n",
      "Epoch: 1510, Loss= 0.6600, Training Accuracy= 0.514\n",
      "Epoch: 1520, Loss= 0.6597, Training Accuracy= 0.514\n",
      "Epoch: 1530, Loss= 0.6595, Training Accuracy= 0.514\n",
      "Epoch: 1540, Loss= 0.6593, Training Accuracy= 0.514\n",
      "Epoch: 1550, Loss= 0.6591, Training Accuracy= 0.516\n",
      "Epoch: 1560, Loss= 0.6590, Training Accuracy= 0.517\n",
      "Epoch: 1570, Loss= 0.6584, Training Accuracy= 0.520\n",
      "Epoch: 1580, Loss= 0.6581, Training Accuracy= 0.521\n",
      "Epoch: 1590, Loss= 0.6583, Training Accuracy= 0.519\n",
      "Epoch: 1600, Loss= 0.6571, Training Accuracy= 0.520\n",
      "Epoch: 1610, Loss= 0.6581, Training Accuracy= 0.525\n",
      "Epoch: 1620, Loss= 0.6559, Training Accuracy= 0.525\n",
      "Epoch: 1630, Loss= 0.6553, Training Accuracy= 0.526\n",
      "Epoch: 1640, Loss= 0.6547, Training Accuracy= 0.535\n",
      "Epoch: 1650, Loss= 0.6537, Training Accuracy= 0.542\n",
      "Epoch: 1660, Loss= 0.6784, Training Accuracy= 0.521\n",
      "Epoch: 1670, Loss= 0.6823, Training Accuracy= 0.525\n",
      "Epoch: 1680, Loss= 0.6725, Training Accuracy= 0.515\n",
      "Epoch: 1690, Loss= 0.6668, Training Accuracy= 0.531\n",
      "Epoch: 1700, Loss= 0.6659, Training Accuracy= 0.538\n",
      "Epoch: 1710, Loss= 0.6566, Training Accuracy= 0.542\n",
      "Epoch: 1720, Loss= 0.6501, Training Accuracy= 0.536\n",
      "Epoch: 1730, Loss= 0.6448, Training Accuracy= 0.541\n",
      "Epoch: 1740, Loss= 0.6360, Training Accuracy= 0.547\n",
      "Epoch: 1750, Loss= 0.6186, Training Accuracy= 0.558\n",
      "Epoch: 1760, Loss= 0.6039, Training Accuracy= 0.562\n",
      "Epoch: 1770, Loss= 0.5810, Training Accuracy= 0.605\n",
      "Epoch: 1780, Loss= 0.5597, Training Accuracy= 0.592\n",
      "Epoch: 1790, Loss= 0.5262, Training Accuracy= 0.695\n",
      "Epoch: 1800, Loss= 0.3756, Training Accuracy= 0.888\n",
      "Epoch: 1810, Loss= 0.0403, Training Accuracy= 0.999\n",
      "Epoch: 1820, Loss= 0.0230, Training Accuracy= 0.999\n",
      "Epoch: 1830, Loss= 0.0168, Training Accuracy= 0.999\n",
      "Epoch: 1840, Loss= 0.0133, Training Accuracy= 0.999\n",
      "Epoch: 1850, Loss= 0.0111, Training Accuracy= 0.999\n",
      "Epoch: 1860, Loss= 0.0095, Training Accuracy= 0.999\n",
      "Epoch: 1870, Loss= 0.0083, Training Accuracy= 0.999\n",
      "Epoch: 1880, Loss= 0.0073, Training Accuracy= 0.999\n",
      "Epoch: 1890, Loss= 0.0066, Training Accuracy= 0.999\n",
      "Epoch: 1900, Loss= 0.0060, Training Accuracy= 0.999\n",
      "Epoch: 1910, Loss= 0.0054, Training Accuracy= 0.999\n",
      "Epoch: 1920, Loss= 0.0050, Training Accuracy= 0.999\n",
      "Epoch: 1930, Loss= 0.0046, Training Accuracy= 0.999\n",
      "Epoch: 1940, Loss= 0.0043, Training Accuracy= 0.999\n",
      "Epoch: 1950, Loss= 0.0040, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 2000, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 2010, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 2020, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 2030, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 2040, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 2050, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 2060, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 2070, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2080, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2090, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 2100, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 2110, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2120, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2130, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2140, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2150, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2160, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2170, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2180, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2190, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2200, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2210, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2220, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2230, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2240, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2250, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2260, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 2280, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0006, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2620, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Loss= 0.7032, Training Accuracy= 0.503\n",
      "Epoch: 10, Loss= 0.6932, Training Accuracy= 0.493\n",
      "Epoch: 20, Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 30, Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 40, Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 50, Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 70, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 80, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 90, Loss= 0.6928, Training Accuracy= 0.504\n",
      "Epoch: 100, Loss= 0.6928, Training Accuracy= 0.504\n",
      "Epoch: 110, Loss= 0.6928, Training Accuracy= 0.504\n",
      "Epoch: 120, Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 130, Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 140, Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 150, Loss= 0.6927, Training Accuracy= 0.515\n",
      "Epoch: 160, Loss= 0.6927, Training Accuracy= 0.519\n",
      "Epoch: 170, Loss= 0.6926, Training Accuracy= 0.517\n",
      "Epoch: 180, Loss= 0.6926, Training Accuracy= 0.517\n",
      "Epoch: 190, Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 200, Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 210, Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 220, Loss= 0.6925, Training Accuracy= 0.510\n",
      "Epoch: 230, Loss= 0.6925, Training Accuracy= 0.508\n",
      "Epoch: 240, Loss= 0.6925, Training Accuracy= 0.508\n",
      "Epoch: 250, Loss= 0.6925, Training Accuracy= 0.503\n",
      "Epoch: 260, Loss= 0.6925, Training Accuracy= 0.507\n",
      "Epoch: 270, Loss= 0.6924, Training Accuracy= 0.511\n",
      "Epoch: 280, Loss= 0.6924, Training Accuracy= 0.513\n",
      "Epoch: 290, Loss= 0.6924, Training Accuracy= 0.510\n",
      "Epoch: 300, Loss= 0.6924, Training Accuracy= 0.508\n",
      "Epoch: 310, Loss= 0.6923, Training Accuracy= 0.509\n",
      "Epoch: 320, Loss= 0.6923, Training Accuracy= 0.513\n",
      "Epoch: 330, Loss= 0.6923, Training Accuracy= 0.509\n",
      "Epoch: 340, Loss= 0.6923, Training Accuracy= 0.508\n",
      "Epoch: 350, Loss= 0.6922, Training Accuracy= 0.508\n",
      "Epoch: 360, Loss= 0.6922, Training Accuracy= 0.511\n",
      "Epoch: 370, Loss= 0.6922, Training Accuracy= 0.512\n",
      "Epoch: 380, Loss= 0.6922, Training Accuracy= 0.514\n",
      "Epoch: 390, Loss= 0.6921, Training Accuracy= 0.515\n",
      "Epoch: 400, Loss= 0.6921, Training Accuracy= 0.515\n",
      "Epoch: 410, Loss= 0.6921, Training Accuracy= 0.517\n",
      "Epoch: 420, Loss= 0.6921, Training Accuracy= 0.519\n",
      "Epoch: 430, Loss= 0.6920, Training Accuracy= 0.520\n",
      "Epoch: 440, Loss= 0.6920, Training Accuracy= 0.521\n",
      "Epoch: 450, Loss= 0.6920, Training Accuracy= 0.522\n",
      "Epoch: 460, Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 470, Loss= 0.6919, Training Accuracy= 0.518\n",
      "Epoch: 480, Loss= 0.6919, Training Accuracy= 0.517\n",
      "Epoch: 490, Loss= 0.6919, Training Accuracy= 0.517\n",
      "Epoch: 500, Loss= 0.6918, Training Accuracy= 0.517\n",
      "Epoch: 510, Loss= 0.6918, Training Accuracy= 0.524\n",
      "Epoch: 520, Loss= 0.6917, Training Accuracy= 0.524\n",
      "Epoch: 530, Loss= 0.6917, Training Accuracy= 0.526\n",
      "Epoch: 540, Loss= 0.6917, Training Accuracy= 0.528\n",
      "Epoch: 550, Loss= 0.6916, Training Accuracy= 0.527\n",
      "Epoch: 560, Loss= 0.6916, Training Accuracy= 0.524\n",
      "Epoch: 570, Loss= 0.6915, Training Accuracy= 0.531\n",
      "Epoch: 580, Loss= 0.6915, Training Accuracy= 0.527\n",
      "Epoch: 590, Loss= 0.6914, Training Accuracy= 0.528\n",
      "Epoch: 600, Loss= 0.6913, Training Accuracy= 0.529\n",
      "Epoch: 610, Loss= 0.6913, Training Accuracy= 0.525\n",
      "Epoch: 620, Loss= 0.6912, Training Accuracy= 0.524\n",
      "Epoch: 630, Loss= 0.6911, Training Accuracy= 0.519\n",
      "Epoch: 640, Loss= 0.6910, Training Accuracy= 0.519\n",
      "Epoch: 650, Loss= 0.6909, Training Accuracy= 0.520\n",
      "Epoch: 660, Loss= 0.6908, Training Accuracy= 0.521\n",
      "Epoch: 670, Loss= 0.6907, Training Accuracy= 0.528\n",
      "Epoch: 680, Loss= 0.6906, Training Accuracy= 0.532\n",
      "Epoch: 690, Loss= 0.6905, Training Accuracy= 0.532\n",
      "Epoch: 700, Loss= 0.6903, Training Accuracy= 0.532\n",
      "Epoch: 710, Loss= 0.6902, Training Accuracy= 0.534\n",
      "Epoch: 720, Loss= 0.6901, Training Accuracy= 0.539\n",
      "Epoch: 730, Loss= 0.6900, Training Accuracy= 0.537\n",
      "Epoch: 740, Loss= 0.6898, Training Accuracy= 0.536\n",
      "Epoch: 750, Loss= 0.6897, Training Accuracy= 0.534\n",
      "Epoch: 760, Loss= 0.6896, Training Accuracy= 0.532\n",
      "Epoch: 770, Loss= 0.6894, Training Accuracy= 0.530\n",
      "Epoch: 780, Loss= 0.6893, Training Accuracy= 0.532\n",
      "Epoch: 790, Loss= 0.6892, Training Accuracy= 0.531\n",
      "Epoch: 800, Loss= 0.6890, Training Accuracy= 0.528\n",
      "Epoch: 810, Loss= 0.6889, Training Accuracy= 0.530\n",
      "Epoch: 820, Loss= 0.6888, Training Accuracy= 0.531\n",
      "Epoch: 830, Loss= 0.6887, Training Accuracy= 0.536\n",
      "Epoch: 840, Loss= 0.6885, Training Accuracy= 0.539\n",
      "Epoch: 850, Loss= 0.6884, Training Accuracy= 0.536\n",
      "Epoch: 860, Loss= 0.6883, Training Accuracy= 0.540\n",
      "Epoch: 870, Loss= 0.6881, Training Accuracy= 0.541\n",
      "Epoch: 880, Loss= 0.6880, Training Accuracy= 0.542\n",
      "Epoch: 890, Loss= 0.6878, Training Accuracy= 0.538\n",
      "Epoch: 900, Loss= 0.6876, Training Accuracy= 0.540\n",
      "Epoch: 910, Loss= 0.6873, Training Accuracy= 0.549\n",
      "Epoch: 920, Loss= 0.6870, Training Accuracy= 0.549\n",
      "Epoch: 930, Loss= 0.6863, Training Accuracy= 0.551\n",
      "Epoch: 940, Loss= 0.6842, Training Accuracy= 0.561\n",
      "Epoch: 950, Loss= 0.6780, Training Accuracy= 0.601\n",
      "Epoch: 960, Loss= 0.6646, Training Accuracy= 0.626\n",
      "Epoch: 970, Loss= 0.5350, Training Accuracy= 0.857\n",
      "Epoch: 980, Loss= 0.2136, Training Accuracy= 1.000\n",
      "Epoch: 990, Loss= 0.0826, Training Accuracy= 1.000\n",
      "Epoch: 1000, Loss= 0.0454, Training Accuracy= 1.000\n",
      "Epoch: 1010, Loss= 0.0301, Training Accuracy= 1.000\n",
      "Epoch: 1020, Loss= 0.0221, Training Accuracy= 1.000\n",
      "Epoch: 1030, Loss= 0.0173, Training Accuracy= 1.000\n",
      "Epoch: 1040, Loss= 0.0142, Training Accuracy= 1.000\n",
      "Epoch: 1050, Loss= 0.0119, Training Accuracy= 1.000\n",
      "Epoch: 1060, Loss= 0.0103, Training Accuracy= 1.000\n",
      "Epoch: 1070, Loss= 0.0090, Training Accuracy= 1.000\n",
      "Epoch: 1080, Loss= 0.0079, Training Accuracy= 1.000\n",
      "Epoch: 1090, Loss= 0.0071, Training Accuracy= 1.000\n",
      "Epoch: 1100, Loss= 0.0064, Training Accuracy= 1.000\n",
      "Epoch: 1110, Loss= 0.0059, Training Accuracy= 1.000\n",
      "Epoch: 1120, Loss= 0.0054, Training Accuracy= 1.000\n",
      "Epoch: 1130, Loss= 0.0050, Training Accuracy= 1.000\n",
      "Epoch: 1140, Loss= 0.0046, Training Accuracy= 1.000\n",
      "Epoch: 1150, Loss= 0.0043, Training Accuracy= 1.000\n",
      "Epoch: 1160, Loss= 0.0040, Training Accuracy= 1.000\n",
      "Epoch: 1170, Loss= 0.0038, Training Accuracy= 1.000\n",
      "Epoch: 1180, Loss= 0.0036, Training Accuracy= 1.000\n",
      "Epoch: 1190, Loss= 0.0034, Training Accuracy= 1.000\n",
      "Epoch: 1200, Loss= 0.0032, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1210, Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 1220, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 1230, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 1240, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 1250, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 1260, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 1270, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 1280, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 1290, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 1300, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1310, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 1320, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 1330, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 1340, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1350, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 1360, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1370, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1380, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1390, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 1400, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1410, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1420, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1430, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1440, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1450, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1460, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1470, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1480, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1490, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1500, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1510, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1520, Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1530, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1540, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1550, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1560, Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1570, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1580, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1590, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1600, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1610, Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1620, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1630, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1640, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1650, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1660, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1670, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1680, Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1690, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1700, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1710, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1720, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1730, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1740, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1750, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1760, Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1770, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1780, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1790, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1800, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1810, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1820, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1830, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 2000, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2010, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2020, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2030, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2040, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2050, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2060, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2070, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2080, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2090, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2100, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2110, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2120, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2130, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2140, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2150, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2160, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2170, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2180, Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 2190, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2200, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2210, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2220, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2230, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2240, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2250, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2260, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2280, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0003, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2790, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2960, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0002, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 8: \n",
      "Epoch: 0, Loss= 0.7109, Training Accuracy= 0.488\n",
      "Epoch: 10, Loss= 0.6950, Training Accuracy= 0.489\n",
      "Epoch: 20, Loss= 0.6939, Training Accuracy= 0.497\n",
      "Epoch: 30, Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 40, Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 50, Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 70, Loss= 0.6930, Training Accuracy= 0.497\n",
      "Epoch: 80, Loss= 0.6929, Training Accuracy= 0.506\n",
      "Epoch: 90, Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 100, Loss= 0.6928, Training Accuracy= 0.513\n",
      "Epoch: 110, Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 120, Loss= 0.6927, Training Accuracy= 0.514\n",
      "Epoch: 130, Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 140, Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 150, Loss= 0.6926, Training Accuracy= 0.517\n",
      "Epoch: 160, Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 170, Loss= 0.6925, Training Accuracy= 0.513\n",
      "Epoch: 180, Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 190, Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 200, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 210, Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 220, Loss= 0.6923, Training Accuracy= 0.522\n",
      "Epoch: 230, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 240, Loss= 0.6922, Training Accuracy= 0.513\n",
      "Epoch: 250, Loss= 0.6922, Training Accuracy= 0.509\n",
      "Epoch: 260, Loss= 0.6921, Training Accuracy= 0.509\n",
      "Epoch: 270, Loss= 0.6921, Training Accuracy= 0.508\n",
      "Epoch: 280, Loss= 0.6920, Training Accuracy= 0.512\n",
      "Epoch: 290, Loss= 0.6920, Training Accuracy= 0.512\n",
      "Epoch: 300, Loss= 0.6919, Training Accuracy= 0.515\n",
      "Epoch: 310, Loss= 0.6919, Training Accuracy= 0.511\n",
      "Epoch: 320, Loss= 0.6919, Training Accuracy= 0.508\n",
      "Epoch: 330, Loss= 0.6918, Training Accuracy= 0.513\n",
      "Epoch: 340, Loss= 0.6918, Training Accuracy= 0.508\n",
      "Epoch: 350, Loss= 0.6918, Training Accuracy= 0.510\n",
      "Epoch: 360, Loss= 0.6917, Training Accuracy= 0.516\n",
      "Epoch: 370, Loss= 0.6917, Training Accuracy= 0.513\n",
      "Epoch: 380, Loss= 0.6917, Training Accuracy= 0.515\n",
      "Epoch: 390, Loss= 0.6917, Training Accuracy= 0.521\n",
      "Epoch: 400, Loss= 0.6916, Training Accuracy= 0.524\n",
      "Epoch: 410, Loss= 0.6916, Training Accuracy= 0.527\n",
      "Epoch: 420, Loss= 0.6916, Training Accuracy= 0.522\n",
      "Epoch: 430, Loss= 0.6916, Training Accuracy= 0.517\n",
      "Epoch: 440, Loss= 0.6915, Training Accuracy= 0.518\n",
      "Epoch: 450, Loss= 0.6915, Training Accuracy= 0.519\n",
      "Epoch: 460, Loss= 0.6915, Training Accuracy= 0.523\n",
      "Epoch: 470, Loss= 0.6915, Training Accuracy= 0.521\n",
      "Epoch: 480, Loss= 0.6914, Training Accuracy= 0.521\n",
      "Epoch: 490, Loss= 0.6914, Training Accuracy= 0.524\n",
      "Epoch: 500, Loss= 0.6914, Training Accuracy= 0.521\n",
      "Epoch: 510, Loss= 0.6914, Training Accuracy= 0.526\n",
      "Epoch: 520, Loss= 0.6913, Training Accuracy= 0.525\n",
      "Epoch: 530, Loss= 0.6913, Training Accuracy= 0.529\n",
      "Epoch: 540, Loss= 0.6913, Training Accuracy= 0.527\n",
      "Epoch: 550, Loss= 0.6913, Training Accuracy= 0.524\n",
      "Epoch: 560, Loss= 0.6912, Training Accuracy= 0.525\n",
      "Epoch: 570, Loss= 0.6912, Training Accuracy= 0.520\n",
      "Epoch: 580, Loss= 0.6912, Training Accuracy= 0.520\n",
      "Epoch: 590, Loss= 0.6912, Training Accuracy= 0.521\n",
      "Epoch: 600, Loss= 0.6911, Training Accuracy= 0.518\n",
      "Epoch: 610, Loss= 0.6911, Training Accuracy= 0.517\n",
      "Epoch: 620, Loss= 0.6911, Training Accuracy= 0.519\n",
      "Epoch: 630, Loss= 0.6911, Training Accuracy= 0.517\n",
      "Epoch: 640, Loss= 0.6910, Training Accuracy= 0.518\n",
      "Epoch: 650, Loss= 0.6910, Training Accuracy= 0.518\n",
      "Epoch: 660, Loss= 0.6910, Training Accuracy= 0.520\n",
      "Epoch: 670, Loss= 0.6910, Training Accuracy= 0.521\n",
      "Epoch: 680, Loss= 0.6909, Training Accuracy= 0.522\n",
      "Epoch: 690, Loss= 0.6909, Training Accuracy= 0.522\n",
      "Epoch: 700, Loss= 0.6909, Training Accuracy= 0.525\n",
      "Epoch: 710, Loss= 0.6908, Training Accuracy= 0.526\n",
      "Epoch: 720, Loss= 0.6908, Training Accuracy= 0.527\n",
      "Epoch: 730, Loss= 0.6908, Training Accuracy= 0.524\n",
      "Epoch: 740, Loss= 0.6907, Training Accuracy= 0.532\n",
      "Epoch: 750, Loss= 0.6907, Training Accuracy= 0.533\n",
      "Epoch: 760, Loss= 0.6907, Training Accuracy= 0.535\n",
      "Epoch: 770, Loss= 0.6906, Training Accuracy= 0.535\n",
      "Epoch: 780, Loss= 0.6906, Training Accuracy= 0.537\n",
      "Epoch: 790, Loss= 0.6905, Training Accuracy= 0.538\n",
      "Epoch: 800, Loss= 0.6905, Training Accuracy= 0.540\n",
      "Epoch: 810, Loss= 0.6904, Training Accuracy= 0.543\n",
      "Epoch: 820, Loss= 0.6904, Training Accuracy= 0.543\n",
      "Epoch: 830, Loss= 0.6903, Training Accuracy= 0.543\n",
      "Epoch: 840, Loss= 0.6902, Training Accuracy= 0.541\n",
      "Epoch: 850, Loss= 0.6902, Training Accuracy= 0.536\n",
      "Epoch: 860, Loss= 0.6901, Training Accuracy= 0.534\n",
      "Epoch: 870, Loss= 0.6900, Training Accuracy= 0.534\n",
      "Epoch: 880, Loss= 0.6899, Training Accuracy= 0.535\n",
      "Epoch: 890, Loss= 0.6898, Training Accuracy= 0.534\n",
      "Epoch: 900, Loss= 0.6897, Training Accuracy= 0.535\n",
      "Epoch: 910, Loss= 0.6896, Training Accuracy= 0.534\n",
      "Epoch: 920, Loss= 0.6895, Training Accuracy= 0.537\n",
      "Epoch: 930, Loss= 0.6894, Training Accuracy= 0.535\n",
      "Epoch: 940, Loss= 0.6892, Training Accuracy= 0.535\n",
      "Epoch: 950, Loss= 0.6891, Training Accuracy= 0.535\n",
      "Epoch: 960, Loss= 0.6889, Training Accuracy= 0.536\n",
      "Epoch: 970, Loss= 0.6886, Training Accuracy= 0.538\n",
      "Epoch: 980, Loss= 0.6884, Training Accuracy= 0.537\n",
      "Epoch: 990, Loss= 0.6880, Training Accuracy= 0.544\n",
      "Epoch: 1000, Loss= 0.6876, Training Accuracy= 0.542\n",
      "Epoch: 1010, Loss= 0.6871, Training Accuracy= 0.542\n",
      "Epoch: 1020, Loss= 0.6866, Training Accuracy= 0.548\n",
      "Epoch: 1030, Loss= 0.6860, Training Accuracy= 0.542\n",
      "Epoch: 1040, Loss= 0.6854, Training Accuracy= 0.545\n",
      "Epoch: 1050, Loss= 0.6846, Training Accuracy= 0.549\n",
      "Epoch: 1060, Loss= 0.6836, Training Accuracy= 0.554\n",
      "Epoch: 1070, Loss= 0.6825, Training Accuracy= 0.563\n",
      "Epoch: 1080, Loss= 0.6811, Training Accuracy= 0.560\n",
      "Epoch: 1090, Loss= 0.6795, Training Accuracy= 0.561\n",
      "Epoch: 1100, Loss= 0.6776, Training Accuracy= 0.564\n",
      "Epoch: 1110, Loss= 0.6755, Training Accuracy= 0.567\n",
      "Epoch: 1120, Loss= 0.6731, Training Accuracy= 0.577\n",
      "Epoch: 1130, Loss= 0.6704, Training Accuracy= 0.593\n",
      "Epoch: 1140, Loss= 0.6664, Training Accuracy= 0.607\n",
      "Epoch: 1150, Loss= 0.6590, Training Accuracy= 0.605\n",
      "Epoch: 1160, Loss= 0.6483, Training Accuracy= 0.624\n",
      "Epoch: 1170, Loss= 0.6362, Training Accuracy= 0.648\n",
      "Epoch: 1180, Loss= 0.6340, Training Accuracy= 0.647\n",
      "Epoch: 1190, Loss= 0.6243, Training Accuracy= 0.649\n",
      "Epoch: 1200, Loss= 0.6283, Training Accuracy= 0.653\n",
      "Epoch: 1210, Loss= 0.5613, Training Accuracy= 0.718\n",
      "Epoch: 1220, Loss= 0.5539, Training Accuracy= 0.712\n",
      "Epoch: 1230, Loss= 0.5082, Training Accuracy= 0.752\n",
      "Epoch: 1240, Loss= 0.4917, Training Accuracy= 0.768\n",
      "Epoch: 1250, Loss= 0.4739, Training Accuracy= 0.783\n",
      "Epoch: 1260, Loss= 0.4832, Training Accuracy= 0.780\n",
      "Epoch: 1270, Loss= 0.4764, Training Accuracy= 0.785\n",
      "Epoch: 1280, Loss= 0.4959, Training Accuracy= 0.771\n",
      "Epoch: 1290, Loss= 0.4727, Training Accuracy= 0.791\n",
      "Epoch: 1300, Loss= 0.4901, Training Accuracy= 0.768\n",
      "Epoch: 1310, Loss= 0.4609, Training Accuracy= 0.788\n",
      "Epoch: 1320, Loss= 0.4538, Training Accuracy= 0.800\n",
      "Epoch: 1330, Loss= 0.4556, Training Accuracy= 0.799\n",
      "Epoch: 1340, Loss= 0.4886, Training Accuracy= 0.777\n",
      "Epoch: 1350, Loss= 0.4630, Training Accuracy= 0.794\n",
      "Epoch: 1360, Loss= 0.5523, Training Accuracy= 0.747\n",
      "Epoch: 1370, Loss= 0.5096, Training Accuracy= 0.764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1380, Loss= 0.3823, Training Accuracy= 0.820\n",
      "Epoch: 1390, Loss= 0.3698, Training Accuracy= 0.848\n",
      "Epoch: 1400, Loss= 0.3371, Training Accuracy= 0.859\n",
      "Epoch: 1410, Loss= 0.4813, Training Accuracy= 0.781\n",
      "Epoch: 1420, Loss= 0.5659, Training Accuracy= 0.768\n",
      "Epoch: 1430, Loss= 0.2876, Training Accuracy= 0.902\n",
      "Epoch: 1440, Loss= 0.5822, Training Accuracy= 0.744\n",
      "Epoch: 1450, Loss= 0.2793, Training Accuracy= 0.909\n",
      "Epoch: 1460, Loss= 0.2697, Training Accuracy= 0.909\n",
      "Epoch: 1470, Loss= 0.3834, Training Accuracy= 0.858\n",
      "Epoch: 1480, Loss= 0.2474, Training Accuracy= 0.926\n",
      "Epoch: 1490, Loss= 0.3419, Training Accuracy= 0.870\n",
      "Epoch: 1500, Loss= 0.2232, Training Accuracy= 0.928\n",
      "Epoch: 1510, Loss= 0.3010, Training Accuracy= 0.899\n",
      "Epoch: 1520, Loss= 0.5678, Training Accuracy= 0.792\n",
      "Epoch: 1530, Loss= 0.4943, Training Accuracy= 0.816\n",
      "Epoch: 1540, Loss= 0.2364, Training Accuracy= 0.922\n",
      "Epoch: 1550, Loss= 0.1860, Training Accuracy= 0.951\n",
      "Epoch: 1560, Loss= 0.1789, Training Accuracy= 0.945\n",
      "Epoch: 1570, Loss= 0.1790, Training Accuracy= 0.941\n",
      "Epoch: 1580, Loss= 0.1767, Training Accuracy= 0.942\n",
      "Epoch: 1590, Loss= 0.1673, Training Accuracy= 0.947\n",
      "Epoch: 1600, Loss= 0.1702, Training Accuracy= 0.947\n",
      "Epoch: 1610, Loss= 0.1608, Training Accuracy= 0.946\n",
      "Epoch: 1620, Loss= 0.3024, Training Accuracy= 0.883\n",
      "Epoch: 1630, Loss= 0.1623, Training Accuracy= 0.952\n",
      "Epoch: 1640, Loss= 0.1908, Training Accuracy= 0.932\n",
      "Epoch: 1650, Loss= 0.1504, Training Accuracy= 0.948\n",
      "Epoch: 1660, Loss= 0.1387, Training Accuracy= 0.960\n",
      "Epoch: 1670, Loss= 0.1380, Training Accuracy= 0.953\n",
      "Epoch: 1680, Loss= 0.1365, Training Accuracy= 0.956\n",
      "Epoch: 1690, Loss= 0.1284, Training Accuracy= 0.962\n",
      "Epoch: 1700, Loss= 0.5610, Training Accuracy= 0.805\n",
      "Epoch: 1710, Loss= 0.1298, Training Accuracy= 0.951\n",
      "Epoch: 1720, Loss= 0.0933, Training Accuracy= 0.973\n",
      "Epoch: 1730, Loss= 0.1351, Training Accuracy= 0.955\n",
      "Epoch: 1740, Loss= 0.0879, Training Accuracy= 0.976\n",
      "Epoch: 1750, Loss= 0.1498, Training Accuracy= 0.956\n",
      "Epoch: 1760, Loss= 0.4572, Training Accuracy= 0.848\n",
      "Epoch: 1770, Loss= 0.0698, Training Accuracy= 0.988\n",
      "Epoch: 1780, Loss= 0.3026, Training Accuracy= 0.907\n",
      "Epoch: 1790, Loss= 0.0635, Training Accuracy= 0.993\n",
      "Epoch: 1800, Loss= 0.0460, Training Accuracy= 0.997\n",
      "Epoch: 1810, Loss= 0.0358, Training Accuracy= 0.999\n",
      "Epoch: 1820, Loss= 0.0320, Training Accuracy= 0.998\n",
      "Epoch: 1830, Loss= 0.0232, Training Accuracy= 1.000\n",
      "Epoch: 1840, Loss= 0.0198, Training Accuracy= 1.000\n",
      "Epoch: 1850, Loss= 0.0177, Training Accuracy= 1.000\n",
      "Epoch: 1860, Loss= 0.0161, Training Accuracy= 1.000\n",
      "Epoch: 1870, Loss= 0.0148, Training Accuracy= 1.000\n",
      "Epoch: 1880, Loss= 0.0137, Training Accuracy= 1.000\n",
      "Epoch: 1890, Loss= 0.0127, Training Accuracy= 1.000\n",
      "Epoch: 1900, Loss= 0.0119, Training Accuracy= 1.000\n",
      "Epoch: 1910, Loss= 0.0111, Training Accuracy= 1.000\n",
      "Epoch: 1920, Loss= 0.0105, Training Accuracy= 1.000\n",
      "Epoch: 1930, Loss= 0.0100, Training Accuracy= 1.000\n",
      "Epoch: 1940, Loss= 0.0094, Training Accuracy= 1.000\n",
      "Epoch: 1950, Loss= 0.0090, Training Accuracy= 1.000\n",
      "Epoch: 1960, Loss= 0.0086, Training Accuracy= 1.000\n",
      "Epoch: 1970, Loss= 0.0082, Training Accuracy= 1.000\n",
      "Epoch: 1980, Loss= 0.0078, Training Accuracy= 1.000\n",
      "Epoch: 1990, Loss= 0.0075, Training Accuracy= 1.000\n",
      "Epoch: 2000, Loss= 0.0072, Training Accuracy= 1.000\n",
      "Epoch: 2010, Loss= 0.0069, Training Accuracy= 1.000\n",
      "Epoch: 2020, Loss= 0.0067, Training Accuracy= 1.000\n",
      "Epoch: 2030, Loss= 0.0064, Training Accuracy= 1.000\n",
      "Epoch: 2040, Loss= 0.0062, Training Accuracy= 1.000\n",
      "Epoch: 2050, Loss= 0.0060, Training Accuracy= 1.000\n",
      "Epoch: 2060, Loss= 0.0057, Training Accuracy= 1.000\n",
      "Epoch: 2070, Loss= 0.0055, Training Accuracy= 1.000\n",
      "Epoch: 2080, Loss= 0.0053, Training Accuracy= 1.000\n",
      "Epoch: 2090, Loss= 0.0052, Training Accuracy= 1.000\n",
      "Epoch: 2100, Loss= 0.0050, Training Accuracy= 1.000\n",
      "Epoch: 2110, Loss= 0.0048, Training Accuracy= 1.000\n",
      "Epoch: 2120, Loss= 0.0047, Training Accuracy= 1.000\n",
      "Epoch: 2130, Loss= 0.0046, Training Accuracy= 1.000\n",
      "Epoch: 2140, Loss= 0.0044, Training Accuracy= 1.000\n",
      "Epoch: 2150, Loss= 0.0043, Training Accuracy= 1.000\n",
      "Epoch: 2160, Loss= 0.0042, Training Accuracy= 1.000\n",
      "Epoch: 2170, Loss= 0.0041, Training Accuracy= 1.000\n",
      "Epoch: 2180, Loss= 0.0040, Training Accuracy= 1.000\n",
      "Epoch: 2190, Loss= 0.0039, Training Accuracy= 1.000\n",
      "Epoch: 2200, Loss= 0.0038, Training Accuracy= 1.000\n",
      "Epoch: 2210, Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 2220, Loss= 0.0036, Training Accuracy= 1.000\n",
      "Epoch: 2230, Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 2240, Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 2250, Loss= 0.0034, Training Accuracy= 1.000\n",
      "Epoch: 2260, Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 2270, Loss= 0.0033, Training Accuracy= 1.000\n",
      "Epoch: 2280, Loss= 0.0032, Training Accuracy= 1.000\n",
      "Epoch: 2290, Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 2300, Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 2310, Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 2320, Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 2330, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 2340, Loss= 0.0029, Training Accuracy= 1.000\n",
      "Epoch: 2350, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 2360, Loss= 0.0028, Training Accuracy= 1.000\n",
      "Epoch: 2370, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 2380, Loss= 0.0027, Training Accuracy= 1.000\n",
      "Epoch: 2390, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 2400, Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 2410, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 2420, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 2430, Loss= 0.0025, Training Accuracy= 1.000\n",
      "Epoch: 2440, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 2450, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 2460, Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 2470, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 2480, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 2490, Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 2500, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 2510, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 2520, Loss= 0.0022, Training Accuracy= 1.000\n",
      "Epoch: 2530, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2540, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2550, Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 2560, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 2570, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 2580, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 2590, Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 2600, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 2610, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 2620, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 2630, Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 2640, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2650, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2660, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2670, Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 2680, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2690, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2700, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2710, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2720, Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 2730, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2740, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2750, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2760, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2770, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2780, Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 2790, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2800, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2810, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2820, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2830, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2840, Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 2850, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2860, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2870, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2880, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2890, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2900, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2910, Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 2920, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2930, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2940, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0013, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2960, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0013, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 9: \n",
      "Epoch: 0, Loss= 0.7041, Training Accuracy= 0.516\n",
      "Epoch: 10, Loss= 0.6946, Training Accuracy= 0.495\n",
      "Epoch: 20, Loss= 0.6942, Training Accuracy= 0.495\n",
      "Epoch: 30, Loss= 0.6939, Training Accuracy= 0.499\n",
      "Epoch: 40, Loss= 0.6937, Training Accuracy= 0.499\n",
      "Epoch: 50, Loss= 0.6936, Training Accuracy= 0.504\n",
      "Epoch: 60, Loss= 0.6935, Training Accuracy= 0.504\n",
      "Epoch: 70, Loss= 0.6933, Training Accuracy= 0.507\n",
      "Epoch: 80, Loss= 0.6932, Training Accuracy= 0.515\n",
      "Epoch: 90, Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 100, Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 110, Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 120, Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 130, Loss= 0.6928, Training Accuracy= 0.507\n",
      "Epoch: 140, Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 150, Loss= 0.6927, Training Accuracy= 0.519\n",
      "Epoch: 160, Loss= 0.6926, Training Accuracy= 0.525\n",
      "Epoch: 170, Loss= 0.6926, Training Accuracy= 0.525\n",
      "Epoch: 180, Loss= 0.6925, Training Accuracy= 0.521\n",
      "Epoch: 190, Loss= 0.6925, Training Accuracy= 0.520\n",
      "Epoch: 200, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 210, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 220, Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 230, Loss= 0.6923, Training Accuracy= 0.520\n",
      "Epoch: 240, Loss= 0.6923, Training Accuracy= 0.521\n",
      "Epoch: 250, Loss= 0.6923, Training Accuracy= 0.518\n",
      "Epoch: 260, Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 270, Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 280, Loss= 0.6922, Training Accuracy= 0.517\n",
      "Epoch: 290, Loss= 0.6922, Training Accuracy= 0.515\n",
      "Epoch: 300, Loss= 0.6921, Training Accuracy= 0.515\n",
      "Epoch: 310, Loss= 0.6921, Training Accuracy= 0.514\n",
      "Epoch: 320, Loss= 0.6921, Training Accuracy= 0.513\n",
      "Epoch: 330, Loss= 0.6921, Training Accuracy= 0.517\n",
      "Epoch: 340, Loss= 0.6920, Training Accuracy= 0.522\n",
      "Epoch: 350, Loss= 0.6920, Training Accuracy= 0.528\n",
      "Epoch: 360, Loss= 0.6920, Training Accuracy= 0.530\n",
      "Epoch: 370, Loss= 0.6919, Training Accuracy= 0.527\n",
      "Epoch: 380, Loss= 0.6919, Training Accuracy= 0.527\n",
      "Epoch: 390, Loss= 0.6919, Training Accuracy= 0.527\n",
      "Epoch: 400, Loss= 0.6919, Training Accuracy= 0.528\n",
      "Epoch: 410, Loss= 0.6918, Training Accuracy= 0.528\n",
      "Epoch: 420, Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 430, Loss= 0.6918, Training Accuracy= 0.521\n",
      "Epoch: 440, Loss= 0.6917, Training Accuracy= 0.524\n",
      "Epoch: 450, Loss= 0.6917, Training Accuracy= 0.526\n",
      "Epoch: 460, Loss= 0.6917, Training Accuracy= 0.527\n",
      "Epoch: 470, Loss= 0.6917, Training Accuracy= 0.525\n",
      "Epoch: 480, Loss= 0.6917, Training Accuracy= 0.526\n",
      "Epoch: 490, Loss= 0.6916, Training Accuracy= 0.524\n",
      "Epoch: 500, Loss= 0.6916, Training Accuracy= 0.524\n",
      "Epoch: 510, Loss= 0.6916, Training Accuracy= 0.523\n",
      "Epoch: 520, Loss= 0.6916, Training Accuracy= 0.525\n",
      "Epoch: 530, Loss= 0.6916, Training Accuracy= 0.526\n",
      "Epoch: 540, Loss= 0.6915, Training Accuracy= 0.527\n",
      "Epoch: 550, Loss= 0.6915, Training Accuracy= 0.526\n",
      "Epoch: 560, Loss= 0.6915, Training Accuracy= 0.522\n",
      "Epoch: 570, Loss= 0.6915, Training Accuracy= 0.525\n",
      "Epoch: 580, Loss= 0.6915, Training Accuracy= 0.525\n",
      "Epoch: 590, Loss= 0.6915, Training Accuracy= 0.527\n",
      "Epoch: 600, Loss= 0.6915, Training Accuracy= 0.524\n",
      "Epoch: 610, Loss= 0.6914, Training Accuracy= 0.524\n",
      "Epoch: 620, Loss= 0.6914, Training Accuracy= 0.524\n",
      "Epoch: 630, Loss= 0.6914, Training Accuracy= 0.524\n",
      "Epoch: 640, Loss= 0.6914, Training Accuracy= 0.527\n",
      "Epoch: 650, Loss= 0.6914, Training Accuracy= 0.525\n",
      "Epoch: 660, Loss= 0.6914, Training Accuracy= 0.522\n",
      "Epoch: 670, Loss= 0.6914, Training Accuracy= 0.523\n",
      "Epoch: 680, Loss= 0.6914, Training Accuracy= 0.525\n",
      "Epoch: 690, Loss= 0.6913, Training Accuracy= 0.524\n",
      "Epoch: 700, Loss= 0.6913, Training Accuracy= 0.522\n",
      "Epoch: 710, Loss= 0.6913, Training Accuracy= 0.524\n",
      "Epoch: 720, Loss= 0.6913, Training Accuracy= 0.522\n",
      "Epoch: 730, Loss= 0.6913, Training Accuracy= 0.522\n",
      "Epoch: 740, Loss= 0.6913, Training Accuracy= 0.520\n",
      "Epoch: 750, Loss= 0.6913, Training Accuracy= 0.517\n",
      "Epoch: 760, Loss= 0.6913, Training Accuracy= 0.519\n",
      "Epoch: 770, Loss= 0.6912, Training Accuracy= 0.519\n",
      "Epoch: 780, Loss= 0.6912, Training Accuracy= 0.517\n",
      "Epoch: 790, Loss= 0.6912, Training Accuracy= 0.518\n",
      "Epoch: 800, Loss= 0.6912, Training Accuracy= 0.517\n",
      "Epoch: 810, Loss= 0.6912, Training Accuracy= 0.516\n",
      "Epoch: 820, Loss= 0.6912, Training Accuracy= 0.516\n",
      "Epoch: 830, Loss= 0.6912, Training Accuracy= 0.516\n",
      "Epoch: 840, Loss= 0.6911, Training Accuracy= 0.514\n",
      "Epoch: 850, Loss= 0.6911, Training Accuracy= 0.517\n",
      "Epoch: 860, Loss= 0.6911, Training Accuracy= 0.517\n",
      "Epoch: 870, Loss= 0.6911, Training Accuracy= 0.514\n",
      "Epoch: 880, Loss= 0.6911, Training Accuracy= 0.512\n",
      "Epoch: 890, Loss= 0.6911, Training Accuracy= 0.511\n",
      "Epoch: 900, Loss= 0.6911, Training Accuracy= 0.513\n",
      "Epoch: 910, Loss= 0.6910, Training Accuracy= 0.515\n",
      "Epoch: 920, Loss= 0.6910, Training Accuracy= 0.518\n",
      "Epoch: 930, Loss= 0.6910, Training Accuracy= 0.521\n",
      "Epoch: 940, Loss= 0.6910, Training Accuracy= 0.524\n",
      "Epoch: 950, Loss= 0.6910, Training Accuracy= 0.523\n",
      "Epoch: 960, Loss= 0.6909, Training Accuracy= 0.522\n",
      "Epoch: 970, Loss= 0.6909, Training Accuracy= 0.524\n",
      "Epoch: 980, Loss= 0.6909, Training Accuracy= 0.521\n",
      "Epoch: 990, Loss= 0.6909, Training Accuracy= 0.524\n",
      "Epoch: 1000, Loss= 0.6908, Training Accuracy= 0.524\n",
      "Epoch: 1010, Loss= 0.6908, Training Accuracy= 0.526\n",
      "Epoch: 1020, Loss= 0.6908, Training Accuracy= 0.525\n",
      "Epoch: 1030, Loss= 0.6908, Training Accuracy= 0.523\n",
      "Epoch: 1040, Loss= 0.6907, Training Accuracy= 0.523\n",
      "Epoch: 1050, Loss= 0.6907, Training Accuracy= 0.524\n",
      "Epoch: 1060, Loss= 0.6907, Training Accuracy= 0.526\n",
      "Epoch: 1070, Loss= 0.6907, Training Accuracy= 0.528\n",
      "Epoch: 1080, Loss= 0.6906, Training Accuracy= 0.526\n",
      "Epoch: 1090, Loss= 0.6906, Training Accuracy= 0.531\n",
      "Epoch: 1100, Loss= 0.6906, Training Accuracy= 0.530\n",
      "Epoch: 1110, Loss= 0.6905, Training Accuracy= 0.530\n",
      "Epoch: 1120, Loss= 0.6905, Training Accuracy= 0.531\n",
      "Epoch: 1130, Loss= 0.6905, Training Accuracy= 0.529\n",
      "Epoch: 1140, Loss= 0.6904, Training Accuracy= 0.533\n",
      "Epoch: 1150, Loss= 0.6904, Training Accuracy= 0.531\n",
      "Epoch: 1160, Loss= 0.6904, Training Accuracy= 0.531\n",
      "Epoch: 1170, Loss= 0.6903, Training Accuracy= 0.533\n",
      "Epoch: 1180, Loss= 0.6903, Training Accuracy= 0.533\n",
      "Epoch: 1190, Loss= 0.6903, Training Accuracy= 0.527\n",
      "Epoch: 1200, Loss= 0.6902, Training Accuracy= 0.527\n",
      "Epoch: 1210, Loss= 0.6902, Training Accuracy= 0.528\n",
      "Epoch: 1220, Loss= 0.6902, Training Accuracy= 0.526\n",
      "Epoch: 1230, Loss= 0.6901, Training Accuracy= 0.524\n",
      "Epoch: 1240, Loss= 0.6901, Training Accuracy= 0.525\n",
      "Epoch: 1250, Loss= 0.6900, Training Accuracy= 0.524\n",
      "Epoch: 1260, Loss= 0.6900, Training Accuracy= 0.523\n",
      "Epoch: 1270, Loss= 0.6900, Training Accuracy= 0.522\n",
      "Epoch: 1280, Loss= 0.6899, Training Accuracy= 0.523\n",
      "Epoch: 1290, Loss= 0.6899, Training Accuracy= 0.524\n",
      "Epoch: 1300, Loss= 0.6899, Training Accuracy= 0.520\n",
      "Epoch: 1310, Loss= 0.6898, Training Accuracy= 0.521\n",
      "Epoch: 1320, Loss= 0.6898, Training Accuracy= 0.525\n",
      "Epoch: 1330, Loss= 0.6898, Training Accuracy= 0.522\n",
      "Epoch: 1340, Loss= 0.6897, Training Accuracy= 0.521\n",
      "Epoch: 1350, Loss= 0.6897, Training Accuracy= 0.525\n",
      "Epoch: 1360, Loss= 0.6897, Training Accuracy= 0.529\n",
      "Epoch: 1370, Loss= 0.6896, Training Accuracy= 0.528\n",
      "Epoch: 1380, Loss= 0.6896, Training Accuracy= 0.528\n",
      "Epoch: 1390, Loss= 0.6896, Training Accuracy= 0.527\n",
      "Epoch: 1400, Loss= 0.6895, Training Accuracy= 0.528\n",
      "Epoch: 1410, Loss= 0.6895, Training Accuracy= 0.530\n",
      "Epoch: 1420, Loss= 0.6895, Training Accuracy= 0.531\n",
      "Epoch: 1430, Loss= 0.6894, Training Accuracy= 0.533\n",
      "Epoch: 1440, Loss= 0.6894, Training Accuracy= 0.535\n",
      "Epoch: 1450, Loss= 0.6893, Training Accuracy= 0.536\n",
      "Epoch: 1460, Loss= 0.6893, Training Accuracy= 0.537\n",
      "Epoch: 1470, Loss= 0.6893, Training Accuracy= 0.536\n",
      "Epoch: 1480, Loss= 0.6892, Training Accuracy= 0.539\n",
      "Epoch: 1490, Loss= 0.6892, Training Accuracy= 0.539\n",
      "Epoch: 1500, Loss= 0.6892, Training Accuracy= 0.539\n",
      "Epoch: 1510, Loss= 0.6891, Training Accuracy= 0.539\n",
      "Epoch: 1520, Loss= 0.6891, Training Accuracy= 0.535\n",
      "Epoch: 1530, Loss= 0.6891, Training Accuracy= 0.538\n",
      "Epoch: 1540, Loss= 0.6890, Training Accuracy= 0.537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1550, Loss= 0.6890, Training Accuracy= 0.540\n",
      "Epoch: 1560, Loss= 0.6889, Training Accuracy= 0.540\n",
      "Epoch: 1570, Loss= 0.6889, Training Accuracy= 0.540\n",
      "Epoch: 1580, Loss= 0.6889, Training Accuracy= 0.538\n",
      "Epoch: 1590, Loss= 0.6888, Training Accuracy= 0.538\n",
      "Epoch: 1600, Loss= 0.6888, Training Accuracy= 0.538\n",
      "Epoch: 1610, Loss= 0.6887, Training Accuracy= 0.539\n",
      "Epoch: 1620, Loss= 0.6887, Training Accuracy= 0.539\n",
      "Epoch: 1630, Loss= 0.6887, Training Accuracy= 0.534\n",
      "Epoch: 1640, Loss= 0.6886, Training Accuracy= 0.533\n",
      "Epoch: 1650, Loss= 0.6886, Training Accuracy= 0.536\n",
      "Epoch: 1660, Loss= 0.6885, Training Accuracy= 0.538\n",
      "Epoch: 1670, Loss= 0.6885, Training Accuracy= 0.539\n",
      "Epoch: 1680, Loss= 0.6884, Training Accuracy= 0.539\n",
      "Epoch: 1690, Loss= 0.6884, Training Accuracy= 0.536\n",
      "Epoch: 1700, Loss= 0.6883, Training Accuracy= 0.537\n",
      "Epoch: 1710, Loss= 0.6883, Training Accuracy= 0.535\n",
      "Epoch: 1720, Loss= 0.6882, Training Accuracy= 0.537\n",
      "Epoch: 1730, Loss= 0.6882, Training Accuracy= 0.535\n",
      "Epoch: 1740, Loss= 0.6881, Training Accuracy= 0.535\n",
      "Epoch: 1750, Loss= 0.6880, Training Accuracy= 0.534\n",
      "Epoch: 1760, Loss= 0.6880, Training Accuracy= 0.538\n",
      "Epoch: 1770, Loss= 0.6879, Training Accuracy= 0.536\n",
      "Epoch: 1780, Loss= 0.6879, Training Accuracy= 0.538\n",
      "Epoch: 1790, Loss= 0.6878, Training Accuracy= 0.538\n",
      "Epoch: 1800, Loss= 0.6878, Training Accuracy= 0.535\n",
      "Epoch: 1810, Loss= 0.6877, Training Accuracy= 0.534\n",
      "Epoch: 1820, Loss= 0.6877, Training Accuracy= 0.539\n",
      "Epoch: 1830, Loss= 0.6876, Training Accuracy= 0.538\n",
      "Epoch: 1840, Loss= 0.6876, Training Accuracy= 0.538\n",
      "Epoch: 1850, Loss= 0.6875, Training Accuracy= 0.537\n",
      "Epoch: 1860, Loss= 0.6875, Training Accuracy= 0.537\n",
      "Epoch: 1870, Loss= 0.6874, Training Accuracy= 0.534\n",
      "Epoch: 1880, Loss= 0.6874, Training Accuracy= 0.537\n",
      "Epoch: 1890, Loss= 0.6873, Training Accuracy= 0.538\n",
      "Epoch: 1900, Loss= 0.6873, Training Accuracy= 0.538\n",
      "Epoch: 1910, Loss= 0.6872, Training Accuracy= 0.535\n",
      "Epoch: 1920, Loss= 0.6872, Training Accuracy= 0.535\n",
      "Epoch: 1930, Loss= 0.6872, Training Accuracy= 0.535\n",
      "Epoch: 1940, Loss= 0.6871, Training Accuracy= 0.534\n",
      "Epoch: 1950, Loss= 0.6871, Training Accuracy= 0.534\n",
      "Epoch: 1960, Loss= 0.6870, Training Accuracy= 0.531\n",
      "Epoch: 1970, Loss= 0.6870, Training Accuracy= 0.531\n",
      "Epoch: 1980, Loss= 0.6870, Training Accuracy= 0.531\n",
      "Epoch: 1990, Loss= 0.6869, Training Accuracy= 0.533\n",
      "Epoch: 2000, Loss= 0.6869, Training Accuracy= 0.529\n",
      "Epoch: 2010, Loss= 0.6869, Training Accuracy= 0.527\n",
      "Epoch: 2020, Loss= 0.6868, Training Accuracy= 0.532\n",
      "Epoch: 2030, Loss= 0.6868, Training Accuracy= 0.532\n",
      "Epoch: 2040, Loss= 0.6867, Training Accuracy= 0.531\n",
      "Epoch: 2050, Loss= 0.6867, Training Accuracy= 0.531\n",
      "Epoch: 2060, Loss= 0.6867, Training Accuracy= 0.530\n",
      "Epoch: 2070, Loss= 0.6866, Training Accuracy= 0.531\n",
      "Epoch: 2080, Loss= 0.6866, Training Accuracy= 0.531\n",
      "Epoch: 2090, Loss= 0.6865, Training Accuracy= 0.534\n",
      "Epoch: 2100, Loss= 0.6865, Training Accuracy= 0.532\n",
      "Epoch: 2110, Loss= 0.6865, Training Accuracy= 0.531\n",
      "Epoch: 2120, Loss= 0.6864, Training Accuracy= 0.530\n",
      "Epoch: 2130, Loss= 0.6864, Training Accuracy= 0.530\n",
      "Epoch: 2140, Loss= 0.6863, Training Accuracy= 0.528\n",
      "Epoch: 2150, Loss= 0.6863, Training Accuracy= 0.528\n",
      "Epoch: 2160, Loss= 0.6862, Training Accuracy= 0.528\n",
      "Epoch: 2170, Loss= 0.6862, Training Accuracy= 0.531\n",
      "Epoch: 2180, Loss= 0.6861, Training Accuracy= 0.530\n",
      "Epoch: 2190, Loss= 0.6861, Training Accuracy= 0.531\n",
      "Epoch: 2200, Loss= 0.6860, Training Accuracy= 0.530\n",
      "Epoch: 2210, Loss= 0.6860, Training Accuracy= 0.533\n",
      "Epoch: 2220, Loss= 0.6859, Training Accuracy= 0.535\n",
      "Epoch: 2230, Loss= 0.6858, Training Accuracy= 0.538\n",
      "Epoch: 2240, Loss= 0.6857, Training Accuracy= 0.539\n",
      "Epoch: 2250, Loss= 0.6856, Training Accuracy= 0.540\n",
      "Epoch: 2260, Loss= 0.6855, Training Accuracy= 0.539\n",
      "Epoch: 2270, Loss= 0.6854, Training Accuracy= 0.542\n",
      "Epoch: 2280, Loss= 0.6853, Training Accuracy= 0.542\n",
      "Epoch: 2290, Loss= 0.6851, Training Accuracy= 0.545\n",
      "Epoch: 2300, Loss= 0.6849, Training Accuracy= 0.547\n",
      "Epoch: 2310, Loss= 0.6847, Training Accuracy= 0.542\n",
      "Epoch: 2320, Loss= 0.6844, Training Accuracy= 0.543\n",
      "Epoch: 2330, Loss= 0.6840, Training Accuracy= 0.542\n",
      "Epoch: 2340, Loss= 0.6835, Training Accuracy= 0.547\n",
      "Epoch: 2350, Loss= 0.6829, Training Accuracy= 0.548\n",
      "Epoch: 2360, Loss= 0.6820, Training Accuracy= 0.551\n",
      "Epoch: 2370, Loss= 0.6807, Training Accuracy= 0.561\n",
      "Epoch: 2380, Loss= 0.6790, Training Accuracy= 0.558\n",
      "Epoch: 2390, Loss= 0.6767, Training Accuracy= 0.552\n",
      "Epoch: 2400, Loss= 0.6734, Training Accuracy= 0.570\n",
      "Epoch: 2410, Loss= 0.6693, Training Accuracy= 0.570\n",
      "Epoch: 2420, Loss= 0.6645, Training Accuracy= 0.582\n",
      "Epoch: 2430, Loss= 0.6583, Training Accuracy= 0.599\n",
      "Epoch: 2440, Loss= 0.6493, Training Accuracy= 0.615\n",
      "Epoch: 2450, Loss= 0.6343, Training Accuracy= 0.621\n",
      "Epoch: 2460, Loss= 0.6277, Training Accuracy= 0.630\n",
      "Epoch: 2470, Loss= 0.6282, Training Accuracy= 0.622\n",
      "Epoch: 2480, Loss= 0.6006, Training Accuracy= 0.645\n",
      "Epoch: 2490, Loss= 0.5729, Training Accuracy= 0.672\n",
      "Epoch: 2500, Loss= 0.5601, Training Accuracy= 0.683\n",
      "Epoch: 2510, Loss= 0.6410, Training Accuracy= 0.616\n",
      "Epoch: 2520, Loss= 0.5611, Training Accuracy= 0.687\n",
      "Epoch: 2530, Loss= 0.5549, Training Accuracy= 0.701\n",
      "Epoch: 2540, Loss= 0.5602, Training Accuracy= 0.697\n",
      "Epoch: 2550, Loss= 0.5540, Training Accuracy= 0.703\n",
      "Epoch: 2560, Loss= 0.5684, Training Accuracy= 0.704\n",
      "Epoch: 2570, Loss= 0.5530, Training Accuracy= 0.703\n",
      "Epoch: 2580, Loss= 0.5290, Training Accuracy= 0.729\n",
      "Epoch: 2590, Loss= 0.4869, Training Accuracy= 0.747\n",
      "Epoch: 2600, Loss= 0.5100, Training Accuracy= 0.734\n",
      "Epoch: 2610, Loss= 0.5104, Training Accuracy= 0.737\n",
      "Epoch: 2620, Loss= 0.4929, Training Accuracy= 0.742\n",
      "Epoch: 2630, Loss= 0.5024, Training Accuracy= 0.746\n",
      "Epoch: 2640, Loss= 0.5025, Training Accuracy= 0.746\n",
      "Epoch: 2650, Loss= 0.5210, Training Accuracy= 0.735\n",
      "Epoch: 2660, Loss= 0.4941, Training Accuracy= 0.752\n",
      "Epoch: 2670, Loss= 0.5946, Training Accuracy= 0.701\n",
      "Epoch: 2680, Loss= 0.4290, Training Accuracy= 0.819\n",
      "Epoch: 2690, Loss= 0.6488, Training Accuracy= 0.705\n",
      "Epoch: 2700, Loss= 0.4363, Training Accuracy= 0.830\n",
      "Epoch: 2710, Loss= 0.2736, Training Accuracy= 0.924\n",
      "Epoch: 2720, Loss= 0.2340, Training Accuracy= 0.931\n",
      "Epoch: 2730, Loss= 0.2150, Training Accuracy= 0.936\n",
      "Epoch: 2740, Loss= 0.1808, Training Accuracy= 0.953\n",
      "Epoch: 2750, Loss= 0.2593, Training Accuracy= 0.911\n",
      "Epoch: 2760, Loss= 0.1866, Training Accuracy= 0.941\n",
      "Epoch: 2770, Loss= 0.1601, Training Accuracy= 0.952\n",
      "Epoch: 2780, Loss= 0.1407, Training Accuracy= 0.957\n",
      "Epoch: 2790, Loss= 0.0973, Training Accuracy= 0.980\n",
      "Epoch: 2800, Loss= 0.1889, Training Accuracy= 0.939\n",
      "Epoch: 2810, Loss= 0.0883, Training Accuracy= 0.978\n",
      "Epoch: 2820, Loss= 0.0802, Training Accuracy= 0.983\n",
      "Epoch: 2830, Loss= 0.0867, Training Accuracy= 0.980\n",
      "Epoch: 2840, Loss= 0.7234, Training Accuracy= 0.803\n",
      "Epoch: 2850, Loss= 0.0541, Training Accuracy= 0.996\n",
      "Epoch: 2860, Loss= 0.0439, Training Accuracy= 0.997\n",
      "Epoch: 2870, Loss= 0.0394, Training Accuracy= 0.999\n",
      "Epoch: 2880, Loss= 0.0360, Training Accuracy= 0.999\n",
      "Epoch: 2890, Loss= 0.0332, Training Accuracy= 0.999\n",
      "Epoch: 2900, Loss= 0.0314, Training Accuracy= 0.999\n",
      "Epoch: 2910, Loss= 0.0286, Training Accuracy= 0.999\n",
      "Epoch: 2920, Loss= 0.0268, Training Accuracy= 0.999\n",
      "Epoch: 2930, Loss= 0.0251, Training Accuracy= 0.999\n",
      "Epoch: 2940, Loss= 0.0231, Training Accuracy= 1.000\n",
      "Epoch: 2950, Loss= 0.0215, Training Accuracy= 0.999\n",
      "Epoch: 2960, Loss= 0.0201, Training Accuracy= 1.000\n",
      "Epoch: 2970, Loss= 0.0190, Training Accuracy= 1.000\n",
      "Epoch: 2980, Loss= 0.0179, Training Accuracy= 1.000\n",
      "Epoch: 2990, Loss= 0.0172, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.0175\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 3000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a RNN cell with tensorflow\n",
    "    rnn_cell = rnn.BasicRNNCell(num_hidden)\n",
    "\n",
    "    # Get RNN cell output\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 0.9993, 1.0, 0.50919998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "mean of test_accuracies_10replications:  0.95085\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.00147216811776\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkf8PtwaVuPOxbSkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd842c85890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
