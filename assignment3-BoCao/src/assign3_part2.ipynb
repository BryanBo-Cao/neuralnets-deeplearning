{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gina-husband-Emilio', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]\n",
      " \n",
      "['Lucia-husband-Marco', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]\n",
      " \n",
      "Gina-husband-Emilio\n",
      " \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#Reference: https://www.cs.colorado.edu/~mozer/Teaching/syllabi/DeepLearningFall2017/assignments/family_trees/create_dataset.py\n",
    "import numpy as np\n",
    "\n",
    "def familytree():\n",
    "    def bitvec(ix,nbit):\n",
    "        out = []\n",
    "        for i in range(nbit):\n",
    "            out.append((i==ix)+0.0)\n",
    "        return np.array(out)\n",
    "\n",
    "    names = [ \"Christopher\", \"Andrew\", \"Arthur\", \"James\", \"Charles\", \"Colin\", \"Penelope\", \"Christine\", \"Victoria\", \"Jennifer\", \"Margaret\", \"Charlotte\", \"Roberto\", \"Pierro\", \"Emilio\", \"Marco\", \"Tomaso\", \"Alfonso\", \"Maria\", \"Francesca\", \"Lucia\", \"Angela\", \"Gina\", \"Sophia\"]\n",
    "    relations = [ \"husband\", \"wife\", \"son\", \"daughter\", \"father\", \"mother\", \"brother\", \"sister\", \"nephew\", \"niece\", \"uncle\", \"aunt\"]\n",
    "\n",
    "    dataset = []\n",
    "    with open('relations.txt','r') as f:\n",
    "        for line in f:\n",
    "            sline = line.split();\n",
    "            p1 = names.index(sline[0])\n",
    "            r = relations.index(sline[1])\n",
    "            p2 = names.index(sline[2])\n",
    "            d = [ sline[0]+'-'+sline[1]+'-'+sline[2], \n",
    "                  np.concatenate((bitvec(p1,len(names)),bitvec(r,len(relations)))),\n",
    "                  bitvec(p2,len(names)) ]\n",
    "                  #bitvec(p2,len(names)) ]\n",
    "            dataset.append(d)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def familytree():\n",
    "    def bitvec(ix,nbit):\n",
    "        out = []\n",
    "        for i in range(nbit):\n",
    "            out.append((i==ix)+0.0)\n",
    "        return np.array(out)\n",
    "\n",
    "    names = [ \"Christopher\", \"Andrew\", \"Arthur\", \"James\", \"Charles\", \"Colin\", \"Penelope\", \"Christine\", \"Victoria\", \"Jennifer\", \"Margaret\", \"Charlotte\", \"Roberto\", \"Pierro\", \"Emilio\", \"Marco\", \"Tomaso\", \"Alfonso\", \"Maria\", \"Francesca\", \"Lucia\", \"Angela\", \"Gina\", \"Sophia\"]\n",
    "    relations = [ \"husband\", \"wife\", \"son\", \"daughter\", \"father\", \"mother\", \"brother\", \"sister\", \"nephew\", \"niece\", \"uncle\", \"aunt\"]\n",
    "\n",
    "    dataset = []\n",
    "    with open('relations.txt','r') as f:\n",
    "        for line in f:\n",
    "            sline = line.split();\n",
    "            p1 = names.index(sline[0])\n",
    "            r = relations.index(sline[1])\n",
    "            p2 = names.index(sline[2])\n",
    "            d = [ sline[0]+'-'+sline[1]+'-'+sline[2], \n",
    "                  np.concatenate((bitvec(p1,len(names)),bitvec(r,len(relations)))),\n",
    "                  bitvec(p2,len(names)) ]\n",
    "                  #bitvec(p2,len(names)) ]\n",
    "            dataset.append(d)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = familytree()\n",
    "\n",
    "print (dataset[0])\n",
    "print (\" \")\n",
    "print (dataset[1])\n",
    "print (\" \")\n",
    "print (dataset[0][0])\n",
    "print (\" \")\n",
    "print (dataset[0][1])\n",
    "print (\" \")\n",
    "print (dataset[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Colin-aunt-Jennifer', array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]\n",
      " \n",
      "['Sophia-aunt-Angela', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])]\n",
      " \n",
      "Colin-aunt-Jennifer\n",
      " \n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#randomly shuffle the whole dataset\n",
    "random.shuffle(dataset)\n",
    "\n",
    "print (dataset[0])\n",
    "print (\" \")\n",
    "print (dataset[1])\n",
    "print (\" \")\n",
    "print (dataset[0][0])\n",
    "print (\" \")\n",
    "print (dataset[0][1])\n",
    "print (\" \")\n",
    "print (dataset[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data[1]:  ['Sophia-aunt-Angela', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])]\n",
      "test_dat[1]:  ['Marco-father-Pierro', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset[0:89]\n",
    "test_data = dataset[90:104]\n",
    "print (\"train_data[1]: \", train_data[1])\n",
    "print (\"test_dat[1]: \", test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_Xa[1]:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.]\n",
      "train_data_Xb[1]:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "train_data_Y[1]:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# get train input and output data\n",
    "train_data_Xa = []\n",
    "train_data_Xb = []\n",
    "train_data_Y = []\n",
    "for i in range(len(train_data)):\n",
    "    train_data_Xa.append(train_data[i][1][0:24])\n",
    "    train_data_Xb.append(train_data[i][1][24:])\n",
    "    train_data_Y.append(train_data[i][2])\n",
    "    \n",
    "print (\"train_data_Xa[1]: \", train_data_Xa[1])\n",
    "print (\"train_data_Xb[1]: \", train_data_Xb[1])\n",
    "print (\"train_data_Y[1]: \", train_data_Y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data_Xa[1]:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "test_data_Xb[1]:  [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "test_data_Y[1]:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# get train input and output data\n",
    "test_data_Xa = []\n",
    "test_data_Xb = []\n",
    "test_data_Y = []\n",
    "for i in range(len(test_data)):\n",
    "    test_data_Xa.append(test_data[i][1][0:24])\n",
    "    test_data_Xb.append(test_data[i][1][24:])\n",
    "    test_data_Y.append(test_data[i][2])\n",
    "    \n",
    "print (\"test_data_Xa[1]: \", test_data_Xa[1])\n",
    "print (\"test_data_Xb[1]: \", test_data_Xb[1])\n",
    "print (\"test_data_Y[1]: \", test_data_Y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_73:0' shape=(24, 6) dtype=float32_ref>\n",
      "Tensor(\"Sigmoid_44:0\", shape=(?, 6), dtype=float32)\n",
      "Tensor(\"concat_15:0\", shape=(?, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# build the network architecture\n",
    "lr = 0.05\n",
    "n_inputa = 24\n",
    "n_inputb = 12\n",
    "n_H1a = 6\n",
    "n_H1b = 6\n",
    "n_H2 = 12\n",
    "n_H3 = 6\n",
    "n_output = 24\n",
    "\n",
    "Xa = tf.placeholder(tf.float32)\n",
    "Xb = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.int32)\n",
    "\n",
    "wsXa_H1a = tf.Variable(tf.random_uniform([n_inputa, n_H1a], 0.0, 1.0))\n",
    "wsXb_H1b = tf.Variable(tf.random_uniform([n_inputb, n_H1b], 0.0, 1.0))\n",
    "wsH2_H3 = tf.Variable(tf.random_uniform([n_H2, n_H3], 0.0, 1.0))\n",
    "wsH3_Y = tf.Variable(tf.random_uniform([n_H3, n_output], 0.0, 1.0))\n",
    "\n",
    "H1a_outputs = tf.sigmoid(tf.matmul(Xa, wsXa_H1a))\n",
    "H1b_outputs = tf.sigmoid(tf.matmul(Xb, wsXb_H1b))\n",
    "H2_outputs = tf.concat([H1a_outputs, H1b_outputs], 1)\n",
    "print (wsXa_H1a)\n",
    "print (H1a_outputs)\n",
    "print (H2_outputs)\n",
    "H3_outputs = tf.sigmoid(tf.matmul(H2_outputs, wsH2_H3))\n",
    "hy = tf.sigmoid(tf.matmul(H3_outputs, wsH3_Y))\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(labels = Y,\n",
    "                                                    logits = tf.matmul(H3_outputs, wsH3_Y)))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "   \n",
    "    for step in xrange(epochs):\n",
    "        \n",
    "        #train network in batch size = bs\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        \n",
    "        if step % 5 == 0:\n",
    "            #print (hy.eval({X: x_data, Y: y_data}))\n",
    "            print (\"Cost:\", sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "            correct_prediction = tf.equal(tf.floor(hy + 0.5), Y)\n",
    "            #correct_prediction = tf.equal(hy,Y)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            #print (sess.run([hy], feed_dict={X: x_data, Y: y_data}))\n",
    "            print (\"Accuracy: \", accuracy.eval({X: x_data, Y: y_data}))\n",
    "            \n",
    "    correct_prediction = tf.equal(tf.floor(hy + 0.5), Y)\n",
    "    #correct_prediction = tf.equal(hy,Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        \n",
    "    print (sess.run([hy], feed_dict={X: x_data, Y: y_data}))\n",
    "    print (\"Accuracy: \", accuracy.eval({X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
