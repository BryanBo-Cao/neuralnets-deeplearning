{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gina-husband-Emilio', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]\n",
      " \n",
      "['Lucia-husband-Marco', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]\n",
      " \n",
      "Gina-husband-Emilio\n",
      " \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#Reference: https://www.cs.colorado.edu/~mozer/Teaching/syllabi/DeepLearningFall2017/assignments/family_trees/create_dataset.py\n",
    "import numpy as np\n",
    "\n",
    "def familytree():\n",
    "    def bitvec(ix,nbit):\n",
    "        out = []\n",
    "        for i in range(nbit):\n",
    "            out.append((i==ix)+0.0)\n",
    "        return np.array(out)\n",
    "\n",
    "    names = [ \"Christopher\", \"Andrew\", \"Arthur\", \"James\", \"Charles\", \"Colin\", \"Penelope\", \"Christine\", \"Victoria\", \"Jennifer\", \"Margaret\", \"Charlotte\", \"Roberto\", \"Pierro\", \"Emilio\", \"Marco\", \"Tomaso\", \"Alfonso\", \"Maria\", \"Francesca\", \"Lucia\", \"Angela\", \"Gina\", \"Sophia\"]\n",
    "    relations = [ \"husband\", \"wife\", \"son\", \"daughter\", \"father\", \"mother\", \"brother\", \"sister\", \"nephew\", \"niece\", \"uncle\", \"aunt\"]\n",
    "\n",
    "    dataset = []\n",
    "    with open('relations.txt','r') as f:\n",
    "        for line in f:\n",
    "            sline = line.split();\n",
    "            p1 = names.index(sline[0])\n",
    "            r = relations.index(sline[1])\n",
    "            p2 = names.index(sline[2])\n",
    "            d = [ sline[0]+'-'+sline[1]+'-'+sline[2], \n",
    "                  np.concatenate((bitvec(p1,len(names)),bitvec(r,len(relations)))),\n",
    "                  bitvec(p2,len(names)) ]\n",
    "                  #bitvec(p2,len(names)) ]\n",
    "            dataset.append(d)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def familytree():\n",
    "    def bitvec(ix,nbit):\n",
    "        out = []\n",
    "        for i in range(nbit):\n",
    "            out.append((i==ix)+0.0)\n",
    "        return np.array(out)\n",
    "\n",
    "    names = [ \"Christopher\", \"Andrew\", \"Arthur\", \"James\", \"Charles\", \"Colin\", \"Penelope\", \"Christine\", \"Victoria\", \"Jennifer\", \"Margaret\", \"Charlotte\", \"Roberto\", \"Pierro\", \"Emilio\", \"Marco\", \"Tomaso\", \"Alfonso\", \"Maria\", \"Francesca\", \"Lucia\", \"Angela\", \"Gina\", \"Sophia\"]\n",
    "    relations = [ \"husband\", \"wife\", \"son\", \"daughter\", \"father\", \"mother\", \"brother\", \"sister\", \"nephew\", \"niece\", \"uncle\", \"aunt\"]\n",
    "\n",
    "    dataset = []\n",
    "    with open('relations.txt','r') as f:\n",
    "        for line in f:\n",
    "            sline = line.split();\n",
    "            p1 = names.index(sline[0])\n",
    "            r = relations.index(sline[1])\n",
    "            p2 = names.index(sline[2])\n",
    "            d = [ sline[0]+'-'+sline[1]+'-'+sline[2], \n",
    "                  np.concatenate((bitvec(p1,len(names)),bitvec(r,len(relations)))),\n",
    "                  bitvec(p2,len(names)) ]\n",
    "                  #bitvec(p2,len(names)) ]\n",
    "            dataset.append(d)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = familytree()\n",
    "\n",
    "print (dataset[0])\n",
    "print (\" \")\n",
    "print (dataset[1])\n",
    "print (\" \")\n",
    "print (dataset[0][0])\n",
    "print (\" \")\n",
    "print (dataset[0][1])\n",
    "print (\" \")\n",
    "print (dataset[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lucia-husband-Marco', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]\n",
      " \n",
      "['Roberto-wife-Maria', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.])]\n",
      " \n",
      "Lucia-husband-Marco\n",
      " \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#randomly shuffle the whole dataset\n",
    "random.shuffle(dataset)\n",
    "\n",
    "print (dataset[0])\n",
    "print (\" \")\n",
    "print (dataset[1])\n",
    "print (\" \")\n",
    "print (dataset[0][0])\n",
    "print (\" \")\n",
    "print (dataset[0][1])\n",
    "print (\" \")\n",
    "print (dataset[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data[1]:  ['Roberto-wife-Maria', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.])]\n",
      "test_dat[1]:  ['Andrew-wife-Christine', array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset[0:89]\n",
    "test_data = dataset[90:104]\n",
    "print (\"train_data[1]: \", train_data[1])\n",
    "print (\"test_dat[1]: \", test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_Xa[1]:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "train_data_Xb[1]:  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "train_data_Y[1]:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.]\n",
      "len(train_data_Y):  89\n",
      "len(train_data_Y[0]):  24\n",
      "train_data_labels:  [15, 18, 17, 2, 17, 18, 12, 9, 7, 8, 3, 11, 12, 6, 11, 2, 14, 4, 9, 14, 16, 7, 5, 20, 21, 19, 23, 13, 1, 17, 20, 0, 15, 3, 1, 3, 8, 21, 0, 20, 17, 8, 15, 19, 21, 2, 9, 9, 10, 1, 5, 5, 23, 11, 2, 14, 19, 15, 5, 21, 20, 11, 3, 2, 8, 15, 18, 23, 23, 17, 5, 11, 15, 14, 8, 22, 11, 20, 23, 17, 23, 5, 5, 11, 0, 13, 8, 9, 14]\n"
     ]
    }
   ],
   "source": [
    "# get train input and output data\n",
    "train_data_Xa = []\n",
    "train_data_Xb = []\n",
    "train_data_Y = []\n",
    "train_data_labels = []\n",
    "for i in range(len(train_data)):\n",
    "    train_data_Xa.append(train_data[i][1][0:24])\n",
    "    train_data_Xb.append(train_data[i][1][24:])\n",
    "    train_data_Y.append(train_data[i][2])\n",
    "    for j in range(len(train_data[i][2])):\n",
    "        if (train_data[i][2][j] == 1):\n",
    "            train_data_labels.append(j)\n",
    "    \n",
    "print (\"train_data_Xa[1]: \", train_data_Xa[1])\n",
    "print (\"train_data_Xb[1]: \", train_data_Xb[1])\n",
    "print (\"train_data_Y[1]: \", train_data_Y[1])\n",
    "print (\"len(train_data_Y): \", len(train_data_Y))\n",
    "print (\"len(train_data_Y[0]): \", len(train_data_Y[0]))\n",
    "print (\"train_data_labels: \", train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data_Xa[1]:  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "test_data_Xb[1]:  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "test_data_Y[1]:  [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "len(test_data_Y):  14\n",
      "len(test_data_Y[0]):  24\n",
      "test_data_labels:  [20, 7, 3, 13, 21, 12, 3, 9, 23, 6, 14, 6, 21, 2]\n"
     ]
    }
   ],
   "source": [
    "# get train input and output data\n",
    "test_data_Xa = []\n",
    "test_data_Xb = []\n",
    "test_data_Y = []\n",
    "test_data_labels = []\n",
    "for i in range(len(test_data)):\n",
    "    test_data_Xa.append(test_data[i][1][0:24])\n",
    "    test_data_Xb.append(test_data[i][1][24:])\n",
    "    test_data_Y.append(test_data[i][2])\n",
    "    for j in range(len(test_data[i][2])):\n",
    "        if (test_data[i][2][j] == 1):\n",
    "            test_data_labels.append(j)\n",
    "    \n",
    "print (\"test_data_Xa[1]: \", test_data_Xa[1])\n",
    "print (\"test_data_Xb[1]: \", test_data_Xb[1])\n",
    "print (\"test_data_Y[1]: \", test_data_Y[1])\n",
    "print (\"len(test_data_Y): \", len(test_data_Y))\n",
    "print (\"len(test_data_Y[0]): \", len(test_data_Y[0]))\n",
    "print (\"test_data_labels: \", test_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_72:0' shape=(24, 6) dtype=float32_ref>\n",
      "Tensor(\"Relu_12:0\", shape=(?, 6), dtype=float32)\n",
      "Tensor(\"concat_28:0\", shape=(?, 12), dtype=float32)\n",
      "hy:  Tensor(\"Sigmoid_61:0\", shape=(?, 24), dtype=float32)\n",
      "softmax_hy: Tensor(\"Softmax_18:0\", shape=(?, 24), dtype=float32)\n",
      "train_data_labels: [15, 18, 17, 2, 17, 18, 12, 9, 7, 8, 3, 11, 12, 6, 11, 2, 14, 4, 9, 14, 16, 7, 5, 20, 21, 19, 23, 13, 1, 17, 20, 0, 15, 3, 1, 3, 8, 21, 0, 20, 17, 8, 15, 19, 21, 2, 9, 9, 10, 1, 5, 5, 23, 11, 2, 14, 19, 15, 5, 21, 20, 11, 3, 2, 8, 15, 18, 23, 23, 17, 5, 11, 15, 14, 8, 22, 11, 20, 23, 17, 23, 5, 5, 11, 0, 13, 8, 9, 14]\n"
     ]
    }
   ],
   "source": [
    "# build the network architecture\n",
    "lr = 0.05\n",
    "epochs = 1000000000\n",
    "n_inputa = 24\n",
    "n_inputb = 12\n",
    "n_H1a = 6\n",
    "n_H1b = 6\n",
    "n_H2 = 12\n",
    "n_H3 = 6\n",
    "n_output = 24\n",
    "\n",
    "Xa = tf.placeholder(tf.float32)\n",
    "Xb = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.int32)\n",
    "\n",
    "wsXa_H1a = tf.Variable(tf.random_uniform([n_inputa, n_H1a], -3.0, 3.0))\n",
    "wsXb_H1b = tf.Variable(tf.random_uniform([n_inputb, n_H1b], -3.0, 3.0))\n",
    "wsH2_H3 = tf.Variable(tf.random_uniform([n_H2, n_H3], -3.0, 3.0))\n",
    "wsH3_Y = tf.Variable(tf.random_uniform([n_H3, n_output], -3.0, 3.0))\n",
    "\n",
    "#H1a_outputs = tf.sigmoid(tf.matmul(Xa, wsXa_H1a))\n",
    "H1a_outputs = tf.nn.relu(tf.matmul(Xa, wsXa_H1a))\n",
    "#H1b_outputs = tf.sigmoid(tf.matmul(Xb, wsXb_H1b))\n",
    "H1b_outputs = tf.nn.relu(tf.matmul(Xb, wsXb_H1b))\n",
    "H2_outputs = tf.concat([H1a_outputs, H1b_outputs], 1)\n",
    "print (wsXa_H1a)\n",
    "print (H1a_outputs)\n",
    "print (H2_outputs)\n",
    "H3_outputs = tf.sigmoid(tf.matmul(H2_outputs, wsH2_H3))\n",
    "hy = tf.sigmoid(tf.matmul(H3_outputs, wsH3_Y))\n",
    "print (\"hy: \",hy)\n",
    "#train_data_hy_one = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = train_data_labels, logits = Y)\n",
    "#train_data_hy_one = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = train_data_labels, logits = train_data_Y)\n",
    "softmax_hy = tf.nn.softmax(hy)\n",
    "print (\"softmax_hy:\",softmax_hy)\n",
    "\n",
    "#cost = tf.reduce_mean(tf.square(Y - hy))\n",
    "#cost = tf.reduce_mean(-tf.reduce_sum(train_data_hy * tf.log(Y), reduction_indices=[1])) #cross entropy\n",
    "#cost = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = train_data_labels, logits = Y)\n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = train_data_labels, logits = hy)\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_data_labels, logits=Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "print (\"train_data_labels:\", train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Step:  0\n",
      "Cost: [ 3.79552484  3.33672237  3.48606539  3.64483857  3.79267883  2.81953001\n",
      "  3.11632061  3.52684879  3.11875319  2.88509941  3.74037218  2.76681614\n",
      "  3.43939829  3.69766092  2.75112844  3.66140223  3.30590558  2.72657728\n",
      "  3.54796696  3.75094748  3.40007114  3.04427075  2.74542093  3.46820998\n",
      "  3.00238061  2.71955013  3.71059489  3.69487715  2.876791    3.7357111\n",
      "  2.80992317  3.39462686  3.43078184  3.6935544   2.925457    3.66912937\n",
      "  2.97219133  3.00208187  2.87405777  3.52601099  3.73101354  3.55000782\n",
      "  3.30425715  2.82284474  2.98430109  3.49883199  3.367033    3.39654016\n",
      "  3.41565418  2.90559053  2.76213408  3.02905869  3.28756666  2.79289579\n",
      "  3.65037584  3.72373414  3.08033085  3.52753019  3.37540889  2.88177323\n",
      "  3.06365538  2.78603601  3.67422438  3.65365076  3.39075851  3.11056995\n",
      "  2.78449798  3.72009754  3.60157704  3.36353493  2.69004321  2.8141346\n",
      "  2.84573698  3.71581316  3.55167508  3.71285343  2.81914616  3.18877506\n",
      "  3.437325    3.25628233  3.25296474  2.9227581   2.76800227  2.86326838\n",
      "  3.20557261  3.68350124  2.9344461   3.36209488  3.67902422]\n",
      "tf.argmax(softmax_hy,1): [11  5 19 10  7 10 11 10 10 19 11 19 18 18 11 11  5  0 10 18 11 10 11 10 10\n",
      " 18 11 19 18  7 19 19  5  4 18  5 11 11 11 10  7  5 10 10  7 11 19  5 11 11\n",
      " 11 19  5 18 11 18 10 18  7 19 18 19 11 19 11 18 11 18 19  0  5 19 19 11  5\n",
      "  0 19  7 18 18 18 18  5 18 18  5 19  4 10]\n",
      "Accuracy:  0.0337079\n",
      " \n",
      "Step:  1000\n",
      "Cost: [ 2.79462481  2.71587968  2.44718099  2.54004145  2.43936849  2.76391101\n",
      "  2.58568835  2.41412354  2.67415071  2.48245597  2.55080557  2.53722024\n",
      "  2.58992624  2.62193441  2.38058829  2.4761734   2.52164483  2.5485158\n",
      "  2.42701721  2.64379716  2.66736531  2.67432141  2.49809194  2.6413846\n",
      "  2.58041978  2.6215961   2.70461369  3.40628147  2.55444503  2.44663358\n",
      "  2.54026842  2.49873972  2.46037364  2.54179168  2.68816471  2.43670034\n",
      "  2.43967366  2.66426516  2.61054897  2.50494623  2.44655323  2.73997688\n",
      "  2.77184582  2.7000761   2.53449488  2.47323728  2.7542634   2.46449423\n",
      "  2.66837001  2.54511118  2.43689108  2.45092416  2.47590303  2.40409017\n",
      "  2.45368552  3.03162551  2.66338253  2.46114516  2.45017529  2.53672433\n",
      "  2.6309185   2.46639585  2.9277854   2.53792572  2.81804919  2.53673196\n",
      "  2.55074978  2.49363089  2.52341509  2.44797993  2.45420361  2.37604642\n",
      "  2.48106599  2.46023226  2.7402463   3.43517399  2.44874787  2.54593182\n",
      "  2.46321273  2.6657176   2.48124981  2.45360589  2.45093346  2.64312077\n",
      "  2.51771927  3.32281423  2.4820714   2.46736598  2.46062589]\n",
      "tf.argmax(softmax_hy,1): [12 11 17  5 17  3 11  9  3 11 15 11 11 11 11 14  5  9 11 12 14  3  5  3 23\n",
      " 23 11 15  3 17 11 11 17 17 23  3  8 23 11 23 17  3 23 15 23 14 23  9 11 11\n",
      "  5 17 23 11 14 17  3 17 17 23  3 11  5  5 11 15  8  8 15 17  5 11 15  5  3\n",
      " 23 11 23 23 15 23  8 17 23  0  9 11  9  5]\n",
      "Accuracy:  0.280899\n",
      " \n",
      "Step:  2000\n",
      "Cost: [ 2.64122319  2.6241231   2.39309192  2.41397309  2.39228797  2.66286969\n",
      "  2.54789829  2.38110185  2.61708736  2.44851971  2.39688993  2.54829121\n",
      "  2.56674099  2.51419115  2.3570087   2.42564011  2.54155207  2.46408534\n",
      "  2.38743806  2.55930853  2.52760935  2.61715031  2.48861098  2.5904243\n",
      "  2.52296162  2.5763433   2.50983167  3.26588893  2.5170927   2.39185476\n",
      "  2.49977398  2.4639802   2.38874769  2.50603318  2.64786482  2.36732984\n",
      "  2.37533927  2.64402819  2.57347155  2.47601318  2.39177465  2.65979886\n",
      "  2.66062951  2.54493213  2.51882124  2.42621922  2.66118884  2.40328002\n",
      "  2.64668179  2.43534708  2.4107101   2.39520645  2.40389371  2.36384153\n",
      "  2.4147265   2.50728703  2.60468388  2.3916266   2.3970089   2.52115655\n",
      "  2.53432846  2.45689535  2.54082584  2.52003002  2.73917246  2.44818735\n",
      "  2.47398615  2.45077467  2.48581266  2.39367938  2.40539432  2.33116674\n",
      "  2.37429094  2.41725826  2.65978241  3.43563986  2.41863298  2.52375078\n",
      "  2.3986218   2.56540728  2.45197964  2.43848777  2.39522028  2.61433744\n",
      "  2.4347465   2.50611043  2.44570661  2.40480137  2.41657853]\n",
      "tf.argmax(softmax_hy,1): [14 11 15 14 15 20 12 11 20  8  3 11 11 11 11 14  5  9 11 14 16 20  5 20 23\n",
      " 23 11  3  1 15  8 11 15  3 20  3  8 23 11 23 15  5 23 15 23 14 23  9 11 11\n",
      " 14 15 23 11 14  5 20 15 15 23 19 23  5  5 11 15  8  8 15 15  5 11 15 14  5\n",
      " 23  0 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.314607\n",
      " \n",
      "Step:  3000\n",
      "Cost: [ 2.57837343  2.5717268   2.38169575  2.40311003  2.38584328  2.59738755\n",
      "  2.45258522  2.36298323  2.57379365  2.43763685  2.34570646  2.47767997\n",
      "  2.52629042  2.49166346  2.34288836  2.41356277  2.52162147  2.43231964\n",
      "  2.37284875  2.50885201  2.46933699  2.57434916  2.4752636   2.51357317\n",
      "  2.50093961  2.54947567  2.45095444  3.24045014  2.47527027  2.38572669\n",
      "  2.47041416  2.31485415  2.38076401  2.46349835  2.62360024  2.33469772\n",
      "  2.33013248  2.62245798  2.4782207   2.47063923  2.3855269   2.61781669\n",
      "  2.4183619   2.50464106  2.5132544   2.41477227  2.611763    2.36519432\n",
      "  2.59910583  2.339149    2.40742302  2.38807535  2.38846087  2.35824656\n",
      "  2.40286016  2.47402334  2.56226492  2.38189697  2.38910341  2.51192808\n",
      "  2.5100441   2.45458937  2.47328591  2.49352813  2.64059067  2.40167427\n",
      "  2.35924911  2.43838501  2.47899604  2.38654613  2.39486527  2.3189342\n",
      "  2.34913063  2.40560675  2.62104082  3.4367156   2.42754245  2.5288496\n",
      "  2.37983203  2.51457238  2.44699478  2.43585253  2.3880794   2.62276053\n",
      "  2.36793256  2.46492434  2.4372859   2.36683536  2.40568161]\n",
      "tf.argmax(softmax_hy,1): [14  0 15 14 15 20 12  9 20  8  3  0  0 11 11 14  3  9  9  8 16 20  3 20 23\n",
      " 23 11  0  9 15  8  0 15  3 20  3  8 23  0 23 15  5 15 15 23 14 23  9  0  1\n",
      " 14 15 23  9 14  8 20 15 15 23 19 23  3  3  0 15  8  8 15 15 15 11 15 14  5\n",
      " 23  0 23 23 15 23  8 15 23  0  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  4000\n",
      "Cost: [ 2.55389261  2.54061246  2.3714385   2.39462042  2.3822937   2.57936859\n",
      "  2.41129494  2.34722614  2.55823755  2.39707041  2.3223505   2.46214437\n",
      "  2.5032928   2.47091341  2.29881406  2.40436268  2.50344658  2.41815233\n",
      "  2.35734725  2.49749804  2.44434738  2.55962658  2.46562123  2.48117208\n",
      "  2.48717666  2.54203892  2.41501617  3.22910094  2.4374547   2.38222265\n",
      "  2.46881008  2.28838634  2.37827229  2.44986391  2.58670044  2.31758523\n",
      "  2.29896641  2.51351166  2.39770365  2.47037935  2.38196492  2.59302354\n",
      "  2.39334774  2.48727298  2.50818849  2.40544128  2.56641316  2.35192394\n",
      "  2.55763006  2.30668497  2.40301824  2.38445568  2.37674451  2.34050417\n",
      "  2.39445019  2.46479654  2.53741312  2.37895799  2.38518119  2.50486469\n",
      "  2.48118424  2.45672131  2.45555019  2.47919035  2.59957933  2.38604283\n",
      "  2.34948349  2.39645791  2.47715473  2.38230252  2.38637829  2.29696751\n",
      "  2.32906914  2.39781618  2.59507465  3.42180967  2.38931537  2.52175236\n",
      "  2.35905123  2.48391867  2.43096638  2.43529844  2.38445711  2.6185689\n",
      "  2.3607049   2.45260239  2.39702272  2.35218263  2.39787626]\n",
      "tf.argmax(softmax_hy,1): [14  0 15 14 15 20 12  9 20  8  3  0  0 11 11 14  3  9  9  8 16 20  3 19 23\n",
      " 23 11  0  9 15  8  0 15  3 20  3  8  9  0 23 15  5 15 15 23 14 23  9  0  1\n",
      " 14 15 23 11 14  8 20 15 15 23 19 23  3  3  0 15  8  8 15 15 15 11 15 14  5\n",
      " 23  0 23 23 15 23  8 15 23  0  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  5000\n",
      "Cost: [ 2.5297482   2.52896905  2.38983202  2.39002824  2.38927937  2.52187276\n",
      "  2.3911097   2.32837582  2.50518489  2.38094687  2.30496502  2.45613694\n",
      "  2.49800253  2.45975351  2.28137445  2.40028572  2.4901104   2.4156785\n",
      "  2.33928061  2.48228717  2.42329431  2.50552225  2.45510721  2.43997383\n",
      "  2.53001285  2.52089882  2.37398338  3.22236896  2.40724945  2.38864756\n",
      "  2.41965008  2.28185964  2.37209749  2.44184542  2.57241225  2.30365801\n",
      "  2.28244615  2.45077491  2.36921024  2.47273874  2.38865089  2.55650043\n",
      "  2.33922601  2.39387035  2.50743484  2.40039968  2.508255    2.34309268\n",
      "  2.54098582  2.29583454  2.40677953  2.38094115  2.39224482  2.32544565\n",
      "  2.38998461  2.45538878  2.47763157  2.37661958  2.38127923  2.50725245\n",
      "  2.4399724   2.42092371  2.4442358   2.46911573  2.58100557  2.33991313\n",
      "  2.34729958  2.3814795   2.48171592  2.38925838  2.38124967  2.28141308\n",
      "  2.31254554  2.3946178   2.55670524  3.36986876  2.28189063  2.51571274\n",
      "  2.35046363  2.38934517  2.39634013  2.43422794  2.38094139  2.50458932\n",
      "  2.36662197  2.44608927  2.38089323  2.34315443  2.39465117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [14  0 15 14 15 20 12 11 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 19 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0 23 15  5 15 15 23 14 23  9  0  1\n",
      " 14 15 23 11 14  8 20 15 15 23 19 23  3  3  0 15  8  8 15 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.325843\n",
      " \n",
      "Step:  6000\n",
      "Cost: [ 2.50129342  2.52171087  2.38864779  2.38551474  2.38829875  2.50833154\n",
      "  2.37900186  2.32357097  2.49101782  2.37862182  2.29701281  2.45195532\n",
      "  2.49497104  2.44021273  2.27453756  2.39624405  2.4811635   2.4044199\n",
      "  2.33246183  2.46232986  2.40956116  2.49112463  2.45336199  2.42899895\n",
      "  2.52689958  2.5145843   2.3574264   3.21949697  2.39904404  2.38789916\n",
      "  2.40332055  2.27602959  2.36454821  2.43993282  2.5573225   2.29643464\n",
      "  2.27445197  2.43545246  2.35151291  2.47066593  2.38790154  2.51641035\n",
      "  2.32964921  2.37634754  2.50496149  2.3944006   2.49099278  2.33205366\n",
      "  2.53355002  2.28837228  2.41670442  2.37962699  2.37800217  2.32341003\n",
      "  2.38548183  2.45150232  2.46656609  2.37578177  2.37984681  2.50506639\n",
      "  2.42900205  2.40707016  2.44191289  2.46383905  2.572294    2.33248496\n",
      "  2.34538078  2.37895012  2.46593285  2.38847327  2.37967396  2.27480149\n",
      "  2.30600452  2.39130425  2.51718473  3.36321568  2.27490902  2.50975847\n",
      "  2.33909655  2.38821435  2.38375759  2.43722582  2.37962723  2.48836875\n",
      "  2.36361241  2.44700289  2.37854218  2.33208346  2.39134073]\n",
      "tf.argmax(softmax_hy,1): [14  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 19 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      " 14 15 23 11 14  8 20 15 15 23 19 23  3  3  0 15  8  8 15 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.325843\n",
      " \n",
      "Step:  7000\n",
      "Cost: [ 2.48673606  2.51597118  2.3875258   2.37931776  2.38741088  2.50102663\n",
      "  2.37088847  2.32013679  2.4836278   2.37704802  2.29027891  2.44652414\n",
      "  2.4934299   2.41095567  2.27017283  2.38935614  2.4747746   2.39598775\n",
      "  2.32741547  2.45078659  2.40088415  2.4836185   2.45226097  2.41189718\n",
      "  2.51801085  2.51043487  2.34887695  3.21627593  2.39345407  2.3871398\n",
      "  2.39764094  2.27137852  2.35924554  2.43854046  2.54269934  2.29171419\n",
      "  2.27088785  2.42999983  2.34081483  2.46621943  2.38714099  2.49647522\n",
      "  2.32674575  2.3684268   2.50222111  2.37484217  2.47908258  2.32417512\n",
      "  2.52835226  2.28345037  2.43193507  2.3783865   2.37042117  2.32268643\n",
      "  2.37928224  2.44867897  2.46070075  2.37524796  2.37852001  2.50229478\n",
      "  2.41191244  2.39820242  2.44062901  2.45738411  2.56100655  2.33026314\n",
      "  2.34461522  2.37736082  2.45161748  2.38769841  2.37837124  2.27067113\n",
      "  2.29891443  2.38627958  2.49700332  3.36039901  2.27079415  2.50603461\n",
      "  2.3331008   2.38729286  2.37840056  2.44202089  2.37838674  2.48218441\n",
      "  2.35836768  2.44353437  2.37688279  2.32416821  2.38632154]\n",
      "tf.argmax(softmax_hy,1): [14  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 19 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      " 14 15 23  9 14  8 20 15 15 23 19 23  3  3  0 15  8  8 15 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.314607\n",
      " \n",
      "Step:  8000\n",
      "Cost: [ 2.47839069  2.50976348  2.38669038  2.37313175  2.3867569   2.49182439\n",
      "  2.36452675  2.31783628  2.47679782  2.37585258  2.28503942  2.44035149\n",
      "  2.49199152  2.38022065  2.26726842  2.38055563  2.46920562  2.39036345\n",
      "  2.32454371  2.44495487  2.39232254  2.47680664  2.45024729  2.39982224\n",
      "  2.51439333  2.50681233  2.34359884  3.21434522  2.39016199  2.38649154\n",
      "  2.39554334  2.26788497  2.35649943  2.43707061  2.53204775  2.28727317\n",
      "  2.26919532  2.42553473  2.33488679  2.46236038  2.38649178  2.48199153\n",
      "  2.3298471   2.35701656  2.49964452  2.36025763  2.46954298  2.3176949\n",
      "  2.52441859  2.27935266  2.44688725  2.37721658  2.3682766   2.32250285\n",
      "  2.37311697  2.44596338  2.45574951  2.37480712  2.37730193  2.49971795\n",
      "  2.39867258  2.38955545  2.43876982  2.4553616   2.55085182  2.34117627\n",
      "  2.34687662  2.37620354  2.44632125  2.38700318  2.37721443  2.2679739\n",
      "  2.26338005  2.3779366   2.4821434   3.35892582  2.26833439  2.50362015\n",
      "  2.33068681  2.38661218  2.37639856  2.44833899  2.37721682  2.47130609\n",
      "  2.35233903  2.43846083  2.3754797   2.31766605  2.37799048]\n",
      "tf.argmax(softmax_hy,1): [14  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 19 23\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      " 14 15 23  9 14  8 20 15 15 23 19 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.314607\n",
      " \n",
      "Step:  9000\n",
      "Cost: [ 2.46884489  2.50585771  2.38608027  2.34723783  2.38634396  2.4859848\n",
      "  2.3595686   2.31640863  2.47244954  2.37523484  2.27755189  2.43671608\n",
      "  2.49124718  2.35779262  2.26528454  2.34997797  2.4654479   2.38876557\n",
      "  2.32225966  2.44079065  2.38430691  2.47253919  2.46141934  2.39503384\n",
      "  2.51375389  2.50603843  2.33935237  3.21370864  2.38705516  2.3859539\n",
      "  2.39438558  2.26538467  2.3522172   2.43418694  2.5234642   2.27970934\n",
      "  2.26899338  2.42252827  2.33028531  2.45724106  2.38595414  2.46761465\n",
      "  2.32876062  2.35354805  2.49842119  2.34070063  2.46231651  2.30975962\n",
      "  2.52178335  2.27624464  2.46325254  2.37605405  2.36475968  2.3223474\n",
      "  2.34730244  2.44140244  2.45361233  2.37438178  2.37610936  2.49844313\n",
      "  2.3933661   2.38073397  2.43550014  2.45611429  2.54423022  2.33978224\n",
      "  2.34779239  2.37558174  2.44411278  2.38635206  2.37604189  2.26613832\n",
      "  2.26101708  2.34706688  2.46763849  3.35838103  2.26676965  2.50192165\n",
      "  2.32780242  2.38609028  2.37430692  2.48137665  2.37605453  2.45794153\n",
      "  2.34775114  2.43503165  2.37426543  2.30975962  2.34713006]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 23\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  10000\n",
      "Cost: [ 2.46270895  2.50307894  2.38524771  2.33537054  2.38552523  2.48165464\n",
      "  2.35414886  2.31526351  2.46904159  2.37365294  2.27439332  2.43320036\n",
      "  2.49072504  2.34690595  2.26359987  2.33760142  2.4633832   2.38623381\n",
      "  2.32098413  2.43975878  2.37819672  2.46915102  2.45581818  2.39104509\n",
      "  2.51496315  2.50568485  2.33425236  3.21186733  2.38393307  2.3851707\n",
      "  2.40141296  2.26339769  2.35429692  2.43310738  2.51558328  2.27709913\n",
      "  2.26541281  2.4207437   2.32692504  2.44938874  2.38517094  2.45701122\n",
      "  2.32786441  2.35105252  2.49711514  2.33424354  2.45366764  2.30434895\n",
      "  2.51982093  2.27354383  2.45666885  2.37471581  2.3606112   2.32256699\n",
      "  2.33535457  2.44108605  2.4521904   2.37417054  2.37476587  2.49719954\n",
      "  2.3888905   2.3729198   2.43436193  2.45565414  2.53803539  2.33848071\n",
      "  2.34529209  2.37400889  2.44263697  2.38558149  2.37467217  2.26471758\n",
      "  2.26257753  2.33470702  2.45704508  3.35784292  2.26529455  2.50235796\n",
      "  2.32505226  2.38531399  2.37285995  2.46713877  2.37471604  2.45376587\n",
      "  2.34392595  2.43285871  2.35124874  2.30435467  2.33474708]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 23\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  11000\n",
      "Cost: [ 2.45851898  2.50087905  2.38440418  2.33084345  2.38464689  2.47728419\n",
      "  2.3506372   2.31433058  2.46558905  2.37326121  2.27255893  2.42972016\n",
      "  2.49013901  2.33317614  2.26201248  2.33298898  2.46134973  2.38319492\n",
      "  2.32031322  2.43929863  2.3739872   2.46568847  2.45200014  2.38939524\n",
      "  2.5173049   2.50587916  2.33173203  3.20950627  2.37998605  2.38433719\n",
      "  2.40161848  2.26177597  2.3525455   2.43260336  2.5068109   2.27549124\n",
      "  2.2626462   2.41718769  2.32460952  2.43919659  2.38433766  2.44723034\n",
      "  2.32680178  2.34867382  2.4957788   2.33120203  2.44608355  2.29908848\n",
      "  2.51813269  2.27142787  2.45263958  2.37434292  2.35085678  2.32318902\n",
      "  2.33092427  2.44048834  2.45046687  2.37390995  2.37439346  2.4960165\n",
      "  2.38666463  2.3672204   2.43387175  2.45444036  2.53337908  2.3370378\n",
      "  2.34426212  2.37366343  2.44344139  2.38474321  2.3742466   2.26357079\n",
      "  2.26251268  2.33025861  2.44731975  3.35746551  2.26453209  2.50026846\n",
      "  2.32374167  2.38447332  2.37282705  2.46092844  2.37434387  2.45249891\n",
      "  2.34111619  2.42930937  2.34582829  2.29914069  2.33029389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 23\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  12000\n",
      "Cost: [ 2.45534611  2.4993608   2.38368297  2.32844019  2.38389206  2.47290158\n",
      "  2.3474493   2.31315064  2.46113443  2.37317824  2.27098846  2.42155337\n",
      "  2.48987579  2.32214117  2.25849175  2.33037448  2.45959473  2.38041019\n",
      "  2.31972098  2.4387641   2.3707993   2.46122766  2.44915152  2.38637209\n",
      "  2.5181942   2.50861597  2.33085251  3.20747566  2.37038064  2.38363838\n",
      "  2.40068245  2.26030731  2.34971786  2.43219757  2.49781513  2.2741437\n",
      "  2.25912166  2.40501976  2.32217431  2.43231082  2.38363838  2.43907571\n",
      "  2.32417679  2.34825706  2.42715287  2.3292098   2.44017959  2.29446173\n",
      "  2.5165925   2.26984882  2.44964218  2.37407637  2.3272295   2.32311463\n",
      "  2.32841825  2.44000673  2.44724441  2.37362933  2.37411165  2.49387026\n",
      "  2.38360977  2.35837078  2.43335557  2.45332837  2.5284934   2.3353498\n",
      "  2.34117913  2.3742249   2.45400047  2.38391352  2.37388659  2.26016021\n",
      "  2.26162934  2.32777691  2.43907881  3.35661125  2.26032758  2.50002193\n",
      "  2.32735491  2.38375735  2.3930192   2.45687866  2.37407732  2.43294525\n",
      "  2.3382287   2.42247772  2.33492565  2.29445291  2.32780838]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 23\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  13000\n",
      "Cost: [ 2.45293307  2.49823642  2.38300633  2.32674742  2.38320184  2.47086787\n",
      "  2.34473467  2.31239367  2.45935011  2.37327337  2.2698319   2.41548443\n",
      "  2.48960471  2.31549549  2.2568469   2.32688713  2.45819736  2.37656164\n",
      "  2.31857014  2.43833733  2.3676374   2.45944929  2.447258    2.38458371\n",
      "  2.5199635   2.50790691  2.33040881  3.20627332  2.36066389  2.38294792\n",
      "  2.39732265  2.25900316  2.34760332  2.43205881  2.48656058  2.27272105\n",
      "  2.25780368  2.40217662  2.31914473  2.4231391   2.38294768  2.43250036\n",
      "  2.32365942  2.34607029  2.42129874  2.32778955  2.43517923  2.290133\n",
      "  2.51517558  2.26923633  2.4474206   2.37395287  2.32633972  2.32432032\n",
      "  2.32672     2.43931842  2.44631219  2.37350321  2.37399626  2.49235654\n",
      "  2.38165188  2.35161424  2.43299484  2.45242929  2.52274489  2.33373952\n",
      "  2.33969331  2.37562418  2.45613074  2.38317013  2.37370348  2.25860715\n",
      "  2.26091146  2.32621026  2.43269038  3.35701513  2.25891185  2.49813604\n",
      "  2.3263979   2.38305855  2.39873552  2.45411706  2.37395406  2.42345715\n",
      "  2.33577919  2.41953993  2.31700087  2.29011035  2.32623482]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 23\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  14000\n",
      "Cost: [ 2.45146275  2.49696445  2.38238764  2.32543635  2.38255024  2.46839762\n",
      "  2.34346724  2.31168437  2.45868874  2.37301946  2.26938534  2.41117525\n",
      "  2.48918223  2.30863738  2.25627804  2.32546282  2.45662975  2.37209415\n",
      "  2.31822729  2.43777275  2.36560464  2.45896173  2.44583988  2.38126278\n",
      "  2.52020645  2.50790095  2.33026433  3.20557427  2.34992194  2.3822968\n",
      "  2.39588594  2.25688148  2.34589338  2.43189359  2.46658373  2.27209949\n",
      "  2.25629258  2.39913654  2.30089068  2.41614389  2.38229799  2.42708492\n",
      "  2.32345295  2.34448266  2.41601944  2.3268652   2.43054819  2.28635001\n",
      "  2.51414013  2.26669812  2.44604778  2.37386608  2.32523155  2.32776785\n",
      "  2.32543993  2.43860435  2.44576526  2.37340832  2.37387991  2.49052167\n",
      "  2.37817025  2.3496263   2.43265104  2.4514327   2.51983809  2.33283329\n",
      "  2.33897281  2.37688017  2.45536518  2.38246346  2.37358665  2.25874734\n",
      "  2.26023626  2.32528019  2.42732096  3.35681009  2.25923038  2.49699974\n",
      "  2.32507682  2.38242054  2.39774537  2.45153618  2.37386751  2.40634251\n",
      "  2.33080339  2.41728258  2.30486798  2.2862823   2.32530451]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 23\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23  8 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  15000\n",
      "Cost: [ 2.4505589   2.49543858  2.38202429  2.32126904  2.38188457  2.46674919\n",
      "  2.34285498  2.29502964  2.45766854  2.37161708  2.26764393  2.40989828\n",
      "  2.48907876  2.2987504   2.2589345   2.32129216  2.45500803  2.36189246\n",
      "  2.27376461  2.38572049  2.36070371  2.4581542   2.44975734  2.37898159\n",
      "  2.51553059  2.50901294  2.32729721  3.20196748  2.33110762  2.38183141\n",
      "  2.39715266  2.25768209  2.3432281   2.43157959  2.45641899  2.27009177\n",
      "  2.25662351  2.40057611  2.29506969  2.39268827  2.38183451  2.42435694\n",
      "  2.32100844  2.34206438  2.41089225  2.32465601  2.39298558  2.28296423\n",
      "  2.51125979  2.27117753  2.44994736  2.37378073  2.2921741   2.36922264\n",
      "  2.32125664  2.43075895  2.44620037  2.37327719  2.3737812   2.49057484\n",
      "  2.37533593  2.37655854  2.43207312  2.45028782  2.51778221  2.33311653\n",
      "  2.33795834  2.37567401  2.42759037  2.38191962  2.37374306  2.26584768\n",
      "  2.25678444  2.32238793  2.42396688  3.31333852  2.26598191  2.49825978\n",
      "  2.28717184  2.38213396  2.34093189  2.37392426  2.37378168  2.37541437\n",
      "  2.32985139  2.41486645  2.2973299   2.28281808  2.32240987]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 23\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23 15 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  16000\n",
      "Cost: [ 2.44985867  2.4947803   2.38128734  2.31920481  2.38115335  2.46388435\n",
      "  2.34179688  2.28479624  2.45552206  2.37134171  2.26639318  2.40593457\n",
      "  2.48869061  2.29644752  2.25731778  2.31920171  2.45360255  2.3602252\n",
      "  2.2721889   2.37868881  2.356879    2.45576191  2.45126724  2.37152767\n",
      "  2.492136    2.50987053  2.32577229  3.20086241  2.32879543  2.38110399\n",
      "  2.39602971  2.25661564  2.33242822  2.43135476  2.4561646   2.26861906\n",
      "  2.25692391  2.39635181  2.28905272  2.38927269  2.38110685  2.42101359\n",
      "  2.32033658  2.33966208  2.40766168  2.32363272  2.38207412  2.27942991\n",
      "  2.5094285   2.27174163  2.45149446  2.37396765  2.28170443  2.35378098\n",
      "  2.31921363  2.40053177  2.44474459  2.37328529  2.3739686   2.49054193\n",
      "  2.36835766  2.38914895  2.43181491  2.44975734  2.51554656  2.33201075\n",
      "  2.33171582  2.37657809  2.41937399  2.38114071  2.37399578  2.26525855\n",
      "  2.25410223  2.32132173  2.42095709  3.30768585  2.27581501  2.49988127\n",
      "  2.28213453  2.38152432  2.33590269  2.3740344   2.37396955  2.39859486\n",
      "  2.33000851  2.41219759  2.2896359   2.2792747   2.32133937]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23 15 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  17000\n",
      "Cost: [ 2.44885516  2.49390674  2.38059425  2.31853795  2.38052869  2.46146703\n",
      "  2.34028649  2.27334237  2.45267153  2.37103367  2.2655313   2.40203714\n",
      "  2.48815727  2.29417777  2.25523782  2.31854677  2.45296955  2.35808349\n",
      "  2.27036452  2.37714291  2.3540864   2.45288086  2.44779658  2.36575818\n",
      "  2.48142481  2.51109385  2.32453704  3.19971037  2.32633686  2.38044691\n",
      "  2.39480543  2.25597906  2.31434917  2.43156314  2.45322084  2.26737475\n",
      "  2.25703096  2.39278722  2.28485394  2.38627887  2.38044906  2.41766572\n",
      "  2.31888938  2.3383522   2.40638685  2.32313013  2.37843132  2.27707005\n",
      "  2.50783014  2.27045608  2.44799209  2.37435389  2.28510094  2.34933853\n",
      "  2.31864119  2.38636303  2.44277549  2.37321997  2.3743577   2.4918797\n",
      "  2.36264825  2.39814043  2.43207645  2.44924068  2.51354885  2.33102417\n",
      "  2.32933569  2.3786602   2.43463564  2.38046622  2.37442398  2.26536512\n",
      "  2.25287104  2.32104397  2.41784716  3.3056159   2.27356601  2.50183153\n",
      "  2.28432989  2.38100839  2.32787418  2.37440014  2.37435889  2.41389418\n",
      "  2.3296032   2.40781069  2.28369689  2.27699327  2.32106113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15  5 15 15 23 14 23  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23 15 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  18000\n",
      "Cost: [ 2.44794607  2.49181986  2.38026023  2.31820726  2.38025117  2.45837426\n",
      "  2.33925915  2.26552534  2.45061398  2.37083602  2.26487732  2.39934731\n",
      "  2.48798823  2.29200411  2.25390887  2.31821609  2.45243716  2.3566308\n",
      "  2.2694521   2.37657237  2.35208273  2.45090532  2.44374323  2.36897087\n",
      "  2.47844839  2.51059961  2.32189512  3.19938517  2.3249104   2.3801105\n",
      "  2.39429903  2.2542088   2.3060329   2.43172288  2.45099735  2.26649046\n",
      "  2.25186968  2.38905811  2.28139687  2.38424349  2.38011289  2.41505837\n",
      "  2.31786776  2.33731389  2.40181804  2.32271981  2.36977243  2.27682233\n",
      "  2.50641346  2.26998544  2.44392347  2.37468767  2.27346897  2.34435558\n",
      "  2.31828928  2.38310051  2.44137073  2.37309361  2.37470126  2.49303746\n",
      "  2.36502767  2.40532017  2.43222833  2.44871116  2.5114975   2.33084059\n",
      "  2.33554268  2.38077378  2.41648388  2.38012648  2.37481642  2.25793934\n",
      "  2.25226188  2.32079315  2.41537952  3.30700016  2.26093817  2.50076509\n",
      "  2.27024555  2.38098097  2.30517602  2.37470102  2.37469816  2.39833641\n",
      "  2.32860184  2.40380573  2.27960157  2.27747059  2.3208096 ]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8  9  0  9 15  5 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14  5\n",
      " 23 11 23 23 15 23 15 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  19000\n",
      "Cost: [ 2.44711304  2.49101353  2.37987709  2.31787539  2.37987351  2.45709753\n",
      "  2.33812594  2.26098871  2.44919086  2.37079835  2.26428175  2.39729738\n",
      "  2.48789215  2.29016018  2.25264168  2.31789064  2.451581    2.35488486\n",
      "  2.26820469  2.37622571  2.35014868  2.44943571  2.44124246  2.36597991\n",
      "  2.47506356  2.51110792  2.32063389  3.19863915  2.32356548  2.37975907\n",
      "  2.39285374  2.25381947  2.30189514  2.43181801  2.44752693  2.26577258\n",
      "  2.25163746  2.38621426  2.27813482  2.3816874   2.37976122  2.41254711\n",
      "  2.31704402  2.33586526  2.39951181  2.32231092  2.35904169  2.27520323\n",
      "  2.50506473  2.2692101   2.44137073  2.37499809  2.27336001  2.34059238\n",
      "  2.31790495  2.38161182  2.44054604  2.37295198  2.37501979  2.49372101\n",
      "  2.36190367  2.4070847   2.43227935  2.44807339  2.50988817  2.33059883\n",
      "  2.33370852  2.38153911  2.41552687  2.37976599  2.37507987  2.25628257\n",
      "  2.25191784  2.32051492  2.41302872  3.30284739  2.25868106  2.50143504\n",
      "  2.27101445  2.38054061  2.30155182  2.37500668  2.37500858  2.40041947\n",
      "  2.32770514  2.401613    2.27687693  2.27576637  2.32053351]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8  9  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  20000\n",
      "Cost: [ 2.44627213  2.49043465  2.37955117  2.31755829  2.37958241  2.45581722\n",
      "  2.33700991  2.25713921  2.44801426  2.37073898  2.26361704  2.39584446\n",
      "  2.4877646   2.28751373  2.25218344  2.31757379  2.45069528  2.35219574\n",
      "  2.26697063  2.37597871  2.34833932  2.44821072  2.43950891  2.36297178\n",
      "  2.46995616  2.51239824  2.31947184  3.19776726  2.3223567   2.37947559\n",
      "  2.39127588  2.25352931  2.29569364  2.43181896  2.44143081  2.26496649\n",
      "  2.25107527  2.38167429  2.27554965  2.37674093  2.37947702  2.41037464\n",
      "  2.3162024   2.33497143  2.39394999  2.32180643  2.3469553   2.27394533\n",
      "  2.50396156  2.2680645   2.43959093  2.37520671  2.27703905  2.33961511\n",
      "  2.31756687  2.38075924  2.43990302  2.3728385   2.37523246  2.49281979\n",
      "  2.35877943  2.4208498   2.43222809  2.44742823  2.50879526  2.329983\n",
      "  2.33207679  2.38278246  2.41929626  2.3794806   2.37528229  2.25462627\n",
      "  2.25161052  2.32015586  2.41086102  3.29614353  2.25805974  2.50155783\n",
      "  2.27470016  2.38028264  2.29729652  2.37521124  2.37521696  2.41506171\n",
      "  2.32705069  2.40300941  2.27450943  2.27448487  2.32017756]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8  9  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  21000\n",
      "Cost: [ 2.44551802  2.49016905  2.37928772  2.31725454  2.37931681  2.45506811\n",
      "  2.33597279  2.25467563  2.44748592  2.37056398  2.26312828  2.39584112\n",
      "  2.48768973  2.28529119  2.25195599  2.31727386  2.44990873  2.35027695\n",
      "  2.26614666  2.37575984  2.34654379  2.44762063  2.43830085  2.3606236\n",
      "  2.46768379  2.51466918  2.31854033  3.19696021  2.32141352  2.37922287\n",
      "  2.39109278  2.25319099  2.29277587  2.4317987   2.41918588  2.26430321\n",
      "  2.25080752  2.37980938  2.27310658  2.36128211  2.37922478  2.40862465\n",
      "  2.31544209  2.3342495   2.38473058  2.32136726  2.32741976  2.27240753\n",
      "  2.50310087  2.26747036  2.43836594  2.37534332  2.28332329  2.33791161\n",
      "  2.31727099  2.38020492  2.43961501  2.37276363  2.3753767   2.49337649\n",
      "  2.356323    2.426543    2.43216491  2.44674993  2.5074563   2.32949781\n",
      "  2.33066344  2.38355303  2.42018437  2.37922788  2.37541413  2.25267148\n",
      "  2.25137091  2.31985545  2.40911579  3.29272604  2.25761342  2.50203323\n",
      "  2.28123999  2.38005137  2.29644656  2.37534595  2.37535214  2.42297792\n",
      "  2.32641506  2.40180373  2.27263379  2.2730217   2.31988335]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  22000\n",
      "Cost: [ 2.44477081  2.48994589  2.37896347  2.31696987  2.37896442  2.45451617\n",
      "  2.33492303  2.25351977  2.44689012  2.37084746  2.26260233  2.39719343\n",
      "  2.48772001  2.28397632  2.25181961  2.31698561  2.4490962   2.34863186\n",
      "  2.26499104  2.37559223  2.34489202  2.44701385  2.43741417  2.35824728\n",
      "  2.4653101   2.51558638  2.31738472  3.19632626  2.32106185  2.37889385\n",
      "  2.39046907  2.2528336   2.29037404  2.43180275  2.401443    2.26366019\n",
      "  2.25079179  2.37918282  2.27118325  2.34589696  2.37889576  2.40701103\n",
      "  2.31535482  2.33293915  2.37706327  2.32095289  2.31945395  2.2710042\n",
      "  2.50261521  2.267591    2.43746209  2.37542295  2.28176379  2.33411407\n",
      "  2.31697702  2.37975621  2.43945003  2.37270951  2.37545323  2.49471617\n",
      "  2.35392189  2.42604256  2.43213296  2.4461751   2.50606012  2.3292501\n",
      "  2.32921982  2.38056159  2.41240382  2.37889743  2.37551332  2.25232983\n",
      "  2.25122261  2.31956482  2.40746045  3.28859735  2.25669789  2.5025816\n",
      "  2.27966952  2.37968016  2.29489732  2.37542462  2.37542939  2.42184019\n",
      "  2.32613826  2.4009614   2.27270675  2.27151322  2.31960416]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8  9  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3  9  8  9 14]\n",
      "Accuracy:  0.337079\n",
      " \n",
      "Step:  23000\n",
      "Cost: [ 2.44407701  2.48975301  2.3786242   2.31671476  2.37860274  2.45385122\n",
      "  2.33390141  2.25293517  2.44612598  2.37110567  2.26208329  2.39760447\n",
      "  2.48778081  2.28326678  2.25147963  2.31673002  2.44829655  2.3469851\n",
      "  2.26381707  2.37544608  2.34340024  2.44625044  2.43671465  2.3558836\n",
      "  2.46333289  2.51462555  2.31661749  3.19572973  2.32085371  2.37854576\n",
      "  2.38932657  2.25252914  2.28795362  2.43177915  2.39537716  2.26306677\n",
      "  2.25079465  2.37871313  2.26956725  2.33868384  2.37854791  2.40534854\n",
      "  2.31541252  2.33167815  2.37130022  2.32057333  2.31626344  2.26961946\n",
      "  2.5021944   2.26729298  2.43675113  2.37544394  2.27769828  2.33101845\n",
      "  2.3167181   2.37937832  2.43924403  2.37269831  2.37546921  2.49603796\n",
      "  2.35157299  2.42185092  2.43209386  2.44564438  2.50469518  2.32878375\n",
      "  2.32794476  2.37861395  2.40497899  2.3785491   2.37555718  2.25200939\n",
      "  2.25110841  2.3192811   2.40579224  3.28631353  2.25579262  2.50282001\n",
      "  2.27558374  2.3792851   2.29267597  2.37544513  2.37544918  2.41631389\n",
      "  2.32591009  2.4003284   2.27243662  2.27003646  2.31933022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  24000\n",
      "Cost: [ 2.44346142  2.48957062  2.37832117  2.31648088  2.37828326  2.45313334\n",
      "  2.33292127  2.25252151  2.44540691  2.37127519  2.2615881   2.39722252\n",
      "  2.4878149   2.28244209  2.25113869  2.31649494  2.44756222  2.34533167\n",
      "  2.26274109  2.37532353  2.34206343  2.44552994  2.4361248   2.35325956\n",
      "  2.46179628  2.51304531  2.31612277  3.1950767   2.32052565  2.37823391\n",
      "  2.3881917   2.25225067  2.28539443  2.43172765  2.39250374  2.26250744\n",
      "  2.25072861  2.37820816  2.26815963  2.33479786  2.37823701  2.40373826\n",
      "  2.31550264  2.33069348  2.36695957  2.32021141  2.31427598  2.26828551\n",
      "  2.50171041  2.26665092  2.43615389  2.37540793  2.27465034  2.32909226\n",
      "  2.31648302  2.3790741   2.4390707   2.37269711  2.37542939  2.49688983\n",
      "  2.34908295  2.41715646  2.43202734  2.44511199  2.50354719  2.32830381\n",
      "  2.32674003  2.37764978  2.40000606  2.37823772  2.37553644  2.25171375\n",
      "  2.25099659  2.31900096  2.4041698   3.28503227  2.25508738  2.5028851\n",
      "  2.27255774  2.37892771  2.29099774  2.37540913  2.37541246  2.41044474\n",
      "  2.32562208  2.39972472  2.27158427  2.26862073  2.31905627]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  25000\n",
      "Cost: [ 2.44290519  2.48939204  2.37804365  2.31626558  2.37799335  2.4523921\n",
      "  2.33199596  2.25219965  2.44472218  2.37139821  2.26112103  2.39646673\n",
      "  2.48782253  2.28141522  2.25083995  2.3162775   2.44687128  2.34374619\n",
      "  2.26173019  2.37521458  2.34085417  2.44483995  2.43562317  2.35045433\n",
      "  2.46048903  2.51138639  2.31576443  3.19442058  2.3201232   2.37794876\n",
      "  2.38717604  2.25199127  2.28269124  2.43166471  2.39073157  2.26198363\n",
      "  2.25062394  2.37770724  2.26691151  2.33231735  2.37795234  2.4022193\n",
      "  2.31559992  2.32986331  2.3633852   2.31987047  2.31275845  2.26702905\n",
      "  2.50120234  2.26593542  2.43564606  2.37533283  2.27235484  2.32771683\n",
      "  2.31626749  2.37881231  2.43891239  2.37270069  2.37535238  2.49736094\n",
      "  2.34653831  2.41260052  2.43194723  2.44459009  2.50258803  2.32785249\n",
      "  2.32556987  2.37709141  2.39652157  2.37795258  2.37547112  2.25145149\n",
      "  2.25089121  2.31873274  2.40263939  3.28413677  2.25451231  2.5028255\n",
      "  2.27032161  2.37859344  2.28972197  2.37533402  2.37533712  2.40493059\n",
      "  2.32528758  2.39911938  2.27049518  2.26729107  2.31879091]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  26000\n",
      "Cost: [ 2.44239259  2.48919344  2.37778544  2.31606603  2.37772536  2.45163822\n",
      "  2.33113647  2.25196338  2.44405866  2.37149787  2.26068449  2.39557123\n",
      "  2.4878068   2.28018212  2.25058603  2.31607628  2.44621897  2.34225917\n",
      "  2.26078153  2.37511539  2.33977318  2.44416714  2.43519497  2.3475709\n",
      "  2.4593339   2.50981855  2.31547737  3.19378877  2.31968975  2.37768507\n",
      "  2.38627195  2.25174975  2.27994823  2.43159771  2.38944674  2.26149464\n",
      "  2.25050569  2.37721801  2.26580024  2.33051991  2.37768912  2.4007988\n",
      "  2.31568766  2.32912874  2.36026502  2.31955338  2.31145287  2.26586819\n",
      "  2.50071144  2.26524305  2.43521261  2.37523389  2.27053118  2.32649469\n",
      "  2.31606817  2.37857938  2.43875742  2.37270784  2.37525225  2.49759293\n",
      "  2.34403157  2.40826654  2.43186212  2.44408727  2.50177431  2.32742023\n",
      "  2.32442188  2.37671781  2.39389205  2.37768888  2.37537718  2.25122046\n",
      "  2.25079322  2.31848001  2.4012084   3.28335333  2.25401545  2.50268555\n",
      "  2.26859188  2.37827611  2.28870916  2.3752346   2.3752377   2.3998754\n",
      "  2.32492065  2.39850926  2.26937056  2.26606393  2.31853867]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  27000\n",
      "Cost: [ 2.44191313  2.48888707  2.37754655  2.31588006  2.37747979  2.45086694\n",
      "  2.33037639  2.25189519  2.44340301  2.37158966  2.26028275  2.39465618\n",
      "  2.48775697  2.27845907  2.25038481  2.31588769  2.44560862  2.3408699\n",
      "  2.25988293  2.37502193  2.33887434  2.4434979   2.43483162  2.34462667\n",
      "  2.458318    2.50839043  2.31523085  3.19318748  2.31924462  2.3774426\n",
      "  2.38544464  2.25152421  2.27735615  2.43153071  2.38842654  2.26103878\n",
      "  2.25039172  2.37673903  2.26482439  2.32908344  2.37744713  2.39946723\n",
      "  2.31575584  2.32846618  2.35746002  2.31926179  2.31023741  2.26481891\n",
      "  2.50029612  2.26464772  2.43484473  2.37512398  2.26905775  2.32493639\n",
      "  2.31588316  2.37836742  2.4386034   2.37271738  2.37514162  2.49768496\n",
      "  2.34158301  2.40407085  2.43177819  2.44360638  2.50107646  2.32697701\n",
      "  2.32324123  2.37644625  2.39175463  2.37744617  2.3752687   2.25103807\n",
      "  2.25070047  2.3182435   2.3998661   3.28248024  2.2535584   2.5025115\n",
      "  2.26726103  2.37797809  2.28793573  2.37512445  2.37512732  2.39527917\n",
      "  2.3245163   2.39790344  2.26832986  2.2649579   2.31830168]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  28000\n",
      "Cost: [ 2.44146109  2.48798633  2.37732697  2.31570435  2.37725496  2.45003843\n",
      "  2.32991576  2.2525878   2.44272089  2.3716898   2.25991535  2.39375567\n",
      "  2.4876101   2.27511501  2.25021124  2.3157084   2.44504976  2.33950758\n",
      "  2.25887918  2.37494111  2.33830953  2.44279671  2.43452477  2.34162116\n",
      "  2.45745468  2.50713229  2.31505179  3.19261789  2.31879234  2.37722039\n",
      "  2.38470578  2.25131249  2.27500749  2.43146276  2.38757467  2.26061964\n",
      "  2.25023723  2.37627029  2.26406336  2.32777882  2.37722635  2.39826083\n",
      "  2.31580734  2.3278718   2.35463476  2.31896377  2.308851    2.26386523\n",
      "  2.50014448  2.26441383  2.43453455  2.37501001  2.26755786  2.32144928\n",
      "  2.31570983  2.37817669  2.43844414  2.3727262   2.37502837  2.49772048\n",
      "  2.33922744  2.40021658  2.43169761  2.44314837  2.50059009  2.32648516\n",
      "  2.32190228  2.37626672  2.38988042  2.37722421  2.37514591  2.25075889\n",
      "  2.25060177  2.31800556  2.39863467  3.28115582  2.25317883  2.50235581\n",
      "  2.26599789  2.37769222  2.28734231  2.37501049  2.37501311  2.3911252\n",
      "  2.32400584  2.39730477  2.26768088  2.26395297  2.31806207]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  29000\n",
      "Cost: [ 2.44087148  2.4214766   2.37719059  2.31537628  2.37708545  2.44601917\n",
      "  2.33132386  2.25537777  2.44186592  2.37248635  2.2595427   2.39276719\n",
      "  2.48905802  2.27089262  2.25046825  2.31538081  2.44456506  2.33804083\n",
      "  2.25752735  2.37490368  2.34848475  2.4419086   2.43423986  2.33965445\n",
      "  2.45664144  2.50788951  2.31479883  3.19200015  2.31809449  2.37705874\n",
      "  2.38466883  2.25135708  2.27345967  2.4313581   2.3870883   2.26019502\n",
      "  2.24950957  2.37563229  2.26739979  2.32701826  2.37706661  2.39721894\n",
      "  2.31603456  2.32816315  2.35655212  2.31798196  2.30781746  2.26304054\n",
      "  2.50578976  2.26428795  2.43424582  2.37487793  2.27147913  2.31680942\n",
      "  2.3154192   2.37803912  2.43858337  2.37270689  2.37489367  2.49727774\n",
      "  2.3382771   2.41544867  2.43158197  2.44277811  2.50247335  2.3259716\n",
      "  2.31770277  2.37650132  2.39643145  2.37706232  2.37497067  2.25177646\n",
      "  2.25033212  2.31709337  2.39751077  3.27838755  2.25441504  2.50145578\n",
      "  2.26750231  2.37744045  2.28805017  2.37487841  2.37487888  2.40111756\n",
      "  2.32282233  2.39706254  2.26907897  2.26307535  2.31713772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  30000\n",
      "Cost: [ 2.44075632  2.3951304   2.37702084  2.3152566   2.37691832  2.44879723\n",
      "  2.331038    2.25627518  2.44081783  2.3724699   2.25932741  2.39186859\n",
      "  2.49035573  2.27142859  2.25021839  2.31525993  2.44417834  2.33682752\n",
      "  2.25669098  2.37486982  2.35313368  2.44085073  2.43399358  2.3344276\n",
      "  2.45553732  2.50745249  2.31455755  3.19166136  2.31755185  2.37689471\n",
      "  2.38427734  2.25113869  2.27164888  2.43127012  2.3862021   2.25993204\n",
      "  2.24940014  2.37514591  2.26751423  2.32600665  2.37690139  2.39622116\n",
      "  2.3160491   2.3272531   2.35221624  2.31785488  2.3058517   2.26224375\n",
      "  2.50602913  2.26327062  2.43399835  2.37479115  2.26828456  2.31635714\n",
      "  2.31526351  2.37800312  2.43808174  2.37269759  2.37480569  2.49739122\n",
      "  2.33425617  2.41113234  2.43148279  2.44240689  2.50036621  2.32566714\n",
      "  2.31704688  2.37652349  2.39289784  2.37689829  2.37488174  2.25151587\n",
      "  2.25031948  2.31697941  2.39654303  3.27753067  2.2543478   2.5023911\n",
      "  2.2644496   2.37722445  2.28531647  2.37479115  2.37479162  2.39599109\n",
      "  2.32190323  2.39640355  2.26709819  2.26220298  2.31702304]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.348315\n",
      " \n",
      "Step:  31000\n",
      "Cost: [ 2.44047475  2.38733792  2.37685442  2.31516051  2.3767519   2.44943714\n",
      "  2.32993555  2.25630188  2.44040155  2.37234068  2.25901103  2.39126825\n",
      "  2.4902997   2.27137756  2.25001812  2.31516075  2.44365311  2.33585739\n",
      "  2.25607014  2.37479639  2.3534193   2.44043303  2.43383217  2.33313274\n",
      "  2.45485067  2.50637579  2.314466    3.19126701  2.31724477  2.37673092\n",
      "  2.38335252  2.25092483  2.27071595  2.43121362  2.385499    2.25956297\n",
      "  2.24936032  2.37461758  2.26622105  2.32524204  2.37673688  2.39534712\n",
      "  2.31604314  2.32652664  2.34939528  2.31776524  2.30475283  2.26164055\n",
      "  2.50512004  2.26267219  2.43383598  2.37472296  2.26675892  2.31625748\n",
      "  2.31516647  2.37786508  2.43777251  2.37270832  2.37473607  2.49753046\n",
      "  2.33306026  2.40593863  2.43141937  2.44202209  2.49922371  2.32522964\n",
      "  2.3169415   2.37627411  2.390589    2.3767345   2.37481475  2.25119925\n",
      "  2.2502687   2.31690907  2.39565039  3.27701235  2.25393963  2.50256538\n",
      "  2.26324749  2.37703037  2.28442478  2.37472343  2.37472391  2.39087892\n",
      "  2.32156205  2.39586353  2.2661097   2.2615726   2.31695151]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.359551\n",
      " \n",
      "Step:  32000\n",
      "Cost: [ 2.44014263  2.38254499  2.37670135  2.315063    2.37660098  2.4492023\n",
      "  2.32895947  2.25622535  2.44009733  2.37226987  2.2586844   2.39066982\n",
      "  2.49016666  2.27100515  2.24983358  2.31506038  2.4431386   2.33497739\n",
      "  2.25552058  2.374722    2.35292554  2.44012809  2.43368769  2.33228374\n",
      "  2.45413947  2.50524354  2.31439281  3.19082618  2.31698704  2.37658143\n",
      "  2.38261962  2.25073314  2.26997042  2.43116045  2.38493991  2.2591846\n",
      "  2.24931955  2.37400675  2.26502323  2.32461071  2.37658691  2.39448977\n",
      "  2.31604338  2.32593751  2.3469789   2.31764245  2.30395818  2.26109552\n",
      "  2.50440478  2.26220727  2.43369102  2.37466073  2.26561689  2.31614852\n",
      "  2.31506824  2.37770605  2.43757391  2.3727138   2.37467265  2.49753022\n",
      "  2.33224106  2.40139866  2.43136024  2.44167161  2.49837828  2.32480884\n",
      "  2.31682062  2.3760097   2.3888979   2.37658501  2.3747499   2.25091863\n",
      "  2.25020504  2.31681633  2.39477706  3.2765007   2.25357461  2.50247383\n",
      "  2.26234722  2.37685561  2.28376269  2.37466073  2.37466168  2.38647795\n",
      "  2.32137275  2.39539862  2.2653923   2.26101184  2.31685829]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.359551\n",
      " \n",
      "Step:  33000\n",
      "Cost: [ 2.43981361  2.3788507   2.3765583   2.31496668  2.37646151  2.44876575\n",
      "  2.32811952  2.2561214   2.43982267  2.37223411  2.25837851  2.39008927\n",
      "  2.49005294  2.27052665  2.24965882  2.31496263  2.44265842  2.33414555\n",
      "  2.2550354   2.37465119  2.35212398  2.43985271  2.4335475   2.33155179\n",
      "  2.4533968   2.50415516  2.31432343  3.19039321  2.3167603   2.37644339\n",
      "  2.3820498   2.25055909  2.26933622  2.43110228  2.38447762  2.25883198\n",
      "  2.24927831  2.37314773  2.26397824  2.32406521  2.37644839  2.39365435\n",
      "  2.31604362  2.32540512  2.34460998  2.31750298  2.30345607  2.2605989\n",
      "  2.50378776  2.26180029  2.4335506   2.37460232  2.26465511  2.31603599\n",
      "  2.31497145  2.37754869  2.43740988  2.37271452  2.37461329  2.49738812\n",
      "  2.33152533  2.39728975  2.4312973   2.44134927  2.49767947  2.32441163\n",
      "  2.31668663  2.37576962  2.38755226  2.37644649  2.37468767  2.25066113\n",
      "  2.250139    2.31670928  2.39392638  3.27595758  2.25325251  2.50226641\n",
      "  2.26159072  2.37669468  2.28314209  2.37460232  2.37460279  2.38259578\n",
      "  2.32121372  2.39504886  2.2647481   2.26050591  2.316751  ]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.359551\n",
      " \n",
      "Step:  34000\n",
      "Cost: [ 2.43950725  2.37551379  2.3764267   2.3148725   2.37633419  2.44829917\n",
      "  2.32738209  2.25603795  2.43956923  2.37222195  2.25808883  2.38947916\n",
      "  2.48994637  2.27003121  2.24947834  2.31486654  2.44219828  2.33330703\n",
      "  2.25461245  2.37458467  2.35117579  2.43959856  2.43339705  2.33084846\n",
      "  2.45239878  2.50307608  2.31425476  3.18999028  2.3165617   2.37631655\n",
      "  2.38157296  2.25039124  2.26889992  2.43101621  2.38419437  2.25850797\n",
      "  2.24926329  2.37074471  2.26306248  2.32361841  2.37632108  2.39279699\n",
      "  2.31606388  2.32485867  2.34138393  2.31735253  2.30413055  2.26016355\n",
      "  2.503232    2.26139712  2.43340015  2.37454915  2.26362443  2.31595874\n",
      "  2.31487703  2.37739229  2.43724966  2.37271142  2.3745594   2.49674129\n",
      "  2.3308332   2.39317703  2.43121433  2.44103336  2.49704957  2.32403088\n",
      "  2.31654406  2.37555289  2.38620234  2.37631965  2.37463045  2.25038314\n",
      "  2.25007772  2.31659508  2.3930521   3.27525234  2.25293016  2.50201273\n",
      "  2.26079082  2.37654781  2.28232813  2.37454939  2.37454987  2.37878966\n",
      "  2.32105398  2.39527941  2.26411033  2.26006675  2.31663656]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3  9  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.359551\n",
      " \n",
      "Step:  35000\n",
      "Cost: [ 2.43923497  2.36784577  2.37652898  2.31475854  2.3764534   2.44666815\n",
      "  2.3268857   2.26360607  2.43806362  2.37234449  2.25732493  2.3886342\n",
      "  2.48971033  2.27025723  2.24873972  2.31475353  2.44133615  2.33370185\n",
      "  2.25479746  2.37453485  2.34973478  2.438097    2.43320942  2.32993698\n",
      "  2.45142579  2.50000906  2.31407213  3.19010472  2.31646395  2.37643266\n",
      "  2.38042688  2.25007105  2.28005362  2.4302597   2.38471603  2.25797105\n",
      "  2.24996948  2.32299638  2.26208043  2.32373834  2.37643528  2.39069581\n",
      "  2.31633639  2.32313681  2.32638788  2.31715417  2.25361061  2.26279998\n",
      "  2.50276828  2.25687504  2.43321347  2.37470436  2.25909901  2.31739712\n",
      "  2.31475925  2.37717414  2.43555284  2.37260866  2.37471509  2.49505997\n",
      "  2.32992029  2.3740325   2.43075705  2.44032121  2.49604225  2.32383299\n",
      "  2.31652522  2.37496281  2.3814044   2.37643552  2.37476349  2.24904299\n",
      "  2.25010157  2.31649017  2.39093471  3.25185323  2.25062919  2.50203228\n",
      "  2.25722814  2.37664652  2.2613945   2.37470436  2.37470531  2.36315632\n",
      "  2.32067394  2.38097858  2.26386905  2.26326013  2.31654119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0  9 15 15 19 19 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.359551\n",
      " \n",
      "Step:  36000\n",
      "Cost: [ 2.43891478  2.37016582  2.37635279  2.31469941  2.37633324  2.44550037\n",
      "  2.32611489  2.26611447  2.43742442  2.37244368  2.25667906  2.39050961\n",
      "  2.48963642  2.26926541  2.24859953  2.3146615   2.44050264  2.33542514\n",
      "  2.25401378  2.37441111  2.3497808   2.4374733   2.4331851   2.32944822\n",
      "  2.45479441  2.50223732  2.31439304  3.18978858  2.31677818  2.37630081\n",
      "  2.37912822  2.25003505  2.27770615  2.43004489  2.38442183  2.25749254\n",
      "  2.24965024  2.29677439  2.26128793  2.32221031  2.37630486  2.38998938\n",
      "  2.31638408  2.32438111  2.32449746  2.31696224  2.25574875  2.26406622\n",
      "  2.50195956  2.25589061  2.43318629  2.37472129  2.26689625  2.31368256\n",
      "  2.3147068   2.37688041  2.43572497  2.37265968  2.37472963  2.49481106\n",
      "  2.32944465  2.39343381  2.4307003   2.43959236  2.49529648  2.32327223\n",
      "  2.31663465  2.37532878  2.38935757  2.376302    2.37474012  2.24960828\n",
      "  2.24986577  2.3163507   2.39023328  3.21329832  2.25138474  2.50200367\n",
      "  2.26246881  2.37644696  2.26143217  2.37472177  2.374722    2.38809729\n",
      "  2.32002401  2.35480952  2.26513147  2.26462173  2.31645894]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.359551\n",
      " \n",
      "Step:  37000\n",
      "Cost: [ 2.43857765  2.36593461  2.37622309  2.31466293  2.37623835  2.4452672\n",
      "  2.32546949  2.26406956  2.43714905  2.37240458  2.25620842  2.38946533\n",
      "  2.4896872   2.26870894  2.24862385  2.31460881  2.44001174  2.33589125\n",
      "  2.2529676   2.37437057  2.34857321  2.43719292  2.43305635  2.32937026\n",
      "  2.45243311  2.50242543  2.31424546  3.18973732  2.31631064  2.37616992\n",
      "  2.37952042  2.24977875  2.27572894  2.43001056  2.38448858  2.2571311\n",
      "  2.25029302  2.28908825  2.26061678  2.32211471  2.37617946  2.38934565\n",
      "  2.31608582  2.3238225   2.32325602  2.3168056   2.25029349  2.26339984\n",
      "  2.50152302  2.25564957  2.43305492  2.37466908  2.2629559   2.3131392\n",
      "  2.31465173  2.37677455  2.43545485  2.37268734  2.37467766  2.49542785\n",
      "  2.32935953  2.38452005  2.4307065   2.43908     2.49502039  2.32329082\n",
      "  2.31641626  2.37485695  2.38537908  2.37617135  2.37466574  2.2494216\n",
      "  2.24981189  2.31622887  2.38960028  3.20157146  2.25058985  2.50089931\n",
      "  2.25908589  2.37627172  2.2598443   2.37467003  2.37466908  2.38025546\n",
      "  2.31974077  2.34743834  2.26294231  2.26390505  2.31639218]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23  9 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.359551\n",
      " \n",
      "Step:  38000\n",
      "Cost: [ 2.43830609  2.36155987  2.37611389  2.31461596  2.3761344   2.44502163\n",
      "  2.32491612  2.26196051  2.43696213  2.37238097  2.25594687  2.38784981\n",
      "  2.48967052  2.26809883  2.24860406  2.31455302  2.43966341  2.33541512\n",
      "  2.25220776  2.37431622  2.34747791  2.43699741  2.43291545  2.32909966\n",
      "  2.44896078  2.50212431  2.31413436  3.18946266  2.31593728  2.37605333\n",
      "  2.37970471  2.24953651  2.27486873  2.43003273  2.38441181  2.25687957\n",
      "  2.25090814  2.2852962   2.26017928  2.32198     2.37606859  2.38865542\n",
      "  2.31601405  2.3233552   2.32205606  2.31667852  2.24988985  2.26264858\n",
      "  2.5011158   2.25531721  2.43291283  2.37461066  2.2586062   2.31297874\n",
      "  2.31459665  2.3767283   2.43519783  2.37268734  2.37462044  2.49527192\n",
      "  2.32905579  2.3755188   2.43072224  2.43875074  2.49470448  2.32313681\n",
      "  2.31613803  2.37456012  2.38175702  2.37605476  2.37460232  2.24909997\n",
      "  2.24977136  2.31612325  2.38894844  3.1961472   2.25014663  2.50042629\n",
      "  2.25548339  2.37614608  2.25683236  2.37461233  2.3746109   2.3697772\n",
      "  2.31959343  2.344064    2.26193595  2.26306915  2.31627345]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0  9 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.370787\n",
      " \n",
      "Step:  39000\n",
      "Cost: [ 2.4380784   2.36405873  2.37602425  2.3145473   2.37602305  2.44487333\n",
      "  2.32436538  2.26227188  2.43686295  2.37229848  2.25576997  2.38885641\n",
      "  2.48954988  2.26760101  2.24871922  2.31448483  2.43939137  2.3348918\n",
      "  2.25171351  2.37429333  2.34624195  2.43689728  2.43281126  2.32864189\n",
      "  2.4257319   2.50253248  2.31403041  3.18912697  2.31581783  2.37595534\n",
      "  2.380126    2.24959517  2.27306461  2.43010759  2.38425303  2.25667357\n",
      "  2.25001216  2.28166199  2.259588    2.32126164  2.37597728  2.3879137\n",
      "  2.3157773   2.32321119  2.32173371  2.31652069  2.2499752   2.26217723\n",
      "  2.50065541  2.25471663  2.43280792  2.37457275  2.26211452  2.31211925\n",
      "  2.31452775  2.37669897  2.4351337   2.37267709  2.37458611  2.49363732\n",
      "  2.32864499  2.38911867  2.43072248  2.43848705  2.49429202  2.32292032\n",
      "  2.31592894  2.37462497  2.38514233  2.3759563   2.37457132  2.2495718\n",
      "  2.24972653  2.31598067  2.38819718  3.19191265  2.25066495  2.49986744\n",
      "  2.25885248  2.37606382  2.26032734  2.37457514  2.37457275  2.38851571\n",
      "  2.31930256  2.34021592  2.26115513  2.26260376  2.31609082]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  40000\n",
      "Cost: [ 2.43785262  2.36250639  2.3759644   2.31448126  2.37594318  2.44434738\n",
      "  2.32393217  2.26655674  2.43666339  2.37232852  2.25553346  2.38833261\n",
      "  2.48959494  2.26712084  2.24861169  2.31441498  2.43915653  2.33401275\n",
      "  2.25179148  2.37426901  2.34588814  2.43668365  2.43266916  2.3282423\n",
      "  2.41040826  2.50325918  2.31390572  3.1886735   2.31561112  2.37589121\n",
      "  2.3799026   2.2494154   2.27084255  2.43016386  2.38376737  2.25650144\n",
      "  2.25002027  2.28030801  2.25942087  2.31925035  2.37592316  2.38752365\n",
      "  2.31577611  2.32314396  2.32171345  2.31632614  2.25052094  2.26209164\n",
      "  2.50011349  2.25425172  2.43266582  2.37448835  2.26403451  2.28094363\n",
      "  2.31445456  2.37666273  2.43497133  2.37266397  2.3744998   2.49405527\n",
      "  2.3282485   2.38942146  2.43071246  2.43829775  2.49453402  2.32274055\n",
      "  2.31570721  2.37447262  2.38582373  2.3758924   2.37447691  2.24915695\n",
      "  2.24961257  2.31579709  2.38776445  3.18982291  2.24999595  2.49981594\n",
      "  2.25796556  2.37597537  2.2597332   2.37449121  2.37448859  2.3885355\n",
      "  2.31923819  2.339118    2.26114368  2.26258707  2.31589103]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  41000\n",
      "Cost: [ 2.43767595  2.36377048  2.37584257  2.31442738  2.37580729  2.44395661\n",
      "  2.32353854  2.27162886  2.43642759  2.37242317  2.25533509  2.38991022\n",
      "  2.48954606  2.26684165  2.24865651  2.31436372  2.43888807  2.33393383\n",
      "  2.25285125  2.37423563  2.34507561  2.43643332  2.4325459   2.32732105\n",
      "  2.4013567   2.50293374  2.3139143   3.18860555  2.31562591  2.37576747\n",
      "  2.37888551  2.24954748  2.26967645  2.43019104  2.38262558  2.25639296\n",
      "  2.24958587  2.2795682   2.25900745  2.30066156  2.3758049   2.38750482\n",
      "  2.31588221  2.32260656  2.32198954  2.3162396   2.25185776  2.26275444\n",
      "  2.49973583  2.25355649  2.43254256  2.37442303  2.26699185  2.26597285\n",
      "  2.31440639  2.37657642  2.4348321   2.37267971  2.37443137  2.49527812\n",
      "  2.32730341  2.39511657  2.43069124  2.43802428  2.49443817  2.32270575\n",
      "  2.31576252  2.37444115  2.38923025  2.37576866  2.37441015  2.2491262\n",
      "  2.24956679  2.31573129  2.38773704  3.1899507   2.25027251  2.49678755\n",
      "  2.26211643  2.3758204   2.26450729  2.37442565  2.37442303  2.40193629\n",
      "  2.31897569  2.33798361  2.26082325  2.26336718  2.31582999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  42000\n",
      "Cost: [ 2.4374969   2.36049461  2.37577391  2.31437445  2.37572479  2.44342232\n",
      "  2.32311773  2.27193642  2.43617392  2.37240815  2.25510621  2.38933468\n",
      "  2.48944283  2.26626825  2.2485559   2.31431627  2.4386189   2.33404922\n",
      "  2.25351095  2.37419534  2.34436369  2.43616867  2.43246889  2.32659841\n",
      "  2.39559221  2.50233054  2.31382275  3.18849277  2.31564474  2.37569332\n",
      "  2.37904716  2.24931383  2.268574    2.43022299  2.38129258  2.2562201\n",
      "  2.2497437   2.27880931  2.25856805  2.272048    2.37573576  2.38737416\n",
      "  2.31593657  2.32224965  2.32128572  2.3161931   2.25248599  2.26254749\n",
      "  2.49932051  2.25324893  2.43246627  2.37437797  2.26372528  2.26102138\n",
      "  2.31434965  2.37646961  2.43472385  2.37268734  2.3743844   2.49621987\n",
      "  2.32658744  2.3897872   2.43067431  2.4377265   2.49428415  2.32264853\n",
      "  2.31568193  2.374259    2.38625908  2.37569451  2.37436223  2.24880123\n",
      "  2.24952745  2.31570864  2.38760328  3.18920112  2.24967861  2.49692488\n",
      "  2.2594316   2.37572932  2.2615602   2.37438035  2.37437797  2.39635897\n",
      "  2.31871486  2.33721828  2.26017022  2.26314831  2.31581879]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 23 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  43000\n",
      "Cost: [ 2.4373107   2.3524003   2.37568545  2.31434441  2.37561321  2.4429822\n",
      "  2.32272434  2.26539326  2.4358983   2.37235355  2.25495601  2.38338184\n",
      "  2.48926401  2.26577878  2.24836016  2.31426454  2.43848991  2.33295727\n",
      "  2.25320864  2.37412024  2.34315348  2.43588996  2.43242884  2.32609963\n",
      "  2.39104533  2.5004673   2.31387615  3.18821883  2.31557822  2.37560558\n",
      "  2.37885094  2.24917984  2.26740646  2.43033123  2.37869787  2.25609159\n",
      "  2.25173759  2.27500582  2.2582171   2.26343679  2.37564778  2.38756919\n",
      "  2.3156631   2.3213973   2.27356672  2.31613541  2.25186825  2.2611227\n",
      "  2.49868655  2.25315428  2.43242788  2.37432218  2.25479078  2.25479126\n",
      "  2.31428719  2.37641263  2.43436003  2.3726759   2.37432933  2.49542904\n",
      "  2.32610941  2.35601902  2.43070817  2.43759847  2.49436712  2.32221889\n",
      "  2.31550264  2.37475562  2.37684727  2.37560701  2.3743      2.24818277\n",
      "  2.24950695  2.31565905  2.3873105   3.18368483  2.24964809  2.5012629\n",
      "  2.25362206  2.37563562  2.25474715  2.37432504  2.37432218  2.34996319\n",
      "  2.31866932  2.33783627  2.25792718  2.26141548  2.31577373]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.370787\n",
      " \n",
      "Step:  44000\n",
      "Cost: [ 2.437047    2.40897441  2.37586904  2.31426883  2.37577343  2.44297218\n",
      "  2.32243323  2.27314472  2.43698049  2.37241197  2.25492287  2.40513802\n",
      "  2.48924255  2.26679158  2.25110221  2.31419706  2.43848491  2.33246946\n",
      "  2.25461197  2.3744781   2.34248734  2.43696785  2.43257666  2.32570958\n",
      "  2.40928411  2.49912214  2.31384277  3.18829489  2.31627655  2.37577081\n",
      "  2.37882829  2.25548291  2.27343321  2.4304049   2.34054422  2.25579667\n",
      "  2.24800301  2.27046442  2.25838304  2.26030064  2.37583256  2.3863976\n",
      "  2.3155098   2.32121301  2.26949739  2.31609249  2.25249052  2.26139045\n",
      "  2.49841404  2.25165224  2.43257666  2.3744545   2.3305769   2.31089354\n",
      "  2.31422782  2.37644911  2.43447399  2.3725419   2.37447095  2.49470854\n",
      "  2.3257153   2.4378705   2.43070364  2.43753171  2.4938004   2.32102489\n",
      "  2.31541252  2.37429619  2.47067881  2.37577534  2.37443209  2.25758696\n",
      "  2.2494545   2.31565499  2.38651347  3.18929601  2.27535129  2.4949441\n",
      "  2.32931089  2.37581062  2.32945442  2.37445736  2.3744545   2.45845747\n",
      "  2.31852722  2.33783031  2.26219463  2.2620759   2.31576705]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.393258\n",
      " \n",
      "Step:  45000\n",
      "Cost: [ 2.43690562  2.36367178  2.37579083  2.31420517  2.37570095  2.44290876\n",
      "  2.32208228  2.26493073  2.43694377  2.37240887  2.25485802  2.39020133\n",
      "  2.48912811  2.2650497   2.2484026   2.31413269  2.43853521  2.33155513\n",
      "  2.25247645  2.37414622  2.34163189  2.43693352  2.43253827  2.32539368\n",
      "  2.39288116  2.4982059   2.31378484  3.18763208  2.31506991  2.37569928\n",
      "  2.37891674  2.24896407  2.27157092  2.4305315   2.33086491  2.25572968\n",
      "  2.24923205  2.26906729  2.25774312  2.25918627  2.37576723  2.38595009\n",
      "  2.31560111  2.32092333  2.26797962  2.31594753  2.25155234  2.26011825\n",
      "  2.49797153  2.25221729  2.43253851  2.37444782  2.2823832   2.29427552\n",
      "  2.31415486  2.37644005  2.43439054  2.37247133  2.3744638   2.49520898\n",
      "  2.32539678  2.3870225   2.43073153  2.43755579  2.49370551  2.32142496\n",
      "  2.31517148  2.37414217  2.38872719  2.37570381  2.37443161  2.24877691\n",
      "  2.2494123   2.3155241   2.38605404  3.18618393  2.24967265  2.49638152\n",
      "  2.27543497  2.37573242  2.27934122  2.37445068  2.37444782  2.39715123\n",
      "  2.31843448  2.33654976  2.25964403  2.26051474  2.31562519]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 15  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.393258\n",
      " \n",
      "Step:  46000\n",
      "Cost: [ 2.43674707  2.34928727  2.37569523  2.31414294  2.3756144   2.44269061\n",
      "  2.32180071  2.25937605  2.43658066  2.3724153   2.25478792  2.38283587\n",
      "  2.48903465  2.26430655  2.24808311  2.31407881  2.43858862  2.33093262\n",
      "  2.25158691  2.37400126  2.34096098  2.43657351  2.43245769  2.32525516\n",
      "  2.38838553  2.49775815  2.31373215  3.18709898  2.31456995  2.3756125\n",
      "  2.37893677  2.2489903   2.27061558  2.43060589  2.32775617  2.25566578\n",
      "  2.25217915  2.26833344  2.25746727  2.25852609  2.3756845   2.38556838\n",
      "  2.31578827  2.32076907  2.26731586  2.31582952  2.25103426  2.25938773\n",
      "  2.49763513  2.25254893  2.43245792  2.37440085  2.25428605  2.25259185\n",
      "  2.31409431  2.3763957   2.43422699  2.37240624  2.37441611  2.49569297\n",
      "  2.32525849  2.34742713  2.43074894  2.43757606  2.49359035  2.32148504\n",
      "  2.31501222  2.3739717   2.37553596  2.37561774  2.3743875   2.2481842\n",
      "  2.24936199  2.3154068   2.38567686  3.18491101  2.24956179  2.49809027\n",
      "  2.2530756   2.37564039  2.25453377  2.37440443  2.37440085  2.34321761\n",
      "  2.31834888  2.33576536  2.25701451  2.25968289  2.31550026]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.370787\n",
      " \n",
      "Step:  47000\n",
      "Cost: [ 2.43660402  2.34870005  2.37562537  2.31408191  2.37555599  2.4424417\n",
      "  2.32160759  2.25833392  2.43626046  2.37242961  2.25478172  2.38722682\n",
      "  2.48893499  2.2637291   2.24804115  2.31401968  2.43868446  2.33046913\n",
      "  2.251405    2.37395716  2.34023333  2.43625402  2.43236613  2.32513523\n",
      "  2.38903928  2.49697351  2.31377506  3.1872406   2.31449056  2.37555456\n",
      "  2.37883329  2.24928617  2.2725687   2.43063951  2.32616663  2.25605536\n",
      "  2.24963737  2.26768732  2.25738287  2.2581265   2.3756268   2.3852222\n",
      "  2.31567621  2.32051563  2.2671957   2.31573725  2.25069189  2.25890112\n",
      "  2.49733329  2.25259233  2.43236613  2.3743484   2.26316762  2.25572062\n",
      "  2.31404614  2.37637568  2.43404484  2.37228131  2.37436199  2.49578857\n",
      "  2.32511353  2.36786294  2.43074274  2.43755102  2.4933598   2.32144809\n",
      "  2.31495953  2.37384915  2.37997389  2.37556052  2.3743341   2.24837923\n",
      "  2.24934864  2.31531525  2.3853054   3.18587422  2.24940658  2.49651504\n",
      "  2.26849985  2.37557888  2.27141738  2.3743515   2.3743484   2.40202451\n",
      "  2.31827164  2.33504963  2.26096058  2.25911784  2.31539798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11  3  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  48000\n",
      "Cost: [ 2.43643093  2.35473108  2.37561989  2.3140254   2.37555552  2.44214129\n",
      "  2.32126546  2.2554462   2.43600035  2.37244368  2.25459695  2.3823266\n",
      "  2.48885465  2.26373005  2.24826002  2.31396437  2.43895626  2.33001089\n",
      "  2.25092411  2.37393093  2.33960891  2.43599534  2.43221092  2.32490063\n",
      "  2.38678932  2.49661398  2.31364298  3.18697524  2.31445765  2.37555408\n",
      "  2.37872148  2.24934077  2.26545906  2.43061852  2.32458138  2.25551748\n",
      "  2.25214934  2.26713514  2.25701213  2.25789785  2.37562633  2.38484955\n",
      "  2.31587648  2.32031822  2.26621008  2.31566787  2.25048494  2.25826335\n",
      "  2.49706268  2.25251126  2.43221116  2.37425971  2.25525331  2.25755358\n",
      "  2.31399298  2.37645721  2.43388224  2.37190652  2.37427282  2.49575424\n",
      "  2.32489014  2.34393597  2.43069196  2.43749189  2.49315047  2.32127523\n",
      "  2.31483102  2.37372398  2.37637544  2.37556219  2.37424397  2.24858856\n",
      "  2.24930716  2.31523085  2.38492942  3.18486643  2.24992609  2.49793983\n",
      "  2.25381351  2.37557602  2.25496101  2.37426233  2.37425971  2.34343457\n",
      "  2.31819487  2.33431721  2.25845098  2.25846553  2.31530976]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11  3  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.370787\n",
      " \n",
      "Step:  49000\n",
      "Cost: [ 2.4362483   2.34681416  2.37586546  2.31397581  2.3758018   2.44184136\n",
      "  2.32100558  2.25510406  2.43579149  2.37245703  2.25461507  2.38212585\n",
      "  2.48874497  2.26315904  2.24809647  2.31391501  2.43967533  2.32944465\n",
      "  2.25066447  2.37393832  2.33894873  2.43578649  2.43200731  2.32462835\n",
      "  2.38642502  2.49579144  2.31359172  3.1861968   2.31437349  2.37580037\n",
      "  2.37857366  2.24878979  2.26457548  2.43053341  2.32400346  2.25552845\n",
      "  2.25186872  2.26650834  2.25660944  2.25747824  2.37587404  2.38433862\n",
      "  2.3158071   2.32003236  2.26545835  2.31560516  2.25028014  2.25780988\n",
      "  2.49678373  2.25238872  2.43200755  2.37416196  2.2541678   2.251369\n",
      "  2.313941    2.37674379  2.43372774  2.37026858  2.37417412  2.49555349\n",
      "  2.32462859  2.34253502  2.43057156  2.43744969  2.49283957  2.3211391\n",
      "  2.31473255  2.37364888  2.37500381  2.3758142   2.37414122  2.2480917\n",
      "  2.24925661  2.31515408  2.38442826  3.18482447  2.24928665  2.4968133\n",
      "  2.25276375  2.37582111  2.25441718  2.37416482  2.37416196  2.33801198\n",
      "  2.31809878  2.33355403  2.25628781  2.25802732  2.31522822]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  50000\n",
      "Cost: [ 2.43604708  2.34637475  2.37622213  2.31393051  2.37616038  2.44159317\n",
      "  2.32078218  2.25453782  2.43561363  2.37247562  2.25474381  2.3821125\n",
      "  2.48865414  2.26281548  2.24807453  2.31387806  2.44068861  2.32890344\n",
      "  2.25043631  2.37393188  2.33817887  2.43560886  2.43175554  2.3243444\n",
      "  2.38600063  2.49489522  2.31358242  3.18582463  2.31432056  2.37615871\n",
      "  2.37831807  2.24870372  2.26378179  2.43041825  2.32349563  2.25563288\n",
      "  2.25115395  2.2657299   2.25636649  2.25705314  2.37623382  2.38390517\n",
      "  2.31570435  2.31958127  2.26468539  2.31556201  2.25009775  2.25733948\n",
      "  2.49653172  2.25225496  2.43175578  2.37406015  2.25503087  2.25091076\n",
      "  2.31389952  2.37706137  2.43354869  2.36700177  2.37407088  2.49520326\n",
      "  2.32434464  2.34306526  2.43042707  2.43751001  2.4925828   2.32102323\n",
      "  2.31467199  2.37362552  2.37520862  2.37617874  2.37403154  2.24806213\n",
      "  2.24923921  2.31508803  2.38399196  3.1845665   2.24909306  2.4958601\n",
      "  2.25306773  2.3761797   2.25452328  2.37406278  2.37406015  2.33842587\n",
      "  2.31803918  2.33273721  2.25625539  2.25757265  2.3151567 ]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  51000\n",
      "Cost: [ 2.43585777  2.34737659  2.37644029  2.31387806  2.37638402  2.44123888\n",
      "  2.32062149  2.25318551  2.43545818  2.37247181  2.25486326  2.38200235\n",
      "  2.48860502  2.26275492  2.24816418  2.31384087  2.44152308  2.32827187\n",
      "  2.25023651  2.37386703  2.33777499  2.43545508  2.43155622  2.32422924\n",
      "  2.38575315  2.49501753  2.31348228  3.18522429  2.31428623  2.37638235\n",
      "  2.37847614  2.24898005  2.26299381  2.43032575  2.32318449  2.25571895\n",
      "  2.25249052  2.26558638  2.2562387   2.2573154   2.37645149  2.38353181\n",
      "  2.31586146  2.31974649  2.26464319  2.31549764  2.24995446  2.25694776\n",
      "  2.49633217  2.25210953  2.43155622  2.37400341  2.25507808  2.25553894\n",
      "  2.31384921  2.37717175  2.43350005  2.36351585  2.37401342  2.49532986\n",
      "  2.32422996  2.34051061  2.43031764  2.43764758  2.49250984  2.32093906\n",
      "  2.31454992  2.37341928  2.37511587  2.3764081   2.37396884  2.24841213\n",
      "  2.24915862  2.31499958  2.38363171  3.18482137  2.24948907  2.49742937\n",
      "  2.25377178  2.37640238  2.25735903  2.37400579  2.37400341  2.33561587\n",
      "  2.31799936  2.33222032  2.25599766  2.25718045  2.31506062]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  52000\n",
      "Cost: [ 2.43569613  2.34519458  2.37651658  2.31383491  2.37646818  2.44104767\n",
      "  2.32049465  2.25283456  2.43531132  2.37249732  2.25490832  2.38167238\n",
      "  2.48848462  2.26237798  2.24809051  2.31380892  2.44214988  2.32776499\n",
      "  2.25004101  2.37383032  2.33697867  2.43530822  2.43141961  2.32389522\n",
      "  2.3852787   2.49381638  2.31351018  3.18504596  2.31421447  2.37646604\n",
      "  2.37807846  2.24863076  2.26260209  2.43028307  2.32285285  2.25572562\n",
      "  2.25183821  2.26465988  2.25599122  2.25659037  2.37652445  2.38331389\n",
      "  2.31568289  2.31906557  2.26362562  2.3154676   2.24978495  2.2565558\n",
      "  2.49607468  2.25200772  2.43141985  2.37396884  2.25470304  2.25127387\n",
      "  2.31381226  2.37712836  2.43328571  2.36045408  2.37398005  2.49470592\n",
      "  2.32389569  2.33938694  2.43026018  2.43780041  2.49219275  2.32071328\n",
      "  2.31451344  2.37349248  2.375036    2.37649775  2.37392998  2.24807167\n",
      "  2.24917459  2.31495595  2.38340092  3.18407726  2.24910593  2.49556351\n",
      "  2.25313663  2.37648535  2.25550175  2.37397099  2.37396884  2.33592725\n",
      "  2.31797361  2.33145499  2.25571752  2.25680304  2.31501102]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  53000\n",
      "Cost: [ 2.43555713  2.34547591  2.37651825  2.31378865  2.37647605  2.44078255\n",
      "  2.32038355  2.25192332  2.43517613  2.37250471  2.25488234  2.38203287\n",
      "  2.48836946  2.26217461  2.24811029  2.31377053  2.44260669  2.3272109\n",
      "  2.24984694  2.3737855   2.33639932  2.43517399  2.43131638  2.32367945\n",
      "  2.38504601  2.49329209  2.31347656  3.18478012  2.31417131  2.37647367\n",
      "  2.37801909  2.24855804  2.26231599  2.43025398  2.32257104  2.25566936\n",
      "  2.2521174   2.26419473  2.25582623  2.25642323  2.37652516  2.38309741\n",
      "  2.3156395   2.3188858   2.26322007  2.31541872  2.24960971  2.25623322\n",
      "  2.49582648  2.25190067  2.43131661  2.37393856  2.25687909  2.25364637\n",
      "  2.31376863  2.37702274  2.43317914  2.35775638  2.37395144  2.49436665\n",
      "  2.32367849  2.3398931   2.43022299  2.43790793  2.49198866  2.3205986\n",
      "  2.31444168  2.37342572  2.37568426  2.37651062  2.37389731  2.24803638\n",
      "  2.24913859  2.31490064  2.38318467  3.18382454  2.24926138  2.49531889\n",
      "  2.25454855  2.37649155  2.25756598  2.37394071  2.37393856  2.33803272\n",
      "  2.31794739  2.3308537   2.25571513  2.25647759  2.31494784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  54000\n",
      "Cost: [ 2.435431    2.3455174   2.37648296  2.31374359  2.37644577  2.44053125\n",
      "  2.32026887  2.25241518  2.43505383  2.37251329  2.25480747  2.38516283\n",
      "  2.48831582  2.26183438  2.24798298  2.31373692  2.44292498  2.32676458\n",
      "  2.24976635  2.37372589  2.33589411  2.43505144  2.43122292  2.32349682\n",
      "  2.38493896  2.49293399  2.3134346   3.1845541   2.31408978  2.37644291\n",
      "  2.37800717  2.2486217   2.26188517  2.43022275  2.32237339  2.25560164\n",
      "  2.24951386  2.26384282  2.25568175  2.25639248  2.37648821  2.38290882\n",
      "  2.31551385  2.31884933  2.26299691  2.31536484  2.24950457  2.25599408\n",
      "  2.49564219  2.25178671  2.43122363  2.37390876  2.26638722  2.25140238\n",
      "  2.31373262  2.37689519  2.43309784  2.35535288  2.37392235  2.49414825\n",
      "  2.3234961   2.35562921  2.43018675  2.43793821  2.4918201   2.320539\n",
      "  2.31436539  2.37333846  2.37966824  2.37647963  2.3738625   2.24815178\n",
      "  2.24909115  2.31484795  2.38299942  3.18485165  2.24921203  2.49414587\n",
      "  2.26122093  2.3764596   2.26223564  2.37391043  2.37390876  2.37092638\n",
      "  2.31791019  2.33040857  2.25618553  2.25626922  2.31489205]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.393258\n",
      " \n",
      "Step:  55000\n",
      "Cost: [ 2.43531609  2.34296751  2.37642622  2.3137033   2.37639451  2.44037819\n",
      "  2.32017541  2.25147939  2.43492889  2.37254047  2.25469375  2.38096571\n",
      "  2.48821616  2.26156783  2.24798512  2.31369543  2.44315767  2.32636356\n",
      "  2.24957347  2.37369442  2.33520222  2.43492699  2.43116331  2.32319403\n",
      "  2.38460064  2.49222422  2.31344366  3.18444777  2.31408167  2.37639165\n",
      "  2.37768531  2.24841642  2.26160359  2.43021441  2.3220911   2.25543737\n",
      "  2.2509141   2.26313925  2.25550842  2.255862    2.37643337  2.382761\n",
      "  2.31545019  2.31840611  2.26215172  2.31532502  2.24934673  2.25570917\n",
      "  2.49540973  2.25171566  2.43116403  2.37388182  2.25498295  2.25023103\n",
      "  2.31368613  2.37676668  2.43294001  2.35321569  2.37389922  2.49357319\n",
      "  2.32319427  2.33607888  2.43017411  2.43797684  2.49154687  2.32026768\n",
      "  2.31433344  2.37338495  2.37482429  2.37643456  2.37383652  2.24779797\n",
      "  2.24909306  2.31481314  2.38284683  3.18349361  2.24905181  2.49379277\n",
      "  2.25317979  2.37640738  2.25502658  2.37388372  2.37388182  2.33249617\n",
      "  2.31786942  2.32982874  2.25526953  2.25594091  2.31485152]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 23 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  56000\n",
      "Cost: [ 2.43520164  2.34288573  2.37635612  2.31366611  2.37632847  2.44016552\n",
      "  2.32006598  2.25117302  2.43481612  2.37254095  2.25455809  2.38004923\n",
      "  2.48817158  2.26151562  2.2480278   2.31366181  2.44329214  2.32595897\n",
      "  2.24943495  2.37362385  2.33476162  2.43481517  2.43110228  2.32306385\n",
      "  2.38453531  2.49213696  2.31334686  3.18422771  2.31402302  2.37632585\n",
      "  2.37776613  2.24925399  2.2612741   2.4301908   2.32212448  2.25529242\n",
      "  2.25142813  2.26291275  2.25540209  2.25592422  2.37636733  2.38258886\n",
      "  2.31560469  2.3184998   2.26203561  2.31525874  2.24925303  2.25552368\n",
      "  2.49522972  2.25161552  2.43110299  2.37385416  2.25557256  2.25160193\n",
      "  2.31364846  2.376647    2.43288398  2.35130548  2.37387276  2.49350047\n",
      "  2.3230648   2.33559036  2.43015194  2.43793941  2.49145603  2.32012606\n",
      "  2.31426334  2.37329125  2.37467027  2.37636876  2.37380505  2.24835086\n",
      "  2.24903703  2.31475687  2.38266826  3.18342376  2.24930167  2.49422812\n",
      "  2.2543273   2.37634039  2.25711536  2.37385607  2.37385416  2.33200908\n",
      "  2.31781673  2.32943916  2.25503707  2.25573349  2.31479383]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3  0  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 23 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 19 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  57000\n",
      "Cost: [ 2.43515205  2.3428359   2.37624907  2.31371212  2.37622142  2.43985844\n",
      "  2.31955862  2.25106955  2.43465972  2.37257695  2.25470257  2.32099366\n",
      "  2.48823595  2.26416278  2.24795723  2.31372023  2.44335938  2.32575941\n",
      "  2.24973488  2.37362814  2.33509636  2.43466067  2.43105054  2.32336235\n",
      "  2.38463736  2.49541521  2.31309962  3.18343806  2.31397057  2.37621593\n",
      "  2.3779521   2.24931693  2.26066613  2.43022585  2.32327557  2.25539732\n",
      "  2.25138116  2.26338291  2.25567746  2.25676823  2.37623429  2.38246632\n",
      "  2.31584835  2.32019162  2.26287413  2.31513882  2.24955797  2.25548267\n",
      "  2.49446011  2.25151348  2.43105149  2.37382603  2.25477719  2.25152516\n",
      "  2.31359935  2.37650323  2.43297505  2.34949255  2.37385154  2.4952631\n",
      "  2.32336044  2.33239603  2.43019557  2.43788171  2.49206924  2.31900668\n",
      "  2.31421471  2.37303996  2.25255823  2.37633538  2.37378049  2.24858689\n",
      "  2.24884915  2.31465149  2.3825593   3.1851325   2.25092959  2.49459767\n",
      "  2.25429082  2.37623405  2.25485897  2.37382627  2.37382603  2.33016515\n",
      "  2.31771636  2.33004713  2.25400162  2.25573158  2.31470346]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 15 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 15  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  58000\n",
      "Cost: [ 2.43490624  2.34191561  2.37619591  2.31356096  2.37617207  2.43980694\n",
      "  2.31906652  2.25155854  2.43455195  2.37259483  2.25410938  2.27288485\n",
      "  2.48820782  2.26576805  2.24774575  2.31358123  2.44333839  2.3258841\n",
      "  2.24979186  2.37356734  2.33521056  2.43455172  2.43097425  2.32297659\n",
      "  2.38444376  2.49485326  2.31289244  3.18344474  2.31376791  2.37616706\n",
      "  2.37766814  2.24891758  2.26064825  2.43015075  2.3220911   2.25475383\n",
      "  2.25017953  2.26284814  2.25692916  2.25641203  2.3761785   2.38232684\n",
      "  2.3159833   2.31924105  2.26226759  2.31510234  2.2496891   2.25537777\n",
      "  2.49325562  2.25116777  2.43097496  2.37380171  2.25374556  2.24993515\n",
      "  2.31357145  2.37636995  2.43273425  2.34805584  2.37382269  2.49543118\n",
      "  2.32297683  2.3336482   2.43012714  2.43775082  2.49202442  2.31884837\n",
      "  2.31410456  2.3731308   2.2526176   2.37631607  2.37376046  2.24788237\n",
      "  2.24889517  2.31459093  2.38240075  3.1854465   2.25049472  2.4938302\n",
      "  2.25367856  2.37618518  2.25354075  2.37380219  2.37380171  2.33027244\n",
      "  2.31889892  2.32963419  2.25328088  2.25565386  2.31465745]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 15 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 15  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  59000\n",
      "Cost: [ 2.43470335  2.34137297  2.37618756  2.31351686  2.37616634  2.43974328\n",
      "  2.31901336  2.25129199  2.43442607  2.37261748  2.25393796  2.28000045\n",
      "  2.48818731  2.26554728  2.24783278  2.31353736  2.4432857   2.32578921\n",
      "  2.24964547  2.37353849  2.33451223  2.43442631  2.43103671  2.32262945\n",
      "  2.38413715  2.49405479  2.31284738  3.18352127  2.31368232  2.37616134\n",
      "  2.37734127  2.25025272  2.26007247  2.43017459  2.32207203  2.25455642\n",
      "  2.25062943  2.26237178  2.25741577  2.25585699  2.37617064  2.38209915\n",
      "  2.31585789  2.31859756  2.26168489  2.31514215  2.24954128  2.25505996\n",
      "  2.49283361  2.25101256  2.43103719  2.37384844  2.25353718  2.25019884\n",
      "  2.31350136  2.37623453  2.43259311  2.34646606  2.3738718   2.49498439\n",
      "  2.32262969  2.33337259  2.43014503  2.43764448  2.49181151  2.3187809\n",
      "  2.3141129   2.37326121  2.25230479  2.37631702  2.37380886  2.24781609\n",
      "  2.24894071  2.31458354  2.38215661  3.18415833  2.2509141   2.49400353\n",
      "  2.25388789  2.37618065  2.25419331  2.37384844  2.37384844  2.33080935\n",
      "  2.31903124  2.32921171  2.25309634  2.25529122  2.31464338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 15  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  60000\n",
      "Cost: [ 2.43453789  2.34084606  2.37606764  2.31347871  2.37605166  2.4396019\n",
      "  2.31903863  2.25068307  2.43431425  2.3726368   2.25388336  2.26614642\n",
      "  2.48814607  2.26462865  2.24788451  2.31348085  2.44330001  2.32542038\n",
      "  2.249511    2.3735292   2.33394647  2.43431449  2.43097258  2.32230663\n",
      "  2.38361502  2.49328876  2.31287265  3.1835649   2.31374502  2.37604666\n",
      "  2.37708879  2.24847555  2.26025701  2.43018913  2.32158017  2.2545774\n",
      "  2.25059319  2.2617507   2.25739598  2.2555542   2.37605405  2.38198566\n",
      "  2.31579161  2.31822371  2.26109791  2.31516218  2.24938011  2.2548995\n",
      "  2.49308777  2.25095153  2.43097329  2.37378788  2.25376034  2.2500217\n",
      "  2.31349349  2.37616014  2.43251538  2.34537983  2.37381387  2.49433255\n",
      "  2.32230663  2.33381486  2.43015647  2.43757868  2.49153519  2.31859088\n",
      "  2.31413937  2.37329865  2.25200248  2.37620044  2.37375379  2.24770689\n",
      "  2.24892402  2.31456184  2.38203478  3.18404388  2.24914789  2.49329472\n",
      "  2.25356698  2.37606525  2.25390482  2.37378812  2.37378788  2.33050108\n",
      "  2.31876922  2.32862282  2.2530086   2.25511074  2.31461143]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 15  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  61000\n",
      "Cost: [ 2.4344101   2.34070587  2.3760581   2.31342816  2.37604403  2.43945289\n",
      "  2.31897354  2.24995613  2.43421221  2.37266541  2.25375557  2.26390505\n",
      "  2.48805976  2.26404047  2.24778032  2.31342292  2.44323635  2.32493281\n",
      "  2.24919653  2.37355542  2.33339882  2.43421268  2.4310689   2.32196856\n",
      "  2.38308048  2.49164915  2.31287575  3.18369555  2.31371403  2.37604046\n",
      "  2.37673378  2.24840403  2.25969887  2.43024182  2.32133245  2.25442576\n",
      "  2.25009608  2.26120806  2.25744176  2.25505853  2.37604642  2.38168073\n",
      "  2.31557965  2.3175652   2.26052928  2.31510091  2.24900007  2.25459599\n",
      "  2.49277544  2.25086665  2.43106985  2.37384701  2.2536993   2.24963355\n",
      "  2.31342053  2.37605953  2.43241668  2.34396935  2.373878    2.49325418\n",
      "  2.32196879  2.33543444  2.43020558  2.43755293  2.49116611  2.31859398\n",
      "  2.31416178  2.37333417  2.25202537  2.37616086  2.37380028  2.24758601\n",
      "  2.24896002  2.31453657  2.38174391  3.1834259   2.24809551  2.49242806\n",
      "  2.25366163  2.37605715  2.25356793  2.37384701  2.37384701  2.3318429\n",
      "  2.31868649  2.32811594  2.25318885  2.25476599  2.31457734]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  62000\n",
      "Cost: [ 2.43425035  2.33964133  2.37618613  2.31338978  2.37617064  2.43921399\n",
      "  2.31897926  2.24983764  2.43413401  2.37265754  2.25388074  2.26232076\n",
      "  2.48798919  2.26388073  2.24764895  2.31339526  2.44313931  2.32440901\n",
      "  2.24907517  2.37348938  2.33310199  2.43413496  2.43107605  2.32190037\n",
      "  2.38295984  2.49147558  2.31278419  3.18350196  2.31352973  2.37616682\n",
      "  2.37682319  2.24843502  2.27996731  2.43022966  2.32127237  2.25435853\n",
      "  2.25039935  2.2615602   2.25758314  2.25520802  2.37617302  2.38126564\n",
      "  2.31550002  2.31780601  2.26096988  2.31502628  2.24888635  2.25556016\n",
      "  2.49259448  2.25079393  2.43107796  2.37386727  2.25304413  2.24960303\n",
      "  2.31338334  2.37597418  2.43247175  2.34355307  2.37390137  2.49374318\n",
      "  2.32190037  2.33324933  2.43019485  2.43753815  2.4910481   2.3184166\n",
      "  2.31414819  2.37321067  2.25162983  2.3763051   2.3738184   2.24762583\n",
      "  2.24888301  2.31447577  2.38132763  3.18376923  2.24812651  2.4926033\n",
      "  2.25301957  2.37618446  2.25314927  2.37386751  2.37386727  2.33010483\n",
      "  2.3185401   2.32815313  2.25301218  2.25588512  2.31451035]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.393258\n",
      " \n",
      "Step:  63000\n",
      "Cost: [ 2.43414903  2.33954954  2.3758812   2.31336832  2.3758657   2.43900681\n",
      "  2.31883025  2.24999952  2.434062    2.37264967  2.25363779  2.26265955\n",
      "  2.48790431  2.26337361  2.24764252  2.31335878  2.44303942  2.32417893\n",
      "  2.24900508  2.37344074  2.33270121  2.43406272  2.43092299  2.32166553\n",
      "  2.38253069  2.49126053  2.31273293  3.18338823  2.31347418  2.37586236\n",
      "  2.37688327  2.24859834  2.2594502   2.43018961  2.32113314  2.25436449\n",
      "  2.2496767   2.26116586  2.25725722  2.25533032  2.37586832  2.38120604\n",
      "  2.3155899   2.31787872  2.26049304  2.31492496  2.24882126  2.25440621\n",
      "  2.49249411  2.25074863  2.43092465  2.37380385  2.25443792  2.2505765\n",
      "  2.31336331  2.37592721  2.43248558  2.34189773  2.37384534  2.49306822\n",
      "  2.32166553  2.33652568  2.43015242  2.43747425  2.49090672  2.31853843\n",
      "  2.3141346   2.37313008  2.25351024  2.37597466  2.37375808  2.24759936\n",
      "  2.24885535  2.31442952  2.38126516  3.18426704  2.24807858  2.49236727\n",
      "  2.25334263  2.37587881  2.25329399  2.37380409  2.37380385  2.33479834\n",
      "  2.31834888  2.32757926  2.25313115  2.25456357  2.31446052]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  64000\n",
      "Cost: [ 2.43406343  2.33849263  2.37615824  2.31332922  2.37614012  2.43884683\n",
      "  2.31890631  2.24959612  2.43398094  2.37265015  2.25367975  2.26040554\n",
      "  2.48782086  2.26292777  2.24769402  2.31332445  2.44288111  2.3239069\n",
      "  2.24891424  2.37342715  2.3322072   2.4339819   2.43104792  2.32155657\n",
      "  2.38265634  2.49081945  2.3127172   3.1833663   2.31345224  2.37613678\n",
      "  2.37677741  2.24844885  2.28247547  2.4301846   2.32070208  2.25419927\n",
      "  2.25025105  2.26134634  2.2572422   2.25495648  2.37614369  2.38072133\n",
      "  2.31530237  2.31772637  2.26057172  2.31486535  2.24873114  2.25495648\n",
      "  2.49232125  2.25072837  2.4310503   2.37390876  2.25293994  2.2496438\n",
      "  2.31332445  2.37583923  2.43243885  2.34214973  2.37395167  2.49345088\n",
      "  2.32155681  2.3318572   2.43014383  2.43744612  2.49072361  2.31809592\n",
      "  2.31416607  2.37313104  2.25145388  2.3762393   2.37385941  2.2476275\n",
      "  2.24880767  2.31438756  2.38078737  3.18350816  2.24806261  2.49215317\n",
      "  2.25297546  2.37615442  2.25308418  2.373909    2.37390876  2.3290329\n",
      "  2.31817889  2.32776499  2.25293064  2.25515771  2.31441545]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.393258\n",
      " \n",
      "Step:  65000\n",
      "Cost: [ 2.43395662  2.33802724  2.37574363  2.31331778  2.37572598  2.43867207\n",
      "  2.318753    2.24944305  2.43390512  2.37265611  2.25344729  2.25962877\n",
      "  2.48773575  2.26239872  2.24763036  2.31330347  2.44278049  2.32377219\n",
      "  2.24887061  2.37343025  2.33175278  2.43390632  2.43082571  2.32123375\n",
      "  2.38217735  2.49058485  2.31270528  3.18333983  2.31344748  2.37572289\n",
      "  2.37667632  2.24841762  2.25880075  2.43013787  2.32064176  2.25423121\n",
      "  2.24995399  2.26040053  2.25685239  2.25482488  2.37572908  2.38082981\n",
      "  2.31533575  2.31759882  2.25971842  2.31481481  2.24868298  2.25416231\n",
      "  2.49219704  2.25070286  2.43082833  2.37377453  2.25300884  2.24961662\n",
      "  2.31331062  2.37581205  2.43240547  2.34006476  2.3738246   2.49243569\n",
      "  2.32123399  2.33222818  2.43010092  2.43732309  2.490556    2.3183701\n",
      "  2.31416512  2.37311482  2.25146008  2.37583065  2.3737309   2.2476213\n",
      "  2.24881005  2.31435418  2.38088226  3.18336725  2.24799728  2.49182749\n",
      "  2.25299191  2.37573838  2.2529695   2.37377453  2.37377453  2.32934809\n",
      "  2.31800938  2.3269012   2.25297976  2.25429511  2.31437874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  66000\n",
      "Cost: [ 2.43387628  2.34055138  2.37567472  2.31329536  2.37565589  2.4385078\n",
      "  2.31872392  2.24948096  2.43382955  2.37265778  2.25335097  2.26304793\n",
      "  2.48765922  2.2619431   2.24762368  2.31327868  2.44266105  2.32355738\n",
      "  2.2488203   2.37341762  2.33138084  2.43383002  2.43074512  2.32104325\n",
      "  2.38231325  2.49030113  2.3126862   3.18333435  2.31348634  2.37565327\n",
      "  2.37660336  2.24840021  2.25884104  2.43010616  2.32040501  2.25417304\n",
      "  2.24893427  2.26004148  2.2566576   2.25469804  2.37565994  2.38069654\n",
      "  2.31520176  2.31751418  2.25946832  2.31475782  2.24863148  2.25411892\n",
      "  2.49209976  2.25067377  2.43074822  2.37371874  2.25887346  2.25564241\n",
      "  2.31328845  2.37576818  2.43237114  2.33928013  2.37376833  2.49224544\n",
      "  2.32104397  2.3426187   2.43007112  2.43721557  2.4904089   2.31832933\n",
      "  2.31417441  2.37309313  2.25839019  2.37575626  2.37367702  2.24758506\n",
      "  2.24878955  2.3143146   2.38074613  3.18360949  2.24809957  2.49117947\n",
      "  2.25798512  2.37566829  2.25845766  2.37371874  2.37371874  2.34365749\n",
      "  2.31786132  2.32648683  2.25344086  2.25426626  2.31433702]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  67000\n",
      "Cost: [ 2.43376565  2.33695984  2.37589788  2.31325102  2.37587667  2.4383626\n",
      "  2.31865883  2.24918365  2.43375397  2.37265873  2.25318336  2.25840425\n",
      "  2.48759937  2.26158762  2.24759412  2.31323552  2.44243741  2.3234148\n",
      "  2.24875188  2.37337518  2.33110237  2.43375468  2.43093395  2.32095814\n",
      "  2.38195968  2.49011993  2.3126595   3.18327236  2.31336832  2.3758738\n",
      "  2.37654352  2.24846125  2.25744081  2.43010306  2.32025671  2.25394702\n",
      "  2.24987578  2.26012135  2.25644302  2.25450277  2.3758812   2.3801868\n",
      "  2.31508899  2.31742883  2.25942659  2.31471252  2.24856997  2.25386763\n",
      "  2.49192309  2.25066066  2.43093824  2.37390327  2.25288963  2.24958897\n",
      "  2.31324434  2.37567782  2.4323287   2.33754635  2.37396026  2.49239254\n",
      "  2.32095814  2.33105612  2.4300673   2.43717575  2.49028873  2.31800985\n",
      "  2.31418896  2.37307477  2.25132942  2.37598705  2.37386036  2.24761605\n",
      "  2.24873948  2.31426859  2.38024139  3.18299961  2.24794173  2.49134874\n",
      "  2.25287151  2.37589025  2.25290036  2.37390351  2.37390327  2.32834768\n",
      "  2.31772947  2.32685947  2.25292706  2.25399017  2.31428981]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  68000\n",
      "Cost: [ 2.43372297  2.33877683  2.37556458  2.31324506  2.37554359  2.43821454\n",
      "  2.31861544  2.2491858   2.43368578  2.37267327  2.25313854  2.26052833\n",
      "  2.48753762  2.26120234  2.24759436  2.31322479  2.44234562  2.32326984\n",
      "  2.24871135  2.37339377  2.33065701  2.43368649  2.43071747  2.32065439\n",
      "  2.3817687   2.48975086  2.31266165  3.1833148   2.31341338  2.37554145\n",
      "  2.37636232  2.24842238  2.25832129  2.43007326  2.32011509  2.25398159\n",
      "  2.24896288  2.25937009  2.25627851  2.25429916  2.37554836  2.38029337\n",
      "  2.3150239   2.31717157  2.25879288  2.31466842  2.24852514  2.25388765\n",
      "  2.49182749  2.25061679  2.43072176  2.37374854  2.2573626   2.25340867\n",
      "  2.31323862  2.37566185  2.4322722   2.33776712  2.37380695  2.49155378\n",
      "  2.32065511  2.34009171  2.43003845  2.43703723  2.49010348  2.31823325\n",
      "  2.31419396  2.37308836  2.25616241  2.37563801  2.37370777  2.24758315\n",
      "  2.24876142  2.31424713  2.38033748  3.18299222  2.24800348  2.49064612\n",
      "  2.25666738  2.37555599  2.25699854  2.37374878  2.37374854  2.33978271\n",
      "  2.31761551  2.32594705  2.25333166  2.25402164  2.31426597]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  69000\n",
      "Cost: [ 2.43366241  2.33605289  2.37550044  2.31322551  2.37547779  2.43806338\n",
      "  2.31854391  2.24902272  2.43361521  2.37266135  2.25304747  2.25746775\n",
      "  2.48747015  2.26098251  2.24758482  2.31320357  2.44221997  2.32304931\n",
      "  2.24867129  2.37333751  2.33036685  2.43361616  2.43064594  2.32052088\n",
      "  2.38145494  2.48981977  2.31261945  3.18318796  2.31329441  2.37547588\n",
      "  2.37641859  2.24849176  2.25827694  2.43004799  2.32005119  2.25391817\n",
      "  2.24986458  2.2592237   2.2560575   2.25427604  2.37548351  2.38014269\n",
      "  2.31507063  2.3172791   2.25862288  2.31461525  2.24849486  2.25381613\n",
      "  2.49162626  2.25057507  2.43065095  2.37369657  2.25299239  2.24955845\n",
      "  2.31321931  2.37562633  2.43226957  2.33712435  2.37375259  2.49162436\n",
      "  2.32052088  2.33042741  2.4300158   2.43692589  2.49003816  2.31819153\n",
      "  2.31417847  2.37305093  2.25135303  2.37557125  2.37365818  2.24761057\n",
      "  2.2487216   2.31420755  2.3801837   3.18254066  2.24789786  2.49100566\n",
      "  2.25296354  2.37549019  2.25304914  2.3736968   2.37369657  2.32791328\n",
      "  2.31749749  2.32562113  2.25283957  2.25392747  2.31422424]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  70000\n",
      "Cost: [ 2.43359923  2.33541775  2.37544847  2.31320095  2.37542439  2.4378643\n",
      "  2.31847191  2.24912643  2.43355465  2.37264872  2.25294065  2.2572279\n",
      "  2.48743081  2.26077437  2.24756885  2.31317854  2.44207096  2.32282925\n",
      "  2.24864292  2.37331605  2.33024907  2.4335556   2.43060493  2.32046008\n",
      "  2.38137484  2.48995519  2.31257534  3.18303919  2.313241    2.37542248\n",
      "  2.37656236  2.24852705  2.25810766  2.43001986  2.31995773  2.25382185\n",
      "  2.249614    2.25927067  2.25593138  2.25450826  2.37543058  2.37993789\n",
      "  2.31507874  2.31750464  2.25872874  2.31456089  2.24847627  2.2537632\n",
      "  2.49156213  2.25054336  2.43060994  2.37368011  2.25263977  2.24983263\n",
      "  2.3132      2.37558627  2.43229485  2.33648419  2.37373567  2.49180007\n",
      "  2.32046008  2.32990766  2.42999077  2.43681908  2.48995686  2.31813574\n",
      "  2.31414008  2.37297058  2.2512629   2.37551498  2.37364364  2.24757147\n",
      "  2.24867177  2.31416392  2.37998033  3.183249    2.24786973  2.49118376\n",
      "  2.2525363   2.37543631  2.25251985  2.37368011  2.37368011  2.32755589\n",
      "  2.31740928  2.32544255  2.25276351  2.25387716  2.31417942]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 23 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  71000\n",
      "Cost: [ 2.43349981  2.33508635  2.37567472  2.31316304  2.37564826  2.43779802\n",
      "  2.31841707  2.24884176  2.43348551  2.37266827  2.25279331  2.25669622\n",
      "  2.48737621  2.26036739  2.24756622  2.31314182  2.44185448  2.32276988\n",
      "  2.24858379  2.37330937  2.32977962  2.43348694  2.43081307  2.32030416\n",
      "  2.3812418   2.48945379  2.31258631  3.18311691  2.3132453   2.37564635\n",
      "  2.37627602  2.24840403  2.25677323  2.43003416  2.31969261  2.25360107\n",
      "  2.24965978  2.25902843  2.25573897  2.25402427  2.37565494  2.37940693\n",
      "  2.31483793  2.31707644  2.25841212  2.31454039  2.24841475  2.25351691\n",
      "  2.4914279   2.25053859  2.43081999  2.37390065  2.25269604  2.2495563\n",
      "  2.31315756  2.37550354  2.43218565  2.33492661  2.37396765  2.49153876\n",
      "  2.32030416  2.32990074  2.43000317  2.43678856  2.48979211  2.31781507\n",
      "  2.31418276  2.37302065  2.2511487   2.37574887  2.37386036  2.24757218\n",
      "  2.24866033  2.31413794  2.37945318  3.18247294  2.24784994  2.49054122\n",
      "  2.25267339  2.37566137  2.25271392  2.37390065  2.37390065  2.32746887\n",
      "  2.31731796  2.32577896  2.25279307  2.25362277  2.31415224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  72000\n",
      "Cost: [ 2.43346834  2.33479357  2.37535071  2.31315827  2.37532473  2.43767118\n",
      "  2.31834507  2.24878502  2.43342185  2.37266135  2.25275707  2.25640893\n",
      "  2.48730516  2.26011324  2.24755383  2.31313372  2.44176269  2.32261491\n",
      "  2.24855876  2.3732996   2.32949209  2.43342328  2.43060899  2.32008576\n",
      "  2.38098073  2.48938727  2.3125701   3.18304706  2.31322074  2.3753233\n",
      "  2.37628269  2.24843407  2.25749779  2.43001151  2.31960297  2.25363827\n",
      "  2.24954939  2.25861979  2.25553489  2.25398874  2.37533188  2.37948751\n",
      "  2.31487918  2.31706095  2.25804925  2.31449175  2.24838996  2.2535162\n",
      "  2.49127293  2.25048828  2.43061638  2.37374759  2.25279355  2.24954152\n",
      "  2.31315303  2.37549543  2.43216538  2.33525729  2.37381196  2.49109173\n",
      "  2.32008576  2.32974362  2.42998195  2.43666315  2.48969173  2.3179965\n",
      "  2.31416059  2.37300253  2.25120997  2.37541246  2.37371111  2.24755549\n",
      "  2.24865651  2.31410837  2.37952805  3.18231273  2.24782634  2.49050927\n",
      "  2.25277042  2.37533689  2.2527554   2.37374783  2.37374759  2.32735944\n",
      "  2.31721497  2.32498646  2.25275087  2.25362039  2.31412101]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  73000\n",
      "Cost: [ 2.43341541  2.33420563  2.37529325  2.31314301  2.37526584  2.43750238\n",
      "  2.31826806  2.24878836  2.43336654  2.37265515  2.2526741   2.25612926\n",
      "  2.48726439  2.25993085  2.24754882  2.31311655  2.44164515  2.32238531\n",
      "  2.24852848  2.37327385  2.3292923   2.43336821  2.43053961  2.31999683\n",
      "  2.38088608  2.48940277  2.3125422   3.18293929  2.31317949  2.37526464\n",
      "  2.37633848  2.24850273  2.25748539  2.42999363  2.31951046  2.25357747\n",
      "  2.24953675  2.25851774  2.25542259  2.2540791   2.37527323  2.37931681\n",
      "  2.31489682  2.31716156  2.25799847  2.31444693  2.2483654   2.25347996\n",
      "  2.49118614  2.25045443  2.43054724  2.37370253  2.25247526  2.24956346\n",
      "  2.31313825  2.37546802  2.43216991  2.33475208  2.3737638   2.49112749\n",
      "  2.3199966   2.32898331  2.42996621  2.43655586  2.48959851  2.31795979\n",
      "  2.31412554  2.3729558   2.25098491  2.37535071  2.37366748  2.2475729\n",
      "  2.24862456  2.31407547  2.37935543  3.18259668  2.24782085  2.49053121\n",
      "  2.252455    2.37527752  2.25248861  2.37370253  2.37370253  2.32672477\n",
      "  2.31715155  2.32473063  2.2526629   2.25358176  2.31408715]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  74000\n",
      "Cost: [ 2.43336201  2.33392239  2.37524605  2.31312537  2.37521744  2.43741202\n",
      "  2.31820846  2.24865746  2.43330622  2.37266159  2.25259066  2.25582695\n",
      "  2.48721027  2.2596457   2.24754405  2.31309819  2.44151187  2.32226992\n",
      "  2.24849844  2.37327003  2.32896066  2.43330765  2.43050766  2.31983256\n",
      "  2.38073444  2.48915958  2.31254005  3.18294954  2.31316161  2.37521648\n",
      "  2.37619734  2.24845171  2.25744057  2.42998171  2.31936979  2.25350428\n",
      "  2.24953198  2.25813675  2.25522518  2.25384092  2.37522554  2.37913752\n",
      "  2.31479502  2.31694794  2.25762129  2.31441307  2.24833512  2.25340796\n",
      "  2.49106193  2.25043201  2.43051624  2.37369275  2.25259709  2.24950981\n",
      "  2.31311989  2.37543392  2.43210554  2.33423543  2.37375498  2.49088836\n",
      "  2.31983256  2.32893515  2.42995548  2.43646121  2.48948693  2.31787992\n",
      "  2.31413627  2.37297201  2.25104141  2.37529945  2.37365746  2.24755573\n",
      "  2.24862289  2.31404877  2.37917495  3.18217754  2.24779773  2.49020433\n",
      "  2.25257277  2.37522888  2.25262046  2.37369275  2.37369275  2.32670665\n",
      "  2.31706381  2.32445431  2.25265527  2.25350571  2.31405926]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  75000\n",
      "Cost: [ 2.43331146  2.33368397  2.37519932  2.31310821  2.37517047  2.43730664\n",
      "  2.31813908  2.24857044  2.43324947  2.37266302  2.25250673  2.25557566\n",
      "  2.48715496  2.25940847  2.24753904  2.31307983  2.44137716  2.32215023\n",
      "  2.24845982  2.37326288  2.32863188  2.43325067  2.43048668  2.31968832\n",
      "  2.38060641  2.4889977   2.31253195  3.18292093  2.31314707  2.37516928\n",
      "  2.37611961  2.24841857  2.25733447  2.42997313  2.31923914  2.2534256\n",
      "  2.24943662  2.25784731  2.2550571   2.25367975  2.37517881  2.37892556\n",
      "  2.31472015  2.31683016  2.25734401  2.31437969  2.24829912  2.25332403\n",
      "  2.49093366  2.2504034   2.43049574  2.37369633  2.25269723  2.24951005\n",
      "  2.31310296  2.37539768  2.43206215  2.33373833  2.37375879  2.49070787\n",
      "  2.31968832  2.32892704  2.42994833  2.43637085  2.48938298  2.31782842\n",
      "  2.3141346   2.37297487  2.25111604  2.37525082  2.37366056  2.2475307\n",
      "  2.24861026  2.31402302  2.3789618   3.1819098   2.24778104  2.48997855\n",
      "  2.25267029  2.37518191  2.25266314  2.37369657  2.37369633  2.32670403\n",
      "  2.31698966  2.32419372  2.25263357  2.25341797  2.31403208]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  76000\n",
      "Cost: [ 2.43326211  2.33307099  2.37515497  2.31308866  2.37512445  2.43714023\n",
      "  2.31805086  2.24867749  2.4331975   2.37264109  2.25243092  2.2553606\n",
      "  2.48712492  2.25942969  2.24751973  2.31305933  2.44123268  2.32198334\n",
      "  2.2484374   2.37321782  2.32853222  2.43319893  2.4304595   2.31964922\n",
      "  2.38060832  2.48925757  2.31249046  3.18272805  2.31305695  2.37512398\n",
      "  2.37633038  2.24892187  2.25707722  2.42995596  2.31935382  2.25335503\n",
      "  2.24950361  2.25798368  2.25495243  2.25391078  2.37513351  2.37864995\n",
      "  2.3148365   2.31714797  2.25752544  2.31433153  2.24829745  2.25325561\n",
      "  2.49080992  2.2503469   2.43046784  2.37370825  2.25236416  2.24960399\n",
      "  2.31308484  2.37536287  2.43210196  2.33325338  2.3737669   2.49094677\n",
      "  2.31964898  2.32771158  2.42993355  2.43627858  2.48937845  2.31783271\n",
      "  2.31408191  2.37291002  2.25094891  2.37520981  2.37367702  2.24760008\n",
      "  2.24855399  2.31398273  2.37867713  3.18221378  2.24779868  2.49037695\n",
      "  2.25233722  2.3751359   2.25238252  2.37370825  2.37370825  2.32571459\n",
      "  2.31691647  2.32401752  2.25242019  2.2533474   2.31399107]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  77000\n",
      "Cost: [ 2.433213    2.33375859  2.37510943  2.31307459  2.37507915  2.43706322\n",
      "  2.31799459  2.248487    2.43314528  2.37265158  2.25235343  2.2560854\n",
      "  2.48707867  2.25930095  2.24760532  2.31304359  2.44110346  2.32189941\n",
      "  2.24840879  2.37320757  2.32815933  2.43314719  2.43044496  2.31949949\n",
      "  2.38058734  2.48898268  2.31248546  3.18276358  2.31306863  2.37507844\n",
      "  2.376158    2.2488687   2.25697374  2.42995119  2.31920218  2.25327468\n",
      "  2.25004792  2.25762129  2.25481248  2.25366354  2.37508845  2.37838101\n",
      "  2.31477404  2.31688595  2.25718999  2.31430984  2.24826288  2.2531724\n",
      "  2.49073982  2.25032997  2.43045402  2.37372971  2.2540009   2.25194883\n",
      "  2.31306934  2.37533021  2.4320333   2.33280325  2.37379217  2.49066877\n",
      "  2.31950021  2.3292098   2.42992949  2.43619847  2.48925614  2.31772947\n",
      "  2.31408954  2.37293077  2.25230861  2.37515926  2.37369609  2.24762249\n",
      "  2.24856043  2.31396604  2.37841487  3.18171215  2.24784636  2.49006462\n",
      "  2.2543242   2.3750906   2.25494981  2.37372971  2.37372971  2.32783318\n",
      "  2.31684923  2.32380033  2.25241661  2.25324988  2.3139739 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  78000\n",
      "Cost: [ 2.43316269  2.33239651  2.37506986  2.31305575  2.37503719  2.43694687\n",
      "  2.31793094  2.24848509  2.43309569  2.37265205  2.25226903  2.25495505\n",
      "  2.48704815  2.25886226  2.24752212  2.31302619  2.44097471  2.32169342\n",
      "  2.24838114  2.37321281  2.32795811  2.4330976   2.43042588  2.31941271\n",
      "  2.38030577  2.48882151  2.31247616  3.18271732  2.31305575  2.37503648\n",
      "  2.37614441  2.24843526  2.25679326  2.4299438   2.31897306  2.25318837\n",
      "  2.24932313  2.25747561  2.25468087  2.2536819   2.37504625  2.37805319\n",
      "  2.31467009  2.3167963   2.25705218  2.31427526  2.24823809  2.25312376\n",
      "  2.4906776   2.25031185  2.43043613  2.37375998  2.25217247  2.24950743\n",
      "  2.3130517   2.37529778  2.43200016  2.3323617   2.37382603  2.49055552\n",
      "  2.31941271  2.32767773  2.42992258  2.43611526  2.48912811  2.31766725\n",
      "  2.31406188  2.37290502  2.25074458  2.37511587  2.3737278   2.24753428\n",
      "  2.24854255  2.31393743  2.37808561  3.18214417  2.24775457  2.48985624\n",
      "  2.25215006  2.37504792  2.25219035  2.37375998  2.37375998  2.32567215\n",
      "  2.31679821  2.32363749  2.25243258  2.25321102  2.3139441 ]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  79000\n",
      "Cost: [ 2.43311715  2.3322413   2.3750236   2.31304026  2.37499094  2.4368763\n",
      "  2.31786013  2.24837899  2.43304229  2.37265635  2.25220156  2.25470972\n",
      "  2.48699379  2.25865793  2.2475152   2.31300974  2.44085312  2.32160568\n",
      "  2.24834919  2.37320399  2.32766151  2.4330442   2.43040967  2.31926227\n",
      "  2.38016725  2.48860598  2.31247807  3.18271065  2.31304502  2.37499022\n",
      "  2.37601638  2.24841952  2.2566433   2.4299407   2.31884289  2.25312209\n",
      "  2.24934506  2.25714922  2.25450802  2.25344229  2.37500048  2.37768173\n",
      "  2.31458139  2.31661916  2.25671959  2.31424236  2.24820423  2.25303435\n",
      "  2.49053764  2.25028491  2.43042111  2.37380147  2.25237703  2.24946475\n",
      "  2.31303549  2.37526536  2.43194342  2.33194017  2.37387013  2.49030018\n",
      "  2.31926227  2.32763243  2.4299202   2.43604112  2.48903656  2.31760502\n",
      "  2.31406617  2.37292576  2.25086832  2.37506771  2.37376833  2.24750876\n",
      "  2.24853539  2.31391072  2.37771511  3.18163204  2.24773359  2.48960948\n",
      "  2.25235295  2.37500167  2.252388    2.37380147  2.37380147  2.32565069\n",
      "  2.31672478  2.32339835  2.25241947  2.25311661  2.31391621]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  80000\n",
      "Cost: [ 2.43307185  2.33188176  2.37498116  2.31302547  2.37494731  2.43677187\n",
      "  2.31779289  2.24836659  2.43299866  2.37265849  2.25213146  2.25457072\n",
      "  2.4869628   2.25846481  2.24751472  2.31299472  2.44072676  2.32144117\n",
      "  2.24832487  2.37319398  2.32739449  2.43300033  2.4303906   2.31916475\n",
      "  2.38004565  2.48845601  2.31246948  3.18267274  2.31302547  2.37494683\n",
      "  2.37597227  2.24840212  2.25644588  2.42993426  2.31875873  2.25305057\n",
      "  2.24924731  2.25696492  2.25441241  2.25340271  2.37495708  2.37717676\n",
      "  2.31454515  2.31653142  2.25655723  2.3142128   2.24817967  2.25297952\n",
      "  2.49047136  2.25025797  2.43040323  2.37386465  2.25223351  2.24948239\n",
      "  2.31302094  2.37523365  2.4319129   2.33152986  2.37393665  2.49014473\n",
      "  2.31916499  2.32756853  2.42991495  2.43596387  2.48893428  2.31756544\n",
      "  2.31404424  2.37291408  2.25077772  2.37502027  2.3738327   2.24750566\n",
      "  2.24852133  2.3138876   2.3772068   3.18170118  2.24772906  2.48942256\n",
      "  2.25220966  2.3749578   2.25223827  2.37386465  2.37386465  2.32557821\n",
      "  2.31667805  2.32322049  2.25239205  2.25305867  2.31389236]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  81000\n",
      "Cost: [ 2.4330337   2.33140993  2.37492943  2.31300974  2.37489653  2.43662548\n",
      "  2.31771374  2.24845004  2.43295097  2.37264705  2.25207782  2.25436044\n",
      "  2.48693609  2.25851607  2.24752235  2.31297731  2.44059706  2.3214221\n",
      "  2.24830317  2.37316036  2.32735181  2.43295336  2.43036938  2.31909871\n",
      "  2.38001752  2.48866367  2.31243682  3.18251586  2.31299686  2.37489605\n",
      "  2.37607718  2.24866915  2.25615215  2.42992449  2.31870914  2.25302219\n",
      "  2.24923968  2.25697732  2.25426865  2.25348949  2.37490654  2.37647104\n",
      "  2.31463718  2.3167634   2.25659752  2.3141675   2.24817181  2.25287294\n",
      "  2.49035764  2.25021458  2.43038177  2.37395978  2.25216627  2.24961352\n",
      "  2.31301689  2.37519932  2.43193173  2.33113766  2.37403345  2.49020052\n",
      "  2.31909871  2.32685375  2.42990565  2.43588471  2.48892665  2.31754184\n",
      "  2.31399512  2.37288427  2.25068831  2.37497616  2.37393475  2.24750471\n",
      "  2.2484796   2.31384587  2.37649584  3.18165946  2.24777389  2.48974466\n",
      "  2.25209069  2.37490726  2.25216889  2.37396002  2.37395978  2.32496738\n",
      "  2.31657267  2.3230238   2.2522099   2.25295591  2.31384897]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  82000\n",
      "Cost: [ 2.43298674  2.33139133  2.37488174  2.31299567  2.37484717  2.43659949\n",
      "  2.31766939  2.24826145  2.43290567  2.37266517  2.25200224  2.25423932\n",
      "  2.48689461  2.25810099  2.2475152   2.31296468  2.4404788   2.32127881\n",
      "  2.24827909  2.37317872  2.32691717  2.43290806  2.43035984  2.31894779\n",
      "  2.37982798  2.48825169  2.31244993  3.1826098   2.31300378  2.3748467\n",
      "  2.37581992  2.24839234  2.25594664  2.42992187  2.31857896  2.25291753\n",
      "  2.24911547  2.2565465   2.25413132  2.2531786   2.3748579   2.37539458\n",
      "  2.31444502  2.31635237  2.2561698   2.31415415  2.24814296  2.2528286\n",
      "  2.49028921  2.25021005  2.43037319  2.37412119  2.25232315  2.24948382\n",
      "  2.31299114  2.37517071  2.43183279  2.33075523  2.37420511  2.48984241\n",
      "  2.31894803  2.32752728  2.42990398  2.4358139   2.48875976  2.31746101\n",
      "  2.31402087  2.3729198   2.25084972  2.37491965  2.37409139  2.24747539\n",
      "  2.248487    2.31383491  2.37542152  3.18135095  2.24770761  2.48910093\n",
      "  2.25228906  2.37485719  2.25228333  2.37412119  2.37412119  2.32556391\n",
      "  2.31653404  2.3228364   2.25235915  2.25290465  2.31383753]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  83000\n",
      "Cost: [ 2.43294644  2.3310492   2.3748157   2.3129797   2.37478018  2.43651223\n",
      "  2.3176043   2.24824071  2.4328661   2.37266326  2.25193286  2.25404096\n",
      "  2.48686242  2.25796294  2.24751306  2.31294847  2.44035816  2.32115889\n",
      "  2.24826097  2.37316561  2.32670593  2.43286848  2.43035412  2.31887197\n",
      "  2.37971926  2.48816681  2.3124404   3.18256688  2.31297874  2.37477994\n",
      "  2.3757987   2.24839211  2.25558615  2.42991447  2.31850958  2.25283766\n",
      "  2.24917126  2.25638723  2.25401425  2.25314331  2.37479115  2.37331533\n",
      "  2.31441474  2.31629109  2.25602436  2.31412172  2.24812841  2.25276899\n",
      "  2.49020553  2.25018764  2.43036795  2.37442756  2.25218916  2.24943256\n",
      "  2.31297541  2.37513971  2.43179417  2.33037615  2.37452602  2.48973775\n",
      "  2.31887197  2.32707834  2.42989755  2.43574095  2.48866701  2.31741023\n",
      "  2.31399441  2.37291098  2.25073719  2.37485123  2.37440538  2.24747539\n",
      "  2.24846339  2.31380606  2.37333941  3.18128872  2.24769807  2.48902774\n",
      "  2.25216413  2.37478995  2.25219631  2.37442756  2.37442756  2.32518482\n",
      "  2.31647682  2.32266736  2.25229454  2.25284338  2.31380749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  84000\n",
      "Cost: [ 2.43290877  2.33079004  2.37470317  2.31296325  2.37466788  2.43642163\n",
      "  2.31755352  2.24819183  2.43283105  2.37266254  2.25186706  2.2538383\n",
      "  2.48683214  2.25778079  2.24751997  2.31293082  2.44023705  2.32110882\n",
      "  2.24824071  2.37315583  2.32648897  2.43283367  2.4303689   2.31880403\n",
      "  2.37961841  2.48815918  2.31242657  3.18250489  2.3129735   2.37466764\n",
      "  2.37577033  2.24839091  2.25509334  2.42990613  2.31845713  2.25275874\n",
      "  2.24914002  2.25622678  2.25386095  2.25311255  2.37467933  2.36803699\n",
      "  2.31438112  2.31628704  2.25589132  2.3140893   2.24811363  2.25268388\n",
      "  2.49012566  2.25017595  2.43038273  2.3751657   2.2521615   2.2494154\n",
      "  2.31295776  2.37511086  2.43175149  2.32998753  2.37529397  2.48964524\n",
      "  2.31880403  2.32681584  2.42988992  2.43567276  2.4885819   2.31735039\n",
      "  2.31396675  2.37290502  2.25071263  2.37474036  2.37516928  2.24746466\n",
      "  2.24842453  2.31377196  2.36806512  3.18118405  2.24769115  2.48897362\n",
      "  2.25213647  2.37467694  2.25216722  2.3751657   2.3751657   2.32493234\n",
      "  2.31638575  2.32251143  2.25226855  2.25275779  2.31377149]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  85000\n",
      "Cost: [ 2.43287182  2.33045101  2.37449169  2.31295228  2.37445569  2.43633556\n",
      "  2.31748009  2.24821138  2.43281746  2.37265086  2.25181556  2.25363827\n",
      "  2.48680878  2.2576642   2.24752045  2.31291938  2.44012117  2.32091093\n",
      "  2.24822521  2.373137    2.3263855   2.43282032  2.43031526  2.31880403\n",
      "  2.37956929  2.48809767  2.31242085  3.18243122  2.31294274  2.37445545\n",
      "  2.37584805  2.24843788  2.25455236  2.4298985   2.31840563  2.25272584\n",
      "  2.24906087  2.25620723  2.25375962  2.25326896  2.37446761  2.35298657\n",
      "  2.3143692   2.31630635  2.25589347  2.31404209  2.24810171  2.25265265\n",
      "  2.49005628  2.25015879  2.43032932  2.37689042  2.25196743  2.24943304\n",
      "  2.3129468   2.37508726  2.43170357  2.32957506  2.37706995  2.48965096\n",
      "  2.31880403  2.32634115  2.42988372  2.43562198  2.48846745  2.31731725\n",
      "  2.31389999  2.37287426  2.25057244  2.37452555  2.37701035  2.24747252\n",
      "  2.24837804  2.31372738  2.35307431  3.18134236  2.24768543  2.48906517\n",
      "  2.25194526  2.37446308  2.25196743  2.37689042  2.37689042  2.32448268\n",
      "  2.31633639  2.32235909  2.25223708  2.2527287   2.31372499]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  86000\n",
      "Cost: [ 2.43293571  2.45682478  2.37442207  2.31301045  2.37438679  2.43626785\n",
      "  2.31783223  2.2506299   2.43281293  2.37264729  2.25201464  2.31336594\n",
      "  2.48677588  2.25968742  2.2522881   2.31297922  2.44003701  2.32080221\n",
      "  2.24824357  2.37323952  2.32620931  2.43281579  2.42998052  2.31888223\n",
      "  2.39207435  2.48787451  2.31249714  3.18239212  2.31306028  2.37438655\n",
      "  2.37583899  2.35475898  2.2547884   2.42991996  2.32277632  2.25333357\n",
      "  2.25003481  2.25615883  2.25433564  2.25340486  2.37439942  2.33814836\n",
      "  2.3161962   2.31633878  2.25633717  2.31401634  2.24807072  2.25265169\n",
      "  2.49008322  2.25015068  2.42998886  2.37721968  2.47726297  2.44696784\n",
      "  2.31302428  2.37506151  2.43166065  2.32929015  2.37733793  2.48956418\n",
      "  2.3188777   2.47816229  2.42990589  2.43556833  2.48828793  2.31736016\n",
      "  2.31391835  2.3728528   2.48013115  2.37444758  2.37734437  2.28629279\n",
      "  2.24837923  2.3137033   2.33827019  3.19257355  2.32917976  2.487782\n",
      "  2.4751718   2.37439251  2.47682548  2.37721968  2.37721968  2.48302746\n",
      "  2.31628656  2.32222748  2.25732946  2.25276685  2.31369877]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  3  9  9  8  0 20  3 20 20\n",
      " 11 11 19  9 15  8  0 15  3 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  3 15 23 11 14  8 20 15 15 11 20 23  3  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 11  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  87000\n",
      "Cost: [ 2.43281794  2.32958293  2.37445664  2.31307435  2.37441778  2.43614769\n",
      "  2.31753302  2.24818659  2.43280053  2.37262821  2.25221634  2.31259251\n",
      "  2.4868114   2.25684738  2.24753594  2.31304073  2.43993902  2.32077503\n",
      "  2.24822021  2.37311482  2.32615757  2.43280554  2.42974806  2.31883001\n",
      "  2.3798418   2.48900914  2.31239963  3.18210793  2.31305814  2.37441778\n",
      "  2.37597322  2.31299019  2.25432515  2.42993689  2.31870317  2.25357819\n",
      "  2.24916863  2.25640202  2.25328398  2.25348473  2.37442732  2.33119702\n",
      "  2.31453037  2.31708074  2.25614429  2.31400204  2.2480948   2.25263882\n",
      "  2.48995209  2.25024486  2.4297626   2.37645745  2.25176334  2.24942255\n",
      "  2.31308842  2.37501216  2.43175483  2.32906222  2.37658453  2.49016619\n",
      "  2.31883025  2.32378912  2.42992067  2.43543482  2.4883709   2.31707168\n",
      "  2.31386042  2.37282181  2.25089908  2.37453151  2.37657571  2.24758124\n",
      "  2.2482667   2.31371522  2.33131361  3.18118095  2.24779487  2.48961186\n",
      "  2.25175524  2.37442327  2.25176454  2.37645745  2.37645745  2.32274055\n",
      "  2.31593609  2.32230282  2.25243616  2.25272751  2.31371069]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 15  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  88000\n",
      "Cost: [ 2.43280029  2.32955194  2.37449265  2.31313324  2.37444925  2.43619013\n",
      "  2.31764102  2.24807262  2.43275952  2.37266922  2.25250554  2.3121388\n",
      "  2.48673844  2.25621676  2.24750185  2.31308651  2.43985224  2.32075119\n",
      "  2.2482214   2.37312818  2.32571983  2.43276429  2.42965269  2.31871223\n",
      "  2.37933064  2.48805094  2.31244087  3.18238902  2.31296277  2.37444901\n",
      "  2.37554097  2.31230736  2.2545867   2.42996073  2.31838441  2.25409579\n",
      "  2.24887872  2.25571322  2.25279927  2.25303125  2.37446427  2.32781172\n",
      "  2.31434774  2.31614423  2.25541997  2.31400204  2.24806786  2.25268269\n",
      "  2.4898541   2.25025892  2.42967439  2.37585449  2.25175643  2.24941516\n",
      "  2.31312752  2.37500095  2.43154764  2.32879829  2.37595415  2.4893055\n",
      "  2.31871223  2.32580709  2.42994547  2.43530941  2.48811245  2.3169198\n",
      "  2.31393814  2.37287855  2.25045252  2.3745358   2.37590194  2.24748993\n",
      "  2.24833179  2.31372738  2.3279078   3.18095732  2.2477293   2.4883039\n",
      "  2.25173855  2.37445426  2.25176048  2.37585449  2.37585449  2.32420063\n",
      "  2.31557918  2.32196689  2.25273776  2.2527585   2.3137219 ]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  89000\n",
      "Cost: [ 2.43278098  2.32937217  2.37450361  2.31315494  2.37445951  2.43615365\n",
      "  2.31761432  2.24805784  2.43272066  2.37265944  2.25256729  2.31192493\n",
      "  2.4866643   2.25601125  2.2474792   2.31310439  2.43973732  2.32064271\n",
      "  2.24820185  2.3731184   2.32553864  2.43272567  2.42960644  2.3186512\n",
      "  2.37925482  2.48786879  2.31246901  3.18231916  2.31291032  2.37445951\n",
      "  2.37558103  2.31221008  2.25462079  2.42995763  2.31820583  2.25425482\n",
      "  2.24888372  2.25557923  2.25258636  2.25297618  2.37447596  2.32571673\n",
      "  2.31423497  2.31608272  2.25527811  2.31396794  2.2480464   2.25269651\n",
      "  2.48974013  2.25023317  2.42963314  2.37544513  2.25178647  2.24940324\n",
      "  2.31314945  2.37498856  2.43150926  2.32856345  2.37552214  2.48912525\n",
      "  2.3186512   2.32582092  2.42994475  2.43518949  2.48799419  2.31690621\n",
      "  2.31389523  2.37287521  2.25045013  2.37453222  2.37546539  2.24748421\n",
      "  2.24832702  2.31370783  2.32578707  3.18076229  2.24774504  2.48817301\n",
      "  2.25176501  2.37446356  2.25179291  2.37544513  2.37544513  2.32419801\n",
      "  2.31548619  2.32174969  2.25270367  2.25276566  2.31370211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  90000\n",
      "Cost: [ 2.43275166  2.3291626   2.37449551  2.31315613  2.37445498  2.43610811\n",
      "  2.31753206  2.24800277  2.43268204  2.37265444  2.25253749  2.31186724\n",
      "  2.48663068  2.25597358  2.24747777  2.31310415  2.43961191  2.32066345\n",
      "  2.24819756  2.37310648  2.32537913  2.43268728  2.42958641  2.31858945\n",
      "  2.37922025  2.48797607  2.31246233  3.18219328  2.3128922   2.37445498\n",
      "  2.37560844  2.31212306  2.25459909  2.42994952  2.31812716  2.25425744\n",
      "  2.24891996  2.25551391  2.25243306  2.25292468  2.37447095  2.32435346\n",
      "  2.31423259  2.31618309  2.2552352   2.31393051  2.24804497  2.25265169\n",
      "  2.48963046  2.25021338  2.42961121  2.3751545   2.25170374  2.24937105\n",
      "  2.31315017  2.37496948  2.43149424  2.32835364  2.37521553  2.48913145\n",
      "  2.31858921  2.32558584  2.42993832  2.435076    2.48792386  2.31680465\n",
      "  2.3138566   2.37286258  2.25037694  2.37453103  2.37515879  2.24748063\n",
      "  2.2483077   2.31367922  2.32440639  3.18066192  2.24774814  2.48813176\n",
      "  2.2516818   2.37445927  2.2517066   2.3751545   2.3751545   2.32397747\n",
      "  2.315449    2.32171798  2.25261617  2.25271797  2.3136735 ]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  91000\n",
      "Cost: [ 2.43272495  2.32886076  2.37448931  2.31314349  2.37444973  2.43605494\n",
      "  2.31748271  2.24802256  2.43264079  2.37264252  2.25246024  2.31185055\n",
      "  2.48658848  2.25584221  2.24746919  2.31308913  2.43948245  2.32053781\n",
      "  2.24820018  2.37309813  2.32523799  2.43264556  2.42957449  2.31853557\n",
      "  2.37919259  2.48792744  2.31246376  3.18210316  2.31285644  2.37444949\n",
      "  2.37569404  2.31194091  2.25457335  2.42993736  2.3180325   2.25417542\n",
      "  2.24885035  2.25549006  2.25232482  2.25297093  2.37446547  2.32337165\n",
      "  2.31416988  2.31619787  2.25521612  2.31389022  2.24804425  2.25264645\n",
      "  2.4895637   2.25019622  2.42960334  2.3749373   2.25156903  2.24937248\n",
      "  2.31313729  2.37495184  2.43147469  2.32813287  2.37499094  2.48911071\n",
      "  2.31853533  2.32524586  2.42992711  2.43496871  2.48786497  2.31680131\n",
      "  2.31380057  2.37284017  2.2502799   2.37451696  2.37493896  2.24748349\n",
      "  2.24829674  2.31364512  2.3234117   3.18078852  2.24775457  2.4881525\n",
      "  2.2515471   2.37445354  2.25157237  2.3749373   2.3749373   2.32365584\n",
      "  2.31543183  2.32162929  2.2525456   2.25271106  2.31363893]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  92000\n",
      "Cost: [ 2.43269563  2.32880712  2.37448478  2.3131175   2.37444615  2.43606114\n",
      "  2.31741238  2.24802089  2.43258214  2.37264585  2.25218773  2.31170988\n",
      "  2.48653269  2.2557056   2.24746346  2.31306577  2.43935084  2.32047319\n",
      "  2.24821663  2.3730998   2.32505012  2.43258619  2.42957354  2.31835723\n",
      "  2.37912107  2.48769593  2.31248069  3.18214726  2.31285334  2.37444615\n",
      "  2.37558985  2.2483561   2.25460172  2.42991376  2.31795073  2.25381589\n",
      "  2.24881458  2.25526834  2.25230789  2.25275326  2.37446237  2.3226583\n",
      "  2.31408525  2.31593943  2.25499606  2.31384015  2.24802971  2.25262928\n",
      "  2.48946619  2.25019121  2.42960358  2.37476444  2.25171304  2.24932933\n",
      "  2.31311274  2.37493467  2.43140244  2.32794833  2.37481451  2.4888835\n",
      "  2.31835723  2.32537293  2.42990327  2.43486834  2.48773527  2.31690645\n",
      "  2.31374717  2.37284923  2.25037813  2.3745079   2.37479305  2.24746776\n",
      "  2.24831247  2.31359935  2.32269621  3.18055487  2.24774337  2.4879899\n",
      "  2.251688    2.37444997  2.25171614  2.37476444  2.37476444  2.32377577\n",
      "  2.3156004   2.32145023  2.25251913  2.25269246  2.31359315]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  93000\n",
      "Cost: [ 2.43265915  2.32859039  2.37447572  2.31309438  2.37443924  2.43600082\n",
      "  2.31733847  2.24801493  2.4325366   2.37264037  2.25191712  2.31170297\n",
      "  2.48651409  2.25561452  2.2474556   2.31304312  2.43922353  2.32040477\n",
      "  2.24819112  2.37308502  2.32488155  2.43254066  2.4295783   2.31828475\n",
      "  2.37904763  2.48773789  2.31247187  3.1821506   2.31282806  2.37443924\n",
      "  2.37561512  2.24838161  2.25457096  2.42989135  2.31787491  2.2534852\n",
      "  2.24877548  2.25520635  2.25226331  2.25277114  2.37445426  2.3220849\n",
      "  2.31409049  2.31597137  2.25494289  2.31379652  2.24802804  2.25261259\n",
      "  2.48940659  2.25015759  2.42960882  2.37461877  2.25160122  2.24932194\n",
      "  2.31309009  2.37490749  2.43139076  2.3277719   2.37466478  2.48885322\n",
      "  2.31828475  2.32507491  2.4298811   2.43476868  2.48774767  2.31683683\n",
      "  2.31371212  2.37283087  2.25029373  2.37449813  2.37464046  2.24746561\n",
      "  2.24829626  2.31356072  2.3221209   3.18068528  2.24773669  2.48795819\n",
      "  2.25157738  2.37444305  2.25160456  2.37461877  2.37461877  2.32348466\n",
      "  2.31571198  2.32138848  2.25246716  2.2526722   2.31355405]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  94000\n",
      "Cost: [ 2.43262792  2.32846498  2.37446451  2.31307006  2.37443066  2.43593073\n",
      "  2.31727624  2.24799585  2.43249846  2.37263966  2.25175714  2.31166077\n",
      "  2.48648238  2.25551152  2.2474525   2.31302023  2.4391048   2.32033014\n",
      "  2.24816418  2.37307858  2.32467747  2.43250299  2.42958546  2.31819201\n",
      "  2.37897587  2.48758864  2.31247663  3.18217421  2.3128221   2.37443066\n",
      "  2.37558031  2.24839282  2.25456357  2.42988634  2.31777573  2.25328064\n",
      "  2.24875402  2.25506973  2.25216246  2.25266147  2.37444496  2.32162023\n",
      "  2.31403923  2.31584764  2.2548027   2.31376624  2.24800968  2.25256443\n",
      "  2.48933053  2.25012398  2.42961907  2.37449956  2.25165844  2.24929333\n",
      "  2.31306601  2.37488484  2.43136549  2.32755756  2.37454343  2.48870635\n",
      "  2.31819201  2.32510114  2.42987657  2.43467951  2.48768806  2.31679797\n",
      "  2.31369591  2.37283444  2.25033498  2.37448597  2.37451243  2.24746037\n",
      "  2.24830031  2.31353521  2.32165051  3.18050456  2.24773741  2.48781896\n",
      "  2.25163388  2.37443423  2.25165939  2.37449956  2.37449956  2.32351232\n",
      "  2.31574655  2.32121015  2.25242209  2.25262141  2.31352878]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  95000\n",
      "Cost: [ 2.43259454  2.32825255  2.37444448  2.31304455  2.37441373  2.43584228\n",
      "  2.31719232  2.24796152  2.43246198  2.37263489  2.2516396   2.31161189\n",
      "  2.48646927  2.25548553  2.24745107  2.31299472  2.43899584  2.32029676\n",
      "  2.24815202  2.37306833  2.32453084  2.43246651  2.42959023  2.31812477\n",
      "  2.37892103  2.48767471  2.31246424  3.18210459  2.31280851  2.37441373\n",
      "  2.37559748  2.24839687  2.25451231  2.429883    2.31771207  2.25312233\n",
      "  2.24878621  2.25502205  2.25205898  2.25261736  2.37442684  2.32122469\n",
      "  2.31403041  2.31591582  2.25476694  2.31373549  2.24800825  2.25248742\n",
      "  2.48927116  2.25009227  2.42962193  2.37439823  2.25158238  2.24926353\n",
      "  2.31304026  2.37486362  2.43136621  2.32734299  2.37443805  2.48871922\n",
      "  2.31812477  2.32481551  2.42987394  2.43460083  2.48766756  2.31671548\n",
      "  2.31367683  2.37282395  2.2502737   2.37447047  2.37440538  2.24745846\n",
      "  2.24828434  2.31350732  2.32125258  3.1804595   2.24773359  2.487813\n",
      "  2.25155807  2.37441707  2.25158477  2.37439823  2.37439823  2.32329369\n",
      "  2.31574941  2.32117486  2.25233507  2.25254345  2.31350112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  96000\n",
      "Cost: [ 2.43256545  2.32808232  2.37442994  2.31301928  2.3743999   2.43576694\n",
      "  2.31714725  2.24795961  2.43242621  2.3726337   2.25154805  2.31159735\n",
      "  2.48644328  2.25538039  2.24744868  2.31297112  2.43889523  2.32017875\n",
      "  2.24813294  2.3730638   2.32434034  2.43243122  2.42959571  2.31804466\n",
      "  2.37884998  2.48752165  2.31246758  3.18209863  2.31280065  2.3743999\n",
      "  2.3755846   2.24839997  2.25450134  2.42988396  2.31763792  2.25299287\n",
      "  2.24877262  2.25490499  2.25195527  2.25255036  2.37441301  2.32088614\n",
      "  2.31399441  2.31579351  2.25465107  2.31371212  2.24799228  2.25243473\n",
      "  2.48921037  2.25006485  2.42963123  2.37431312  2.2515862   2.24926949\n",
      "  2.31301522  2.3748455   2.43134356  2.32711244  2.37435269  2.48858976\n",
      "  2.31804466  2.32480717  2.42987466  2.43453074  2.48760653  2.3167038\n",
      "  2.31366158  2.37282324  2.25028658  2.37445307  2.37431335  2.24745584\n",
      "  2.24828863  2.3134861   2.32091045  3.1803844   2.24773765  2.48771667\n",
      "  2.2515595   2.37440324  2.2516017   2.37431312  2.37431312  2.32331944\n",
      "  2.31573439  2.3210237   2.25226974  2.25248933  2.31348014]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  97000\n",
      "Cost: [ 2.43253493  2.32785845  2.37441039  2.31299329  2.37438178  2.43569279\n",
      "  2.3170836   2.24795389  2.43239069  2.37262988  2.25146508  2.31156015\n",
      "  2.48642635  2.25529671  2.24744463  2.31294584  2.4388001   2.32009244\n",
      "  2.24812317  2.37305546  2.32419348  2.43239546  2.42959929  2.31797242\n",
      "  2.37878394  2.48753643  2.31246138  3.18203664  2.31278443  2.37438178\n",
      "  2.37559724  2.24840021  2.25446248  2.42988253  2.31757736  2.25287175\n",
      "  2.24871516  2.25483608  2.25186014  2.25251508  2.37439394  2.32059097\n",
      "  2.31397581  2.31580377  2.25458694  2.3136847   2.24798965  2.25236964\n",
      "  2.48915553  2.25003648  2.42963529  2.37423754  2.25151253  2.24922371\n",
      "  2.31298971  2.37482905  2.43133593  2.32688832  2.37427545  2.48856449\n",
      "  2.31797242  2.32460523  2.4298737   2.43446922  2.48758078  2.31666374\n",
      "  2.31364489  2.37281513  2.25022507  2.37443328  2.37423396  2.24745274\n",
      "  2.24827814  2.31346083  2.32061505  3.18039656  2.2477355   2.48767996\n",
      "  2.25148845  2.37438512  2.25151491  2.37423754  2.37423754  2.32310343\n",
      "  2.31571388  2.32095838  2.25221443  2.25242376  2.31345487]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  98000\n",
      "Cost: [ 2.43250632  2.3277216   2.37439394  2.31296825  2.37436628  2.43562031\n",
      "  2.31703115  2.24794197  2.43235636  2.37262821  2.25139093  2.31153107\n",
      "  2.48639941  2.25521994  2.24744368  2.31292248  2.43870902  2.31997752\n",
      "  2.24810338  2.37304854  2.32403588  2.43236136  2.42960596  2.31789517\n",
      "  2.37871504  2.48742294  2.31246185  3.18200636  2.31277514  2.37436628\n",
      "  2.37558651  2.24839878  2.25443649  2.42988563  2.31750727  2.25275946\n",
      "  2.24876142  2.25473928  2.25176525  2.25245285  2.3743782   2.32032919\n",
      "  2.31394553  2.31572104  2.25449085  2.31366181  2.24797177  2.25230527\n",
      "  2.48908949  2.25000715  2.42964506  2.37417173  2.2515645   2.24927878\n",
      "  2.31296492  2.37481236  2.43131876  2.32666373  2.3742094   2.48846912\n",
      "  2.31789517  2.32457232  2.42987657  2.43441582  2.48752928  2.31664538\n",
      "  2.31363082  2.37281466  2.25028014  2.37441492  2.37416363  2.24745321\n",
      "  2.24827814  2.31343961  2.32035136  3.18030214  2.24774003  2.48762035\n",
      "  2.25153041  2.37436962  2.25159168  2.37417173  2.37417173  2.3231883\n",
      "  2.31568909  2.32082272  2.25213671  2.25235796  2.31343389]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  99000\n",
      "Cost: [ 2.43247819  2.32746172  2.37437129  2.31294227  2.37434578  2.43556404\n",
      "  2.31693888  2.24789262  2.43232703  2.3726306   2.2513175   2.31152058\n",
      "  2.48640108  2.25526547  2.24744678  2.31289864  2.43862009  2.32004881\n",
      "  2.24809313  2.37304163  2.32398129  2.43233252  2.42961216  2.31782126\n",
      "  2.37867284  2.48760486  2.31243062  3.1819098   2.31277061  2.37434578\n",
      "  2.37556529  2.24839044  2.25436854  2.42988706  2.31750154  2.25264645\n",
      "  2.24870539  2.25470495  2.25166178  2.25240135  2.37435699  2.32010221\n",
      "  2.31396055  2.31582284  2.25449014  2.31363368  2.24797487  2.25218177\n",
      "  2.48902559  2.24996972  2.42964244  2.37411118  2.25139976  2.24917722\n",
      "  2.31293869  2.3747921   2.43131065  2.32645535  2.37414598  2.48853064\n",
      "  2.31782126  2.32426786  2.429878    2.4343605   2.48754716  2.31653595\n",
      "  2.31361985  2.37280512  2.25013709  2.37440276  2.37409782  2.24744081\n",
      "  2.24825549  2.31341124  2.32012463  3.1802876   2.24773407  2.48765326\n",
      "  2.25137591  2.37434959  2.25140166  2.37411118  2.37411118  2.32281303\n",
      "  2.31565905  2.32085514  2.25204992  2.2522347   2.31340528]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  100000\n",
      "Cost: [ 2.43245029  2.32731199  2.37435532  2.31292224  2.37433004  2.43549085\n",
      "  2.31691813  2.24790168  2.43229151  2.37262988  2.25125265  2.31147981\n",
      "  2.48637462  2.25508761  2.24743819  2.31287956  2.43854141  2.3198576\n",
      "  2.24807906  2.37303662  2.32375717  2.43229723  2.42961693  2.31776285\n",
      "  2.37860203  2.48741221  2.31244373  3.18191314  2.31275463  2.37433004\n",
      "  2.37554598  2.2483902   2.25437093  2.42988801  2.31742311  2.25254583\n",
      "  2.24864221  2.25457811  2.25159073  2.25234532  2.37434053  2.31989002\n",
      "  2.31391668  2.31565356  2.25436139  2.31362176  2.24796271  2.25215721\n",
      "  2.48897266  2.24994278  2.42965269  2.37405777  2.25140691  2.2491591\n",
      "  2.31291914  2.37477899  2.43128514  2.32623816  2.37409353  2.48838663\n",
      "  2.31776309  2.32431316  2.42987871  2.43431568  2.48747516  2.31652713\n",
      "  2.31360412  2.37280726  2.25014973  2.37438202  2.37404275  2.24743867\n",
      "  2.24826694  2.31340051  2.31990957  3.18023562  2.24773741  2.48755312\n",
      "  2.2513833   2.37433314  2.25140858  2.37405777  2.37405777  2.32284331\n",
      "  2.31563926  2.32068801  2.25202823  2.25220919  2.31339478]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  101000\n",
      "Cost: [ 2.43242288  2.32714462  2.37433863  2.31290007  2.37431359  2.4354198\n",
      "  2.31687212  2.24789786  2.43225718  2.37262654  2.25119209  2.31143856\n",
      "  2.48634577  2.25497413  2.24743414  2.31285858  2.43846107  2.31970882\n",
      "  2.24806356  2.37302852  2.32361674  2.43226266  2.42962193  2.31769419\n",
      "  2.37853718  2.48732233  2.31244755  3.1818645   2.31273961  2.37431359\n",
      "  2.37554836  2.24838638  2.25433946  2.42988944  2.31735325  2.25244904\n",
      "  2.2486093   2.25449657  2.25151682  2.25230813  2.37432408  2.31969357\n",
      "  2.3138864   2.31560516  2.25427842  2.31360054  2.24794865  2.25210619\n",
      "  2.48891473  2.24991584  2.42966175  2.37400842  2.25139093  2.24914718\n",
      "  2.31289721  2.37476325  2.4312737   2.32602549  2.37404513  2.48830891\n",
      "  2.31769443  2.32421637  2.42987967  2.4342742   2.48742771  2.31652021\n",
      "  2.313586    2.37280488  2.250139    2.37436295  2.37399292  2.24743819\n",
      "  2.24826312  2.3133812   2.31971335  3.18019104  2.24773955  2.48749733\n",
      "  2.25136757  2.37431693  2.2513926   2.37400842  2.37400842  2.32276511\n",
      "  2.31561375  2.32057238  2.25198126  2.25215721  2.31337571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  102000\n",
      "Cost: [ 2.43239498  2.32697725  2.37431955  2.31287885  2.374295    2.43535209\n",
      "  2.31681848  2.24789095  2.43222523  2.37262344  2.25113273  2.31139231\n",
      "  2.48632002  2.25488114  2.24743056  2.31283855  2.4383812   2.31958532\n",
      "  2.24804807  2.37302065  2.32348943  2.43223095  2.42962718  2.31762552\n",
      "  2.378474    2.48725796  2.31244755  3.18180776  2.31272697  2.374295\n",
      "  2.37554932  2.24838161  2.2543025   2.42989087  2.31728983  2.25235462\n",
      "  2.24857068  2.25442266  2.25144649  2.25226974  2.37430525  2.31951427\n",
      "  2.31385899  2.31558013  2.2542038   2.31357932  2.24793482  2.2520473\n",
      "  2.48885727  2.24989033  2.42967033  2.37396312  2.25136852  2.24913478\n",
      "  2.31287599  2.37474847  2.43126488  2.32582378  2.37400031  2.48825097\n",
      "  2.31762552  2.32411718  2.42988086  2.43423414  2.4873867   2.3165009\n",
      "  2.31356931  2.37280178  2.25012302  2.3743422   2.37394714  2.247437\n",
      "  2.24825644  2.31336164  2.31953382  3.18015003  2.24774098  2.48744583\n",
      "  2.25134492  2.37429857  2.25136685  2.37396312  2.37396312  2.3226788\n",
      "  2.31558943  2.32047796  2.25193024  2.25209713  2.3133564 ]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  103000\n",
      "Cost: [ 2.43236661  2.32679725  2.37429452  2.31285167  2.37427163  2.43527937\n",
      "  2.31669903  2.24781942  2.43217897  2.37262297  2.25107121  2.31131482\n",
      "  2.4863224   2.25504041  2.24744129  2.312814    2.43829823  2.31975317\n",
      "  2.24802947  2.37300801  2.32355475  2.43218565  2.42963409  2.3175385\n",
      "  2.3784349   2.48755217  2.31240559  3.18166542  2.31274676  2.37427139\n",
      "  2.3755331   2.2483623   2.25421     2.42989182  2.3173089   2.25225782\n",
      "  2.24866486  2.25444627  2.25131965  2.25220013  2.37428141  2.31938028\n",
      "  2.31388664  2.31579781  2.25426149  2.31353498  2.2479279   2.25188279\n",
      "  2.48878336  2.24984813  2.42966342  2.37391806  2.25130725  2.24908972\n",
      "  2.31284857  2.37472773  2.43127108  2.32564759  2.37395024  2.48837566\n",
      "  2.31753826  2.32379889  2.42988229  2.4341929   2.48746538  2.31643462\n",
      "  2.31356597  2.37278986  2.25006151  2.37432623  2.37390041  2.247437\n",
      "  2.24821663  2.31331873  2.31938529  3.18000126  2.24773526  2.48757982\n",
      "  2.25128198  2.37427473  2.25130844  2.37391806  2.37391806  2.32237148\n",
      "  2.31554008  2.32051468  2.25176764  2.25193071  2.31331348]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  104000\n",
      "Cost: [ 2.43233705  2.3266387   2.37428117  2.31284022  2.37425756  2.4352088\n",
      "  2.31670022  2.24783325  2.43216324  2.37262464  2.25101304  2.31125379\n",
      "  2.48630381  2.25481224  2.24742699  2.31280279  2.43822694  2.31951308\n",
      "  2.24802423  2.37300825  2.32324409  2.43216968  2.42963815  2.31751585\n",
      "  2.37836933  2.48730969  2.31242299  3.18170714  2.31271696  2.37425756\n",
      "  2.37550402  2.24836636  2.2542243   2.42989135  2.31723785  2.25216842\n",
      "  2.24858856  2.25429177  2.2512989   2.25216103  2.3742671   2.31921244\n",
      "  2.31383967  2.31554651  2.25410771  2.31354094  2.247926    2.25189638\n",
      "  2.48875761  2.24983644  2.4296751   2.37387943  2.25126529  2.24907231\n",
      "  2.31283784  2.37471342  2.43123627  2.32545257  2.37391424  2.48821735\n",
      "  2.31751609  2.32390189  2.42988133  2.43414879  2.48736048  2.31637526\n",
      "  2.3135457   2.37279415  2.25004625  2.37431002  2.37386227  2.24742603\n",
      "  2.24824142  2.31332541  2.31922126  3.18002796  2.2477355   2.48743796\n",
      "  2.25124121  2.3742609   2.25126648  2.37387943  2.37387943  2.32246542\n",
      "  2.31553984  2.32038903  2.25178385  2.2519443   2.31331992]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  105000\n",
      "Cost: [ 2.43231058  2.32647562  2.37426567  2.31282282  2.37424183  2.43515444\n",
      "  2.31666446  2.24783683  2.43213797  2.37262154  2.25096011  2.31118345\n",
      "  2.48627687  2.25468206  2.24742079  2.31278658  2.43815374  2.31935215\n",
      "  2.24801302  2.3730011   2.32310963  2.43214393  2.42964172  2.3174572\n",
      "  2.37830949  2.4872117   2.31243062  3.18166995  2.31269598  2.37424183\n",
      "  2.37550616  2.24836183  2.25420022  2.42989135  2.31717134  2.25208378\n",
      "  2.24854827  2.25420523  2.2512486   2.2521379   2.37425137  2.31906056\n",
      "  2.31380582  2.31547928  2.25402117  2.31352663  2.24791694  2.25186276\n",
      "  2.48871183  2.24981117  2.42968345  2.37384367  2.25125575  2.24905396\n",
      "  2.31282067  2.37469912  2.43122244  2.32525873  2.37388086  2.48814154\n",
      "  2.31745696  2.3238039   2.42988038  2.4341011   2.48730135  2.31636143\n",
      "  2.31352639  2.37279272  2.25004077  2.37429237  2.37383151  2.24742651\n",
      "  2.2482419   2.31331205  2.31907082  3.18000054  2.24773526  2.48737955\n",
      "  2.25123167  2.37424517  2.25125694  2.37384367  2.37384367  2.32239485\n",
      "  2.31552148  2.32027555  2.25174975  2.25190997  2.31330705]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  106000\n",
      "Cost: [ 2.43228364  2.32631731  2.37424898  2.31280541  2.3742249   2.43510008\n",
      "  2.31661606  2.24783444  2.43211174  2.37261891  2.25090742  2.31110096\n",
      "  2.48624992  2.25458622  2.24741673  2.31277084  2.43807745  2.3192277\n",
      "  2.24799848  2.37299275  2.32300329  2.43211746  2.42964506  2.31739283\n",
      "  2.37824869  2.48714948  2.31243277  3.18161845  2.3126812   2.3742249\n",
      "  2.37550592  2.24835563  2.25416613  2.42989135  2.31711149  2.25200033\n",
      "  2.24851704  2.25413084  2.25119781  2.25210953  2.3742342   2.3189218\n",
      "  2.31377769  2.31544638  2.25394726  2.31350875  2.24790573  2.25181246\n",
      "  2.48865938  2.24978709  2.4296906   2.37380981  2.25124121  2.24903607\n",
      "  2.31280351  2.3746829   2.43121195  2.32507563  2.37384915  2.4880867\n",
      "  2.31739283  2.32369781  2.42987967  2.43404651  2.48725939  2.31634593\n",
      "  2.31350851  2.37279129  2.25003004  2.37427449  2.37380505  2.24742579\n",
      "  2.24823689  2.31329536  2.31893253  3.17996264  2.24773383  2.4873302\n",
      "  2.25121713  2.37422848  2.25124216  2.37380981  2.37380981  2.32231522\n",
      "  2.31550574  2.32018185  2.25169992  2.25185943  2.31329036]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  107000\n",
      "Cost: [ 2.43225622  2.32615829  2.37423182  2.3127892   2.3742075   2.43504667\n",
      "  2.31656361  2.24783182  2.43208385  2.37261677  2.25085425  2.31100416\n",
      "  2.48622561  2.25450397  2.24741316  2.31275606  2.43799973  2.31912374\n",
      "  2.24798322  2.37298369  2.32290816  2.43208957  2.42964768  2.31732917\n",
      "  2.37818837  2.48710251  2.31243181  3.18156576  2.31266904  2.3742075\n",
      "  2.37550449  2.24834871  2.25413084  2.42989111  2.31705594  2.25191712\n",
      "  2.24848843  2.25406241  2.25115061  2.25207973  2.37421703  2.31879544\n",
      "  2.31375146  2.31542206  2.2538805   2.31349039  2.24789476  2.25175571\n",
      "  2.48860621  2.24976039  2.42969608  2.37377715  2.25122285  2.24901676\n",
      "  2.31278753  2.3746655   2.43120098  2.32489824  2.37381935  2.48804474\n",
      "  2.31732941  2.32359481  2.42987776  2.43397784  2.48722744  2.31632447\n",
      "  2.31349182  2.37278962  2.25001669  2.37425661  2.37378263  2.24742508\n",
      "  2.2482307   2.31327772  2.31880522  3.17992067  2.24773192  2.48728514\n",
      "  2.25119925  2.37421107  2.2512238   2.37377715  2.37377715  2.32223606\n",
      "  2.3154974   2.32009506  2.25164413  2.25180244  2.31327271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  108000\n",
      "Cost: [ 2.43226314  2.32909393  2.37424231  2.31276083  2.37421894  2.43507957\n",
      "  2.31636572  2.24858522  2.4320426   2.37259626  2.25084329  2.31319499\n",
      "  2.48621607  2.25500488  2.247998    2.31273317  2.43791294  2.31976151\n",
      "  2.24798226  2.37302303  2.3230927   2.43204594  2.42965198  2.31711745\n",
      "  2.37843084  2.48762345  2.31259537  3.18129182  2.31266594  2.37421894\n",
      "  2.37572455  2.24889255  2.25400662  2.42989349  2.3167479   2.25193667\n",
      "  2.24730921  2.25398588  2.25115728  2.2522428   2.37422752  2.31870341\n",
      "  2.31374192  2.31600881  2.25380945  2.31342173  2.24786496  2.25143194\n",
      "  2.48844647  2.2495091   2.42967129  2.37375045  2.48248005  2.31306005\n",
      "  2.31280041  2.37464666  2.43124056  2.32462025  2.37377739  2.48798895\n",
      "  2.31711817  2.4816432   2.42987323  2.43408561  2.48753142  2.31671596\n",
      "  2.31396937  2.37276864  2.48340225  2.37424755  2.37378621  2.26064324\n",
      "  2.24813986  2.313205    2.3187108   3.17999768  2.31333184  2.48807001\n",
      "  2.48339772  2.37422347  2.48304319  2.37375045  2.37375045  2.4837234\n",
      "  2.31536341  2.3199966   2.25200248  2.25144553  2.3131988 ]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 11 11 14  8 20 15 15 11 20 11  5  5  0 19  8  8 11 15 15 11 15 14 15\n",
      " 23 11 11 11 15 11 15 15 11  3 21  8  9 14]\n",
      "Accuracy:  0.382022\n",
      " \n",
      "Step:  109000\n",
      "Cost: [ 2.43219233  2.32572722  2.37418723  2.31275272  2.37415695  2.43495131\n",
      "  2.31644201  2.24785376  2.43200612  2.37259197  2.25075078  2.31104374\n",
      "  2.48625112  2.25450253  2.24744415  2.31272388  2.43780947  2.31955624\n",
      "  2.24808669  2.37295246  2.32318187  2.43201208  2.42963409  2.31727982\n",
      "  2.37810063  2.48831558  2.31234932  3.18130231  2.31261873  2.37415671\n",
      "  2.37565804  2.24830008  2.25391698  2.42986536  2.31726575  2.25177598\n",
      "  2.24851108  2.25418973  2.25085068  2.25215578  2.37416792  2.31864834\n",
      "  2.31399298  2.31601143  2.25404572  2.31340671  2.24804354  2.25153232\n",
      "  2.48846459  2.24976134  2.4296546   2.37371254  2.25093389  2.24877954\n",
      "  2.31275153  2.37462425  2.43119979  2.32460046  2.3737576   2.48870063\n",
      "  2.31727982  2.32237053  2.42985034  2.43350363  2.487571    2.31595135\n",
      "  2.3135078   2.37272167  2.24975085  2.37425876  2.37379599  2.24742079\n",
      "  2.24813485  2.31318641  2.31863308  3.18022156  2.24873447  2.48754358\n",
      "  2.25090623  2.37416315  2.25093627  2.37371254  2.37371254  2.32095456\n",
      "  2.31536341  2.32046175  2.25132561  2.25159287  2.31318021]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 15 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  5  0 15  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  110000\n",
      "Cost: [ 2.43214512  2.32569146  2.37418127  2.3127656   2.37414861  2.4348793\n",
      "  2.31644487  2.24787092  2.43200707  2.37261629  2.25066757  2.31053281\n",
      "  2.48621917  2.25429535  2.24740505  2.31273985  2.43771148  2.31928229\n",
      "  2.24804926  2.37294364  2.32270575  2.43201256  2.42962289  2.31725883\n",
      "  2.37800241  2.48753452  2.31237555  3.1815021   2.31260967  2.37414837\n",
      "  2.37544084  2.2483151   2.25405264  2.4298563   2.31705666  2.25166512\n",
      "  2.24846792  2.25384045  2.2509141   2.25193596  2.3741591   2.31856084\n",
      "  2.31381989  2.31529713  2.25370216  2.3134563   2.2480154   2.25155044\n",
      "  2.48845959  2.24968863  2.42965031  2.37368107  2.25118613  2.2487123\n",
      "  2.31276464  2.37460804  2.43110943  2.32439661  2.37373614  2.48819399\n",
      "  2.31725883  2.32308149  2.42983413  2.43342209  2.48733616  2.31591463\n",
      "  2.31348896  2.3727746   2.2499578   2.37424254  2.37379694  2.24740505\n",
      "  2.24821734  2.31322479  2.31853819  3.1798768   2.24866772  2.48731256\n",
      "  2.25115848  2.37415624  2.25118732  2.37368107  2.37368107  2.32165027\n",
      "  2.31547666  2.32002258  2.25138426  2.25160909  2.31321883]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15 15 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n",
      " \n",
      "Step:  111000\n",
      "Cost: [ 2.43210363  2.32547474  2.37416101  2.31276178  2.37412763  2.43482351\n",
      "  2.31638002  2.2478683   2.43197823  2.37259865  2.25061297  2.31009197\n",
      "  2.48620677  2.25424552  2.24739766  2.31274104  2.43760324  2.31916428\n",
      "  2.24806213  2.37293053  2.32279825  2.43198252  2.42959356  2.31721926\n",
      "  2.37797999  2.48785806  2.31237102  3.18132663  2.31259036  2.37412763\n",
      "  2.37557006  2.24829102  2.25394583  2.42982793  2.31699562  2.25158334\n",
      "  2.24855447  2.25392962  2.25086832  2.25198936  2.3741374   2.31843138\n",
      "  2.31379199  2.31555319  2.25379515  2.31344461  2.24804878  2.2514925\n",
      "  2.48843884  2.24964714  2.42961621  2.37365389  2.25115633  2.24862862\n",
      "  2.31276083  2.37459064  2.43113947  2.32419991  2.37370872  2.48837209\n",
      "  2.31721926  2.32259941  2.42980337  2.43339872  2.48730469  2.31588984\n",
      "  2.31345415  2.37275434  2.24991322  2.37423253  2.3737998   2.24738073\n",
      "  2.24818397  2.31320167  2.3184104   3.17981553  2.24859285  2.48745728\n",
      "  2.25112677  2.37413645  2.25115752  2.37365389  2.37365389  2.32128191\n",
      "  2.31544971  2.32000923  2.2512629   2.25155568  2.31319666]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  112000\n",
      "Cost: [ 2.43206215  2.32539988  2.37415171  2.31277347  2.3741169   2.4347887\n",
      "  2.31636286  2.24787116  2.43196464  2.37260985  2.25054121  2.30959892\n",
      "  2.48617601  2.25410533  2.2473855   2.31275749  2.43748999  2.31898642\n",
      "  2.24802971  2.37292242  2.32250094  2.43196869  2.42955828  2.31714582\n",
      "  2.37790203  2.48739576  2.31238747  3.18139672  2.31258011  2.37411666\n",
      "  2.3754456   2.24829316  2.25398612  2.42979169  2.3168962   2.25148702\n",
      "  2.24847841  2.2537117   2.25088215  2.2518661   2.37412643  2.3183248\n",
      "  2.31367803  2.31519032  2.25357628  2.31347299  2.24801755  2.25145531\n",
      "  2.48840427  2.24961901  2.42958736  2.37363529  2.25125027  2.2485888\n",
      "  2.31277251  2.37457895  2.4310925   2.32398915  2.37368989  2.48808169\n",
      "  2.31714582  2.3231194   2.42976356  2.4335804   2.48717141  2.31591725\n",
      "  2.31343842  2.372787    2.25000262  2.37421179  2.37377071  2.24737811\n",
      "  2.24822426  2.31321263  2.31832218  3.17966509  2.2485528   2.48725128\n",
      "  2.25121975  2.37412572  2.25125122  2.37363529  2.37363529  2.32174087\n",
      "  2.31546831  2.31981325  2.25125194  2.25151825  2.31320763]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  113000\n",
      "Cost: [ 2.43203354  2.32510304  2.37412596  2.31276131  2.37409067  2.43473959\n",
      "  2.31627464  2.24786115  2.43191671  2.37257552  2.25050735  2.31013274\n",
      "  2.48617721  2.25419617  2.24740338  2.31275129  2.43736339  2.31906319\n",
      "  2.24806952  2.37291384  2.32286072  2.43192029  2.42951345  2.31708074\n",
      "  2.3779273   2.48839235  2.3123455   3.18107414  2.31256485  2.37409043\n",
      "  2.37574029  2.24827719  2.25377941  2.42974424  2.31714058  2.251436\n",
      "  2.2485404   2.25405192  2.25073338  2.25210571  2.37409925  2.31821346\n",
      "  2.31375027  2.31592846  2.25392103  2.31342125  2.24808311  2.25133252\n",
      "  2.48834634  2.24959254  2.42952752  2.37361336  2.25097132  2.24853325\n",
      "  2.31277323  2.37455702  2.43117619  2.32382441  2.37365866  2.48864293\n",
      "  2.3170805   2.32202768  2.42971659  2.43365145  2.48733616  2.31594133\n",
      "  2.31342101  2.37271285  2.24975944  2.3742094   2.37375283  2.24737883\n",
      "  2.24812579  2.31314802  2.31821322  3.17981339  2.24850512  2.48772335\n",
      "  2.25093842  2.37409949  2.25097251  2.37361336  2.37361336  2.32073903\n",
      "  2.31534314  2.32000613  2.25098729  2.25140619  2.31314278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 15 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 15  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  114000\n",
      "Cost: [ 2.43199515  2.32511401  2.37411785  2.31278086  2.37408137  2.43470049\n",
      "  2.31627417  2.24786043  2.43191457  2.37260556  2.25043178  2.30862617\n",
      "  2.48615646  2.25396132  2.2473762   2.31277251  2.43727493  2.31888175\n",
      "  2.24802995  2.37290859  2.32231069  2.43191814  2.42947793  2.31703401\n",
      "  2.37780261  2.48752022  2.31237388  3.18128228  2.31256247  2.37408113\n",
      "  2.37544203  2.24826765  2.25389886  2.42970181  2.31686568  2.25133801\n",
      "  2.24848914  2.25361943  2.25078511  2.25178909  2.37408972  2.31813502\n",
      "  2.31364965  2.31517243  2.25348783  2.31347203  2.24803877  2.25132561\n",
      "  2.48832607  2.24958658  2.42949963  2.37360096  2.25123549  2.24846792\n",
      "  2.31277943  2.37455726  2.43107295  2.32362652  2.37364578  2.48812199\n",
      "  2.31703401  2.32300782  2.42967391  2.43388748  2.48714924  2.31587243\n",
      "  2.313416    2.37278867  2.24998379  2.37418604  2.37373781  2.24737\n",
      "  2.24820995  2.31318283  2.31814075  3.17954922  2.24844193  2.48726845\n",
      "  2.25120258  2.37409067  2.2512362   2.37360096  2.37360096  2.32160282\n",
      "  2.31537604  2.31975126  2.25109649  2.25139451  2.31317759]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  115000\n",
      "Cost: [ 2.43196726  2.32502079  2.37410593  2.31278515  2.37406874  2.4346602\n",
      "  2.31624818  2.247859    2.43189836  2.37259912  2.25037885  2.30727911\n",
      "  2.48612165  2.25382185  2.24736118  2.31278133  2.43717551  2.31868601\n",
      "  2.24799538  2.3729012   2.32216191  2.43190145  2.42943716  2.31698012\n",
      "  2.37773752  2.48729348  2.31239963  3.18125439  2.31255102  2.37406874\n",
      "  2.37545347  2.24826097  2.2538743   2.42965794  2.31676054  2.2512629\n",
      "  2.24845004  2.25353026  2.25077391  2.25174332  2.37407732  2.31802773\n",
      "  2.31355858  2.31506586  2.2533958   2.31347942  2.24800134  2.25129128\n",
      "  2.48828435  2.24955726  2.42946386  2.37358451  2.25139689  2.2484107\n",
      "  2.31278419  2.37455368  2.43106341  2.32343936  2.37362957  2.48799944\n",
      "  2.31698012  2.3232131   2.42962885  2.43407369  2.48705959  2.31588674\n",
      "  2.31339169  2.37281919  2.25010109  2.37416315  2.37372565  2.24736452\n",
      "  2.24821854  2.31317854  2.31803679  3.17937708  2.24838591  2.48721719\n",
      "  2.25136137  2.3740778   2.25139713  2.37358451  2.37358451  2.32179952\n",
      "  2.31535578  2.31958747  2.25102472  2.25135732  2.31317377]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  116000\n",
      "Cost: [ 2.43198991  2.39733124  2.37411666  2.31274414  2.37406921  2.43462563\n",
      "  2.3161273   2.24812794  2.43182063  2.37251091  2.25036621  2.3133347\n",
      "  2.48610926  2.25409865  2.24798584  2.31275272  2.43706131  2.31895733\n",
      "  2.24802232  2.37300968  2.32320499  2.43182278  2.42939973  2.31686401\n",
      "  2.37878108  2.489923    2.31266308  3.18087673  2.31268787  2.37406898\n",
      "  2.37615156  2.24842453  2.25352144  2.42961979  2.31810999  2.25132251\n",
      "  2.24730015  2.25392842  2.25071883  2.2524581   2.37407827  2.31794262\n",
      "  2.3135581   2.31706429  2.25901985  2.31334925  2.24802399  2.25105906\n",
      "  2.48812437  2.24940562  2.42940593  2.37356997  2.32784295  2.31203842\n",
      "  2.31274748  2.37453341  2.4313035   2.32318902  2.37360334  2.48864031\n",
      "  2.31686115  2.44666767  2.42958879  2.43415856  2.48749208  2.3161242\n",
      "  2.31344604  2.37270975  2.34646225  2.37420464  2.37373209  2.24875021\n",
      "  2.24808145  2.31304502  2.31792951  3.17952204  2.3120656   2.48793364\n",
      "  2.32090497  2.37407851  2.32672286  2.37356997  2.37356997  2.46434617\n",
      "  2.31509256  2.31990814  2.26821542  2.2511642   2.31304193]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 15 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 15  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  117000\n",
      "Cost: [ 2.43190765  2.32482862  2.3740778   2.31278419  2.37403655  2.43457794\n",
      "  2.31601834  2.24785519  2.43185377  2.37257195  2.25023341  2.25340652\n",
      "  2.48612094  2.2540319   2.24734497  2.31278467  2.43696475  2.31872034\n",
      "  2.24798346  2.37287903  2.32212019  2.43185735  2.42935205  2.31692743\n",
      "  2.37757778  2.48775506  2.31236982  3.18109632  2.31251574  2.37403655\n",
      "  2.3756299   2.24822378  2.25372124  2.42955279  2.31682491  2.25106096\n",
      "  2.24854326  2.25353837  2.25073791  2.25186634  2.37404466  2.31789303\n",
      "  2.31364202  2.31522441  2.25341582  2.31344461  2.24801278  2.25112891\n",
      "  2.48818636  2.24947047  2.42936182  2.37355614  2.25112152  2.24832654\n",
      "  2.31278419  2.3745296   2.43105769  2.32312679  2.37358809  2.48824215\n",
      "  2.31692767  2.32323194  2.42953014  2.4343822   2.48720217  2.31575298\n",
      "  2.31337023  2.37279272  2.24991441  2.37414074  2.37368679  2.24735975\n",
      "  2.24817228  2.31311989  2.31789494  3.17951465  2.2483027   2.48730922\n",
      "  2.25107765  2.37404561  2.25112176  2.37355614  2.37355614  2.32152557\n",
      "  2.31540585  2.31972384  2.25065064  2.25119472  2.31311488]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  118000\n",
      "Cost: [ 2.43187714  2.32471418  2.37406301  2.31279135  2.37402391  2.43453503\n",
      "  2.31584358  2.2478416   2.43185568  2.37259221  2.25016117  2.25276351\n",
      "  2.48610258  2.25441694  2.24735713  2.31279397  2.43684626  2.31853151\n",
      "  2.24795389  2.37289     2.32193899  2.43185949  2.42929506  2.31687093\n",
      "  2.3775804   2.48727274  2.31235719  3.18114018  2.31250238  2.37402391\n",
      "  2.37550187  2.24822283  2.25376225  2.42950034  2.31681967  2.25094891\n",
      "  2.24851537  2.25345945  2.25092602  2.25190449  2.37403131  2.31780434\n",
      "  2.31355381  2.31490993  2.25334716  2.31346822  2.2479744   2.25110745\n",
      "  2.48815441  2.24937248  2.42930603  2.37353897  2.2509799   2.24837852\n",
      "  2.31279016  2.37451816  2.43103361  2.3229723   2.37357473  2.48804212\n",
      "  2.31687093  2.32314873  2.42947364  2.43457985  2.48704815  2.31580353\n",
      "  2.31331778  2.3727808   2.24983573  2.37412238  2.37366104  2.24734116\n",
      "  2.24821234  2.3131299   2.31779408  3.17962909  2.24834704  2.48725963\n",
      "  2.25094295  2.37403274  2.25098085  2.37353897  2.37353897  2.32157707\n",
      "  2.31556177  2.31953073  2.25060105  2.2511723   2.31312585]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  119000\n",
      "Cost: [ 2.43186688  2.32455778  2.37404728  2.31279707  2.37401152  2.4344883\n",
      "  2.31583428  2.24784088  2.43183517  2.37260652  2.25014019  2.24924397\n",
      "  2.48608446  2.25430274  2.24738264  2.31279945  2.4367137   2.31838655\n",
      "  2.24793339  2.37292719  2.32193184  2.43184042  2.42922378  2.31678867\n",
      "  2.3775599   2.4871099   2.31233835  3.18109632  2.31251764  2.37401152\n",
      "  2.37540698  2.24825501  2.25374079  2.4294343   2.3167901   2.25092053\n",
      "  2.24841356  2.25339127  2.25090766  2.25188398  2.37401843  2.31770873\n",
      "  2.3135407   2.31487536  2.25329018  2.31347895  2.24795222  2.25107145\n",
      "  2.48812199  2.24935722  2.42923331  2.37352276  2.25096464  2.24841833\n",
      "  2.31279564  2.37450361  2.43104219  2.32280874  2.37356138  2.48792195\n",
      "  2.31678867  2.32292509  2.4294014   2.43479943  2.48697805  2.31586242\n",
      "  2.31330156  2.37277842  2.24986792  2.37410641  2.37361622  2.24734473\n",
      "  2.24820805  2.31311846  2.31770945  3.17966628  2.24836278  2.48722005\n",
      "  2.25092983  2.3740201   2.25096679  2.37352276  2.37352276  2.32140017\n",
      "  2.31550097  2.31942606  2.25064373  2.25114131  2.3131144 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  120000\n",
      "Cost: [ 2.43183684  2.32442331  2.37403512  2.31280732  2.3739984   2.43444324\n",
      "  2.31591439  2.24784541  2.43181658  2.37261796  2.25014234  2.24931312\n",
      "  2.48606491  2.2538631   2.24737978  2.31281233  2.4365778   2.31827354\n",
      "  2.24792027  2.37289572  2.32185411  2.43182158  2.42914152  2.31672406\n",
      "  2.37750888  2.48696852  2.31234145  3.18107295  2.31250596  2.37399817\n",
      "  2.37532544  2.24820495  2.25370932  2.42935181  2.31675005  2.25093126\n",
      "  2.24841642  2.25332046  2.25077033  2.25184345  2.37400484  2.31760979\n",
      "  2.31355047  2.31483531  2.25322366  2.31348634  2.24793863  2.25103593\n",
      "  2.48808813  2.24938846  2.42915201  2.37351155  2.25095582  2.24842811\n",
      "  2.31280637  2.37449527  2.43104768  2.32264233  2.37355304  2.48781109\n",
      "  2.31672406  2.32263255  2.42931509  2.43503881  2.4869051   2.31587124\n",
      "  2.31331396  2.37277365  2.2498033   2.37409234  2.37359953  2.24734282\n",
      "  2.24820328  2.31311107  2.31762218  3.17972589  2.2483871   2.48714089\n",
      "  2.2509253   2.37400675  2.25095725  2.37351155  2.37351155  2.32123327\n",
      "  2.31531286  2.31932425  2.25082326  2.25110722  2.31310654]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  121000\n",
      "Cost: [ 2.43181181  2.3243134   2.3740201   2.31282353  2.37398243  2.43440127\n",
      "  2.3159194   2.24784493  2.4317956   2.37262297  2.25011992  2.24938011\n",
      "  2.48604393  2.25369406  2.24737287  2.31283092  2.43642139  2.31817579\n",
      "  2.2479105   2.37287903  2.32173347  2.43180084  2.429039    2.31667376\n",
      "  2.37746263  2.48684645  2.31234193  3.18104434  2.31249928  2.37398243\n",
      "  2.37528992  2.24819183  2.25367284  2.42924786  2.31670141  2.25090551\n",
      "  2.2483871   2.25325465  2.25068831  2.25180411  2.37398863  2.31751776\n",
      "  2.31354594  2.31481004  2.25315642  2.31349468  2.24792886  2.25100279\n",
      "  2.48805666  2.2493968   2.4290514   2.37350035  2.25094104  2.24844432\n",
      "  2.31282234  2.37448835  2.43105173  2.32249022  2.37354445  2.4877243\n",
      "  2.31667376  2.32244349  2.42920685  2.43532109  2.48685932  2.3158412\n",
      "  2.31331277  2.37276745  2.2497859   2.37407541  2.37359333  2.24734497\n",
      "  2.24819803  2.31310153  2.31753874  3.17975807  2.24840474  2.48706865\n",
      "  2.25091124  2.37399101  2.25094247  2.37350035  2.37350035  2.32108808\n",
      "  2.31519294  2.3192358   2.25088024  2.25107408  2.31309652]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 19 21 14  9  9  0  1\n",
      "  5 15 23 11 14  8 20 15 15 11 20 23  5  3  0 19  8  8 23 15 15 11 15 14 15\n",
      " 23 11 11 23 15 23 15 15 23  3 21  8  9 14]\n",
      "Accuracy:  0.41573\n",
      " \n",
      "Step:  122000\n",
      "Cost: [ 2.43208909  2.47463942  2.37400508  2.31281996  2.3739531   2.43412662\n",
      "  2.31589103  2.2484622   2.43171787  2.37256336  2.2502284   2.31346369\n",
      "  2.48606515  2.25611877  2.24898839  2.31283236  2.43624258  2.31838179\n",
      "  2.24795389  2.37283778  2.32244968  2.43171883  2.42893028  2.42988396\n",
      "  2.3790431   2.488065    2.31253386  3.18046284  2.31258726  2.37395287\n",
      "  2.37588048  2.24815702  2.25348973  2.42919946  2.31760573  2.25115728\n",
      "  2.24833775  2.25357962  2.25075269  2.25190425  2.37395763  2.31755447\n",
      "  2.31350517  2.31620216  2.25339913  2.31341577  2.24786949  2.25075936\n",
      "  2.48802829  2.24944425  2.42893839  2.37346816  2.48231125  2.3135879\n",
      "  2.31283498  2.37445641  2.43124294  2.32231474  2.37354541  2.48810792\n",
      "  2.42991686  2.4813714   2.42912292  2.43571639  2.48699141  2.31584239\n",
      "  2.31552696  2.37269354  2.48263836  2.37402558  2.37356567  2.28188443\n",
      "  2.24811888  2.31302643  2.31750536  3.18253732  2.31383467  2.48711491\n",
      "  2.48213196  2.37407064  2.48234177  2.37346816  2.37346816  2.48346758\n",
      "  2.31495714  2.31925082  2.25157595  2.25102496  2.31303072]\n",
      "tf.argmax(softmax_hy,1): [ 8  0 15 14 15 20  8  9 20  8  3 11  0  6 11 14  5  9  9  8  0 20  5 20 20\n",
      " 11 11 19  9 15  8  0 15  5 20  3  8 21  0 20 15  8 19 15 21 14  9  9  0  1\n",
      "  5 15 11 11 14  8 20 15 15 11 20 11  5  3  0 15  8  8 11 15 15 11 15 14  8\n",
      " 23 11 11 11 15 11 15 15 11  3 21  8  9 14]\n",
      "Accuracy:  0.404494\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f87c734efce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         sess.run(optimizer, feed_dict={Xa: train_data_Xa, \n\u001b[1;32m      7\u001b[0m                                        \u001b[0mXb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_data_Xb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                        Y: train_data_Y})\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in xrange(epochs):\n",
    "        #print (\"train_data_hy[0]:\", sess.run(tf.shape(tf.argmax(Y, 1)), feed_dict={Xa: train_data_Xa, Xb: train_data_Xb, Y: train_data_Y}))\n",
    "        #train network in batch size = bs\n",
    "        sess.run(optimizer, feed_dict={Xa: train_data_Xa, \n",
    "                                       Xb: train_data_Xb, \n",
    "                                       Y: train_data_Y})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (\" \")\n",
    "            print (\"Step: \", step)\n",
    "            print (\"Cost:\", sess.run(cost, feed_dict={Xa: train_data_Xa, Xb: train_data_Xb, Y: train_data_Y}))\n",
    "            print (\"tf.argmax(softmax_hy,1):\", sess.run(tf.argmax(softmax_hy,1), feed_dict={Xa: train_data_Xa, Xb: train_data_Xb, Y: train_data_Y}))\n",
    "            #print (\"softmax_hy:\", sess.run(softmax_hy, feed_dict={Xa: train_data_Xa, Xb: train_data_Xb, Y: train_data_Y}))\n",
    "            #print (\"hy:\", sess.run(hy, feed_dict={Xa: train_data_Xa, Xb: train_data_Xb, Y: train_data_Y}))\n",
    "            correct_prediction = tf.equal(tf.argmax(softmax_hy,1), train_data_labels)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            print (\"Accuracy: \", accuracy.eval({Xa: train_data_Xa, Xb: train_data_Xb, Y: train_data_Y}))\n",
    "            \n",
    "    correct_prediction = tf.equal(tf.argmax(softmax_hy,1), train_data_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        \n",
    "    print (sess.run([wsH3_Y], feed_dict={Xa: train_data_Xa, Xb: train_data_Xb, Y: train_data_Y}))\n",
    "    print (\"Accuracy: \", accuracy.eval({Xa: train_data_Xa, Xb: train_data_Xb, Y: train_data_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
