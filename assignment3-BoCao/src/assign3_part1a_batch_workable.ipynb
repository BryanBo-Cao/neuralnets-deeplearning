{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  2.31800003e+01,   2.72719994e+01,   4.26000000e+02,\n",
      "          7.21250000e+02,   4.79298830e-03],\n",
      "       [  2.31499996e+01,   2.72674999e+01,   4.29500000e+02,\n",
      "          7.14000000e+02,   4.78344085e-03],\n",
      "       [  2.31499996e+01,   2.72450008e+01,   4.26000000e+02,\n",
      "          7.13500000e+02,   4.77946363e-03],\n",
      "       ..., \n",
      "       [  2.11000004e+01,   3.60950012e+01,   4.33000000e+02,\n",
      "          7.98500000e+02,   5.59563888e-03],\n",
      "       [  2.11000004e+01,   3.62599983e+01,   4.33000000e+02,\n",
      "          8.20333313e+02,   5.62144956e-03],\n",
      "       [  2.11000004e+01,   3.62000008e+01,   4.47000000e+02,\n",
      "          8.21000000e+02,   5.61206369e-03]], dtype=float32), array([ 1.,  1.,  1., ...,  1.,  1.,  1.])]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading data\n",
    "all_output_0_train_accuracy = 0.787670391748\n",
    "all_output_0_test_accuracy = 0.789889253486\n",
    "all_output_1_train_accuracy = 0.212329608252\n",
    "all_output_1_test_accuracy = 0.210110746514\n",
    "\n",
    "train_data = np.genfromtxt('train_data.txt', delimiter=',')\n",
    "#print \"train_data:\", train_data\n",
    "\n",
    "t = train_data[:,2]\n",
    "hu = train_data[:,3]\n",
    "lt = train_data[:,4]\n",
    "co2 = train_data[:,5]\n",
    "hu_r = train_data[:,6]\n",
    "\n",
    "o = train_data[:,7]\n",
    "\n",
    "#data\n",
    "data = np.column_stack((t, hu, lt, co2, hu_r))\n",
    "data = np.float32(data)\n",
    "#print (\"data:\", data)\n",
    "\n",
    "#print \"np.shape(train_data): \", np.shape(train_data)\n",
    "#print \"np.shape(t): \", np.shape(t)\n",
    "'''\n",
    "print (\"t: \", t)\n",
    "print (\"hu: \", hu)\n",
    "print (\"lt: \", lt)\n",
    "print (\"co2: \", co2)\n",
    "print (\"hu_r: \", hu_r)\n",
    "print (\"o: \", o)\n",
    "'''\n",
    "x_data = np.array(data)\n",
    "y_data = np.array(o)\n",
    "print ([x_data, y_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_data: [[ 1.          0.47053295  0.2754904   0.190933    0.55731839]\n",
      " [ 0.99282283  0.47033185  0.27775383  0.18644592  0.55480719]\n",
      " [ 0.99282283  0.4693262   0.2754904   0.18613647  0.55376107]\n",
      " ..., \n",
      " [ 0.50239241  0.86490113  0.28001723  0.23874362  0.76843745]\n",
      " [ 0.50239241  0.87227613  0.28001723  0.25225642  0.77522635]\n",
      " [ 0.50239241  0.8695944   0.2890709   0.25266904  0.77275759]]\n",
      "[array([[ 1.        ,  0.47053295,  0.2754904 ,  0.190933  ,  0.55731839],\n",
      "       [ 0.99282283,  0.47033185,  0.27775383,  0.18644592,  0.55480719],\n",
      "       [ 0.99282283,  0.4693262 ,  0.2754904 ,  0.18613647,  0.55376107],\n",
      "       ..., \n",
      "       [ 0.50239241,  0.86490113,  0.28001723,  0.23874362,  0.76843745],\n",
      "       [ 0.50239241,  0.87227613,  0.28001723,  0.25225642,  0.77522635],\n",
      "       [ 0.50239241,  0.8695944 ,  0.2890709 ,  0.25266904,  0.77275759]], dtype=float32), array([ 1.,  1.,  1., ...,  1.,  1.,  1.])]\n"
     ]
    }
   ],
   "source": [
    "def normalize(data):\n",
    "    #normalize train data\n",
    "    #normalize t\n",
    "    t = data[:, 0]\n",
    "    t_min = np.min(t)\n",
    "    t_max = np.max(t)\n",
    "    d_t = t_max - t_min\n",
    "    #normalized t: n_t\n",
    "    n_t = []\n",
    "    for each in t:\n",
    "        n_t.append((each - t_min) / d_t)\n",
    "\n",
    "    #normalize hu\n",
    "    hu = data[:, 1]\n",
    "    hu_min = np.min(hu)\n",
    "    hu_max = np.max(hu)\n",
    "    d_hu = hu_max - hu_min\n",
    "    #normalized h: n_hu\n",
    "    n_hu = []\n",
    "    for each in hu:\n",
    "        n_hu.append((each - hu_min) / d_hu)\n",
    "\n",
    "    #normalize lt\n",
    "    lt = data[:, 2]\n",
    "    lt_min = np.min(lt)\n",
    "    lt_max = np.max(lt)\n",
    "    d_lt = lt_max - lt_min\n",
    "    #normalized lt: n_lt\n",
    "    n_lt = []\n",
    "    for each in lt:\n",
    "        n_lt.append((each - lt_min) / d_lt)\n",
    "\n",
    "    #normalize co2\n",
    "    co2 = data[:, 3]\n",
    "    co2_min = np.min(co2)\n",
    "    co2_max = np.max(co2)\n",
    "    d_co2 = co2_max - co2_min\n",
    "    #normalized co2: n_co2\n",
    "    n_co2 = []\n",
    "    for each in co2:\n",
    "        n_co2.append((each - co2_min) / d_co2)\n",
    "\n",
    "    #normalize hu_r\n",
    "    hu_r = data[:, 4]\n",
    "    hu_r_min = np.min(hu_r)\n",
    "    hu_r_max = np.max(hu_r)\n",
    "    d_hu_r = hu_r_max - hu_r_min\n",
    "    #normalized hu_r: n_hu_r\n",
    "    n_hu_r = []\n",
    "    for each in hu_r:\n",
    "        n_hu_r.append((each - hu_r_min) / d_hu_r)\n",
    "\n",
    "    #normalized data: n_data\n",
    "    n_data = np.column_stack((n_t, n_hu, n_lt, n_co2, n_hu_r))\n",
    "\n",
    "    return n_data\n",
    "\n",
    "n_data = normalize(data)\n",
    "print (\"n_data:\", n_data)\n",
    "x_data = np.array(n_data)\n",
    "y_data = np.array(o)\n",
    "print ([x_data, y_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data_batch:  Tensor(\"batch:0\", shape=(100, 8143, 5), dtype=float32)\n",
      "y_data_batch:  Tensor(\"batch_1:0\", shape=(100, 8143), dtype=float64)\n",
      "x_data_batch[0]:  Tensor(\"strided_slice:0\", shape=(8143, 5), dtype=float32)\n",
      "tf.cast(x_data_batch[0][0][0], 'float'):  Tensor(\"strided_slice_3:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n_input = 5\n",
    "H0 = 5\n",
    "n_output = 1\n",
    "output_num_nodes = 1\n",
    "lr = 0.04\n",
    "epochs = 4000\n",
    "bs = 100\n",
    "data_size = len(x_data)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "ws0 = tf.Variable(tf.random_uniform([n_input, H0], 0.0, 1.0))\n",
    "ws1 = tf.Variable(tf.random_uniform([H0, n_output], 0.0, 1.0))\n",
    "\n",
    "#H0_outputs = tf.sigmoid(tf.matmul(X, ws0))\n",
    "H0_outputs = tf.matmul(X, ws0)\n",
    "#hy = tf.sigmoid(tf.matmul(H0_outputs, ws1))\n",
    "hy = tf.matmul(H0_outputs, ws1)\n",
    "\n",
    "#cost = tf.reduce_mean(tf.square(Y - hy))\n",
    "cost = tf.reduce_mean(tf.square(Y - hy) / 2)\n",
    "#cost = tf.reduce_mean(tf.nn.l2_loss(Y - hy))\n",
    "'''\n",
    "x_data_batch, y_data_batch = tf.train.batch(\n",
    "    [x_data, y_data],\n",
    "    batch_size = bs)\n",
    "'''\n",
    "x_data_batch = tf.train.batch([x_data], batch_size = bs)\n",
    "y_data_batch = tf.train.batch([y_data], batch_size = bs)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "print (\"x_data_batch: \", x_data_batch)\n",
    "print (\"y_data_batch: \", y_data_batch)\n",
    "print (\"x_data_batch[0]: \", x_data_batch[0])\n",
    "print (\"tf.cast(x_data_batch[0][0][0], 'float'): \", tf.cast(x_data_batch[0][0][0], \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8143, 5)\n",
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "#print (x_data)\n",
    "print (x_data.shape)\n",
    "xx_data = x_data[0:100]\n",
    "print (xx_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0fc7ad42b037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "   \n",
    "    for step in xrange(epochs):\n",
    "        \n",
    "        #train network in batch size = bs\n",
    "        bs_i = 0\n",
    "        while bs_i <= data_size:\n",
    "            batch_end = 0\n",
    "            \n",
    "            if bs_i + 100 < data_size:\n",
    "                batch_end = bs_i + 100\n",
    "            else:\n",
    "                batch_end = data_size\n",
    "            xx_data_batch = x_data[bs_i : batch_end]\n",
    "            yy_data_batch = y_data[bs_i : batch_end]\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={X: xx_data_batch, Y: yy_data_batch})\n",
    "            bs_i += 100\n",
    "        \n",
    "        #sess.run(optimizer, feed_dict={X: xx_data_batch, Y: yy_data_batch})\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print (\"   \")\n",
    "            print (\"Step:\", step)\n",
    "            #print (\"ws1: \", ws1.eval())\n",
    "            print (\"Cost:\", sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "            #print (\"tf.floor(hy + 0.5)\", tf.floor(hy + 0.5))\n",
    "            print (\"hy: \", sess.run(hy, feed_dict={X: x_data, Y: y_data}))\n",
    "            print (\"H0_outputs: \", sess.run(H0_outputs, feed_dict={X: x_data, Y: y_data}))\n",
    "            correct_prediction = tf.equal(tf.floor(hy + 0.5), Y)\n",
    "            correct_prediction = tf.equal(tf.floor(tf.sigmoid(hy) + 0.5), Y)\n",
    "            #correct_prediction = tf.equal(hy, Y)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            #print (\"correct_prediction: \", sess.run(correct_prediction, feed_dict={X: x_data, Y: y_data}))\n",
    "            print (\"Accuracy: \", accuracy.eval({X: x_data, Y: y_data}))\n",
    "            \n",
    "    correct_prediction = tf.equal(tf.floor(hy + 0.5), Y)\n",
    "    \n",
    "    print (\"correct_prediction: \", sess.run(correct_prediction, feed_dict={X: x_data, Y: y_data}))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        \n",
    "    print (sess.run([hy], feed_dict={X: x_data, Y: y_data}))\n",
    "    print (\"Accuracy: \", accuracy.eval({X: x_data, Y: y_data}))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
