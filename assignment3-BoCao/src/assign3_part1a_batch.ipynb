{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  2.31800003e+01,   2.72719994e+01,   4.26000000e+02,\n",
      "          7.21250000e+02,   4.79298830e-03],\n",
      "       [  2.31499996e+01,   2.72674999e+01,   4.29500000e+02,\n",
      "          7.14000000e+02,   4.78344085e-03],\n",
      "       [  2.31499996e+01,   2.72450008e+01,   4.26000000e+02,\n",
      "          7.13500000e+02,   4.77946363e-03],\n",
      "       ..., \n",
      "       [  2.11000004e+01,   3.60950012e+01,   4.33000000e+02,\n",
      "          7.98500000e+02,   5.59563888e-03],\n",
      "       [  2.11000004e+01,   3.62599983e+01,   4.33000000e+02,\n",
      "          8.20333313e+02,   5.62144956e-03],\n",
      "       [  2.11000004e+01,   3.62000008e+01,   4.47000000e+02,\n",
      "          8.21000000e+02,   5.61206369e-03]], dtype=float32), array([ 1.,  1.,  1., ...,  1.,  1.,  1.])]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading data\n",
    "all_output_0_train_accuracy = 0.787670391748\n",
    "all_output_0_test_accuracy = 0.789889253486\n",
    "all_output_1_train_accuracy = 0.212329608252\n",
    "all_output_1_test_accuracy = 0.210110746514\n",
    "\n",
    "train_data = np.genfromtxt('train_data.txt', delimiter=',')\n",
    "#print \"train_data:\", train_data\n",
    "\n",
    "t = train_data[:,2]\n",
    "hu = train_data[:,3]\n",
    "lt = train_data[:,4]\n",
    "co2 = train_data[:,5]\n",
    "hu_r = train_data[:,6]\n",
    "\n",
    "o = train_data[:,7]\n",
    "\n",
    "#data\n",
    "data = np.column_stack((t, hu, lt, co2, hu_r))\n",
    "data = np.float32(data)\n",
    "#print (\"data:\", data)\n",
    "\n",
    "#print \"np.shape(train_data): \", np.shape(train_data)\n",
    "#print \"np.shape(t): \", np.shape(t)\n",
    "'''\n",
    "print (\"t: \", t)\n",
    "print (\"hu: \", hu)\n",
    "print (\"lt: \", lt)\n",
    "print (\"co2: \", co2)\n",
    "print (\"hu_r: \", hu_r)\n",
    "print (\"o: \", o)\n",
    "'''\n",
    "x_data = np.array(data)\n",
    "y_data = np.array(o)\n",
    "print ([x_data, y_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data_batch:  Tensor(\"batch:0\", shape=(100, 8143, 5), dtype=float32)\n",
      "y_data_batch:  Tensor(\"batch_1:0\", shape=(100, 8143), dtype=float64)\n",
      "x_data_batch[0]:  Tensor(\"strided_slice:0\", shape=(8143, 5), dtype=float32)\n",
      "tf.cast(x_data_batch[0][0][0], 'float'):  Tensor(\"strided_slice_3:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n_input = 5\n",
    "H0 = 5\n",
    "n_output = 1\n",
    "output_num_nodes = 1\n",
    "lr = 0.05\n",
    "epochs = 400\n",
    "bs = 100\n",
    "data_size = len(x_data)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "ws0 = tf.Variable(tf.random_uniform([n_input, H0], 0.0, 1.0))\n",
    "ws1 = tf.Variable(tf.random_uniform([H0, n_output], 0.0, 1.0))\n",
    "\n",
    "H0_outputs = tf.sigmoid(tf.matmul(X, ws0))\n",
    "hy = tf.sigmoid(tf.matmul(H0_outputs, ws1))\n",
    "\n",
    "#cost = tf.reduce_mean(tf.square(Y - hy))\n",
    "cost = tf.reduce_mean(tf.square(Y - hy) / 2)\n",
    "#cost = tf.reduce_mean(tf.nn.l2_loss(Y - hy))\n",
    "'''\n",
    "x_data_batch, y_data_batch = tf.train.batch(\n",
    "    [x_data, y_data],\n",
    "    batch_size = bs)\n",
    "'''\n",
    "x_data_batch = tf.train.batch([x_data], batch_size = bs)\n",
    "y_data_batch = tf.train.batch([y_data], batch_size = bs)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "print (\"x_data_batch: \", x_data_batch)\n",
    "print (\"y_data_batch: \", y_data_batch)\n",
    "print (\"x_data_batch[0]: \", x_data_batch[0])\n",
    "print (\"tf.cast(x_data_batch[0][0][0], 'float'): \", tf.cast(x_data_batch[0][0][0], \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8143, 5)\n",
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "#print (x_data)\n",
    "print (x_data.shape)\n",
    "xx_data = x_data[0:100]\n",
    "print (xx_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "   \n",
    "    for step in xrange(epochs):\n",
    "        \n",
    "        #train network in batch size = bs\n",
    "        bs_i = 0\n",
    "        while bs_i <= data_size:\n",
    "            batch_end = 0\n",
    "            if bs_i + 100 < data_size:\n",
    "                batch_end = bs_i + 100\n",
    "            else:\n",
    "                batch_end = data_size\n",
    "            xx_data_batch = x_data[bs_i : batch_end]\n",
    "            yy_data_batch = y_data[bs_i : batch_end]\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={X: xx_data_batch, Y: yy_data_batch})\n",
    "            bs_i += 100\n",
    "        \n",
    "        if step % 5 == 0:\n",
    "            print (\"   \")\n",
    "            print (\"Step:\", step)\n",
    "            print (\"ws0: \", ws0)\n",
    "            print (\"Cost:\", sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "            correct_prediction = tf.equal(tf.floor(hy + 0.5), Y)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            print (\"Accuracy: \", accuracy.eval({X: x_data, Y: y_data}))\n",
    "            \n",
    "    correct_prediction = tf.equal(tf.floor(hy + 0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        \n",
    "    print (sess.run([hy], feed_dict={X: x_data, Y: y_data}))\n",
    "    print (\"Accuracy: \", accuracy.eval({X: x_data, Y: y_data}))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
