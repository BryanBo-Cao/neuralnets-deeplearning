{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  2.31800003e+01,   2.72719994e+01,   4.26000000e+02,\n",
      "          7.21250000e+02,   4.79298830e-03],\n",
      "       [  2.31499996e+01,   2.72674999e+01,   4.29500000e+02,\n",
      "          7.14000000e+02,   4.78344085e-03],\n",
      "       [  2.31499996e+01,   2.72450008e+01,   4.26000000e+02,\n",
      "          7.13500000e+02,   4.77946363e-03],\n",
      "       ..., \n",
      "       [  2.11000004e+01,   3.60950012e+01,   4.33000000e+02,\n",
      "          7.98500000e+02,   5.59563888e-03],\n",
      "       [  2.11000004e+01,   3.62599983e+01,   4.33000000e+02,\n",
      "          8.20333313e+02,   5.62144956e-03],\n",
      "       [  2.11000004e+01,   3.62000008e+01,   4.47000000e+02,\n",
      "          8.21000000e+02,   5.61206369e-03]], dtype=float32), array([ 1.,  1.,  1., ...,  1.,  1.,  1.])]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading data\n",
    "all_output_0_train_accuracy = 0.787670391748\n",
    "all_output_0_test_accuracy = 0.789889253486\n",
    "all_output_1_train_accuracy = 0.212329608252\n",
    "all_output_1_test_accuracy = 0.210110746514\n",
    "\n",
    "train_data = np.genfromtxt('train_data.txt', delimiter=',')\n",
    "#print \"train_data:\", train_data\n",
    "\n",
    "t = train_data[:,2]\n",
    "hu = train_data[:,3]\n",
    "lt = train_data[:,4]\n",
    "co2 = train_data[:,5]\n",
    "hu_r = train_data[:,6]\n",
    "\n",
    "o = train_data[:,7]\n",
    "\n",
    "#data\n",
    "data = np.column_stack((t, hu, lt, co2, hu_r))\n",
    "data = np.float32(data)\n",
    "#print (\"data:\", data)\n",
    "\n",
    "#print \"np.shape(train_data): \", np.shape(train_data)\n",
    "#print \"np.shape(t): \", np.shape(t)\n",
    "'''\n",
    "print (\"t: \", t)\n",
    "print (\"hu: \", hu)\n",
    "print (\"lt: \", lt)\n",
    "print (\"co2: \", co2)\n",
    "print (\"hu_r: \", hu_r)\n",
    "print (\"o: \", o)\n",
    "'''\n",
    "x_data = np.array(data)\n",
    "y_data = np.array(o)\n",
    "print ([x_data, y_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data_batch:  Tensor(\"batch:0\", shape=(100, 8143, 5), dtype=float32)\n",
      "y_data_batch:  Tensor(\"batch_1:0\", shape=(100, 8143), dtype=float64)\n",
      "x_data_batch[0]:  Tensor(\"strided_slice:0\", shape=(8143, 5), dtype=float32)\n",
      "tf.cast(x_data_batch[0][0][0], 'float'):  Tensor(\"strided_slice_3:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n_input = 5\n",
    "H0 = 5\n",
    "n_output = 1\n",
    "output_num_nodes = 1\n",
    "lr = 0.003\n",
    "epochs = 4000\n",
    "bs = 100\n",
    "data_size = len(x_data)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "ws0 = tf.Variable(tf.random_uniform([n_input, H0], 0.0, 1.0))\n",
    "ws1 = tf.Variable(tf.random_uniform([H0, n_output], 0.0, 1.0))\n",
    "\n",
    "H0_outputs = tf.sigmoid(tf.matmul(X, ws0))\n",
    "hy = tf.sigmoid(tf.matmul(H0_outputs, ws1))\n",
    "\n",
    "#cost = tf.reduce_mean(tf.square(Y - hy))\n",
    "cost = tf.reduce_mean(tf.square(Y - hy) / 2)\n",
    "#cost = tf.reduce_mean(tf.nn.l2_loss(Y - hy))\n",
    "'''\n",
    "x_data_batch, y_data_batch = tf.train.batch(\n",
    "    [x_data, y_data],\n",
    "    batch_size = bs)\n",
    "'''\n",
    "x_data_batch = tf.train.batch([x_data], batch_size = bs)\n",
    "y_data_batch = tf.train.batch([y_data], batch_size = bs)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "print (\"x_data_batch: \", x_data_batch)\n",
    "print (\"y_data_batch: \", y_data_batch)\n",
    "print (\"x_data_batch[0]: \", x_data_batch[0])\n",
    "print (\"tf.cast(x_data_batch[0][0][0], 'float'): \", tf.cast(x_data_batch[0][0][0], \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8143, 5)\n",
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "#print (x_data)\n",
    "print (x_data.shape)\n",
    "xx_data = x_data[0:100]\n",
    "print (xx_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Step: 0\n",
      "ws1:  [[ 0.14182192]\n",
      " [-0.00634497]\n",
      " [ 0.81155229]\n",
      " [ 0.24834581]\n",
      " [ 0.29156289]]\n",
      "Cost: 0.23294\n",
      "Accuracy:  0.21233\n",
      "   \n",
      "Step: 10\n",
      "ws1:  [[-0.09641992]\n",
      " [-0.24458684]\n",
      " [ 0.57331061]\n",
      " [ 0.01010428]\n",
      " [ 0.05332094]]\n",
      "Cost: 0.142819\n",
      "Accuracy:  0.21233\n",
      "   \n",
      "Step: 20\n",
      "ws1:  [[-0.24814412]\n",
      " [-0.39631134]\n",
      " [ 0.42158639]\n",
      " [-0.14162016]\n",
      " [-0.09840346]]\n",
      "Cost: 0.11023\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 30\n",
      "ws1:  [[-0.31736374]\n",
      " [-0.46553105]\n",
      " [ 0.35236669]\n",
      " [-0.21083967]\n",
      " [-0.167623  ]]\n",
      "Cost: 0.0821155\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 40\n",
      "ws1:  [[-0.35301268]\n",
      " [-0.50117999]\n",
      " [ 0.31671774]\n",
      " [-0.24648872]\n",
      " [-0.20327204]]\n",
      "Cost: 0.0790616\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 50\n",
      "ws1:  [[-0.37358248]\n",
      " [-0.52174997]\n",
      " [ 0.29614794]\n",
      " [-0.26705852]\n",
      " [-0.22384195]]\n",
      "Cost: 0.0800164\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 60\n",
      "ws1:  [[-0.38630182]\n",
      " [-0.53447002]\n",
      " [ 0.28342861]\n",
      " [-0.27977785]\n",
      " [-0.23656158]]\n",
      "Cost: 0.0711516\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 70\n",
      "ws1:  [[-0.3945075 ]\n",
      " [-0.5426755 ]\n",
      " [ 0.27522293]\n",
      " [-0.28798354]\n",
      " [-0.24476717]]\n",
      "Cost: 0.0712163\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 80\n",
      "ws1:  [[-0.39994481]\n",
      " [-0.54811317]\n",
      " [ 0.26978561]\n",
      " [-0.29342085]\n",
      " [-0.25020468]]\n",
      "Cost: 0.0719489\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 90\n",
      "ws1:  [[-0.40361196]\n",
      " [-0.55177951]\n",
      " [ 0.26611847]\n",
      " [-0.297088  ]\n",
      " [-0.25387177]]\n",
      "Cost: 0.0719177\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 100\n",
      "ws1:  [[-0.40611416]\n",
      " [-0.55428088]\n",
      " [ 0.26361626]\n",
      " [-0.29959023]\n",
      " [-0.256374  ]]\n",
      "Cost: 0.0719702\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 110\n",
      "ws1:  [[-0.40783548]\n",
      " [-0.55600047]\n",
      " [ 0.26189494]\n",
      " [-0.30131155]\n",
      " [-0.25809532]]\n",
      "Cost: 0.0719723\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 120\n",
      "ws1:  [[-0.40902504]\n",
      " [-0.5571897 ]\n",
      " [ 0.26070538]\n",
      " [-0.30250111]\n",
      " [-0.25928488]]\n",
      "Cost: 0.0719764\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 130\n",
      "ws1:  [[-0.40985051]\n",
      " [-0.55801463]\n",
      " [ 0.25987992]\n",
      " [-0.30332658]\n",
      " [-0.26011035]]\n",
      "Cost: 0.0721509\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 140\n",
      "ws1:  [[-0.41042501]\n",
      " [-0.55858856]\n",
      " [ 0.25930542]\n",
      " [-0.30390108]\n",
      " [-0.26068485]]\n",
      "Cost: 0.0721487\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 150\n",
      "ws1:  [[-0.41082522]\n",
      " [-0.55898923]\n",
      " [ 0.2589052 ]\n",
      " [-0.30430129]\n",
      " [-0.26108506]]\n",
      "Cost: 0.0721488\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 160\n",
      "ws1:  [[-0.41110456]\n",
      " [-0.55926895]\n",
      " [ 0.25862586]\n",
      " [-0.30458063]\n",
      " [-0.2613644 ]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 170\n",
      "ws1:  [[-0.41129982]\n",
      " [-0.55946422]\n",
      " [ 0.2584306 ]\n",
      " [-0.30477589]\n",
      " [-0.26155967]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 180\n",
      "ws1:  [[-0.41143632]\n",
      " [-0.55960095]\n",
      " [ 0.25829411]\n",
      " [-0.30491239]\n",
      " [-0.26169616]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 190\n",
      "ws1:  [[-0.41153172]\n",
      " [-0.5596959 ]\n",
      " [ 0.25819871]\n",
      " [-0.30500779]\n",
      " [-0.26179156]]\n",
      "Cost: 0.0721519\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 200\n",
      "ws1:  [[-0.41159847]\n",
      " [-0.55976278]\n",
      " [ 0.25813195]\n",
      " [-0.30507454]\n",
      " [-0.26185831]]\n",
      "Cost: 0.0721519\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 210\n",
      "ws1:  [[-0.41164511]\n",
      " [-0.5598101 ]\n",
      " [ 0.25808531]\n",
      " [-0.30512118]\n",
      " [-0.26190495]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 220\n",
      "ws1:  [[-0.41167784]\n",
      " [-0.55984139]\n",
      " [ 0.25805259]\n",
      " [-0.30515391]\n",
      " [-0.26193768]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 230\n",
      "ws1:  [[-0.41170079]\n",
      " [-0.55986482]\n",
      " [ 0.25802964]\n",
      " [-0.30517685]\n",
      " [-0.26196063]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 240\n",
      "ws1:  [[-0.41171652]\n",
      " [-0.55988103]\n",
      " [ 0.2580139 ]\n",
      " [-0.30519259]\n",
      " [-0.26197636]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 250\n",
      "ws1:  [[-0.41172785]\n",
      " [-0.55989271]\n",
      " [ 0.25800258]\n",
      " [-0.30520391]\n",
      " [-0.26198769]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 260\n",
      "ws1:  [[-0.41173553]\n",
      " [-0.55989975]\n",
      " [ 0.25799489]\n",
      " [-0.3052116 ]\n",
      " [-0.26199538]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 270\n",
      "ws1:  [[-0.41174093]\n",
      " [-0.55990493]\n",
      " [ 0.2579895 ]\n",
      " [-0.305217  ]\n",
      " [-0.26200077]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 280\n",
      "ws1:  [[-0.41174501]\n",
      " [-0.55990839]\n",
      " [ 0.25798541]\n",
      " [-0.30522108]\n",
      " [-0.26200485]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 290\n",
      "ws1:  [[-0.41174772]\n",
      " [-0.55991054]\n",
      " [ 0.2579827 ]\n",
      " [-0.30522379]\n",
      " [-0.26200756]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 300\n",
      "ws1:  [[-0.41175002]\n",
      " [-0.55991149]\n",
      " [ 0.25798041]\n",
      " [-0.30522609]\n",
      " [-0.26200986]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 310\n",
      "ws1:  [[-0.41175196]\n",
      " [-0.55991113]\n",
      " [ 0.25797847]\n",
      " [-0.30522802]\n",
      " [-0.2620118 ]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 320\n",
      "ws1:  [[-0.41175243]\n",
      " [-0.55991054]\n",
      " [ 0.25797799]\n",
      " [-0.3052285 ]\n",
      " [-0.26201227]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 330\n",
      "ws1:  [[-0.41175273]\n",
      " [-0.55990994]\n",
      " [ 0.25797769]\n",
      " [-0.3052288 ]\n",
      " [-0.26201257]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 340\n",
      "ws1:  [[-0.41175309]\n",
      " [-0.55990934]\n",
      " [ 0.25797734]\n",
      " [-0.30522916]\n",
      " [-0.26201293]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 350\n",
      "ws1:  [[-0.41175339]\n",
      " [-0.55990875]\n",
      " [ 0.25797704]\n",
      " [-0.30522946]\n",
      " [-0.26201323]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 360\n",
      "ws1:  [[-0.41175377]\n",
      " [-0.55990815]\n",
      " [ 0.25797665]\n",
      " [-0.30522984]\n",
      " [-0.26201361]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 370\n",
      "ws1:  [[-0.41175437]\n",
      " [-0.55990756]\n",
      " [ 0.25797606]\n",
      " [-0.30523044]\n",
      " [-0.26201421]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 380\n",
      "ws1:  [[-0.41175497]\n",
      " [-0.55990696]\n",
      " [ 0.25797546]\n",
      " [-0.30523103]\n",
      " [-0.26201481]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 390\n",
      "ws1:  [[-0.41175565]\n",
      " [-0.55990636]\n",
      " [ 0.25797477]\n",
      " [-0.30523172]\n",
      " [-0.26201549]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 400\n",
      "ws1:  [[-0.41175595]\n",
      " [-0.55990577]\n",
      " [ 0.25797448]\n",
      " [-0.30523202]\n",
      " [-0.26201579]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 410\n",
      "ws1:  [[-0.41175625]\n",
      " [-0.55990517]\n",
      " [ 0.25797418]\n",
      " [-0.30523232]\n",
      " [-0.26201609]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 420\n",
      "ws1:  [[-0.41175655]\n",
      " [-0.55990458]\n",
      " [ 0.25797388]\n",
      " [-0.30523261]\n",
      " [-0.26201639]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 430\n",
      "ws1:  [[-0.41175684]\n",
      " [-0.55990398]\n",
      " [ 0.25797358]\n",
      " [-0.30523291]\n",
      " [-0.26201668]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 440\n",
      "ws1:  [[-0.41175714]\n",
      " [-0.55990338]\n",
      " [ 0.25797328]\n",
      " [-0.30523321]\n",
      " [-0.26201698]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 450\n",
      "ws1:  [[-0.41175744]\n",
      " [-0.55990279]\n",
      " [ 0.25797299]\n",
      " [-0.30523351]\n",
      " [-0.26201728]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 460\n",
      "ws1:  [[-0.41175774]\n",
      " [-0.55990219]\n",
      " [ 0.25797269]\n",
      " [-0.30523381]\n",
      " [-0.26201758]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 470\n",
      "ws1:  [[-0.41175804]\n",
      " [-0.5599016 ]\n",
      " [ 0.25797239]\n",
      " [-0.3052341 ]\n",
      " [-0.26201788]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 480\n",
      "ws1:  [[-0.41175818]\n",
      " [-0.559901  ]\n",
      " [ 0.25797224]\n",
      " [-0.30523425]\n",
      " [-0.26201802]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 490\n",
      "ws1:  [[-0.41175833]\n",
      " [-0.5599004 ]\n",
      " [ 0.25797209]\n",
      " [-0.3052344 ]\n",
      " [-0.26201817]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 500\n",
      "ws1:  [[-0.41175845]\n",
      " [-0.55989981]\n",
      " [ 0.25797197]\n",
      " [-0.30523452]\n",
      " [-0.26201829]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 510\n",
      "ws1:  [[-0.41175866]\n",
      " [-0.55989921]\n",
      " [ 0.25797176]\n",
      " [-0.30523473]\n",
      " [-0.2620185 ]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 520\n",
      "ws1:  [[-0.41175878]\n",
      " [-0.55989861]\n",
      " [ 0.25797164]\n",
      " [-0.30523485]\n",
      " [-0.26201862]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 530\n",
      "ws1:  [[-0.4117589 ]\n",
      " [-0.55989802]\n",
      " [ 0.25797153]\n",
      " [-0.30523497]\n",
      " [-0.26201874]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 540\n",
      "ws1:  [[-0.41175908]\n",
      " [-0.55989742]\n",
      " [ 0.25797135]\n",
      " [-0.30523515]\n",
      " [-0.26201892]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 550\n",
      "ws1:  [[-0.41175923]\n",
      " [-0.55989683]\n",
      " [ 0.2579712 ]\n",
      " [-0.3052353 ]\n",
      " [-0.26201907]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 560\n",
      "ws1:  [[-0.41175938]\n",
      " [-0.55989623]\n",
      " [ 0.25797105]\n",
      " [-0.30523545]\n",
      " [-0.26201922]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 570\n",
      "ws1:  [[-0.41175953]\n",
      " [-0.55989563]\n",
      " [ 0.2579709 ]\n",
      " [-0.30523559]\n",
      " [-0.26201937]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 580\n",
      "ws1:  [[-0.41175964]\n",
      " [-0.55989504]\n",
      " [ 0.25797078]\n",
      " [-0.30523571]\n",
      " [-0.26201949]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 590\n",
      "ws1:  [[-0.41175985]\n",
      " [-0.55989444]\n",
      " [ 0.25797057]\n",
      " [-0.30523592]\n",
      " [-0.26201969]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 600\n",
      "ws1:  [[-0.41175997]\n",
      " [-0.55989385]\n",
      " [ 0.25797045]\n",
      " [-0.30523604]\n",
      " [-0.26201981]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 610\n",
      "ws1:  [[-0.41176009]\n",
      " [-0.55989325]\n",
      " [ 0.25797033]\n",
      " [-0.30523616]\n",
      " [-0.26201993]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 620\n",
      "ws1:  [[-0.41176027]\n",
      " [-0.55989265]\n",
      " [ 0.25797015]\n",
      " [-0.30523634]\n",
      " [-0.26202011]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 630\n",
      "ws1:  [[-0.41176042]\n",
      " [-0.55989206]\n",
      " [ 0.25797001]\n",
      " [-0.30523649]\n",
      " [-0.26202026]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 640\n",
      "ws1:  [[-0.41176057]\n",
      " [-0.55989146]\n",
      " [ 0.25796986]\n",
      " [-0.30523664]\n",
      " [-0.26202041]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 650\n",
      "ws1:  [[-0.41176072]\n",
      " [-0.55989087]\n",
      " [ 0.25796971]\n",
      " [-0.30523679]\n",
      " [-0.26202056]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 660\n",
      "ws1:  [[-0.41176084]\n",
      " [-0.55989027]\n",
      " [ 0.25796959]\n",
      " [-0.30523691]\n",
      " [-0.26202068]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 670\n",
      "ws1:  [[-0.41176105]\n",
      " [-0.55988967]\n",
      " [ 0.25796938]\n",
      " [-0.30523711]\n",
      " [-0.26202089]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 680\n",
      "ws1:  [[-0.41176116]\n",
      " [-0.55988908]\n",
      " [ 0.25796926]\n",
      " [-0.30523723]\n",
      " [-0.26202101]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 690\n",
      "ws1:  [[-0.41176128]\n",
      " [-0.55988848]\n",
      " [ 0.25796914]\n",
      " [-0.30523735]\n",
      " [-0.26202112]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n",
      "   \n",
      "Step: 700\n",
      "ws1:  [[-0.41176146]\n",
      " [-0.55988789]\n",
      " [ 0.25796896]\n",
      " [-0.30523753]\n",
      " [-0.2620213 ]]\n",
      "Cost: 0.0721524\n",
      "Accuracy:  0.78767\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "   \n",
    "    for step in xrange(epochs):\n",
    "        \n",
    "        #train network in batch size = bs\n",
    "        bs_i = 0\n",
    "        while bs_i <= data_size:\n",
    "            batch_end = 0\n",
    "            \n",
    "            if bs_i + 100 < data_size:\n",
    "                batch_end = bs_i + 100\n",
    "            else:\n",
    "                batch_end = data_size\n",
    "            xx_data_batch = x_data[bs_i : batch_end]\n",
    "            yy_data_batch = y_data[bs_i : batch_end]\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={X: xx_data_batch, Y: yy_data_batch})\n",
    "            bs_i += 100\n",
    "        \n",
    "        #sess.run(optimizer, feed_dict={X: xx_data_batch, Y: yy_data_batch})\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print (\"   \")\n",
    "            print (\"Step:\", step)\n",
    "            print (\"ws1: \", ws1.eval())\n",
    "            print (\"Cost:\", sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "            correct_prediction = tf.equal(tf.floor(hy + 0.5), Y)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            #print (\"correct_prediction: \", sess.run(correct_prediction, feed_dict={X: x_data, Y: y_data}))\n",
    "            print (\"Accuracy: \", accuracy.eval({X: x_data, Y: y_data}))\n",
    "            \n",
    "    correct_prediction = tf.equal(tf.floor(hy + 0.5), Y)\n",
    "    \n",
    "    print (\"correct_prediction: \", sess.run(correct_prediction, feed_dict={X: x_data, Y: y_data}))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        \n",
    "    print (sess.run([hy], feed_dict={X: x_data, Y: y_data}))\n",
    "    print (\"Accuracy: \", accuracy.eval({X: x_data, Y: y_data}))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
